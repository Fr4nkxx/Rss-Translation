<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最新结果</title>
    <link>http://link.springer.com</link>
    <description>Springer 提供的最新内容</description>
    <lastBuildDate>Thu, 31 Oct 2024 21:13:49 GMT</lastBuildDate>
    <item>
      <title>全光成像和处理</title>
      <link>http://link.springer.com/10.1007/978-981-97-6915-5</link>
      <description><![CDATA[]]></description>
      <guid>http://link.springer.com/10.1007/978-981-97-6915-5</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>迈向大规模全光重建</title>
      <link>http://link.springer.com/10.1007/978-981-97-6915-5_5</link>
      <description><![CDATA[摘要
重建具有无与伦比的真实感和细节水平的真实世界场景一直是计算机视觉和图形领域的长期目标。实现这一目标需要在传感技术和全光重建算法方面进行协调努力。]]></description>
      <guid>http://link.springer.com/10.1007/978-981-97-6915-5_5</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>计算机视觉 – ECCV 2024</title>
      <link>http://link.springer.com/10.1007/978-3-031-73247-8</link>
      <description><![CDATA[]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-73247-8</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>计算机视觉 – ECCV 2024</title>
      <link>http://link.springer.com/10.1007/978-3-031-72640-8</link>
      <description><![CDATA[]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-72640-8</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>计算机视觉 – ECCV 2024</title>
      <link>http://link.springer.com/10.1007/978-3-031-73404-5</link>
      <description><![CDATA[]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-73404-5</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>计算机视觉 – ECCV 2024</title>
      <link>http://link.springer.com/10.1007/978-3-031-72649-1</link>
      <description><![CDATA[]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-72649-1</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>计算机视觉 – ECCV 2024</title>
      <link>http://link.springer.com/10.1007/978-3-031-73347-5</link>
      <description><![CDATA[]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-73347-5</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>计算机视觉 – ECCV 2024</title>
      <link>http://link.springer.com/10.1007/978-3-031-72670-5</link>
      <description><![CDATA[]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-72670-5</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>计算机视觉 – ECCV 2024</title>
      <link>http://link.springer.com/10.1007/978-3-031-73209-6</link>
      <description><![CDATA[]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-73209-6</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>计算机视觉 – ECCV 2024</title>
      <link>http://link.springer.com/10.1007/978-3-031-73116-7</link>
      <description><![CDATA[]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-73116-7</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>计算机视觉 – ECCV 2024</title>
      <link>http://link.springer.com/10.1007/978-3-031-72658-3</link>
      <description><![CDATA[]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-72658-3</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>计算机视觉 – ECCV 2024</title>
      <link>http://link.springer.com/10.1007/978-3-031-72998-0</link>
      <description><![CDATA[]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-72998-0</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>计算机视觉 – ECCV 2024</title>
      <link>http://link.springer.com/10.1007/978-3-031-72624-8</link>
      <description><![CDATA[]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-72624-8</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>计算机视觉 – ECCV 2024</title>
      <link>http://link.springer.com/10.1007/978-3-031-72761-0</link>
      <description><![CDATA[]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-72761-0</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LaRa：高效的大基线辐射场</title>
      <link>http://link.springer.com/10.1007/978-3-031-73247-8_20</link>
      <description><![CDATA[摘要
辐射场方法已经实现了逼真的新型视图合成和几何重建。但它们主要应用于每个场景的优化或小基线设置。虽然最近的几项工作利用变压器研究了具有大基线的前馈重建，但它们都采用标准的全局注意机制，因此忽略了 3D 重建的局部性质。我们提出了一种在变压器层中统一局部和全局推理的方法，从而提高了质量并加快了收敛速度。我们的模型将场景表示为高斯体积，并将其与图像编码器和组注意层相结合，以实现高效的前馈重建。实验结果表明，我们的模型在四块 GPU 上训练了两天，在重建 360
\(^{\circ }\)
 辐射场时表现出高保真度，并且对零样本和域外测试具有很强的鲁棒性。]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-73247-8_20</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>