<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最新结果</title>
    <link>http://link.springer.com</link>
    <description>Springer 提供的最新内容</description>
    <lastBuildDate>Thu, 23 May 2024 12:21:23 GMT</lastBuildDate>
    <item>
      <title>基于多尺度哈希编码的神经几何表示</title>
      <link>http://link.springer.com/10.1007/s41095-023-0340-x</link>
      <description><![CDATA[摘要
最近，基于神经隐式函数的表示引起了越来越多的关注，并被广泛用于使用可微神经网络来表示表面。然而，使用现有的神经几何表示从点云或多视图图像进行表面重建仍然存在计算速度慢和精度差的问题。为了缓解这些问题，我们提出了一种基于多尺度哈希编码的神经几何表示，它有效且高效地将表面表示为带符号的距离场。我们新颖的神经网络结构仔细地将低频傅里叶位置编码与多尺度哈希编码结合起来。相应地重新设计了几何网络的初始化和渲染模块的几何特征。我们的实验表明，所提出的表示对于重建具有数百万个点的点云来说至少快 10 倍。它还显着提高了多视图重建的速度和准确性。我们的代码和模型可以在 https://github.com/Dengzhi-中国科学技术大学/神经几何重建。




]]></description>
      <guid>http://link.springer.com/10.1007/s41095-023-0340-x</guid>
      <pubDate>Sat, 01 Jun 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>以更细粒度解析对象：一项调查</title>
      <link>http://link.springer.com/10.1007/s11633-022-1404-6</link>
      <description><![CDATA[摘要
细粒度视觉解析，包括细粒度部分分割和细粒度对象识别，由于其在农业等许多实际应用中的重要性而引起了相当大的关注、遥感和空间技术。主要的研究工作遵循不同的范式来处理这些细粒度的子任务，而忽略了这些任务之间的内在关系。此外，鉴于大多数研究仍然碎片化，我们从学习零件关系的新角度对先进工作进行了深入研究。从这个角度来看，我们首先将最近的研究和基准综合与新的分类法相结合。在此基础上，我们重新审视细粒度零件分割和识别任务中的普遍挑战，并通过零件关系学习针对这些重要挑战提出新的解决方案。此外，我们还总结了细粒度视觉解析方面的一些有前景的研究方向，以供未来研究使用。]]></description>
      <guid>http://link.springer.com/10.1007/s11633-022-1404-6</guid>
      <pubDate>Sat, 01 Jun 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>WATCHER：用于 Deepfake 检测的小波引导纹理内容分层关系学习</title>
      <link>http://link.springer.com/10.1007/s11263-024-02116-5</link>
      <description><![CDATA[摘要
人脸伪造技术取得了惊人的进步，产生了视觉上无法追踪的深度伪造视频，因此这些技术的潜在恶意滥用引起了人们的极大关注。现有的深度伪造检测器主要关注特定的伪造模式，并通过 CNN 主干提取全局特征进行伪造检测。由于对内容和​​纹理特征的探索不充分，它们经常遭受过度拟合特定于方法的伪造区域的影响，从而对日益逼真的伪造表现出有限的泛化能力。在本文中，我们提出了一种Wavelet-guided T纹理-C内容HiErarchical 关系关系 (WATCHER) 学习框架，可更深入地研究关系感知纹理内容功能。具体来说，我们提出了一种小波引导的自动编码器方案来检索一般视觉表示，该方案了解高频细节以理解伪造品。为了进一步挖掘细粒度的伪造线索，提出了纹理内容注意力图学习模块，通过分层学习协议中的多级注意力图来丰富内容和纹理特征的上下文信息。最后，我们提出了一种渐进式多域特征交互模块，旨在对关系增强的纹理内容伪造特征进行语义推理。对流行基准数据集的大量实验证实了我们的 WATCHER 模型的优越性，始终以显着的优势胜过最先进的方法。]]></description>
      <guid>http://link.springer.com/10.1007/s11263-024-02116-5</guid>
      <pubDate>Thu, 23 May 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>颜色配置文件如何影响光场渲染和新颖视图合成中的视觉质量</title>
      <link>http://link.springer.com/10.1007/s11042-024-19396-1</link>
      <description><![CDATA[摘要
本文研究了图像颜色配置文件对光场渲染中视觉质量的影响。光场渲染方法需要多个输入视图，从不同的相机位置捕获相同的场景。这些视图可以通过摄像机在现实生活中捕获，也可以从合成 3D 场景中渲染。可以从输入视图合成新颖的视图，从虚拟相机位置捕获场景。现代电影摄影利用各种颜色配置文件，这些配置文件会影响相机传感器上测量到的光线如何转换为数字图像的颜色值。不同的配置文件可用于不同的目的，无论是艺术性的还是实用性的，以揭示必要的细节。本文的主要科学问题是某些颜色配置文件是否可以提高光场渲染中新颖视图合成的质量。论文表明，对数轮廓可以显着提高视觉质量。使用来自不同类别的三种光场渲染方法来比较 17 种广泛使用的颜色配置文件。额外的测量表明，需要在渲染管道的最后应用后处理和颜色分级，以确保最佳质量。同时测量了去噪算法对光场渲染的影响。]]></description>
      <guid>http://link.springer.com/10.1007/s11042-024-19396-1</guid>
      <pubDate>Mon, 20 May 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Instant3D：即时文本到 3D 生成</title>
      <link>http://link.springer.com/10.1007/s11263-024-02097-5</link>
      <description><![CDATA[摘要
文本到 3D 生成引起了计算机视觉社区的广泛关注。现有方法主要针对每个文本提示从头开始优化神经场，依赖于繁重且重复的训练成本，这阻碍了它们的实际部署。在本文中，我们提出了一种用于快速文本到 3D 生成的新框架，称为 Instant3D。经过训练后，Instant3D 能够在不到 1 秒的时间内通过一次前馈网络为看不见的文本提示创建 3D 对象。我们通过设计一个直接从文本提示构建 3D 三平面的新网络来实现这一惊人的速度。我们的 Instant3D 的核心创新在于我们探索了将文本条件有效注入网络的策略。具体来说，我们建议结合三种关键机制：交叉注意、风格注入和 token-to-plane 转换，共同确保输出与输入文本的精确对齐。此外，我们提出了一个简单而有效的激活函数 scaled-sigmoid 来替代原来的 sigmoid 函数，这将使训练收敛速度提高十倍以上。最后，针对 3D 生成中的 Janus（多头）问题，我们提出了一种自适应的 Perp-Neg 算法，该算法可以在训练过程中根据 Janus 问题的严重程度动态调整概念否定尺度，有效降低多头效应。在各种基准数据集上进行的大量实验表明，所提出的算法在定性和定量方面均优于最新方法，同时实现了显著更高的效率。代码、数据和模型可在https://ming1993li.github.io/Instant3DProj/获取。]]></description>
      <guid>http://link.springer.com/10.1007/s11263-024-02097-5</guid>
      <pubDate>Thu, 16 May 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>机器学习辅助探索 Affine Deligne–Lusztig 品种</title>
      <link>http://link.springer.com/10.1007/s42543-024-00086-8</link>
      <description><![CDATA[摘要
本文提出了一项新颖的跨学科研究，利用机器学习 (ML) 辅助框架来探索仿射 Deligne–Lusztig 簇 (ADLV) 的几何形状。主要目标是研究 ADLV 不可约成分的非空模式、维数和枚举。我们提出的框架展示了数据生成、模型训练、模式分析和人体检查的递归管道，呈现了机器学习和纯数学研究之间复杂的相互作用。值得注意的是，我们的数据生成过程非常细致，强调选择有意义的子集和适当的特征集。我们证明，该框架有潜力加速纯数学研究，从而发现新的猜想和有前途的研究方向，否则可能需要大量时间才能发现。我们重新发现了虚拟维度公式，并为新发现的有关某个维度下限的问题提供了完整的数学证明。此外，我们向读者发出公开邀请，提供计算 ADLV 和 ML 模型的源代码，促进进一步的探索。本文最后分享了宝贵的经验并强调了从这次合作中汲取的教训。]]></description>
      <guid>http://link.springer.com/10.1007/s42543-024-00086-8</guid>
      <pubDate>Wed, 15 May 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>了解 GAN：基础知识、变体、训练挑战、应用和开放问题</title>
      <link>http://link.springer.com/10.1007/s11042-024-19361-y</link>
      <description><![CDATA[摘要
生成对抗网络 (GAN) 是一种在对抗设置中训练生成模型的新颖框架，近年来引起了广泛关注。 GAN 框架的两个相反的神经网络，即生成器和鉴别器，在零和游戏中同时训练，其中生成器生成图像来欺骗经过训练以区分真实图像和合成图像的鉴别器。在本文中，我们对 GAN 的最新发展进行了全面回顾。首先，我们介绍了GAN的各种深层生成模型、基本理论和训练机制以及潜在空间。我们进一步讨论 GAN 的几种代表性变体。尽管 GAN 已成功应用于各种应用，但众所周知，它们的训练非常不稳定。一般来说，人们对 GAN 如何收敛缺乏了解。我们从统计学、博弈论和控制论的角度简要讨论了 GAN 中不稳定和收敛问题的根源，并描述了几种稳定训练的技术。评估 GAN 一直是一项具有挑战性的任务，因为对于哪种度量更适合模型比较尚未达成共识。因此，我们对 GAN 的定量和定性评估措施进行了简要讨论。然后，我们进行了多项实验，根据这些评估指标来比较代表性的 GAN 变体。此外，还简要讨论了 GAN 的应用领域。最后，我们概述了 GAN 中的几个重要的开放问题和未来的研究趋势。]]></description>
      <guid>http://link.springer.com/10.1007/s11042-024-19361-y</guid>
      <pubDate>Tue, 14 May 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>探索使用预训练特征进行立体匹配</title>
      <link>http://link.springer.com/10.1007/s11263-024-02090-y</link>
      <description><![CDATA[摘要
对于许多视觉任务，利用预训练的功能可以提高性能，并持续受益于预训练技术的快速发展。然而，在立体匹配领域，预训练特征的使用尚未得到广泛研究。在本文中，我们首次系统地探索了利用预训练特征进行立体匹配。为了为预训练主干和立体匹配网络的任意组合提供灵活的使用，我们开发了可变形颈部（DN），它将这两个组件的网络架构解耦。 DN的核心思想是利用可变形注意力机制从浅层到深层迭代融合预训练的特征。根据经验，我们的探索揭示了影响使用预训练特征进行立体匹配的关键因素。我们进一步研究了预训练特征的实例级信息的作用，证明它有利于立体匹配，同时可以在基于卷积的特征融合过程中被抑制。基于注意力机制，所提出的 DN 模块有效地利用了预训练特征中的实例级信息。此外，我们提供了对效率与准确性权衡的理解，得出的结论是，考虑到效率，使用预训练的特征也是一个不错的选择。]]></description>
      <guid>http://link.springer.com/10.1007/s11263-024-02090-y</guid>
      <pubDate>Sat, 11 May 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>BTD-RF：使用块项张量分解进行 3D 场景重建</title>
      <link>http://link.springer.com/10.1007/s10489-024-05476-0</link>
      <description><![CDATA[摘要
神经辐射场 (NeRF) 在视图合成任务中表现出出色的性能，但在三维 (3D) 场景重建过程中需要大量内存和模型参数。本文提出了一种块项张量分解辐射场（BTD-RF），这是一种新颖的方法，可以在保持重建质量的同时实现显着的模型压缩。 BTD-RF将高维辐射场分解为低维张量块，得到的值比基线方法小2.21倍。将模型分解为低维张量块，可以用轻量级多线性注意力机制替代 Transformer 的标准多头注意力，采用元素级乘积并共享参数。这在不影响性能的情况下显着降低了模型的复杂性。对各种数据集的广泛评估表明，与现有方法相比，BTD-RF 实现了卓越的图像重建质量。定量指标和定性评估证实，BTD-RF 生成的图像在结构和感知上都接近真实情况，尽管采用轻量级设计，但仍展现出卓越的性能。 BTD-RF 在三维 (3D) 场景重建的模型大小和重建质量之间提供了令人信服的权衡。其高效的设计使其适合资源受限的应用，同时提供高保真结果，为更广泛的 NeRF 利用铺平了道路。该代码位于 https://github.com/seonbin-kim/BTDRF]]></description>
      <guid>http://link.springer.com/10.1007/s10489-024-05476-0</guid>
      <pubDate>Thu, 09 May 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>神经数字孪生：在虚拟现实中重建复杂的医疗环境以进行空间规划</title>
      <link>http://link.springer.com/10.1007/s11548-024-03143-w</link>
      <description><![CDATA[摘要

目的
专用机器人和手术工具正在增加手术室 (OR) 的复杂性，需要精心准备，尤其是在首次使用技术或设备时。空间规划可以提高效率并提前识别程序障碍，但真正的手术室几乎无法提供优化空间利用率的可用性。需要创建物理设置重建的方法，即数字孪生，以实现虚拟现实中此类复杂环境的沉浸式空间规划。


方法
我们提出了一种基于神经渲染的方法，可以通过随意的视频捕捉创建复杂医疗环境和设备的沉浸式数字孪生，从而实现手术场景的空间规划。为了评估我们的方法，我们通过神经重建重新创建了两个手术室和十个物体，然后与 21 名研究生一起进行用户研究，在生成的虚拟环境中执行规划任务。与相同环境的低视觉复杂性版本相比，我们分析了任务负载、存在、感知效用以及探索和交互行为。


结果
结果显示，使用基于神经重建的环境，感知效用和存在感显着提高，同时感知工作量和探索行为也更高。交互性没有显着差异。


结论
我们探索使用现代重建技术创建复杂医疗环境和物体的数字孪生的可行性。无需专业知识或专用硬件，用户就可以在虚拟环境中创建、探索对象并与之交互。结果表明，在技术上可行的同时，具有高感知效用等优点，这可能表明这种方法在空间规划及其他方面的前景。
]]></description>
      <guid>http://link.springer.com/10.1007/s11548-024-03143-w</guid>
      <pubDate>Mon, 06 May 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于神经辐射场的多视角内窥镜场景重建用于手术模拟</title>
      <link>http://link.springer.com/10.1007/s11548-024-03080-8</link>
      <description><![CDATA[摘要

目的
在虚拟手术中，根据CT图像构建的3D模型的外观缺乏真实感，导致住院医生可能产生误解。因此，利用内窥镜捕获的多视图图像重建真实的内窥镜场景至关重要。


方法
我们提出了一种内窥镜-NeRF 网络，用于在非固定光源下对内窥镜场景进行隐式辐射场重建，并使用体积渲染合成新颖的视图。具有多个 MLP 网络和射线变换器网络的内窥镜-NeRF 网络将内窥镜场景表示为隐式场函数，在连续 5D 向量（3D 位置和 2D 方向）上具有颜色和体积密度。最终的合成图像是通过使用体积渲染聚合目标相机每条射线上的所有采样点而获得的。我们的方法考虑了光源到采样点的距离对场景辐射亮度的影响。


结果
我们的网络在我们的设备收集的猪的肺、肝、肾和心脏上进行了验证。结果表明，我们的方法合成的内窥镜场景的新视图在 PSNR、SSIM 和 LPIPS 指标方面优于现有方法（NeRF 和 IBRNet）。


结论
我们的网络可以有效地学习具有泛化能力的辐射场函数。在新的内窥镜场景上对预训练模型进行微调，进一步优化场景的神经辐射场，可以为手术模拟提供更真实、高分辨率的渲染图像。
]]></description>
      <guid>http://link.springer.com/10.1007/s11548-024-03080-8</guid>
      <pubDate>Wed, 01 May 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>高效的 EndoNeRF 重建及其在数据驱动手术模拟中的应用</title>
      <link>http://link.springer.com/10.1007/s11548-024-03114-1</link>
      <description><![CDATA[摘要


目的

医疗保健行业对手术场景的真实建模和高效模拟的需求日益增长。借助有效的可变形手术场景模型，临床医生能够在接近真实病例的场景下进行手术规划和手术训练。然而，实现这一目标的一个重大挑战是缺乏具有精确形状和纹理的高质量软组织模型。为了解决这一差距，我们提出了一个数据驱动的框架，该框架利用新兴的神经辐射场技术来实现高质量的手术重建，并探索其在手术模拟中的应用。



方法

我们首先专注于开发一种基于 NeRF 的快速手术场景 3D 重建方法，以实现最先进的性能。该方法可以显着优于传统的 3D 重建方法，传统的 3D 重建方法无法捕捉大变形并产生细粒度的形状和纹理。然后，我们提出通过闭合网格提取算法自动创建交互式手术模拟环境的管道。
      



结果

我们的实验验证了我们提出的手术场景 3D 重建方法的卓越性能和效率。我们进一步利用重建的软组织进行 FEM 和 MPM 模拟，展示我们的方法在数据驱动的手术模拟中的实际应用。
      



结论

我们提出了一种新颖的基于 NeRF 的重建框架，重点是模拟目的。我们的重建框架有助于高效创建高质量的手术软组织 3D 模型。通过多次软组织模拟的证明，我们表明我们的工作有可能有益于下游临床任务，例如外科教育。
]]></description>
      <guid>http://link.springer.com/10.1007/s11548-024-03114-1</guid>
      <pubDate>Wed, 01 May 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过 SfM–MVS 从图像序列顺序生成局部 3D 模型之间基于估计相机轨迹的集成</title>
      <link>http://link.springer.com/10.1007/s10015-024-00949-4</link>
      <description><![CDATA[摘要
本文描述了一种三维 (3D) 建模方法，用于从相机获取的图像序列中顺序和空间地了解未知环境中的情况。该方法按时间顺序将图像序列按图像数量划分为子图像序列，通过运动和多视图立体结构（SfM-MVS）从子图像序列生成局部3D模型，并集成模型。每个子图像序列中的图像与先前和后续子图像序列部分重叠。使用根据 SfM-MVS 估计的相机轨迹计算出的变换参数，将局部 3D 模型集成到 3D 模型中。在我们的实验中，我们使用从相机获取的三个真实数据集，定量比较了集成模型与从批次中所有图像生成的 3D 模型的质量以及获得这些模型的计算时间。因此，该方法可以生成高质量的集成模型，并通过 SfM-MVS 与使用批次中所有图像的 3D 模型进行比较，并减少计算时间。]]></description>
      <guid>http://link.springer.com/10.1007/s10015-024-00949-4</guid>
      <pubDate>Wed, 01 May 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于饱和模糊图像的深度非盲去模糊网络</title>
      <link>http://link.springer.com/10.1007/s00521-024-09495-3</link>
      <description><![CDATA[摘要
非盲图像去模糊在低水平视觉领域引起了广泛关注。然而，现有的非盲去模糊方法无法有效处理饱和模糊图像。关键在于饱和模糊图像的退化模型不满足传统模糊图像的线性卷积模型。为了解决这个问题，本文提出了一种新颖的深度非盲去模糊方法，称为饱和图像非盲去模糊网络（SDBNet）。 SDBNet包含两个可训练的子网络，即置信估计网络（CEN）和细节增强网络（DEN）。具体来说，SDBNet使用CEN来估计饱和模糊图像的置信图，用于识别模糊图像中的饱和像素，然后使用置信图和模糊核来恢复模糊图像。最后，我们使用 DEN 来增强恢复图像的边缘和纹理。我们首先预训练 CEN 和 DEN。为了有效地预训练 CEN，我们提出了一个新的鲁棒函数，用于为 CEN 生成标签数据。实验结果表明，与现有的几种非盲去模糊方法相比，SDBNet能够有效恢复饱和模糊图像，更好地恢复模糊图像的纹理、边缘等结构信息。]]></description>
      <guid>http://link.springer.com/10.1007/s00521-024-09495-3</guid>
      <pubDate>Wed, 01 May 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>儿童眼眶病变：骨性和创伤性病变</title>
      <link>http://link.springer.com/10.1007/s00247-024-05882-z</link>
      <description><![CDATA[摘要
眼眶病变可大致分为眼部病变、眼外软组织病变（非肿瘤性和肿瘤性）以及骨性和创伤性病变。在本文中，我们讨论了儿科眼眶和眼球的骨性和创伤性病变的关键影像学特征和鉴别诊断，强调了 CT 和 MRI 作为主要影像学手段的作用。此外，重点介绍眼部超声检查在眼内异物诊断中的辅助作用，并讨论超声检查在外伤性视网膜脱离诊断中的主要作用。

图形摘要






]]></description>
      <guid>http://link.springer.com/10.1007/s00247-024-05882-z</guid>
      <pubDate>Wed, 01 May 2024 00:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>