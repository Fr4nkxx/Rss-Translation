<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最新结果</title>
    <link>http://link.springer.com</link>
    <description>Springer 提供的最新内容</description>
    <lastBuildDate>Fri, 08 Nov 2024 12:26:36 GMT</lastBuildDate>
    <item>
      <title>Deblur e-NeRF：高速或低光条件下运动模糊事件中的 NeRF</title>
      <link>http://link.springer.com/10.1007/978-3-031-73232-4_11</link>
      <description><![CDATA[摘要
事件相机的独特设计理念使其成为高速、高动态范围和低光环境的理想选择，而标准相机在这些环境中表现不佳。然而，与大多数人的想法相反，事件相机也存在运动模糊，尤其是在这些具有挑战性的条件下。这是由于事件传感器像素的带宽有限，而带宽主要与光强度成正比。因此，为了确保事件相机能够真正在这种条件下表现出色，使其比标准相机更具优势，必须在下游任务（尤其是重建）中考虑事件运动模糊。然而，之前没有关于从事件重建神经辐射场 (NeRF) 的研究，也没有事件模拟器考虑过事件运动模糊的全部影响。为此，我们提出了 Deblur e-NeRF，这是一种新方法，可以直接有效地从高速或低光条件下产生的运动模糊事件中重建模糊最小的 NeRF。这项工作的核心部分是一个物理上精确的像素带宽模型，该模型考虑了事件运动模糊。我们还引入了阈值归一化总变分损失，以更好地规范大型无纹理斑块。在真实和新颖的现实模拟序列上进行的实验验证了我们的有效性。我们的代码、事件模拟器和合成事件数据集都是开源的。]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-73232-4_11</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AG-NeRF：用于多高度大规模户外场景渲染的注意力引导神经辐射场</title>
      <link>http://link.springer.com/10.1007/978-981-97-8508-7_8</link>
      <description><![CDATA[摘要
现有的基于神经辐射场 (NeRF) 的大规模室外场景新视图合成方法主要建立在单一高度上。此外，它们通常需要先验相机拍摄高度和场景范围，导致相机高度发生变化时应用效率低下且不切实际。在这项工作中，我们提出了一个端到端框架，称为 AG-NeRF，并寻求通过基于不同场景高度合成自由视点图像来降低构建良好重建的训练成本。具体而言，为了解决从低空（无人机级）到高空（卫星级）的细节变化问题，开发了一种源图像选择方法和一种基于注意的特征融合方法，以从多高度图像中提取和融合目标视图的最相关特征，以实现高保真渲染。大量实验表明，AG-NeRF 在 56 Leonard 和 Transamerica 基准测试中取得了 SOTA 性能，并且与最新的 BungeeNeRF 相比，仅需要半小时的训练时间即可达到具有竞争力的 PSNR。]]></description>
      <guid>http://link.springer.com/10.1007/978-981-97-8508-7_8</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>改进 NeRF 表征，无需姿势先验，实现结肠镜检查中的新型视图合成</title>
      <link>http://link.springer.com/10.1007/978-3-031-73748-0_15</link>
      <description><![CDATA[摘要
结肠镜检查是治疗胃肠道恶性肿瘤的黄金标准程序。然而，一些限制会影响筛查过程的质量。对被调查区域进行可靠的 3D 重建可以减轻这些限制并改善诊断和治疗结果。大多数 3D 重建框架依赖于两个基本任务：a) 可靠的相机深度预测，以及 b) 准确的相机姿势估计。虽然这些框架在自然场景中表现出色，但由于缺乏带注释的地面真实数据，它们对结肠镜检查数据的影响受到极大限制。我们提出了一种新颖的射线采样技术来指导神经辐射场 (NeRF) 系统的优化，而无需姿势先验来联合估计相机姿势预测和新颖的视图合成 (NVS)。我们的方法建立在 NoPe-NeRF [4] 的基础上，该方法在 NVS 和相机姿态估计方面表现出色，但目前仅限于具有大量纹理的自然场景。为了解决这一限制，我们引入了新的深度加权块聚焦随机光线采样 (DW-PFRRS) 技术，并在 C3VD 数据集上评估了我们的方法。]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-73748-0_15</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过地球移动距离进行深度引导的 NeRF 训练</title>
      <link>http://link.springer.com/10.1007/978-3-031-73039-9_1</link>
      <description><![CDATA[摘要

神经辐射场 (NeRF) 经过训练，可最大限度地减少预测视点的渲染损失。然而，光度损失通常不能提供足够的信息来消除产生相同图像的不同可能几何形状之间的歧义。因此，先前的研究在 NeRF 训练期间加入了深度监督，利用来自预训练深度网络的密集预测作为伪地面实况。虽然这些深度先验在过滤噪声后被认为是完美的，但在实践中，它们的准确性更难捕捉。这项工作提出了一种用于 NeRF 监督的深度先验不确定性的新方法。我们使用现成的预训练扩散模型来预测深度​​并在去噪过程中捕获不确定性，而不是使用定制训练的深度或不确定性先验。因为我们知道深度先验容易出错，所以我们建议用 Earth Mover’s Distance 来监督射线终止距离分布，而不是强制渲染深度通过 
\(L_2\)
-loss 精确复制深度先验。我们的深度引导 NeRF 在标准深度指标上的表现远胜于所有基线，同时保持了光度测量的性能。

]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-73039-9_1</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>NeRFect Match：探索 NeRF 的视觉定位功能</title>
      <link>http://link.springer.com/10.1007/978-3-031-72691-0_7</link>
      <description><![CDATA[摘要
在这项工作中，我们建议使用神经辐射场 (NeRF) 作为视觉定位的场景表示。最近，NeRF 已被用于通过扩充训练数据库、通过渲染图像提供辅助监督或作为迭代细化模块来增强姿势回归和场景坐标回归模型。我们扩展了其公认的优势——它能够提供具有逼真外观和准确几何形状的紧凑场景表示——通过探索 NeRF 的内部特征在建立精确的 2D-3D 匹配以进行定位方面的潜力。为此，我们对通过视图合成获得的 NeRF 的隐性知识进行了全面检查，以便在各种条件下进行匹配。这包括探索不同的匹配网络架构、在多个层提取编码器特征以及不同的训练配置。值得注意的是，我们引入了 NeRFMatch，这是一种先进的 2D-3D 匹配函数，它利用通过视图合成学习到的 NeRF 的内部知识。我们在基于结构的管道中对 NeRFMatch 的标准定位基准进行了评估，在剑桥地标的定位性能方面取得了有竞争力的结果。我们将发布所有模型和代码。]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-72691-0_7</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RS-NeRF：来自滚动快门图像的神经辐射场</title>
      <link>http://link.springer.com/10.1007/978-3-031-72952-2_10</link>
      <description><![CDATA[摘要
神经辐射场 (NeRF) 因其令人印象深刻的新颖视图合成能力而变得越来越流行。然而，它们的有效性受到大多数相机系统中常见的滚动快门 (RS) 效应的阻碍。为了解决这个问题，我们提出了 RS-NeRF，这是一种使用具有 RS 失真的输入从新颖视图合成正常图像的方法。这涉及一个物理模型，该模型复制 RS 条件下的图像形成过程并联合优化 NeRF 参数和每个图像行的相机外部参数。我们通过深入研究 RS 特性并开发算法来增强其功能，进一步解决了基本 RS-NeRF 模型的固有缺陷。首先，我们施加平滑度正则化以更好地估计轨迹并提高合成质量，与相机运动先验保持一致。我们还通过引入多采样算法来识别和解决 vanilla RS 模型中的一个根本缺陷。这种新方法通过全面利用每个中间相机姿势的不同行中的 RGB 数据来提高模型的性能。通过严格的实验，我们证明 RS-NeRF 在合成和真实场景中都超越了以前的方法，证明了它能够有效纠正与 RS 相关的失真。可用的代码和数据：https://github.com/MyNiuuu/RS-NeRF。]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-72952-2_10</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RING-NeRF：重新思考多功能高效神经场的归纳偏差</title>
      <link>http://link.springer.com/10.1007/978-3-031-72761-0_9</link>
      <description><![CDATA[摘要
神经领域的最新进展主要依赖于开发特定于任务的监督，这通常会使模型复杂化。与开发难以组合和特定的模块不同，另一种通常被忽视的方法是将场景表示的通用先验（也称为归纳偏差）直接注入 NeRF 架构。基于这个想法，我们提出了 RING-NeRF 架构，其中包括两个归纳偏差：场景的连续多尺度表示和解码器潜在空间在空间和尺度域上的不变性。我们还设计了一个利用这些归纳偏差的单一重建过程，并通过实验证明了在多个任务（抗锯齿、少量视图重建、没有场景特定初始化的 SDF 重建）上与专用架构在质量方面的性能相当，同时效率更高。此外，RING-NeRF 具有动态提高模型分辨率的独特能力，为自适应重建开辟了道路。项目页面位于：https://cea-list.github.io/RING-NeRF]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-72761-0_9</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>NeRF-MAE：用于神经辐射场自监督 3D 表示学习的蒙版自动编码器</title>
      <link>http://link.springer.com/10.1007/978-3-031-73223-2_24</link>
      <description><![CDATA[摘要
神经场在计算机视觉和机器人领域表现出色，因为它们能够理解 3D 视觉世界，例如推断语义、几何和动态。鉴于神经场能够从 2D 图像密集地表示 3D 场景，我们提出了一个问题：我们是否可以扩展它们的自监督预训练，特别是使用蒙版自动编码器，以从摆放的 RGB 图像生成有效的 3D 表示。由于将 Transformer 扩展到新数据模式取得了惊人的成功，我们使用标准的 3D 视觉 Transformer 来适应 NeRF 的独特配方。我们利用 NeRF 的体积网格作为 Transformer 的密集输入，将其与其他 3D 表示（如点云）进行对比，其中信息密度可能不均匀，并且表示不规则。由于将掩蔽自动编码器应用于隐式表示（例如 NeRF）的难度，我们选择通过使用摄像机轨迹进行采样来提取显式表示，该表示可跨域规范化场景。我们的目标是通过从 NeRF 的辐射度和密度网格中屏蔽随机斑块并使用标准 3D Swin Transformer 重建掩蔽斑块来实现的。通过这样做，模型可以学习完整场景的语义和空间结构。我们在我们提出的精选 posed-RGB 数据上大规模预训练此表示，总计超过 180 万张图像。预训练后，编码器可用于有效的 3D 迁移学习。我们针对 NeRF 的新型自监督预训练 NeRF-MAE 具有非常好的扩展性，并提高了各种具有挑战性的 3D 任务的性能。 NeRF-MAE 利用未标记的 2D 数据进行预训练，在 Front3D 和 ScanNet 数据集上的表现明显优于自监督 3D 预训练和 NeRF 场景理解基线，3D 物体检测的绝对性能提升超过 20% AP50 和 8% AP25。项目页面：nerf-mae.github.io]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-73223-2_24</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>URS-NeRF：神经辐射场的无序滚动快门束调整</title>
      <link>http://link.springer.com/10.1007/978-3-031-72761-0_26</link>
      <description><![CDATA[摘要
本文提出了一种新的神经辐射场（NeRF）滚动快门束调整方法，该方法利用无序滚动快门（RS）图像来获得隐式三维表示。现有的 NeRF 方法由于图像中的 RS 效应而存在图像质量低和初始相机姿势不准确的问题。此外，以前将 RS 图像合并到 NeRF 中的方法需要严格的顺序数据输入，从而限制了其广泛的适用性。相比之下，我们的方法通过估计相机姿势和速度来恢复 RS 图像的物理形态，从而消除了对顺序数据的输入限制。此外，我们采用由粗到细的训练策略，其中场景图中成对帧的 RS 极线约束用于检测落入局部最小值的相机姿势。检测到的异常姿势通过邻近姿势的插值方法进行校正。实验结果验证了我们的方法相对于最先进方法的有效性，并表明 3D 表示的重建不受视频序列输入要求的限制。]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-72761-0_26</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>TriNeRFLet：基于小波的三平面 NeRF 表示</title>
      <link>http://link.springer.com/10.1007/978-3-031-72986-7_21</link>
      <description><![CDATA[摘要
近年来，神经辐射场 (NeRF) 模型因其恢复复杂 3D 场景的能力而广受欢迎。在其成功之后，许多方法提出了不同的 NeRF 表示，以进一步改善运行时间和性能。Triplane 就是这样一个例子，其中 NeRF 使用三个 2D 特征平面表示。这使得在此框架中轻松使用现有的 2D 神经网络来生成三个平面成为可能。尽管三平面表示具有优势，但与 NeRF 解决方案相比，其 3D 恢复质量落后。在这项工作中，我们提出了 TriNeRFLet 框架，我们在其中学习三平面的小波表示并对其进行正则化。这种方法具有多个优点：(i) 它允许跨尺度共享信息和高频正则化；(ii) 它有助于以多尺度方式进行学习； （iii）它为执行 NeRF 超分辨率 (SR) 提供了一个“自然”框架，这样就可以从提供的低分辨率多视图图像中计算出低分辨率小波系数，并在预先训练的 2D 扩散模型的指导下获取高频。我们在 Blender 和 LLFF 数据集上展示了 SR 方法的优势。]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-72986-7_21</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Deceptive-NeRF/3DGS：扩散生成的伪观测，用于高质量稀疏视图重建</title>
      <link>http://link.springer.com/10.1007/978-3-031-72640-8_19</link>
      <description><![CDATA[摘要
通过神经辐射场 (NeRF) 或 3D 高斯溅射 (3DGS) 进行新颖的视图合成通常需要对数百张输入图像进行密集观察以规避伪影。我们引入了Deceptive-NeRF/3DGS（在和声进行中，Deceptive Cadence 可能会扰乱和弦进行的预期，但会丰富音乐的情感表达。我们的 Deceptive-X，其中“X”可以是 NeRF、3DGS 或相关的 3D 重建框架，通过密集合成一致的伪观察来抵消对稀疏输入视图的过度拟合，将原始稀疏输入丰富五到十倍。），通过利用从多视图数据集预先训练的扩散模型，仅使用一组有限的输入图像来增强稀疏视图重建。与使用扩散先验来正则化表示优化不同，我们的方法直接使用扩散生成的图像来训练 NeRF/3DGS，就好像它们是真实的输入视图一样。具体来说，我们提出了一个欺骗性扩散模型，将由少视图重建渲染的噪声图像转换为高质量的照片级真实感伪观测。为了解决伪观测和真实输入视图之间的一致性问题，我们开发了一种不确定性度量来指导扩散模型的生成。我们的系统逐步将扩散生成的伪观测纳入训练图像集，最终将稀疏的输入观测密集化 5 到 10 倍。在各种具有挑战性的数据集上进行的大量实验验证了我们的方法优于现有的最先进方法，并且能够在少视图设置中合成具有超分辨率的新视图。项目页面：https://xinhangliu.com/deceptive-nerf-3dgs。]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-72640-8_19</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Structured-NeRF：具有神经表征的分层场景图</title>
      <link>http://link.springer.com/10.1007/978-3-031-72761-0_11</link>
      <description><![CDATA[摘要
我们提出了一种结构化神经辐射场 (Structured-NeRF)，用于室内场景表示，该模型基于一种新颖的分层场景图结构来组织神经辐射场。现有的以对象为中心的方法仅关注对象的固有特性，而忽略了它们之间的语义和物理关系。我们的场景图擅长管理场景中对象之间复杂的现实世界相关性，从而实现超越新颖视图合成的功能，例如场景重新排列。基于分层结构，我们引入了基于语义和物理关系的优化策略，从而简化了场景编辑所涉及的操作，并确保了效率和准确性。此外，我们对对象进行阴影渲染，以进一步增强渲染图像的真实感。实验结果表明，我们的结构化表示不仅在对象级和场景级渲染中实现了最佳（SOTA）性能，而且还与LLM/VLM结合推进了下游应用，例如自动和指令/图像条件场景重新排列，从而方便且可控地将NeRF扩展到交互式编辑。]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-72761-0_11</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>改进的基于端到端多级 NeRF 的密集 RGB-D SLAM</title>
      <link>http://link.springer.com/10.1007/978-981-97-8792-0_10</link>
      <description><![CDATA[摘要
得益于神经辐射场（NeRF）技术在三维重建中的出色表现，将其集成到同步定位和地图绘制（SLAM）任务中进行地图表示已成为近年来广受认可的新颖方法。本文在当前最先进的NICE-SLAM基础上，提出了一种改进的基于端到端多级NeRF的密集RGB-D SLAM。首先，我们增强了多级MLP的结构设计，提高了其表示高级细节的能力并增强了网络的可扩展性。其次，我们改进了关键帧选择策略以缓解网络遗忘问题。最后，在消除深度不确定性和改进多级权重设置方面进行了改进，以进一步提高系统性能。在多个数据集上的大量实验验证了我们的方法与NICE-SLAM相比的准确性改进。]]></description>
      <guid>http://link.springer.com/10.1007/978-981-97-8792-0_10</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>高效的 NeRF 优化——并非所有样本都同样坚硬</title>
      <link>http://link.springer.com/10.1007/978-3-031-72764-1_12</link>
      <description><![CDATA[摘要
我们提出了一种在线硬样本挖掘应用，用于有效训练神经辐射场 (NeRF)。NeRF 模型可为许多 3D 重建和渲染任务提供最先进的质量，但需要大量计算资源。NeRF 网络参数中的场景信息编码需要随机采样。我们观察到，在训练过程中，大部分计算时间和内存使用量都花在处理已经学习过的样本上，这不再对模型更新产生重大影响。我们将随机样本的后向传递确定为优化过程中的计算瓶颈。因此，我们在推理模式下执行第一次前向传递，作为相对低成本的硬样本搜索。然后构建计算图并仅使用硬样本更新 NeRF 网络参数。为了证明所提方法的有效性，我们将该方法应用于 Instant-NGP，结果与基线相比，视图合成质量显著提高（平均每次训练提高 1 dB，或加速 2 倍以达到相同的 PSNR 水平），同时 
\(\sim \)
仅使用硬样本构建计算图即可节省 40% 的内存。由于我们的方法仅与网络模块交互，我们预计它将具有广泛的适用性。]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-72764-1_12</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>S $$^{3}$$ D-NeRF：用于高保真说话头部合成的单次语音驱动神经辐射场</title>
      <link>http://link.springer.com/10.1007/978-3-031-72684-2_21</link>
      <description><![CDATA[摘要
说话头像合成是一种应用广泛的实用技术。目前基于神经辐射场 (NeRF) 的方法已显示出在使用视频或从音频回归的信号驱动单次说话头像方面的优势。然而，它们中的大多数未能直接将音频作为驱动信息，无法享受语音的灵活性和可用性。由于将音频信号映射到面部变形并非易事，我们在本文中设计了一种单次语音驱动神经辐射场 (S
\(^{3}\)
D-NeRF) 方法来解决以下三个难题：为每个身份学习一个有代表性的外观特征、用音频对不同面部区域进行运动建模以及保持唇部区域的时间一致性。为此，我们引入了分层面部外观编码器来学习多尺度表示以捕捉不同说话者的外观，并阐述了跨模态面部变形场以根据音频信号与不同面部区域之间的关系执行语音动画。此外，为了增强重要唇部区域的时间一致性，我们引入了唇形同步鉴别器来惩罚不同步的视听序列。大量实验表明，我们的 S
\(^{3}\)
D-NeRF 在视频保真度和音频唇形同步方面均超越了以前的技术。]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-72684-2_21</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>