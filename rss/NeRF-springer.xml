<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最新结果</title>
    <link>http://link.springer.com</link>
    <description>Springer 提供的最新内容</description>
    <lastBuildDate>Sat, 23 Dec 2023 21:09:10 GMT</lastBuildDate>
    <item>
      <title>神经网络作为摄影测量的替代方案。使用即时 NeRF 和体积渲染</title>
      <link>http://link.springer.com/10.1007/978-3-031-36155-5_30</link>
      <description><![CDATA[摘要
人工智能 (AI) 和机器学习算法的使用最近给许多领域带来了革命性的变化，包括通过数字孪生增强遗产及其在 VR 维度中的使用。本文讨论了各种人工智能技术（生成对抗网络（GAN））在开发交互式和沉浸式 VR 严肃游戏以增强遗产方面的潜在用途。 GAN 可用于生成空间、物体和人脸的真实且完全人工的图像，可应用于构建交互式环境的设计和概念过程。此外，机器学习算法可以提高游戏对用户的适应性，例如根据用户的动作自动构建游戏的难度级别或情节。然而，近年来，新的、更高性能的人工智能过程已经出现，其生成能力已经超越了 GAN 算法，后者主要用于生成不存在元素的 2D 图像。 NeRF（神经辐射场）是 NVIDIA 开发的一项技术，由最近由名为 Instant NeRF 的专有代码优化的复杂神经网络提供支持。与不直接支持人工智能的替代照片建模技术相比，该技术能够使用更少的摄影数据快速准确地生成物理环境的详细 3D 模型。未来，该技术可用于生成与现实无区别的虚拟环境，也可积极用于遗产保护。]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-36155-5_30</guid>
      <pubDate>Mon, 01 Jan 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>T(G)V-NeRF：规则化神经辐射场的强大基线，训练视图很少</title>
      <link>http://link.springer.com/10.1007/978-3-031-47765-2_12</link>
      <description><![CDATA[摘要
诸如神经辐射场 (NeRF) 之类的隐式表示已成为新颖视图领域的事实上标准3D 场景合成。然而，他们令人惊叹的结果通常意味着使用数十张训练图像，并将相应的摄像机很好地定位在场景中。本文研究了新的、基于全变分的正则化方法，用于在很少（少于 10 个）训练图像的情况下训练 NeRF。它利用 NeRF 反向传播算法来评估推断深度图上的一阶和二阶导数项，以增强场景底层表面的平滑度。通过标准真实图像基准上最先进的性能，我们表明所提出的方法（称为 TV-NeRF 和 TGV-NeRF）在很少的训练视图的新颖视图合成中建立了强大的基线。]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-47765-2_12</guid>
      <pubDate>Mon, 01 Jan 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>模式识别和计算机视觉</title>
      <link>http://link.springer.com/10.1007/978-981-99-8432-9</link>
      <description><![CDATA[]]></description>
      <guid>http://link.springer.com/10.1007/978-981-99-8432-9</guid>
      <pubDate>Mon, 01 Jan 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>计算智能的进展</title>
      <link>http://link.springer.com/10.1007/978-3-031-47765-2</link>
      <description><![CDATA[]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-47765-2</guid>
      <pubDate>Mon, 01 Jan 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ACFNeRF：通过基于点云的距离场加速且无缓存的神经渲染</title>
      <link>http://link.springer.com/10.1007/978-981-99-8432-9_27</link>
      <description><![CDATA[摘要
神经辐射场为逼真的场景渲染和新颖的视图合成提供了非凡的途径。然而，诸如训练时间缓慢、推理持续时间过长以及处理大规模场景的限制等挑战仍然存在。为了解决 NeRF 推理速度慢的瓶颈，我们提出 ACFNeRF 利用点云训练距离场，改进 NeRF 的采样策略，大幅提升其推理速度。我们的方法实现了每秒 150 帧的令人印象深刻的推理速率，从而实现了房间规模场景中的实时渲染。全面的实验验证了我们方法的优越性，在无缓存条件下，其速度比现有 NeRF 加速技术显着提高 10-20 倍。
      ]]></description>
      <guid>http://link.springer.com/10.1007/978-981-99-8432-9_27</guid>
      <pubDate>Mon, 01 Jan 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>超越数字表示</title>
      <link>http://link.springer.com/10.1007/978-3-031-36155-5</link>
      <description><![CDATA[]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-36155-5</guid>
      <pubDate>Mon, 01 Jan 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Sem-Avatar：用于高保真音频驱动头像的语义控制神经场</title>
      <link>http://link.springer.com/10.1007/978-981-99-8432-9_6</link>
      <description><![CDATA[摘要
在本文中，我们通过将语义控制的神经场拟合到头部说话的视频中来解决音频驱动的头像挑战。虽然现有的方法与现实主义和头部躯干不一致作斗争，但我们新颖的端到端框架，语义控制神经场（Sem-Avatar）成功克服了上述问题，提供了高保真化身。具体来说，我们设计了一种单阶段音频驱动的前向变形方法，以确保头部躯干对齐。我们进一步建议使用语义掩模作为睁眼的控制信号，将头像的自然度提升到另一个水平。我们通过将渲染的头像与原始视频进行比较来训练我们的框架。我们在稳定训练之前进一步附加了利用人脸的语义损失。对公共数据集的大量实验证明了 Sem-Avatar 卓越的渲染质量和唇形同步，为音频驱动的化身建立了新的最先进技术。]]></description>
      <guid>http://link.springer.com/10.1007/978-981-99-8432-9_6</guid>
      <pubDate>Mon, 01 Jan 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有分层几何约束的可推广神经辐射场</title>
      <link>http://link.springer.com/10.1007/978-981-99-8432-9_26</link>
      <description><![CDATA[摘要
广义神经辐射场模型的出现极大地扩展了新颖的视图合成任务的适用性。然而，现有的方法主要依赖从相邻视图获得的 2D 特征来辅助渲染，这通常会导致看不见的视点的退化。一些方法在模型中引入成本量来提供几何先验，但这种粗略的几何信息无法有效地约束模型，导致渲染图像具有丰富的伪影。在这项工作中，我们建议为模型提供分层几何约束，以实现更好的渲染结果。我们引入级联 MVSNet 来提供分层场景结构特征，用于推断底层场景几何形状。它限制了模型在看不见的视点下的渲染。此外，分层特征提供了有助于细节重建的精细表示。此外，我们利用级联 MVSNet 生成的分层深度图来约束采样过程，确保采样点集中在场景表面附近。这种采样策略过滤掉了大量无用的采样点，提高了采样效率和渲染质量。与之前的广义方法不同，我们采用 Neus 提出的新权重函数来消除密度场中的固有偏差，从而将颜色和密度的预测与带符号的距离场分开。大量实验表明，我们提出的方法显着提高了渲染质量，并且优于以前的方法。]]></description>
      <guid>http://link.springer.com/10.1007/978-981-99-8432-9_26</guid>
      <pubDate>Mon, 01 Jan 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>软计算的进展</title>
      <link>http://link.springer.com/10.1007/978-3-031-47640-2</link>
      <description><![CDATA[]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-47640-2</guid>
      <pubDate>Mon, 01 Jan 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>学习森林结构的神经辐射场以进行可扩展和精细的监控</title>
      <link>http://link.springer.com/10.1007/978-3-031-47640-2_23</link>
      <description><![CDATA[摘要
这项工作利用神经辐射场和遥感进行林业应用。在这里，我们展示了神经辐射场为改进森林监测中现有遥感方法提供了广泛的可能性。我们提出的实验证明了它们的潜力：(1) 表达森林 3D 结构的精细特征，(2) 融合可用的遥感模式，(3) 改进 3D 结构导出的森林指标。总而言之，这些特性使神经场成为一种有吸引力的计算工具，具有进一步提高森林监测项目的可扩展性和准确性的巨大潜力。]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-47640-2_23</guid>
      <pubDate>Mon, 01 Jan 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>医学影像中的机器学习</title>
      <link>http://link.springer.com/10.1007/978-3-031-45673-2</link>
      <description><![CDATA[]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-45673-2</guid>
      <pubDate>Mon, 01 Jan 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>神经信息处理</title>
      <link>http://link.springer.com/10.1007/978-981-99-8181-6</link>
      <description><![CDATA[]]></description>
      <guid>http://link.springer.com/10.1007/978-981-99-8181-6</guid>
      <pubDate>Mon, 01 Jan 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>神经信息处理</title>
      <link>http://link.springer.com/10.1007/978-981-99-8148-9</link>
      <description><![CDATA[]]></description>
      <guid>http://link.springer.com/10.1007/978-981-99-8148-9</guid>
      <pubDate>Mon, 01 Jan 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>深度归一化稳定视图合成</title>
      <link>http://link.springer.com/10.1007/978-981-99-8181-6_5</link>
      <description><![CDATA[摘要
新颖的视图合成 (NVS) 旨在利用现有的源图像合成描绘场景的逼真图像。合成的图像应该尽可能接近场景内容。我们提出了深度归一化稳定视图合成（DNSVS），这是一种基于稳定视图合成（SVS）管道的大规模场景 NVS 方法。 SVS 将神经网络与从运动结构和多视图立体获得的 3D 场景表示相结合，其中对应于场景表示的每个表面点的视图光线和源视图特征向量一起产生图像中每个像素的值。目标视图。然而，它在细化阶段削弱了几何信息，导致新视图中的模糊和伪影。为了解决这个问题，我们提出了 DNSVS，它利用深度图通过标准化方法来增强渲染过程。所提出的方法在 Tanks 和 Temples 数据集以及 FVS 数据集上进行了评估。我们结果的平均学习感知图像块相似度 (LPIPS) 比最先进的 NVS 方法好 0.12%，表明我们方法的优越性。
      ]]></description>
      <guid>http://link.springer.com/10.1007/978-981-99-8181-6_5</guid>
      <pubDate>Mon, 01 Jan 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多视图一致性视图合成</title>
      <link>http://link.springer.com/10.1007/978-981-99-8148-9_25</link>
      <description><![CDATA[摘要
新颖的视图合成 (NVS) 旨在利用现有的源图像合成描绘场景的逼真图像。核心目标是合成图像应尽可能接近场景内容。近年来，各种方法将焦点转向连续空间或时间中图像的视觉效果。目前的静态场景方法将图像的渲染视为孤立的过程，忽略了静态场景中的几何一致性。这通常会导致合成图像序列中出现不连贯的视觉体验，例如闪烁或伪影。为了解决这个限制，我们提出了多视图一致性视图合成（MCVS）。 MCVS 利用长短期记忆 (LSTM) 和自注意力机制来模拟合成图像之间的空间相关性，从而迫使它们更接近真实情况。 MCVS不仅增强了多视图一致性，还提高了合成图像的整体质量。所提出的方法在 Tanks 和 Temples 数据集以及 FVS 数据集上进行了评估。平均而言，学习感知图像块相似度 (LPIPS) 比最先进的方法好 0.14 到 0.16%，表明我们方法的优越性。]]></description>
      <guid>http://link.springer.com/10.1007/978-981-99-8148-9_25</guid>
      <pubDate>Mon, 01 Jan 2024 00:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>