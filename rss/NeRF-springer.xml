<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最新结果</title>
    <link>http://link.springer.com</link>
    <description>Springer 提供的最新内容</description>
    <lastBuildDate>Fri, 03 Jan 2025 12:26:47 GMT</lastBuildDate>
    <item>
      <title>一种用于正向和逆 PDE 问题的增强型混合自适应物理信息神经网络</title>
      <link>http://link.springer.com/10.1007/s10489-024-06195-2</link>
      <description><![CDATA[摘要
物理信息神经网络 (PINN) 已成为解决各种科学和工程应用中偏微分方程 (PDE) 的有力工具。PINN 通过自动微分将 PDE 集成到神经网络的损失函数中，自动微分包括 PDE 残差、边界和初始约束以及观测数据的加权组合。然而，PINN 的准确性和效率需要大幅改进才能满足更广泛的挑战性问题的要求。在本文中，我们提出了一种混合自适应 (HA) 采样方法和 PINN 的特征嵌入层。通过提出的 HA 方法在迭代过程中对用于 PINN 训练的时空点（称为残差点）进行重新采样。HA 方法确保点选择的随机性，同时优先考虑具有较大 PDE 残差的点，从而通过将网络的学习重点放在模型预测不太准确的区域来确保高效训练。此外，特征嵌入层进一步增强了 vanilla PINN 架构，将原始输入转换为更高维空间，使网络能够更好地捕捉 PDE 中潜在的复杂关系并提高其拟合能力。对各种正向和逆 PDE 问题的数值实验表明，所提出的方法显著提高了 PINN 的精度和效率，同时减少了对采样点数量的依赖。vanilla PINN 的 L2 相对误差可以降低约 1
\(\sim \)
2 个数量级，所提出的方法优于最先进的基线。]]></description>
      <guid>http://link.springer.com/10.1007/s10489-024-06195-2</guid>
      <pubDate>Thu, 02 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SUP-NeRF：用于单目 3D 物体重建的姿势估计与 NeRF 的简化统一</title>
      <link>http://link.springer.com/10.1007/978-3-031-72890-7_3</link>
      <description><![CDATA[摘要
分类对象的单目 3D 重建严重依赖于准确感知每个对象的姿势。虽然 NeRF 框架中的基于梯度的优化会更新初始姿势，但本文强调，当初始姿势与真实姿势有适度偏差时，单目对象重建中的尺度深度模糊性会导致失败。因此，现有方法通常依赖第三方 3D 对象来提供初始对象姿势，从而增加复杂性和泛化问题。为了应对这些挑战，我们提出了 SUP-NeRF，即对象姿势估计和基于 NeRF 的对象重建的精简统一。SUP-NeRF 将对象的维度估计和姿势细化解耦以解决尺度深度模糊性，并引入了一种可跨不同领域推广的相机不变投影框表示。 SUP-NeRF 使用了专用的姿态估计器，可以顺利集成到以对象为中心的 NeRF 中，同时无需外部 3D 检测器。SUP-NeRF 在 nuScenes 数据集上的重建和姿态估计任务中都取得了最先进的成果。此外，SUP-NeRF 在 KITTI 和 Waymo 数据集上表现出色，在旋转和平移误差减少高达 50% 的情况下超越了之前的方法。]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-72890-7_3</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Deblur e-NeRF：高速或低光条件下运动模糊事件中的 NeRF</title>
      <link>http://link.springer.com/10.1007/978-3-031-73232-4_11</link>
      <description><![CDATA[摘要
事件相机的独特设计理念使其成为高速、高动态范围和低光环境的理想选择，而标准相机在这些环境中表现不佳。然而，与大多数人的想法相反，事件相机也存在运动模糊，尤其是在这些具有挑战性的条件下。这是由于事件传感器像素的带宽有限，而带宽主要与光强度成正比。因此，为了确保事件相机能够真正在这种条件下表现出色，使其比标准相机更具优势，必须在下游任务（尤其是重建）中考虑事件运动模糊。然而，之前没有关于从事件重建神经辐射场 (NeRF) 的研究，也没有事件模拟器考虑过事件运动模糊的全部影响。为此，我们提出了 Deblur e-NeRF，这是一种新方法，可以直接有效地从高速或低光条件下产生的运动模糊事件中重建模糊最小的 NeRF。这项工作的核心部分是一个物理上精确的像素带宽模型，该模型考虑了事件运动模糊。我们还引入了阈值归一化总变分损失，以更好地规范大型无纹理斑块。在真实和新颖的现实模拟序列上进行的实验验证了我们的有效性。我们的代码、事件模拟器和合成事件数据集都是开源的。]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-73232-4_11</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>KFD-NeRF：使用卡尔曼滤波器重新思考动态 NeRF</title>
      <link>http://link.springer.com/10.1007/978-3-031-72995-9_1</link>
      <description><![CDATA[摘要
我们引入了 KFD-NeRF，这是一种新型动态神经辐射场，集成了基于卡尔曼滤波的高效高质量运动重建框架。我们的主要思想是将动态辐射场建模为一个动态系统，其随时间变化的状态基于两个知识来源进行估计：观察和预测。我们引入了一种新型插件卡尔曼滤波器引导变形场，可以从场景观察和预测中准确估计变形。我们使用浅层多层感知器 (MLP) 进行观察，并将运动建模为局部线性，以使用运动方程计算预测。为了进一步提高观察 MLP 的性能，我们在规范空间中引入了正则化，以促进网络学习不同帧的扭曲的能力。此外，我们采用高效的三平面表示来编码规范空间，实验证明它可以快速高质量地收敛。这使我们能够使用更浅的观察 MLP，在我们的实现中仅包含两层。我们对合成数据和真实数据进行实验，并与过去的动态 NeRF 方法进行比较。我们的 KFD-NeRF 在可比的计算时间内展示了相似甚至更优异的渲染性能，并通过全面的训练实现了最先进的视图合成性能。Github 页面：https://github.com/Yifever20002/KFD-NeRF。]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-72995-9_1</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>VF-NeRF：刚性 NeRF 注册的视域字段</title>
      <link>http://link.springer.com/10.1007/978-3-031-73027-6_10</link>
      <description><![CDATA[摘要
3D 场景配准是计算机视觉中的一个基本问题，它寻求两个场景之间最佳的 6-DoF 对齐。这个问题在点云和网格的情况下得到了广泛的研究，但关于神经辐射场 (NeRF) 的研究相对有限。在本文中，我们考虑了在未给出原始相机位置的情况下两个 NeRF 之间的刚性配准问题。我们的主要创新之处在于引入了视域场 (VF)，这是一个隐式函数，它确定每个 3D 点被原始相机看到的可能性。我们展示了 VF 如何在 NeRF 配准的各个阶段提供帮助，并通过广泛的评估表明 VF-NeRF 在具有不同捕获方法（例如 LLFF 和 Objaverese）的各种数据集上实现了 SOTA 结果。我们的代码将公开。
]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-73027-6_10</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AG-NeRF：用于多高度大规模户外场景渲染的注意力引导神经辐射场</title>
      <link>http://link.springer.com/10.1007/978-981-97-8508-7_8</link>
      <description><![CDATA[摘要
现有的基于神经辐射场 (NeRF) 的大规模室外场景新视图合成方法主要建立在单一高度上。此外，它们通常需要先验相机拍摄高度和场景范围，导致相机高度发生变化时应用效率低下且不切实际。在这项工作中，我们提出了一个端到端框架，称为 AG-NeRF，并寻求通过基于不同场景高度合成自由视点图像来降低构建良好重建的训练成本。具体而言，为了解决从低空（无人机级）到高空（卫星级）的细节变化问题，开发了一种源图像选择方法和一种基于注意的特征融合方法，以从多高度图像中提取和融合目标视图的最相关特征，以实现高保真渲染。大量实验表明，AG-NeRF 在 56 Leonard 和 Transamerica 基准上取得了 SOTA 性能，并且与最新的 BungeeNeRF 相比，仅需要半小时的训练时间即可达到具有竞争力的 PSNR。]]></description>
      <guid>http://link.springer.com/10.1007/978-981-97-8508-7_8</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>改进 NeRF 表征，无需姿势先验，实现结肠镜检查中的新型视图合成</title>
      <link>http://link.springer.com/10.1007/978-3-031-73748-0_15</link>
      <description><![CDATA[摘要
结肠镜检查是治疗胃肠道恶性肿瘤的黄金标准程序。然而，一些限制会影响筛查过程的质量。对被调查区域进行可靠的 3D 重建可以减轻这些限制并改善诊断和治疗结果。大多数 3D 重建框架依赖于两个基本任务：a) 可靠的相机深度预测，以及 b) 准确的相机姿势估计。虽然这些框架在自然场景中表现出色，但由于缺乏带注释的地面真实数据，它们对结肠镜检查数据的影响受到极大限制。我们提出了一种新颖的射线采样技术来指导神经辐射场 (NeRF) 系统的优化，而无需姿势先验来联合估计相机姿势预测和新颖的视图合成 (NVS)。我们的方法建立在 NoPe-NeRF [4] 的基础上，该方法在 NVS 和相机姿态估计方面表现出色，但目前仅限于具有大量纹理的自然场景。为了解决这一限制，我们引入了新的深度加权块聚焦随机光线采样 (DW-PFRRS) 技术，并在 C3VD 数据集上评估了我们的方法。]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-73748-0_15</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Hi-NeRF：将 2D 修复与神经辐射场相结合，实现 3D 场景修复</title>
      <link>http://link.springer.com/10.1007/978-981-96-0972-7_8</link>
      <description><![CDATA[摘要
神经辐射场 (NeRF) 的最新发展展示了新视图合成方面的显著进展。然而，使用隐式表示修复 3D 场景的研究有限。利用 3D 网络进行直接 3D 修复的传统方法在高分辨率设置下往往会失败，主要是由于 GPU 内存限制。本文介绍了 Hi-NeRF，这是一种创新的 3D 修复方法，旨在通过将 2D 修复策略与 NeRF 技术相结合来去除任意 3D 对象。认识到现行的 2D 修复方法通常无法掌握场景的 3D 几何复杂性，我们利用 NeRF 捕捉这些结构的独特能力。此外，我们提出了一种多视图感知损失 (MVPL) 来利用多视图数据，确保 2D 修复和隐式 3D 表示可以相互补偿。此外，我们使用图像膨胀来细化 Segment Anything 模型 (SAM) 的输出，以生成准确的多视图蒙版。为了完成该过程，我们使用 Instant-NGP 从 3D 一致的修复图像中高效地检索 3D 一致的场景。由于没有具有相应蒙版的多视图 3D 场景数据集，我们为多视图 3D 场景修复任务构建了真实世界和合成场景，作为基准数据集。室内和室外场景的实验结果凸显了我们的方法优于现有的 2D 修复方法和基于 NeRF 的基线。]]></description>
      <guid>http://link.springer.com/10.1007/978-981-96-0972-7_8</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过地球移动距离进行深度引导的 NeRF 训练</title>
      <link>http://link.springer.com/10.1007/978-3-031-73039-9_1</link>
      <description><![CDATA[摘要

神经辐射场 (NeRF) 经过训练，可最大限度地减少预测视点的渲染损失。然而，光度损失通常不能提供足够的信息来消除产生相同图像的不同可能几何形状之间的歧义。因此，先前的研究在 NeRF 训练期间加入了深度监督，利用来自预训练深度网络的密集预测作为伪地面实况。虽然这些深度先验在过滤噪声后被认为是完美的，但在实践中，它们的准确性更难捕捉。这项工作提出了一种用于 NeRF 监督的深度先验不确定性的新方法。我们使用现成的预训练扩散模型来预测深度​​并在去噪过程中捕获不确定性，而不是使用定制训练的深度或不确定性先验。因为我们知道深度先验容易出错，所以我们建议用 Earth Mover’s Distance 来监督射线终止距离分布，而不是强制渲染深度通过 
\(L_2\)
-loss 精确复制深度先验。我们的深度引导 NeRF 在标准深度指标上的表现远胜于所有基线，同时保持了光度测量的性能。

]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-73039-9_1</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>NAOL：NeRF辅助全向定位</title>
      <link>http://link.springer.com/10.1007/978-3-031-78128-5_23</link>
      <description><![CDATA[摘要
视觉定位是一项具有挑战性的任务，需要从图像中精确估计相机的位置和方向。具体而言，现有的全景数据集在可用的全向图像数量方面受到限制，导致与分布良好的数据集相比，其分布稀疏且多样性不足。这使得传统的基于特征的视觉定位算法难以实现全向定位。在本文中，我们介绍了一种名为NAOL的新颖而有效的方法，该方法专门用于解决全向定位问题。我们提出的流程分为两个关键阶段：第一阶段采用基于视觉的算法进行初步粗略姿态估计。考虑到全向图像的数量有限且分布稀疏，在第二阶段，我们采取创新步骤来扩充数据集并改进第一阶段的粗略姿态估计。我们引入了深度监督全景神经辐射场 (DP-NeRF)，这是一种新颖的方法，旨在对具有深度的单个全向图像进行训练，从而丰富数据集，同时使基于 DP-NeRF 的迭代算法能够提高定位精度。我们的实验结果验证了 NAOL 算法在稀疏全景数据集场景中执行视觉定位的有效性。]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-78128-5_23</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>NeRFect Match：探索 NeRF 的视觉定位功能</title>
      <link>http://link.springer.com/10.1007/978-3-031-72691-0_7</link>
      <description><![CDATA[摘要
在这项工作中，我们建议使用神经辐射场 (NeRF) 作为视觉定位的场景表示。最近，NeRF 已被用于通过扩充训练数据库、通过渲染图像提供辅助监督或作为迭代细化模块来增强姿势回归和场景坐标回归模型。我们扩展了其公认的优势——它能够提供具有逼真外观和准确几何形状的紧凑场景表示——通过探索 NeRF 的内部特征在建立精确的 2D-3D 匹配以进行定位方面的潜力。为此，我们对通过视图合成获得的 NeRF 的隐性知识进行了全面检查，以便在各种条件下进行匹配。这包括探索不同的匹配网络架构、在多个层提取编码器特征以及不同的训练配置。值得注意的是，我们引入了 NeRFMatch，这是一种先进的 2D-3D 匹配函数，它利用通过视图合成学习到的 NeRF 的内部知识。我们在基于结构的管道中对标准定位基准上的 NeRFMatch 进行了评估，在剑桥地标的定位性能方面取得了有竞争力的结果。我们将发布所有模型和代码。]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-72691-0_7</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RS-NeRF：来自滚动快门图像的神经辐射场</title>
      <link>http://link.springer.com/10.1007/978-3-031-72952-2_10</link>
      <description><![CDATA[摘要
神经辐射场 (NeRF) 因其令人印象深刻的新颖视图合成能力而变得越来越流行。然而，它们的有效性受到大多数相机系统中常见的滚动快门 (RS) 效应的阻碍。为了解决这个问题，我们提出了 RS-NeRF，这是一种使用具有 RS 失真的输入从新颖视图合成正常图像的方法。这涉及一个物理模型，该模型复制 RS 条件下的图像形成过程并联合优化 NeRF 参数和每个图像行的相机外部参数。我们通过深入研究 RS 特性并开发算法来增强其功能，进一步解决了基本 RS-NeRF 模型的固有缺陷。首先，我们施加平滑度正则化以更好地估计轨迹并提高合成质量，与相机运动先验保持一致。我们还通过引入多采样算法来识别和解决 vanilla RS 模型中的一个根本缺陷。这种新方法通过全面利用每个中间相机姿势的不同行中的 RGB 数据来提高模型的性能。通过严格的实验，我们证明 RS-NeRF 在合成和真实场景中都超越了以前的方法，证明了它能够有效纠正与 RS 相关的失真。可用的代码和数据：https://github.com/MyNiuuu/RS-NeRF。]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-72952-2_10</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RING-NeRF：重新思考多功能高效神经场的归纳偏差</title>
      <link>http://link.springer.com/10.1007/978-3-031-72761-0_9</link>
      <description><![CDATA[摘要
神经领域的最新进展主要依赖于开发特定于任务的监督，这通常会使模型复杂化。与开发难以组合和特定的模块不同，另一种通常被忽视的方法是将场景表示的通用先验（也称为归纳偏差）直接注入 NeRF 架构。基于这个想法，我们提出了 RING-NeRF 架构，其中包括两个归纳偏差：场景的连续多尺度表示和解码器潜在空间在空间和尺度域上的不变性。我们还设计了一个利用这些归纳偏差的单一重建过程，并通过实验证明了在多个任务（抗锯齿、少量视图重建、没有场景特定初始化的 SDF 重建）上与专用架构在质量方面的性能相当，同时效率更高。此外，RING-NeRF 具有动态提高模型分辨率的独特能力，为自适应重建开辟了道路。项目页面位于：https://cea-list.github.io/RING-NeRF]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-72761-0_9</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>NeRF-MAE：用于神经辐射场自监督 3D 表示学习的蒙版自动编码器</title>
      <link>http://link.springer.com/10.1007/978-3-031-73223-2_24</link>
      <description><![CDATA[摘要
神经场在计算机视觉和机器人领域表现出色，因为它们能够理解 3D 视觉世界，例如推断语义、几何和动态。鉴于神经场能够从 2D 图像密集地表示 3D 场景，我们提出了一个问题：我们是否可以扩展它们的自监督预训练，特别是使用蒙版自动编码器，以从摆放的 RGB 图像生成有效的 3D 表示。由于将 Transformer 扩展到新数据模式取得了惊人的成功，我们使用标准的 3D 视觉 Transformer 来适应 NeRF 的独特配方。我们利用 NeRF 的体积网格作为 Transformer 的密集输入，将其与其他 3D 表示（如点云）进行对比，其中信息密度可能不均匀，并且表示不规则。由于将掩蔽自动编码器应用于隐式表示（例如 NeRF）的难度，我们选择通过使用摄像机轨迹进行采样来提取显式表示，该表示可跨域规范化场景。我们的目标是通过从 NeRF 的辐射度和密度网格中屏蔽随机斑块并使用标准 3D Swin Transformer 重建掩蔽斑块来实现的。通过这样做，模型可以学习完整场景的语义和空间结构。我们在我们提出的精选 posed-RGB 数据上大规模预训练此表示，总计超过 180 万张图像。预训练后，编码器可用于有效的 3D 迁移学习。我们针对 NeRF 的新型自监督预训练 NeRF-MAE 具有非常好的扩展性，并提高了各种具有挑战性的 3D 任务的性能。 NeRF-MAE 利用未标记的 2D 数据进行预训练，在 Front3D 和 ScanNet 数据集上的表现明显优于自监督 3D 预训练和 NeRF 场景理解基线，3D 物体检测的绝对性能提升超过 20% AP50 和 8% AP25。项目页面：nerf-mae.github.io]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-73223-2_24</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Freditor：通过频率分解实现高保真、可转移的 NeRF 编辑</title>
      <link>http://link.springer.com/10.1007/978-3-031-72940-9_5</link>
      <description><![CDATA[摘要
本文通过频率分解实现了高保真、可迁移的 NeRF 编辑。最近的 NeRF 编辑流程将 2D 风格化结果提升到 3D 场景，但结果模糊，并且无法捕捉到由 2D 编辑之间的不一致导致的细节结构。我们的关键见解是，与高频部分相比，图像的低频成分在编辑后具有更高的多视图一致性。此外，外观风格主要表现在低频分量上，内容细节尤其存在于高频部分。这促使我们对低频分量进行编辑，从而产生高保真编辑的场景。此外，编辑是在低频特征空间中执行的，从而实现稳定的强度控制和新颖的场景转移。在真实感数据集上进行的全面实验证明了高保真和可迁移的 NeRF 编辑的卓越性能。项目页面位于https://aigc3d.github.io/freditor。]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-72940-9_5</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>