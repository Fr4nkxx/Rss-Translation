<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最新结果</title>
    <link>http://link.springer.com</link>
    <description>Springer可用的最新内容</description>
    <lastBuildDate>Fri, 28 Mar 2025 15:15:26 GMT</lastBuildDate>
    <item>
      <title>AAGS：外观感知3D高斯裂开，无约束的照片集</title>
      <link>https://link.springer.com/article/10.1007/s00530-025-01742-4</link>
      <description><![CDATA[从无限制的野外照片收藏中重建3D场景一直是一个挑战性的问题。主要难度在于不同的外观条件和不受控制的图像样本的瞬态遮挡器。随着神经辐射领域（NERF）的发展，以前的作品制定了一些有效的策略来解决此问题。但是，受深网和体积渲染技术的限制，这些方法通常需要大量的时间成本。最近，3D高斯脱落（3DGS）的出现大大加快了3D重建任务的训练和渲染速度。然而，香草3DGS难以区分野外照片集的不同外观。为了解决上述问题，我们提出了出现感知的3D高斯裂片（AAGS），这是3DGS的新型扩展到无约束的照片集。具体而言，我们采用一个外观提取器来捕获图像样本的全局特征，从而使视觉条件的区别，例如，例如，照明和天气，跨不同的观测值。此外，为了减轻瞬态遮挡器的影响，我们设计了一个瞬态驱动模块，该模块可自适应地学习2D可见性图，从而从复杂的现实世界场景中分解静态目标。进行了广泛的实验，以验证我们的AAG的有效性和优势。与以前的作品相比，我们的方法不仅可以更好地重建和渲染质量，而且大大降低了培训和渲染开销。代码将在&lt;a href =“ https://github.com/zhang-wencong/aags”上发布。]]></description>
      <guid>https://link.springer.com/article/10.1007/s00530-025-01742-4</guid>
      <pubDate>Fri, 28 Mar 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>纹理驱动的姿势引导的人类图像合成</title>
      <link>https://link.springer.com/article/10.1007/s10044-025-01452-7</link>
      <description><![CDATA[随着计算机视觉和人工智能的快速发展，在角色图像合成领域已经取得了重大突破。尽管现有方法可以综合目标姿势图像，但处理复杂的纹理和姿势比对仍存在局限性，例如纹理失真，姿势错位和缺失的信息。为了解决这个问题，本文提出了一种姿势引导的人类图像合成方法，称为人姿势转移生成对抗网络（HPT-GAN）。该模型通过引入Resblocks模块，设计纹理传输模块（TTM）和TORGB模块来显着提高合成图像的质量和效率。具体而言，重新建筑增强了梯度稳定性，同时保留上下文信息，TTM通过多头注意机制有效地对齐纹理，并且TORGB模块优化了多分辨率特征的融合。与类似方法相比，HPT-GAN具有少量参数，同时达到更快的处理速度。此外，它在DeepFashion和Market-1501数据集上取得了良好的成果。]]></description>
      <guid>https://link.springer.com/article/10.1007/s10044-025-01452-7</guid>
      <pubDate>Fri, 28 Mar 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>3D神经风格化的进步：一项调查</title>
      <link>https://link.springer.com/article/10.1007/s11263-025-02403-9</link>
      <description><![CDATA[现代人工智能提供了一种新颖而变革的方法，可以跨越图像，视频和3D数据（释放创造力的力量）跨越各种样式和方式创建数字艺术，并彻底改变了我们感知并与视觉内容互动的方式。本文报道了使用神经网络的表达能力进行风格化的3D资产创造和操纵的最新进展。我们考虑了关键的设计选择，例如场景表示，指导数据，优化策略和输出样式，以建立神经风格风格化的分类学。在此类分类法的基础上，我们的调查首先重新审视了2D图像上神经风化的背景，然后对3D数据的最新神经风格化方法进行了深入的讨论，并伴随着评估选定的网格和神经场风格化方法的基准测试。根据调查中获得的见解，我们强调了实际意义，开放挑战，未来的研究以及神经风格的潜在影响，这促进了研究人员和从业人员使用现代人工智能的3D内容创造的迅速发展的景观。 。]]></description>
      <guid>https://link.springer.com/article/10.1007/s11263-025-02403-9</guid>
      <pubDate>Fri, 28 Mar 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>来自多视图特征立体匹配先验的健壮的小说视图综合</title>
      <link>https://link.springer.com/article/10.1007/s00530-025-01757-x</link>
      <description><![CDATA[ nerf（神经辐射场）表现出从未知视图中合成图像的能力。但是，它面临着诸如闭塞，非斜体表面，稀疏输入以及多视图图像中通常遇到的弱质地等因素所面临的挑战。这些复杂性通常会导致拟合错误的场景几何形状，从而导致次优的新型视图综合质量。本文通过利用基于功能的多视立体匹配（MVS）先验的潜力来解决这一挑战。该方法的区别是其基于MVS估算的深度值，不确定性和深度间隔的自适应构建高斯函数的区别，从而为任意缩放场景提供了灵活性和适应性。在此基础上，通过比较该分布之间的差异与量渲染射线上采样点的重量分布之间的差异来实现NERF训练过程的优化。此外，我们提出了一种有效的Riemann和近似策略，以进一步提高深度损失的性能。适用于三个实际场景数据集的定量指标，即LLFF，IBRNET和DTU，表明本文提供的方法显着提高了与当前的先进方法相比，新型视图合成的质量，可实现3.8％至26.9％的增强。可视化实验揭示了强大的优化结果，尤其是在常规NERF遇到困难的挑战区域中。
                图形摘要
                
]]></description>
      <guid>https://link.springer.com/article/10.1007/s00530-025-01757-x</guid>
      <pubDate>Tue, 25 Mar 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>传输图引导的深层展开网络，用于增强水下图像</title>
      <link>https://link.springer.com/article/10.1007/s11227-025-07155-4</link>
      <description><![CDATA[近年来，随着海洋行业的发展，水下图像增强和恢复的重要性变得越来越突出。然而，由于介质在不同波长下的光吸收和光吸收，水下图像通常会遭受颜色失真和低对比度的影响。但是，大多数现有网络都采用了一种端到端的映射方法，该方法忽略了图像增强过程中的先前信息，从而导致缺乏可解释性。为了应对这些挑战，我们提出了一个传输图引导的深层展开的网络，以增强水下图像。我们的方法由三个核心组成部分组成：自适应面膜照明动态先验（AMIDP），传输引导的多尺度卷积词典（TGMCD）和恒定的空间聚合模块（CSAM）。 AMIDP通过掩码自动编码器和动态卷积提取图像的照明特性，从而使照明和反射信息的单独建模分别为共享和独特的特征。然后将这些功能输入到TGMCD模块中，该模块由传输图指导以进行迭代优化。在此过程中，我们用可学习的多尺度残差模块替换传统的近端运算符，并结合了先前的信息和约束以增强模型性能。此外，CSAM旨在加强跨功能的信息融合，确保最终增强的图像在保留关键细节的同时纠正扭曲。在多个水下数据集上进行的广泛实验表明，我们的方法可实现最先进的性能，从而验证其有效性和优势。我们的代码可在 https://github.com/makabala/tgdu-master。]]></description>
      <guid>https://link.springer.com/article/10.1007/s11227-025-07155-4</guid>
      <pubDate>Sun, 23 Mar 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>对基于社区的夏季干预措施进行营养辅助组件的范围审查，旨在改善儿童与体重相关的结果</title>
      <link>https://link.springer.com/article/10.1186/s12889-025-22241-1</link>
      <description><![CDATA[背景
                儿童，尤其是来自低收入家庭的孩子，在夏季，体重增加和粮食不安全。夏季干预措施包括通过免费或补贴食品或食物的钱提供营养援助，可以很好地解决粮食不安全和肥胖。但是，尚无对夏季干预措施的特征和发现的全面审查，旨在改善儿童与体重相关的结果，包括粮食安全，饮食摄入，体育锻炼和体重。这项研究旨在用包括与儿童体重相关的结果在内的营养成分来描述夏季干预的特征和发现。
              
                方法
                使用该术语“夏季”，“夏季”，“食物”，“营养”，“用餐”，“午餐”，“午餐”，“午餐”或“不安全感”，搜索了此范围评论，Cinahl，Eric，Ovid Medline和Scopus数据库。三名独立审阅者筛选了手稿以获得资格。
              
                结果
                确定了13个手稿。除营养援助外，大多数夏季干预措施的大多数（ n  = 10，77％）提供了营养教育和/或体育活动参与或教育的活动。大多数干预措施（69％）是通过夏令营或学校提供的，而60％的干预措施通过夏季食品服务计划提供了营养援助，以免费餐或小吃的形式提供营养援助。粮食不安全是研究最少的结果。这些夏季干预措施与儿童与体重相关的结果之间的关联是使用各种措施和研究设计研究的，只有三项随机对照研究，其中两项没有足够的动力样本。一些准实验研究记录了干预参与与果实和蔬菜摄入，中度至剧烈的体育锻炼与BMI Z分数或百分位数之间的积极关联，但发现不一致。 
              
                结论
                需要进行更严格的设计和足够动力的样品进行进一步的研究，以评估具有营养辅助的多组分夏季干预措施的影响，以最大程度地利用与儿童体重相关的健康和平等的干预益处。
              
                临床试验号
                不适用。]]></description>
      <guid>https://link.springer.com/article/10.1186/s12889-025-22241-1</guid>
      <pubDate>Sat, 22 Mar 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LIDAR，IMU和相机融合用于同时本地化和映射：系统评价</title>
      <link>https://link.springer.com/article/10.1007/s10462-025-11187-w</link>
      <description><![CDATA[同时本地化和映射（SLAM）是智能无名系统估算其运动和重建未知环境的至关重要技术。但是，由于传感器本身的缺陷，具有一个传感器的SLAM系统仅具有稳健性和稳定性。最近的研究表明，由于不同传感器的相互补偿，具有多个传感器（主要由LIDAR，摄像机和IMU）的SLAM系统具有更好的性能。本文研究了多传感器融合大满贯的最新进展。该综述包括对不同传感器的优势和缺点的系统分析以及多传感器解决方案的命令。它通过融合传感器将多传感器融合大满贯系统分为四种主要类型：LIDAR-IMU SLAM，Visual-Imu Slam，Lidar-Visual-Visual-Visual-visual Slam和Lidar-Imu-Visual-Visual Sllam，并进行了详细的分析以及对管道和原理的讨论。同时，该论文调查常用数据集并引入评估指标。最后，总结了多传感器融合大满贯的现有挑战和未来的机会。。]]></description>
      <guid>https://link.springer.com/article/10.1007/s10462-025-11187-w</guid>
      <pubDate>Wed, 19 Mar 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>胺碘酮治疗引起的罕见神经病毒性：病例报告</title>
      <link>https://link.springer.com/article/10.1186/s43044-025-00631-5</link>
      <description><![CDATA[背景
                胺碘酮是一种以其潜在副作用而闻名的抗心律失常药物，其中一种是神经肌病，尽管它仍然相对较少。这种情况可能带有肌肉无力，疼痛和震颤，可能导致功能障碍。尚不完全了解胺碘酮诱导的神经瘤性的确切机制，但可能涉及直接肌肉毒性和对神经传导的影响。
              
                案例表现
                我们介绍了一个68岁的男性患有症状心律失常的右心室发育不良，患有长期胺碘酮，经历了双侧腿部疼痛和与胺碘酮使用相关的弱点。在临床检查中，下肢的运动强度为2/5，触觉降低。生物学评估显示肌酸激酶和C反应蛋白的正常水平。脊柱MRI正常。肌电图的“ EMG”揭示了非长度依赖性感觉运动脱髓鞘性多神经病。停用胺碘酮后，迁移率和功能都显示出显着改善。
              
                结论
                这些观察结果强调了在接受胺碘酮治疗的患者中进行神经系统检查的重要性，以鉴定罕见的并发症，例如神经瘤病。重要的是，在停用药物后，神经瘤通常是可逆的。]]></description>
      <guid>https://link.springer.com/article/10.1186/s43044-025-00631-5</guid>
      <pubDate>Wed, 19 Mar 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Easyvis：用于腹腔镜手术盒培训师的实时3D可视化软件系统</title>
      <link>https://link.springer.com/article/10.1007/s13304-025-02153-w</link>
      <description><![CDATA[ easyvis是一种新兴的沉浸式3D腹腔镜可视化系统，可提高腹腔镜手术的效率。它将多个微型摄像头和光源与手术端口整合在一起，以在所需的角度提供手术内手术的视觉。在这项工作中，我们在腹腔镜手术训练盒环境中使用Easyvis微型摄像机组装来开发一种可视化算法，并具有简化的训练任务，以验证这种新技术的可行性。由于大多数腹腔镜手术工具是刚体的对象，因此可以离线获取它们的3D形状。我们开发了2D对象检测和跟踪算法，以获取每个对象的2D姿势和3D融合算法，以使用估计的2D姿势来估计和跟踪每个对象的3D姿势。然后，与每个对象的获得的3D模型一起，我们能够使用3D表面模型（离线获取）和从单个微型胶片中获取的图像在所需视图处渲染每个对象。除前景刚性对象外，背景3D模型是使用结构化的灯光和运动结构来获取的。与前景物体的快速运动相比，假定背景变化缓慢。因此，背景3D模型仅需要偶尔更新。我们的渲染算法能够整合前景和背景3D模型，以促进从理想的视角渲染基于图像的渲染。我们进行了实验以验证渲染图像的准确性和质量。]]></description>
      <guid>https://link.springer.com/article/10.1007/s13304-025-02153-w</guid>
      <pubDate>Sun, 16 Mar 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>GRPOSENET：使用稀疏RGB视图的可推广且可靠的6D对象姿势估计网络</title>
      <link>https://link.springer.com/article/10.1007/s00371-025-03852-6</link>
      <description><![CDATA[六度的自由对象姿势估计在各种计算机视觉和机器人技术任务中起着至关重要的作用。现有方法通常很大程度上依赖CAD模型和实质性的先验信息，从而将其概括限制为在开放场景中看不见的对象。为了解决此限制，我们提出了GRPOSENET，这是一个可推广且可靠的6D对象姿势估计网络，可以仅使用带有参考姿势的稀疏RGB图像来预测看不见的对象的姿势。 GRPOSENET包括一个开放世界检测器，一个观点选择器和自适应多尺度炼油厂。开放世界检测器利用预先训练的大型模型进行零拍分段和特征提取，克服检测和与看不见的对象的匹配错误。视点选择器使用我们设计的相似性网络选择最初的参考视图以进行初始姿势估计。自适应多尺度炼油厂通过迭代更新旋转和基于多尺度特征和自适应重量的翻译残差而进一步完善了姿势。基准数据集和我们可靠的测试数据集RBMOP的广泛实验表明，GRPOSENET实现了最新的性能，显示出极好的概括和鲁棒性，可对看不见的对象和稀疏视图。这些代码和数据集可在： https://github.com/kiers.com/kiersas/grposenet 。]]></description>
      <guid>https://link.springer.com/article/10.1007/s00371-025-03852-6</guid>
      <pubDate>Tue, 11 Mar 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LFVGS：轻巧的高斯拆卸方法，用于几个镜头综合</title>
      <link>https://link.springer.com/article/10.1007/s11227-025-07114-z</link>
      <description><![CDATA[尽管通过3D高斯拆卸实现了新型视图的显着进步，但其依赖于致密的输入视图和高存储需求限制了其适用性。为了应对这一挑战，这项研究提出了LFVGS，这是一个基于3DGS技术的轻量级小说综合框架。 LFVGS可以实现低成本，高质量的新型视图综合，并限制了有限的输入视图（只有三种），同时大大降低了存储要求。为了通过稀疏输入来实现高性能，我们引入了两种关键策略。首先，为了减轻初始输入不足的问题，我们利用距离得分和不透明度阈值在动态而密集地将新高斯人插入最初的高斯原始人中，从而避免了在稀疏视图约束下表示不足表示的问题。其次，为了加强因稀疏输入视图所施加的几何约束，我们将深度先验纳入了监督，利用全球到本地的深度正规化，以减少渲染深度和深度先验之间的差异，从而纠正场景几何形状。最后，通过使用简单的MLP表示依赖视图的颜色，复杂反射区域和局部对象轮廓的合成质量得到显着改善，而模型存储开销显着降低。实验结果表明，LFVGS在LLFF，MIPNERF360和SHINY数据集上实现了出色的总体性能，从而实现了完全端到端的轻质优化过程。该代码可在： https://github.com/leexiaotong1/lfvgs   ]]></description>
      <guid>https://link.springer.com/article/10.1007/s11227-025-07114-z</guid>
      <pubDate>Wed, 05 Mar 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Phydiisp：弱光机构视觉的物理学导致管道</title>
      <link>https://link.springer.com/article/10.1007/s11760-025-03918-x</link>
      <description><![CDATA[在弱光环境中，机器视觉任务通常会遭受性能退化，因为传统的图像信号处理（ISP）管道主要针对图像质量指标进行优化，例如峰值信噪比和结构相似性指数，这些指数无法充分满足这些应用程序的特定需求。在挑战性照明条件下，现有方法在增强计算机视觉任务所需的关键图像特征方面缺乏。为了解决这个问题，我们介绍了Phydiisp，这是一条物理引导的，可区分的ISP管道，旨在在弱光场景中提高机器视觉性能。 Phydiisp将传统的ISP设计原理与物理见解相结合，包括用于原始RGB转换的表演，全球音调映射以调整整体亮度以及基于多尺度视网膜的增强功能，以应对低光挑战。实验结果表明，通过有效增强关键图像特征，Phydiisp在对象检测准确性中的现有ISP方法优于现有的ISP方法。此外，当经过L1损失训练并与黑光环境的数据集和真正的原始型RGB转换相符时，它表明了竞争性的图像质量。这些结果证实了Phydiisp是现实世界中低光机器视觉应用的可行有效解决方案。]]></description>
      <guid>https://link.springer.com/article/10.1007/s11760-025-03918-x</guid>
      <pubDate>Wed, 05 Mar 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>关于二十年代深立体声匹配的调查</title>
      <link>https://link.springer.com/article/10.1007/s11263-024-02331-0</link>
      <description><![CDATA[立体声匹配即将达到半个世纪的历史，但由于深度学习，在过去十年中迅速发展。尽管2010年代末的先前调查涵盖了这次革命的第一阶段，但最后五年的研究为该领域带来了进一步的突破性进步。本文旨在以两倍的方式填补这一空白：首先，我们对深度立体声匹配的最新发展进行了深入的检查，重点是在2020年代重新定义领域的开创性建筑设计和开创性的范式；其次，我们对与这些进步一起出现的关键挑战进行了详尽的分析，为这些问题提供了全面的分类法，并探索了为解决这些问题而提出的最先进的技术。通过审查建筑创新和主要挑战，我们提供了深入立体声匹配的整体视野，并突出了需要进一步调查的特定领域。为了随附这项调查，我们维护了一个定期更新的项目页面，该页面在我们很棒的匹配存储库中对Deep Stereo匹配的论文进行了分类。]]></description>
      <guid>https://link.springer.com/article/10.1007/s11263-024-02331-0</guid>
      <pubDate>Wed, 26 Feb 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>教机器人建立自己的模拟</title>
      <link>https://link.springer.com/article/10.1038/s42256-025-01006-w</link>
      <description><![CDATA[视觉的出现催化了关键的进化进步，使生物不仅能够感知，而且可以与环境聪明地互动。机器人系统的演变反映了这种转变，在该演变中，利用视力模拟和预测自己的动态的能力标志着朝着自主性和自我意识飞跃。人类利用愿景来记录经验并内部模拟潜在的动作。例如，我们可以想象，如果我们站起来并举起手臂，身体将形成“ T”形状而无需身体运动。同样，仿真允许机器人计划和预测潜在动作的结果而无需执行。在这里，我们介绍了一个自制的学习框架，以使机器人仅使用简短的原始视频数据来建模和预测其形态，运动学和运动控制，从而消除了对广泛的现实数据收集和运动学先验的需求。通过观察自己的动作，类似于人类在镜子中观看反射，机器人学会了模拟自己并预测各种任务的空间运动的能力。我们的结果表明，这种自学模拟不仅可以实现准确的运动计划，而且还允许机器人检测异常并从损害中恢复。]]></description>
      <guid>https://link.springer.com/article/10.1038/s42256-025-01006-w</guid>
      <pubDate>Tue, 25 Feb 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>单阶段卷积神经辐射场</title>
      <link>https://link.springer.com/article/10.1007/s10044-025-01427-8</link>
      <description><![CDATA[从多个图像捕获的新型视图综合是计算机视觉和计算摄影的关键研究主题，因为其应用范围很广。神经辐射场通过使用多层感知器优化连续体积场景函数来显着提高性能。尽管神经辐射场及其修改提供了高质量的场景，但由于其层次结构包括粗网络，它们在优化精确的辐射场方面有限制。它们还需要许多参数，通常不考虑射线上样本之间的局部和全球关系。本文提出了一个统一的单阶段范式，该范式共同了解了使用卷积神经网络的三维射线的相对位置及其对复杂场景的相对颜色和密度的相对位置，以减少噪声和无关的特征并防止过度拟合。包括消融测试在内的实验结果验证了所提出的方法比当前最新模型合成新观点的鲁棒性。该代码可在 https://github.com/xkdytk/scorf 。]]></description>
      <guid>https://link.springer.com/article/10.1007/s10044-025-01427-8</guid>
      <pubDate>Fri, 21 Feb 2025 00:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>