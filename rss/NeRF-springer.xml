<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最新结果</title>
    <link>http://link.springer.com</link>
    <description>Springer 提供的最新内容</description>
    <lastBuildDate>Sat, 11 May 2024 21:11:00 GMT</lastBuildDate>
    <item>
      <title>以更细粒度解析对象：一项调查</title>
      <link>http://link.springer.com/10.1007/s11633-022-1404-6</link>
      <description><![CDATA[摘要
细粒度视觉解析，包括细粒度部分分割和细粒度对象识别，由于其在农业等许多实际应用中的重要性而引起了相当大的关注、遥感和空间技术。主要的研究工作遵循不同的范式来处理这些细粒度的子任务，而忽略了这些任务之间的内在关系。此外，鉴于大多数研究仍然碎片化，我们从学习零件关系的新角度对先进工作进行了深入研究。从这个角度来看，我们首先将最近的研究和基准综合与新的分类法相结合。在此基础上，我们重新审视细粒度零件分割和识别任务中的普遍挑战，并通过零件关系学习针对这些重要挑战提出新的解决方案。此外，我们还总结了细粒度视觉解析方面的一些有前景的研究方向，以供未来研究使用。]]></description>
      <guid>http://link.springer.com/10.1007/s11633-022-1404-6</guid>
      <pubDate>Sat, 01 Jun 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>探索使用预训练特征进行立体匹配</title>
      <link>http://link.springer.com/10.1007/s11263-024-02090-y</link>
      <description><![CDATA[摘要
对于许多视觉任务，利用预训练的功能可以提高性能，并持续受益于预训练技术的快速发展。然而，在立体匹配领域，预训练特征的使用尚未得到广泛研究。在本文中，我们首次系统地探索了利用预训练特征进行立体匹配。为了为预训练主干和立体匹配网络的任意组合提供灵活的使用，我们开发了可变形颈部（DN），它将这两个组件的网络架构解耦。 DN的核心思想是利用可变形注意力机制从浅层到深层迭代融合预训练的特征。根据经验，我们的探索揭示了影响使用预训练特征进行立体匹配的关键因素。我们进一步研究了预训练特征的实例级信息的作用，证明它有利于立体匹配，同时可以在基于卷积的特征融合过程中被抑制。基于注意力机制，所提出的 DN 模块有效地利用了预训练特征中的实例级信息。此外，我们提供了对效率与准确性权衡的理解，得出的结论是，考虑到效率，使用预训练的特征也是一个不错的选择。]]></description>
      <guid>http://link.springer.com/10.1007/s11263-024-02090-y</guid>
      <pubDate>Sat, 11 May 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>BTD-RF：使用块项张量分解进行 3D 场景重建</title>
      <link>http://link.springer.com/10.1007/s10489-024-05476-0</link>
      <description><![CDATA[摘要
神经辐射场 (NeRF) 在视图合成任务中表现出出色的性能，但在三维 (3D) 场景重建过程中需要大量内存和模型参数。本文提出了一种块项张量分解辐射场（BTD-RF），这是一种新颖的方法，可以在保持重建质量的同时实现显着的模型压缩。 BTD-RF将高维辐射场分解为低维张量块，得到的值比基线方法小2.21倍。将模型分解为低维张量块，可以用轻量级多线性注意力机制替代 Transformer 的标准多头注意力，采用元素级乘积并共享参数。这在不影响性能的情况下显着降低了模型的复杂性。对各种数据集的广泛评估表明，与现有方法相比，BTD-RF 实现了卓越的图像重建质量。定量指标和定性评估证实，BTD-RF 生成的图像在结构和感知上都接近真实情况，尽管采用轻量级设计，但仍展现出卓越的性能。 BTD-RF 在三维 (3D) 场景重建的模型大小和重建质量之间提供了令人信服的权衡。其高效的设计使其适合资源受限的应用，同时提供高保真结果，为更广泛的 NeRF 利用铺平了道路。该代码位于 https://github.com/seonbin-kim/BTDRF]]></description>
      <guid>http://link.springer.com/10.1007/s10489-024-05476-0</guid>
      <pubDate>Thu, 09 May 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>神经数字孪生：在虚拟现实中重建复杂的医疗环境以进行空间规划</title>
      <link>http://link.springer.com/10.1007/s11548-024-03143-w</link>
      <description><![CDATA[摘要

目的
专用机器人和手术工具正在增加手术室 (OR) 的复杂性，需要精心准备，尤其是在首次使用技术或设备时。空间规划可以提高效率并提前识别程序障碍，但真正的手术室几乎无法提供优化空间利用率的可用性。需要创建物理设置重建的方法，即数字孪生，以实现虚拟现实中此类复杂环境的沉浸式空间规划。


方法
我们提出了一种基于神经渲染的方法，可以通过随意的视频捕捉创建复杂医疗环境和设备的沉浸式数字孪生，从而实现手术场景的空间规划。为了评估我们的方法，我们通过神经重建重新创建了两个手术室和十个物体，然后与 21 名研究生一起进行用户研究，在生成的虚拟环境中执行规划任务。与相同环境的低视觉复杂性版本相比，我们分析了任务负载、存在、感知效用以及探索和交互行为。


结果
结果显示，使用基于神经重建的环境，感知效用和存在感显着提高，同时感知工作量和探索行为也更高。交互性没有显着差异。


结论
我们探索使用现代重建技术创建复杂医疗环境和物体的数字双胞胎的可行性。无需专业知识或专用硬件，用户就可以在虚拟环境中创建、探索对象并与之交互。结果表明，在技术上易于实现的同时，具有高感知效用等优点，这可能表明这种方法在空间规划及其他方面的前景。
]]></description>
      <guid>http://link.springer.com/10.1007/s11548-024-03143-w</guid>
      <pubDate>Mon, 06 May 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过 SfM–MVS 从图像序列顺序生成局部 3D 模型之间基于估计相机轨迹的集成</title>
      <link>http://link.springer.com/10.1007/s10015-024-00949-4</link>
      <description><![CDATA[摘要
本文描述了一种三维 (3D) 建模方法，用于从相机获取的图像序列中顺序和空间地了解未知环境中的情况。该方法按时间顺序将图像序列按图像数量划分为子图像序列，通过运动和多视图立体结构（SfM-MVS）从子图像序列生成局部3D模型，并集成模型。每个子图像序列中的图像与先前和后续子图像序列部分重叠。使用根据 SfM-MVS 估计的摄像机轨迹计算出的变换参数，将局部 3D 模型集成到 3D 模型中。在我们的实验中，我们定量比较了集成模型的质量与从批次中的所有图像生成的 3D 模型，以及使用从相机获取的三个真实数据集获得这些模型的计算时间。因此，该方法可以生成高质量的集成模型，并通过 SfM-MVS 与使用批次中所有图像的 3D 模型进行比较，并减少计算时间。]]></description>
      <guid>http://link.springer.com/10.1007/s10015-024-00949-4</guid>
      <pubDate>Wed, 01 May 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于饱和模糊图像的深度非盲去模糊网络</title>
      <link>http://link.springer.com/10.1007/s00521-024-09495-3</link>
      <description><![CDATA[摘要
非盲图像去模糊在低水平视觉领域引起了广泛关注。然而，现有的非盲去模糊方法无法有效处理饱和模糊图像。关键在于饱和模糊图像的退化模型不满足传统模糊图像的线性卷积模型。为了解决这个问题，本文提出了一种新颖的深度非盲去模糊方法，称为饱和图像非盲去模糊网络（SDBNet）。 SDBNet包含两个可训练的子网络，即置信估计网络（CEN）和细节增强网络（DEN）。具体来说，SDBNet使用CEN来估计饱和模糊图像的置信图，用于识别模糊图像中的饱和像素，然后使用置信图和模糊核来恢复模糊图像。最后，我们使用 DEN 来增强恢复图像的边缘和纹理。我们首先预训练 CEN 和 DEN。为了有效地预训练 CEN，我们提出了一个新的鲁棒函数，用于为 CEN 生成标签数据。实验结果表明，与现有的几种非盲去模糊方法相比，SDBNet能够有效恢复饱和模糊图像，更好地恢复模糊图像的纹理、边缘等结构信息。]]></description>
      <guid>http://link.springer.com/10.1007/s00521-024-09495-3</guid>
      <pubDate>Wed, 01 May 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>客座社论：2022 年英国机器视觉会议特刊</title>
      <link>http://link.springer.com/10.1007/s11263-024-02038-2</link>
      <description><![CDATA[]]></description>
      <guid>http://link.springer.com/10.1007/s11263-024-02038-2</guid>
      <pubDate>Wed, 24 Apr 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>高效的 EndoNeRF 重建及其在数据驱动手术模拟中的应用</title>
      <link>http://link.springer.com/10.1007/s11548-024-03114-1</link>
      <description><![CDATA[摘要


目的

医疗保健行业对手术场景的真实建模和高效模拟的需求日益增长。借助有效的可变形手术场景模型，临床医生能够在接近真实病例的场景下进行手术规划和手术训练。然而，实现这一目标的一个重大挑战是缺乏具有精确形状和纹理的高质量软组织模型。为了解决这一差距，我们提出了一个数据驱动的框架，该框架利用新兴的神经辐射场技术来实现高质量的手术重建，并探索其在手术模拟中的应用。



方法

我们首先专注于开发一种基于 NeRF 的快速手术场景 3D 重建方法，以实现最先进的性能。该方法可以显着优于传统的 3D 重建方法，传统的 3D 重建方法无法捕捉大变形并产生细粒度的形状和纹理。然后，我们提出通过闭合网格提取算法自动创建交互式手术模拟环境的管道。
      



结果

我们的实验验证了我们提出的手术场景 3D 重建方法的卓越性能和效率。我们进一步利用重建的软组织进行 FEM 和 MPM 模拟，展示我们的方法在数据驱动的手术模拟中的实际应用。
      



结论

我们提出了一种新颖的基于 NeRF 的重建框架，重点是模拟目的。我们的重建框架有助于高效创建高质量的手术软组织 3D 模型。通过多次软组织模拟的验证，我们表明我们的工作有可能有益于下游临床任务，例如外科教育。
]]></description>
      <guid>http://link.springer.com/10.1007/s11548-024-03114-1</guid>
      <pubDate>Wed, 24 Apr 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用机器学习引导方法检测突尼斯方言自发语音中的言语障碍</title>
      <link>http://link.springer.com/10.1007/s42979-024-02775-8</link>
      <description><![CDATA[摘要
这项工作研究了自然口语理解领域内的不流畅处理任务。我们提出了一种基于转录的方法，具有纯粹的语言特征，用于检测突尼斯方言转录中的不流畅。不流畅处理的任务是检测口语记录中的自发障碍，区分流畅和不流畅的单词。该方法的独创性在于自动处理突尼斯方言自发口语中的多种不流利类型。同样，它包含各种语言特征，例如形态句法标签和单词同义词。音节延长、语音单词、单词片段和简单重复是根据基于规则的方法进行的，而复杂的重复、插入、替换和删除是通过机器学习方法使用基于转换的模型来检测的。我们将基于转换的模型与之前工作中提出的基于序列标记的模型进行比较。实验表明，两个模型均适用于突尼斯方言的不流畅检测任务，F-Measure率分别为79.81%和78.97%。]]></description>
      <guid>http://link.springer.com/10.1007/s42979-024-02775-8</guid>
      <pubDate>Wed, 17 Apr 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于新颖视图合成的协作神经辐射场</title>
      <link>http://link.springer.com/10.1007/s00371-024-03379-2</link>
      <description><![CDATA[摘要
神经辐射场 (NeRF) 通过估计点属性（密度和颜色），然后采用体积渲染方法来合成逼真的新颖视图。然而，准确预测任意点属性对基于 NeRF 的单一模型提出了挑战。这种限制直接影响新颖视图合成的质量。为了解决这个问题，提出了一种基于多个 NeRF 模型的协作策略。该策略首次将多模型级联架构引入NeRF，以实现高质量的新颖视图合成。其目的是利用空间中的级联架构来逐步增强点属性的准确性。级联架构包括点调整和快照融合。具体来说，点调整利用基于 NeRF 的预训练模型来预测空间中每个点的初始密度和颜色。此步骤提供目标场景的初始渲染。然后，这些点的初始密度和颜色直接转移到后续基于 NeRF 的模型中。这一过程指导后续基于 NeRF 的模型专注于初始点属性的细化并合成更真实的新颖视图。最后，快照融合融合多个并行后续基于 NeRF 的模型的输出（称为快照），以合成最终的高质量新颖视图。所提出的策略使用一系列已建立的基于 NeRF 的方法进行了测试，例如 NeRF、Instant-NGP 和 TensoRF。本研究的实验数据来源于真实的360度合成数据集和LLFF数据集。结果表明，所提出的协作策略与已建立的基于 NeRF 的方法可以提高新颖视图合成的质量，超越相应的单一模型。我们的项目页面位于 https:/ /github.com/ZhenyangLiu/Collaborative-Neural-Radiance-Fields-for-Novel-View-Synthesis。]]></description>
      <guid>http://link.springer.com/10.1007/s00371-024-03379-2</guid>
      <pubDate>Fri, 12 Apr 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Twinnet：通过卷积编码器-解码器和多层感知器合成体积渲染图像的耦合功能</title>
      <link>http://link.springer.com/10.1007/s00371-024-03368-5</link>
      <description><![CDATA[摘要
体积可视化在学术界和工业界都发挥着至关重要的作用，因为体积数据广泛应用于医学、地球科学和工程等领域。为了解决体积渲染的复杂性，神经渲染已成为一种潜在的解决方案，有助于生成高质量的体积渲染图像。在本文中，我们提出了 TwineNet，一种专门为体渲染设计的神经网络架构。 TwineNet 通过利用跨多个特征层的缠绕跳跃连接来组合从体数据、传递函数和视点中提取的特征。在 TwineNet 架构的基础上，我们引入了两个神经网络 VolTFNet 和 PosTFNet，它们利用卷积编码器解码器和多层感知器来合成具有新颖传递函数和视点的体积渲染图像。我们的实验结果证明，与最先进的方法相比，我们的模型在生成具有新颖的传递函数和视点的高质量体积渲染图像方面具有优越性。这项研究有助于推动体积渲染领域的发展，并展示了神经渲染技术在科学可视化中的潜力。]]></description>
      <guid>http://link.springer.com/10.1007/s00371-024-03368-5</guid>
      <pubDate>Fri, 12 Apr 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Multi3D：3D 感知多模态图像合成</title>
      <link>http://link.springer.com/10.1007/s41095-024-0422-4</link>
      <description><![CDATA[摘要
3D 感知图像合成已实现高质量和强大的 3D 一致性。现有的 3D 可控生成模型旨在通过单一模态（例如 2D 分割或草图）合成 3D 感知图像，但缺乏精细控制生成内容（例如纹理和年龄）的能力。为了增强用户引导的可控性，我们提出了 Multi3D，一种支持多模态输入的 3D 感知可控图像合成模型。我们的模型可以使用二维标签图（例如分割图或草图图）来控制生成图像的几何形状，同时通过文本描述来调节生成图像的外观。为了证明我们方法的有效性，我们在多个数据集上进行了实验，包括 CelebAMask-HQ、AFHQ-cat 和 shapenet-car。定性和定量评估表明，我们的方法优于现有的最先进方法。
      



]]></description>
      <guid>http://link.springer.com/10.1007/s41095-024-0422-4</guid>
      <pubDate>Wed, 03 Apr 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>不成对语义神经人图像合成</title>
      <link>http://link.springer.com/10.1007/s00371-024-03331-4</link>
      <description><![CDATA[摘要
姿势引导的人物图像合成是一项具有挑战性的任务，旨在生成外观与源图像相同但姿势与目标图像相同的逼真人物图像。由于多视图信息的遗漏，现有的方法经常会出现明显的伪影，并且某些方法在训练过程中对源-目标图像配对的要求进一步限制了模型的应用。为了解决这些问题，我们提出了一种名为 SNPIS 的语义神经人图像合成框架，该框架利用神经辐射场（NeRF）从多视图源图像和目标语义图合成任意姿势的高保真人体图像。首先，我们引入语义镜像方向调整，强制采样点聚焦于人体，有效抑制背景干扰并增强人体细节。然后，我们设计了一种基于 NeRF 的外观形状解耦生成对抗网络，该网络将多视图源图像和相应语义图生成的共享体积的外观和形状分开。最后，我们使用获得的解耦生成器来合成由目标语义图引导的人类图像，采用外观反转，并在语义一致性约束下优化姿势重建。实验结果表明，我们的方法不仅优于现有的不配对姿势引导人体图像合成方法，而且还可以与许多配对方法竞争。]]></description>
      <guid>http://link.springer.com/10.1007/s00371-024-03331-4</guid>
      <pubDate>Tue, 02 Apr 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>优化深度学习架构以实现新颖的视图合成：研究 NeRF MLP 参数对复杂场景的影响</title>
      <link>http://link.springer.com/10.1007/s41870-023-01470-w</link>
      <description><![CDATA[摘要
机器学习与几何推理相结合是一种很有前途的方法，可以使用有限的图像捕获生成场景的新视角，称为神经渲染技术。神经辐射场 (NeRF) 通过学习辐射隐函数来表示复杂的 3D 场景，并在各种应用中表现出了令人印象深刻的性能。然而，NeRF 参数对其整体性能的影响在很大程度上仍未得到探索。在本文中，我们对 NeRF 的多层感知器 (MLP) 参数进行了广泛的网格搜索，以检查它们对图像质量的影响。我们通过改变与 MLP 架构相关的参数（例如隐藏层计数和每层神经元）来分析结果。我们的研究结果表明，MLP 架构的选择会显着影响图像质量。我们提出的方法在具有挑战性的场景（包括合成数据集和真实数据集）上优于 NeRF 的默认设置。这些结果揭示了不同参数对 NeRF 性能的影响，帮助从业者为其特定应用选择合适的设置。]]></description>
      <guid>http://link.springer.com/10.1007/s41870-023-01470-w</guid>
      <pubDate>Mon, 01 Apr 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从未曝光图像中学习神经辐射场的鲁棒多尺度表示</title>
      <link>http://link.springer.com/10.1007/s11263-023-01936-1</link>
      <description><![CDATA[摘要
我们针对计算机视觉中基于神经图像的渲染问题引入了一种改进的解决方案。给定在火车时从自由移动的摄像机拍摄的一组图像，所提出的方法可以在测试时从新的视角合成场景的真实图像。本文提出的关键思想是（i）通过强大的管道从未摆出的日常图像中恢复准确的相机参数在神经新视图合成问题中同样重要； (ii) 在不同分辨率下对对象的内容进行建模更为实用，因为在日常的未摆姿势的图像中很可能出现戏剧性的相机运动。为了整合关键思想，我们利用了场景刚性、多尺度神经场景表示和单图像深度预测的基础知识。具体来说，所提出的方法使得相机参数在基于神经场的建模框架中是可学习的。通过假设每个视图的深度预测按比例给出，我们限制了连续帧之间的相对姿势。根据相对姿势，绝对相机姿势估计是通过多尺度神经场网络内基于图神经网络的多个运动平均来建模的，从而产生单个损失函数。优化引入的损失函数可以从未摆出的图像中提供相机内在、外在和图像渲染。我们通过示例证明，对于从日常获取的未摆姿势的多视图图像中准确建模多尺度神经场景表示的统一框架，在场景表示框架内进行精确的相机姿态估计同样重要。如果不考虑相机姿态估计管道中的鲁棒性措施，多尺度混叠伪影的建模可能会适得其反。我们在几个基准数据集上进行了广泛的实验，以证明我们的方法的适用性。]]></description>
      <guid>http://link.springer.com/10.1007/s11263-023-01936-1</guid>
      <pubDate>Mon, 01 Apr 2024 00:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>