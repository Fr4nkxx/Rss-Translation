<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最新结果</title>
    <link>http://link.springer.com</link>
    <description>Springer 提供的最新内容</description>
    <lastBuildDate>Wed, 15 May 2024 18:14:48 GMT</lastBuildDate>
    <item>
      <title>基于多尺度哈希编码的神经几何表示</title>
      <link>http://link.springer.com/10.1007/s41095-023-0340-x</link>
      <description><![CDATA[摘要
最近，基于神经隐式函数的表示引起了越来越多的关注，并被广泛用于使用可微神经网络来表示表面。然而，使用现有的神经几何表示从点云或多视图图像进行表面重建仍然存在计算速度慢和精度差的问题。为了缓解这些问题，我们提出了一种基于多尺度哈希编码的神经几何表示，它有效且高效地将表面表示为带符号的距离场。我们新颖的神经网络结构仔细地将低频傅立叶位置编码与多尺度哈希编码结合起来。相应地重新设计了几何网络的初始化和渲染模块的几何特征。我们的实验表明，所提出的表示对于重建具有数百万个点的点云来说至少快 10 倍。它还显着提高了多视图重建的速度和准确性。我们的代码和模型可以在 https://github.com/Dengzhi-中国科学技术大学/神经几何重建。




]]></description>
      <guid>http://link.springer.com/10.1007/s41095-023-0340-x</guid>
      <pubDate>Sat, 01 Jun 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>以更细粒度解析对象：一项调查</title>
      <link>http://link.springer.com/10.1007/s11633-022-1404-6</link>
      <description><![CDATA[摘要
细粒度视觉解析，包括细粒度部分分割和细粒度对象识别，由于其在农业等许多实际应用中的重要性而引起了相当大的关注、遥感和空间技术。主要的研究工作遵循不同的范式来处理这些细粒度的子任务，而忽略了这些任务之间的内在关系。此外，鉴于大多数研究仍然碎片化，我们从学习零件关系的新角度对先进工作进行了深入研究。从这个角度来看，我们首先将最近的研究和基准综合与新的分类法相结合。在此基础上，我们重新审视细粒度零件分割和识别任务中的普遍挑战，并通过零件关系学习针对这些重要挑战提出新的解决方案。此外，我们还总结了细粒度视觉解析方面的一些有前景的研究方向，以供未来研究使用。]]></description>
      <guid>http://link.springer.com/10.1007/s11633-022-1404-6</guid>
      <pubDate>Sat, 01 Jun 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>机器学习辅助探索 Affine Deligne–Lusztig 品种</title>
      <link>http://link.springer.com/10.1007/s42543-024-00086-8</link>
      <description><![CDATA[摘要
本文提出了一项新颖的跨学科研究，利用机器学习 (ML) 辅助框架来探索仿射 Deligne–Lusztig 簇 (ADLV) 的几何形状。主要目标是研究 ADLV 不可约成分的非空模式、维数和枚举。我们提出的框架展示了数据生成、模型训练、模式分析和人体检查的递归管道，呈现了机器学习和纯数学研究之间复杂的相互作用。值得注意的是，我们的数据生成过程非常细致，强调选择有意义的子集和适当的特征集。我们证明该框架有潜力加速纯数学研究，从而发现新的猜想和有前途的研究方向，否则可能需要大量时间才能发现。我们重新发现了虚拟维度公式，并为新发现的有关某个维度下限的问题提供了完整的数学证明。此外，我们向读者发出公开邀请，提供计算 ADLV 和 ML 模型的源代码，促进进一步的探索。本文最后分享了宝贵的经验并强调了从这次合作中汲取的教训。]]></description>
      <guid>http://link.springer.com/10.1007/s42543-024-00086-8</guid>
      <pubDate>Wed, 15 May 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>了解 GAN：基础知识、变体、训练挑战、应用和开放问题</title>
      <link>http://link.springer.com/10.1007/s11042-024-19361-y</link>
      <description><![CDATA[摘要
生成对抗网络 (GAN) 是一种在对抗设置中训练生成模型的新颖框架，近年来引起了广泛关注。 GAN 框架的两个相反的神经网络，即生成器和鉴别器，在零和游戏中同时训练，其中生成器生成图像来欺骗经过训练以区分真实图像和合成图像的鉴别器。在本文中，我们对 GAN 的最新发展进行了全面回顾。首先，我们介绍了GAN的各种深层生成模型、基本理论和训练机制以及潜在空间。我们进一步讨论 GAN 的几种代表性变体。尽管 GAN 已成功应用于各种应用，但众所周知，它们的训练非常不稳定。一般来说，人们对 GAN 如何收敛缺乏了解。我们从统计学、博弈论和控制论的角度简要讨论了 GAN 中不稳定和收敛问题的根源，并描述了几种稳定训练的技术。评估 GAN 一直是一项具有挑战性的任务，因为对于哪种度量更适合模型比较尚未达成共识。因此，我们对 GAN 的定量和定性评估措施进行了简要讨论。然后，我们进行了多项实验，根据这些评估指标来比较代表性的 GAN 变体。此外，还简要讨论了 GAN 的应用领域。最后，我们概述了 GAN 中的几个重要的开放问题和未来的研究趋势。]]></description>
      <guid>http://link.springer.com/10.1007/s11042-024-19361-y</guid>
      <pubDate>Tue, 14 May 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>探索使用预训练特征进行立体匹配</title>
      <link>http://link.springer.com/10.1007/s11263-024-02090-y</link>
      <description><![CDATA[摘要
对于许多视觉任务，利用预训练的功能可以提高性能，并持续受益于预训练技术的快速发展。然而，在立体匹配领域，预训练特征的使用尚未得到广泛研究。在本文中，我们首次系统地探索了利用预训练特征进行立体匹配。为了为预训练主干和立体匹配网络的任意组合提供灵活的使用，我们开发了可变形颈部（DN），它将这两个组件的网络架构解耦。 DN的核心思想是利用可变形注意力机制从浅层到深层迭代融合预训练的特征。根据经验，我们的探索揭示了影响使用预训练特征进行立体匹配的关键因素。我们进一步研究了预训练特征的实例级信息的作用，证明它有利于立体匹配，同时可以在基于卷积的特征融合过程中被抑制。基于注意力机制，所提出的 DN 模块有效地利用了预训练特征中的实例级信息。此外，我们提供了对效率与准确性权衡的理解，得出的结论是，考虑到效率，使用预训练的特征也是一个不错的选择。]]></description>
      <guid>http://link.springer.com/10.1007/s11263-024-02090-y</guid>
      <pubDate>Sat, 11 May 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>BTD-RF：使用块项张量分解进行 3D 场景重建</title>
      <link>http://link.springer.com/10.1007/s10489-024-05476-0</link>
      <description><![CDATA[摘要
神经辐射场 (NeRF) 在视图合成任务中表现出出色的性能，但在三维 (3D) 场景重建过程中需要大量内存和模型参数。本文提出了一种块项张量分解辐射场（BTD-RF），这是一种新颖的方法，可以在保持重建质量的同时实现显着的模型压缩。 BTD-RF将高维辐射场分解为低维张量块，得到的值比基线方法小2.21倍。将模型分解为低维张量块，可以使用轻量级多线性注意力机制替代 Transformer 的标准多头注意力，采用元素级乘积并共享参数。这在不影响性能的情况下显着降低了模型的复杂性。对各种数据集的广泛评估表明，与现有方法相比，BTD-RF 实现了卓越的图像重建质量。定量指标和定性评估证实，BTD-RF 生成的图像在结构和感知上都接近真实情况，尽管采用轻量级设计，但仍展现出卓越的性能。 BTD-RF 在三维 (3D) 场景重建的模型大小和重建质量之间提供了令人信服的权衡。其高效的设计使其适合资源受限的应用，同时提供高保真结果，为更广泛的 NeRF 利用铺平了道路。该代码位于 https://github.com/seonbin-kim/BTDRF]]></description>
      <guid>http://link.springer.com/10.1007/s10489-024-05476-0</guid>
      <pubDate>Thu, 09 May 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>神经数字孪生：在虚拟现实中重建复杂的医疗环境以进行空间规划</title>
      <link>http://link.springer.com/10.1007/s11548-024-03143-w</link>
      <description><![CDATA[摘要

目的
专用机器人和手术工具正在增加手术室 (OR) 的复杂性，需要精心准备，尤其是在首次使用技术或设备时。空间规划可以提高效率并提前识别程序障碍，但真正的手术室几乎无法提供优化空间利用率的可用性。需要创建物理设置重建的方法，即数字孪生，以实现虚拟现实中此类复杂环境的沉浸式空间规划。


方法
我们提出了一种基于神经渲染的方法，可以通过随意的视频捕捉创建复杂医疗环境和设备的沉浸式数字孪生，从而实现手术场景的空间规划。为了评估我们的方法，我们通过神经重建重新创建了两个手术室和十个物体，然后与 21 名研究生在最终的虚拟环境中执行规划任务进行用户研究。与相同环境的低视觉复杂度版本相比，我们分析了任务负载、存在、感知效用以及探索和交互行为。


结果
结果显示，使用基于神经重建的环境，感知效用和存在感显着提高，同时感知工作量和探索行为也更高。交互性没有显着差异。


结论
我们探索使用现代重建技术创建复杂医疗环境和物体的数字孪生的可行性。无需专业知识或专用硬件，用户就可以在虚拟环境中创建、探索对象并与之交互。结果表明，在技术上易于实现的同时，具有高感知效用等优点，这可能表明这种方法在空间规划及其他方面的前景。
]]></description>
      <guid>http://link.springer.com/10.1007/s11548-024-03143-w</guid>
      <pubDate>Mon, 06 May 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过 SfM–MVS 从图像序列顺序生成局部 3D 模型之间基于估计相机轨迹的集成</title>
      <link>http://link.springer.com/10.1007/s10015-024-00949-4</link>
      <description><![CDATA[摘要
本文描述了一种三维 (3D) 建模方法，用于从相机获取的图像序列中顺序和空间地了解未知环境中的情况。该方法按时间顺序将图像序列按图像数量划分为子图像序列，通过运动和多视图立体结构（SfM-MVS）从子图像序列生成局部3D模型，并集成模型。每个子图像序列中的图像与先前和后续子图像序列部分重叠。使用根据 SfM-MVS 估计的摄像机轨迹计算出的变换参数，将局部 3D 模型集成到 3D 模型中。在我们的实验中，我们定量比较了集成模型的质量与从批次中的所有图像生成的 3D 模型，以及使用从相机获取的三个真实数据集获得这些模型的计算时间。因此，该方法可以生成高质量的集成模型，并通过 SfM-MVS 与使用批次中所有图像的 3D 模型进行比较，并减少计算时间。]]></description>
      <guid>http://link.springer.com/10.1007/s10015-024-00949-4</guid>
      <pubDate>Wed, 01 May 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于饱和模糊图像的深度非盲去模糊网络</title>
      <link>http://link.springer.com/10.1007/s00521-024-09495-3</link>
      <description><![CDATA[摘要
非盲图像去模糊在低水平视觉领域引起了广泛关注。然而，现有的非盲去模糊方法无法有效处理饱和模糊图像。关键在于饱和模糊图像的退化模型不满足传统模糊图像的线性卷积模型。为了解决这个问题，本文提出了一种新颖的深度非盲去模糊方法，称为饱和图像非盲去模糊网络（SDBNet）。 SDBNet包含两个可训练的子网络，即置信估计网络（CEN）和细节增强网络（DEN）。具体来说，SDBNet使用CEN来估计饱和模糊图像的置信图，用于识别模糊图像中的饱和像素，然后使用置信图和模糊核来恢复模糊图像。最后，我们使用 DEN 来增强恢复图像的边缘和纹理。我们首先预训练 CEN 和 DEN。为了有效地预训练 CEN，我们提出了一个新的鲁棒函数，用于为 CEN 生成标签数据。实验结果表明，与现有的几种非盲去模糊方法相比，SDBNet能够有效恢复饱和模糊图像，更好地恢复模糊图像的纹理、边缘等结构信息。]]></description>
      <guid>http://link.springer.com/10.1007/s00521-024-09495-3</guid>
      <pubDate>Wed, 01 May 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>客座社论：2022 年英国机器视觉会议特刊</title>
      <link>http://link.springer.com/10.1007/s11263-024-02038-2</link>
      <description><![CDATA[]]></description>
      <guid>http://link.springer.com/10.1007/s11263-024-02038-2</guid>
      <pubDate>Wed, 24 Apr 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>高效的 EndoNeRF 重建及其在数据驱动手术模拟中的应用</title>
      <link>http://link.springer.com/10.1007/s11548-024-03114-1</link>
      <description><![CDATA[摘要


目的

医疗保健行业对手术场景的真实建模和高效模拟的需求日益增长。借助有效的可变形手术场景模型，临床医生能够在接近真实病例的场景下进行手术规划和手术训练。然而，实现这一目标的一个重大挑战是缺乏具有精确形状和纹理的高质量软组织模型。为了解决这一差距，我们提出了一个数据驱动的框架，该框架利用新兴的神经辐射场技术来实现高质量的手术重建，并探索其在手术模拟中的应用。



方法

我们首先专注于开发一种基于 NeRF 的快速手术场景 3D 重建方法，以实现最先进的性能。该方法可以显着优于传统的 3D 重建方法，传统的 3D 重建方法无法捕捉大变形并产生细粒度的形状和纹理。然后，我们提出通过闭合网格提取算法自动创建交互式手术模拟环境的管道。
      



结果

我们的实验验证了我们提出的手术场景 3D 重建方法的卓越性能和效率。我们进一步利用重建的软组织进行 FEM 和 MPM 模拟，展示我们的方法在数据驱动的手术模拟中的实际应用。
      



结论

我们提出了一种新颖的基于 NeRF 的重建框架，重点是模拟目的。我们的重建框架有助于高效创建高质量的手术软组织 3D 模型。通过多次软组织模拟的验证，我们表明我们的工作有可能有益于下游临床任务，例如外科教育。
]]></description>
      <guid>http://link.springer.com/10.1007/s11548-024-03114-1</guid>
      <pubDate>Wed, 24 Apr 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用机器学习引导方法检测突尼斯方言自发语音中的言语障碍</title>
      <link>http://link.springer.com/10.1007/s42979-024-02775-8</link>
      <description><![CDATA[摘要
这项工作研究了自然口语理解领域内的不流畅处理任务。我们提出了一种基于转录的方法，具有纯粹的语言特征，用于检测突尼斯方言转录中的不流畅。不流畅处理的任务是检测口语记录中的自发障碍，区分流畅和不流畅的单词。该方法的独创性在于自动处理突尼斯方言自发口语中的多种不流利类型。同样，它包含各种语言特征，例如形态句法标签和单词同义词。音节延长、语音单词、单词片段和简单重复是根据基于规则的方法进行的，而复杂的重复、插入、替换和删除是通过机器学习方法使用基于转换的模型来检测的。我们将基于转换的模型与之前工作中提出的基于序列标记的模型进行比较。实验表明，两个模型均适用于突尼斯方言的不流畅检测任务，F-Measure率分别为79.81%和78.97%。]]></description>
      <guid>http://link.springer.com/10.1007/s42979-024-02775-8</guid>
      <pubDate>Wed, 17 Apr 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于新颖视图合成的协作神经辐射场</title>
      <link>http://link.springer.com/10.1007/s00371-024-03379-2</link>
      <description><![CDATA[摘要
神经辐射场 (NeRF) 通过估计点属性（密度和颜色），然后采用体积渲染方法来合成逼真的新颖视图。然而，准确预测任意点属性对基于 NeRF 的单一模型提出了挑战。这种限制直接影响新颖视图合成的质量。为了解决这个问题，提出了一种基于多个 NeRF 模型的协作策略。该策略首次将多模型级联架构引入NeRF，以实现高质量的新颖视图合成。其目的是利用空间中的级联架构来逐步增强点属性的准确性。级联架构包括点调整和快照融合。具体来说，点调整利用基于 NeRF 的预训练模型来预测空间中每个点的初始密度和颜色。此步骤提供目标场景的初始渲染。然后，这些点的初始密度和颜色直接转移到后续基于 NeRF 的模型中。这一过程指导后续基于 NeRF 的模型专注于初始点属性的细化并合成更真实的新颖视图。最后，快照融合融合多个并行后续基于 NeRF 的模型的输出（称为快照），以合成最终的高质量新颖视图。所提出的策略使用一系列已建立的基于 NeRF 的方法进行了测试，例如 NeRF、Instant-NGP 和 TensoRF。本研究的实验数据来源于真实的360度合成数据集和LLFF数据集。结果表明，所提出的协作策略与已建立的基于 NeRF 的方法可以提高新颖视图合成的质量，超越相应的单一模型。我们的项目页面位于 https:/ /github.com/ZhenyangLiu/Collaborative-Neural-Radiance-Fields-for-Novel-View-Synthesis。]]></description>
      <guid>http://link.springer.com/10.1007/s00371-024-03379-2</guid>
      <pubDate>Fri, 12 Apr 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Twinnet：通过卷积编码器-解码器和多层感知器合成体积渲染图像的耦合功能</title>
      <link>http://link.springer.com/10.1007/s00371-024-03368-5</link>
      <description><![CDATA[摘要
体积可视化在学术界和工业界都发挥着至关重要的作用，因为体积数据广泛应用于医学、地球科学和工程等领域。为了解决体积渲染的复杂性，神经渲染已成为一种潜在的解决方案，有助于生成高质量的体积渲染图像。在本文中，我们提出了 TwineNet，一种专门为体渲染设计的神经网络架构。 TwineNet 通过利用跨多个特征层的缠绕跳跃连接来组合从体数据、传递函数和视点中提取的特征。在 TwineNet 架构的基础上，我们引入了两个神经网络 VolTFNet 和 PosTFNet，它们利用卷积编码器解码器和多层感知器来合成具有新颖传递函数和视点的体积渲染图像。我们的实验结果证明，与最先进的方法相比，我们的模型在生成具有新颖的传递函数和视点的高质量体积渲染图像方面具有优越性。这项研究有助于推动体积渲染领域的发展，并展示了神经渲染技术在科学可视化中的潜力。]]></description>
      <guid>http://link.springer.com/10.1007/s00371-024-03368-5</guid>
      <pubDate>Fri, 12 Apr 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Multi3D：3D 感知多模态图像合成</title>
      <link>http://link.springer.com/10.1007/s41095-024-0422-4</link>
      <description><![CDATA[摘要
3D 感知图像合成已实现高质量和强大的 3D 一致性。现有的 3D 可控生成模型旨在通过单一模态（例如 2D 分割或草图）合成 3D 感知图像，但缺乏精细控制生成内容（例如纹理和年龄）的能力。为了增强用户引导的可控性，我们提出了 Multi3D，一种支持多模态输入的 3D 感知可控图像合成模型。我们的模型可以使用二维标签图（例如分割图或草图图）来控制生成图像的几何形状，同时通过文本描述来调节生成图像的外观。为了证明我们方法的有效性，我们在多个数据集上进行了实验，包括 CelebAMask-HQ、AFHQ-cat 和 shapenet-car。定性和定量评估表明，我们的方法优于现有的最先进方法。
      



]]></description>
      <guid>http://link.springer.com/10.1007/s41095-024-0422-4</guid>
      <pubDate>Wed, 03 Apr 2024 00:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>