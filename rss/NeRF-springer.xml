<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最新结果</title>
    <link>http://link.springer.com</link>
    <description>Springer 提供的最新内容</description>
    <lastBuildDate>Sat, 06 Apr 2024 03:12:39 GMT</lastBuildDate>
    <item>
      <title>Multi3D：3D 感知多模态图像合成</title>
      <link>http://link.springer.com/10.1007/s41095-024-0422-4</link>
      <description><![CDATA[摘要
3D 感知图像合成已实现高质量和强大的 3D 一致性。现有的 3D 可控生成模型旨在通过单一模态（例如 2D 分割或草图）合成 3D 感知图像，但缺乏精细控制生成内容（例如纹理和年龄）的能力。为了增强用户引导的可控性，我们提出了 Multi3D，一种支持多模态输入的 3D 感知可控图像合成模型。我们的模型可以使用二维标签图（例如分割图或草图图）来控制生成图像的几何形状，同时通过文本描述来调节生成图像的外观。为了证明我们方法的有效性，我们在多个数据集上进行了实验，包括 CelebAMask-HQ、AFHQ-cat 和 shapenet-car。定性和定量评估表明，我们的方法优于现有的最先进方法。
      



]]></description>
      <guid>http://link.springer.com/10.1007/s41095-024-0422-4</guid>
      <pubDate>Wed, 03 Apr 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>不成对语义神经人图像合成</title>
      <link>http://link.springer.com/10.1007/s00371-024-03331-4</link>
      <description><![CDATA[摘要
姿势引导的人物图像合成是一项具有挑战性的任务，旨在生成外观与源图像相同但姿势与目标图像相同的逼真人物图像。由于多视图信息的遗漏，现有的方法经常会出现明显的伪影，并且某些方法在训练过程中对源-目标图像配对的要求进一步限制了模型的应用。为了解决这些问题，我们提出了一种名为 SNPIS 的语义神经人体图像合成框架，它利用神经辐射场（NeRF）从多视图源图像和目标语义图合成任意姿势的高保真人体图像。首先，我们引入语义镜像方向调整，强制采样点聚焦于人体，有效抑制背景干扰并增强人体细节。然后，我们设计了一种基于 NeRF 的外观形状解耦生成对抗网络，该网络将多视图源图像和相应语义图生成的共享体积的外观和形状分开。最后，我们使用获得的解耦生成器来合成由目标语义图引导的人类图像，采用外观反转，并在语义一致性约束下优化姿势重建。实验结果表明，我们的方法不仅优于现有的不配对姿势引导人体图像合成方法，而且还可以与许多配对方法竞争。]]></description>
      <guid>http://link.springer.com/10.1007/s00371-024-03331-4</guid>
      <pubDate>Tue, 02 Apr 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从未曝光图像中学习神经辐射场的鲁棒多尺度表示</title>
      <link>http://link.springer.com/10.1007/s11263-023-01936-1</link>
      <description><![CDATA[摘要
我们针对计算机视觉中基于神经图像的渲染问题引入了一种改进的解决方案。给定在火车时从自由移动的摄像机拍摄的一组图像，所提出的方法可以在测试时从新的视角合成场景的真实图像。本文提出的关键思想是（i）通过强大的管道从未摆出的日常图像中恢复准确的相机参数在神经新视图合成问题中同样重要； (ii) 在不同分辨率下对对象的内容进行建模更为实用，因为在日常的未摆姿势的图像中很可能出现戏剧性的相机运动。为了整合关键思想，我们利用了场景刚性、多尺度神经场景表示和单图像深度预测的基础知识。具体来说，所提出的方法使得相机参数在基于神经场的建模框架中是可学习的。通过假设每个视图的深度预测按比例给出，我们限制了连续帧之间的相对姿势。根据相对姿势，绝对相机姿势估计是通过多尺度神经场网络内基于图神经网络的多个运动平均来建模的，从而产生单个损失函数。优化引入的损失函数可以从未摆出的图像中提供相机内在、外在和图像渲染。我们通过示例证明，对于从日常获取的未摆姿势的多视图图像中准确建模多尺度神经场景表示的统一框架，在场景表示框架内进行精确的相机姿态估计同样重要。如果不考虑相机姿态估计管道中的鲁棒性措施，多尺度混叠伪影的建模可能会适得其反。我们在几个基准数据集上进行了广泛的实验，以证明我们的方法的适用性。]]></description>
      <guid>http://link.springer.com/10.1007/s11263-023-01936-1</guid>
      <pubDate>Mon, 01 Apr 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于实时距离场加速的大型运动场自由视点视频合成</title>
      <link>http://link.springer.com/10.1007/s41095-022-0323-3</link>
      <description><![CDATA[摘要
自由视点视频允许用户从任何虚拟角度观看物体，创造身临其境的视觉体验。该技术增强了多媒体表演的交互性和自由度。然而，许多自由视点视频合成方法很难满足实时、高精度的要求，特别是对于面积较大、运动物体较多的运动场。为了解决这些问题，我们提出了一种基于距离场加速的自由视点视频合成方法。其中心思想是融合多视点距离场信息并利用其自适应调整搜索步长。自适应步长搜索有两种用途：用于多目标三维表面的快速估计，以及基于全局遮挡判断的合成视图渲染。我们使用并行计算进行交互式显示、使用 CUDA 和 OpenGL 框架来实现我们的想法，并使用真实世界和模拟实验数据集进行评估。结果表明，所提出的方法可以在大型运动场上以 25 fps 渲染具有多个对象的自由视点视频。此外，我们合成的新颖视点图像的视觉质量超过了最先进的基于神经渲染的方法。
      



]]></description>
      <guid>http://link.springer.com/10.1007/s41095-022-0323-3</guid>
      <pubDate>Mon, 01 Apr 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>体积可重新照明面的更深入分析</title>
      <link>http://link.springer.com/10.1007/s11263-023-01899-3</link>
      <description><![CDATA[摘要
人像视点和照明编辑是 VR/AR、电影和摄影等多种应用中的一个重要问题。几何和照明的全面知识对于获得逼真的结果至关重要。当前的方法无法在 3D 中显式建模，同时处理单个图像的视点和照明编辑。在本文中，我们提出了 VoRF，这是一种新颖的方法，甚至可以将单个肖像图像作为输入，并在可以从任意视点观看的新颖照明下重新照亮人头。 VoRF 将人体头部表示为连续的体积场，并使用基于坐标的 MLP 以及用于身份和照明的单独潜在空间来学习人体头部的先验模型。先前的模型是通过自动解码器的方式在不同类别的头部形状和外观上学习的，从而允许 VoRF 从单个输入图像泛化到新的测试身份。此外，VoRF 具有反射 MLP，它使用先前模型的中间特征在新颖的视图下渲染一次一光 (OLAT) 图像。我们通过将这些 OLAT 图像与目标环境图相结合来合成新颖的照明。定性和定量评估证明了 VoRF 在重新照明和新颖视图合成方面的有效性，即使应用于不受控制的照明下看不见的物体也是如此。这项工作是 Rao 等人的延伸。 （VoRF：体积可重新照明面孔 2022）。我们对我们的模型进行了广泛的评估和烧蚀研究，并提供了一个应用程序，可以使用文本输入重新照亮任何面孔。]]></description>
      <guid>http://link.springer.com/10.1007/s11263-023-01899-3</guid>
      <pubDate>Mon, 01 Apr 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>FFEINR：时空超分辨率的流特征增强隐式神经表示</title>
      <link>http://link.springer.com/10.1007/s12650-024-00959-1</link>
      <description><![CDATA[摘要
大规模数值模拟能够生成高达 TB 甚至 PB 的数据。作为一种有前途的数据缩减方法，超分辨率（SR）已在科学可视化界得到广泛研究。然而，它们大多数都是基于深度卷积神经网络或生成对抗网络，需要在构建网络之前确定比例因子。导致单次训练仅支持固定因子，泛化能力较差。为了解决这些问题，本文提出了一种用于流场数据时空超分辨率的流特征增强隐式神经表示（FFEINR）。它可以在模型结构和采样分辨率方面充分利用隐式神经表示。神经表示基于具有周期性激活函数的全连接网络，这使我们能够获得轻量级模型。学习到的连续表示可以将低分辨率流场输入数据解码为任意空间和时间分辨率，从而允许灵活的上采样。通过引入输入层的特征增强来促进 FFEINR 的训练过程，这补充了流场的上下文信息。为了证明该方法的有效性，通过设置不同的超参数在不同的数据集上进行了一系列实验。结果表明，FFEINR取得了明显优于三线性插值方法的结果。

图形摘要






]]></description>
      <guid>http://link.springer.com/10.1007/s12650-024-00959-1</guid>
      <pubDate>Mon, 01 Apr 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过 SfM–MVS 从图像序列顺序生成局部 3D 模型之间基于估计相机轨迹的集成</title>
      <link>http://link.springer.com/10.1007/s10015-024-00949-4</link>
      <description><![CDATA[摘要
本文描述了一种三维 (3D) 建模方法，用于从相机获取的图像序列中顺序和空间地了解未知环境中的情况。该方法按时间顺序将图像序列按图像数量划分为子图像序列，通过运动和多视图立体结构（SfM-MVS）从子图像序列生成局部3D模型，并集成模型。每个子图像序列中的图像与先前和后续子图像序列部分重叠。使用根据 SfM-MVS 估计的摄像机轨迹计算出的变换参数，将局部 3D 模型集成到 3D 模型中。在我们的实验中，我们使用从相机获取的三个真实数据集，定量比较了集成模型与从批次中所有图像生成的 3D 模型的质量以及获得这些模型的计算时间。因此，该方法可以生成高质量的集成模型，并通过 SfM-MVS 与使用批次中所有图像的 3D 模型进行比较，并减少计算时间。]]></description>
      <guid>http://link.springer.com/10.1007/s10015-024-00949-4</guid>
      <pubDate>Mon, 01 Apr 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于可微渲染的动态海洋反建模</title>
      <link>http://link.springer.com/10.1007/s41095-023-0338-4</link>
      <description><![CDATA[摘要
学习和推断捕获的 2D 场景的潜在运动模式，然后重新创建与现实世界自然现象一致的动态演化，这对图形和动画具有很高的吸引力。为了弥合虚拟和现实环境之间的技术差距，我们专注于视觉一致和属性可验证的海洋的逆向建模和重建，利用深度学习和可微物理来学习几何并以自我监督的方式构成波浪。首先，我们使用两个网络推断分层几何，这两个网络通过可微渲染器进行了优化。我们通过配备可微分海洋模型的网络从推断的几何序列中提取波浪分量。然后，可以使用重建的波浪分量来演化海洋动力学。通过大量的实验，我们验证了我们的新方法在几何重建和波浪估计方面都能产生令人满意的结果。此外，新框架具有逆向建模潜力，可促进大量图形应用，例如快速生成物理精确的场景动画以及由真实海洋场景引导的编辑。
      



]]></description>
      <guid>http://link.springer.com/10.1007/s41095-023-0338-4</guid>
      <pubDate>Mon, 01 Apr 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>将体积和表面渲染与全局照明缓存相结合</title>
      <link>http://link.springer.com/10.1007/s00371-023-02932-9</link>
      <description><![CDATA[摘要
我们提出了一种具有全局照明缓存的组合体积和表面渲染技术。我们的方法使用体积路径追踪来计算全局照明体积和用于渲染等值面的局部着色模型。通过结合这两种可视化方法，我们增强了表面的显示和照明，同时保留了参与媒体的物理真实照明。为了实现实时性能并避免在相机视图变化时重新计算图像，我们增量计算全局照明体积并将投影推迟到后面的步骤。我们通过将等值面渲染的不同局部着色模型与完整体积路径追踪的结果以及我们技术的非缓存变体进行比较来评估我们的技术。结果表明，缓存和非缓存变体的性能相当好，而缓存变体具有独立于相机视图的额外优势。此外，我们表明我们的方法比体积路径追踪更好地强调体积内的表面。]]></description>
      <guid>http://link.springer.com/10.1007/s00371-023-02932-9</guid>
      <pubDate>Mon, 01 Apr 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于城市场景新颖视图合成的多视图立体调节 NeRF</title>
      <link>http://link.springer.com/10.1007/s00371-024-03321-6</link>
      <description><![CDATA[摘要
神经辐射场 (NeRF) 将场景编码为神经表示，在单个对象和小空间区域上展示了令人印象深刻的新颖视图合成质量。然而，当面对城市室外环境时，NeRF 受到单个 MLP 容量和输入视图不足的限制，导致几何形状不正确，阻碍了真实渲染的制作。在本文中，我们提出了 MVSRegNeRF，这是专注于大规模自动驾驶场景的神经辐射场的扩展。我们采用传统的基于补丁匹配的多视图立体（MVS）方法来生成密集的深度图，我们利用它来调节 NeRF 的几何优化。我们还将多分辨率哈希编码集成到我们的神经场景表示中，以加速训练过程。由于我们的方法相对精确的几何约束，我们在现实世界的大规模街道场景上实现了高质量的新颖视图合成。我们在 KITTI-360 数据集上的实验表明，MVSRegNeRF 在新颖视图外观合成任务中优于最先进的方法。
      ]]></description>
      <guid>http://link.springer.com/10.1007/s00371-024-03321-6</guid>
      <pubDate>Wed, 27 Mar 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于隐式表示的 3D 形状生成的最新进展</title>
      <link>http://link.springer.com/10.1007/s44267-024-00042-1</link>
      <description><![CDATA[摘要
各种技术已经被开发和引入，以满足为虚拟现实和增强现实等高级应用创建三维 (3D) 内容的迫切需求。然而，与标准二维 (2D) 图像数据相比，3D 形状的复杂性对其表示和生成提出了更大的挑战。文献中已经提出了不同类型的表示，包括网格、体素和隐函数。由于辐射场表示的出现，隐式表示引起了研究人员的极大兴趣，它允许同时重建几何形状和外观。随后的工作成功地将传统的带符号距离场与隐式表示联系起来，最近，三平面提供了使用 2D 内容生成器生成辐射场的可能性。已经发表了许多专注于这些特定研究领域的文章。本文对基于隐式表示的 3D 形状生成的最新研究进行了全面分析，并根据所采用的表示和生成架构对这些研究进行了分类。详细检查每个表示的属性。还提出了该领域未来研究的潜在途径。]]></description>
      <guid>http://link.springer.com/10.1007/s44267-024-00042-1</guid>
      <pubDate>Mon, 25 Mar 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于多尺度哈希编码的神经几何表示</title>
      <link>http://link.springer.com/10.1007/s41095-023-0340-x</link>
      <description><![CDATA[摘要
最近，基于神经隐式函数的表示引起了越来越多的关注，并被广泛用于使用可微神经网络来表示表面。然而，使用现有的神经几何表示从点云或多视图图像进行表面重建仍然存在计算速度慢和精度差的问题。为了缓解这些问题，我们提出了一种基于多尺度哈希编码的神经几何表示，它有效且高效地将表面表示为带符号的距离场。我们新颖的神经网络结构仔细地将低频傅里叶位置编码与多尺度哈希编码结合起来。相应地重新设计了几何网络的初始化和渲染模块的几何特征。我们的实验表明，所提出的表示对于重建具有数百万个点的点云来说至少快 10 倍。它还显着提高了多视图重建的速度和准确性。我们的代码和模型可以在 https://github.com/Dengzhi-中国科学技术大学/神经几何重建。
      



]]></description>
      <guid>http://link.springer.com/10.1007/s41095-023-0340-x</guid>
      <pubDate>Fri, 22 Mar 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大学生的自闭症、性别和身份</title>
      <link>http://link.springer.com/10.1007/s44202-024-00116-7</link>
      <description><![CDATA[摘要

目的
本研究旨在调查出生时指定女性 (AFAB) 自闭症患者如何看待自己的自闭症和性别认同及其关系。


方法
这是一项基于访谈的定性研究，对象为 10 名自闭症大学生，出生时被指定为女性。参与者分享了他们在自闭症诊断、性别认同和自我意识方面的经验。


结果
该研究发现了四个主题： (i) 存在多种类型的诊断障碍，以及其中一些障碍的缓解因素； (ii) 各种动机导致参与者进行伪装，但负面影响促使许多人减少伪装行为； (iii) 自闭症与性别观念和行为有关； (iv) 自闭症以性别以外的多种方式影响身份。


结论
这项研究对自闭症与性别和跨性别身份的关系进行了观察并提出了问题。这项研究在很大程度上同意并建立在现有文献中发现的模式的基础上，同时将自闭症患者的声音添加到文献中。
]]></description>
      <guid>http://link.springer.com/10.1007/s44202-024-00116-7</guid>
      <pubDate>Thu, 21 Mar 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>机器视觉中的综合数据增强方法综述</title>
      <link>http://link.springer.com/10.1007/s11633-022-1411-7</link>
      <description><![CDATA[摘要
解决计算机视觉问题的标准方法是使用代表目标任务的大规模图像数据集来训练深度卷积神经网络 (CNN) 模型。然而，在许多场景中，为目标任务获取足够的图像数据通常具有挑战性。数据增强是缓解这一挑战的一种方法。常见的做法是以所需的方式显式地转换现有图像，以创建实现良好泛化性能所需的训练数据量和可变性。在无法访问目标域数据的情况下，一个可行的解决方法是从头开始合成训练数据，即合成数据增强。本文对合成数据增强技术进行了广泛的回顾。它涵盖了基于真实 3D 图形建模、神经风格迁移 (NST)、差分神经渲染以及使用生成对抗网络 (GAN) 和变分自动编码器 (VAE) 的生成建模的数据合成方法。对于每一类方法，我们重点关注重要的数据生成和增强技术、一般应用范围和特定用例，以及现有的限制和可能的解决方法。此外，我们还提供了用于训练计算机视觉模型的常见合成数据集的摘要，重点介绍了主要功能、应用领域和支持的任务。最后，我们讨论合成数据增强方法的有效性。由于这是第一篇详细探讨合成数据增强方法的论文，我们希望为读者提供必要的背景信息以及对现有方法及其随之而来的问题的深入了解。]]></description>
      <guid>http://link.springer.com/10.1007/s11633-022-1411-7</guid>
      <pubDate>Wed, 20 Mar 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过学习自适应多模态先验来生成形状</title>
      <link>http://link.springer.com/10.1007/s00371-024-03303-8</link>
      <description><![CDATA[摘要
使用深度生成模型进行图像创建的最新进展引起了人们的极大兴趣和进展，但自动三维形状创建领域在很大程度上尚未开发，并激发了巨大的兴趣跨多个学科的研究活动。我们使用被描述为体积网格的几何数据将一种先前命名的后验变分混合添加到对抗网络中。我们的主要贡献是将一种称为后验变分混合先验的新型先验引入到对抗性网络中，称为VampPrior-3DGAN，以数学原理的方式。具体来说，我们利用编码器作为正则化器来惩罚缺失模式，同时引入后验先验的变分混合作为 GAN 的潜变量分布，以动态自适应地更新其先验分布。这种架构背后的关键直觉是，潜在变量应该保留有关数据的信息，以尽量减少先前假设的不当影响。这种对 GAN 框架看似简单的修改却出人意料地有效，尽管使用有限的数据进行训练，但所产生的模型仍可实现生成样本的多样性。通过对 VampPrior-3DGAN 的潜在概率流形进行采样，可以轻松生成逼真的 3D 对象。为了验证，我们将我们的方法应用于三维体积生成、单个 RGB 图像的重建和单个透视图的部分形状完成等领域的任务，并表明它与状态相同或优于状态 -定量和定性方面的最先进方法。]]></description>
      <guid>http://link.springer.com/10.1007/s00371-024-03303-8</guid>
      <pubDate>Wed, 20 Mar 2024 00:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>