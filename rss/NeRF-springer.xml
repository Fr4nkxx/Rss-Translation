<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最新结果</title>
    <link>http://link.springer.com</link>
    <description>Springer可用的最新内容</description>
    <lastBuildDate>Sun, 16 Mar 2025 18:19:03 GMT</lastBuildDate>
    <item>
      <title>Easyvis：用于腹腔镜手术盒培训师的实时3D可视化软件系统</title>
      <link>https://link.springer.com/article/10.1007/s13304-025-02153-w</link>
      <description><![CDATA[ easyvis是一种新兴的沉浸式3D腹腔镜可视化系统，可提高腹腔镜手术的效率。它将多个微型摄像头和光源与手术端口整合在一起，以在所需的角度提供手术内手术的视觉。在这项工作中，我们在腹腔镜手术训练盒环境中使用Easyvis微型摄像机组装来开发一种可视化算法，并具有简化的训练任务，以验证这种新技术的可行性。由于大多数腹腔镜手术工具是刚体的对象，因此可以离线获取它们的3D形状。我们开发了2D对象检测和跟踪算法，以获取每个对象的2D姿势和3D融合算法，以使用估计的2D姿势来估计和跟踪每个对象的3D姿势。然后，与每个对象的获得的3D模型一起，我们能够使用3D表面模型（离线获取）和从单个微型胶片中获取的图像在所需视图处渲染每个对象。除前景刚性对象外，背景3D模型是使用结构化的灯光和运动结构来获取的。与前景物体的快速运动相比，假定背景变化缓慢。因此，背景3D模型仅需要偶尔更新。我们的渲染算法能够整合前景和背景3D模型，以促进从理想的视角渲染基于图像的渲染。我们进行了实验以验证渲染图像的准确性和质量。]]></description>
      <guid>https://link.springer.com/article/10.1007/s13304-025-02153-w</guid>
      <pubDate>Sun, 16 Mar 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>GRPOSENET：使用稀疏RGB视图的可推广且可靠的6D对象姿势估计网络</title>
      <link>https://link.springer.com/article/10.1007/s00371-025-03852-6</link>
      <description><![CDATA[六度的自由对象姿势估计在各种计算机视觉和机器人技术任务中起着至关重要的作用。现有方法通常很大程度上依赖CAD模型和实质性的先验信息，从而将其概括限制为在开放场景中看不见的对象。为了解决此限制，我们提出了GRPOSENET，这是一个可推广且可靠的6D对象姿势估计网络，可以仅使用带有参考姿势的稀疏RGB图像来预测看不见的对象的姿势。 GRPOSENET包括一个开放世界检测器，一个观点选择器和自适应多尺度炼油厂。开放世界检测器利用预先训练的大型模型进行零拍分段和特征提取，克服检测和与看不见的对象的匹配错误。视点选择器使用我们设计的相似性网络选择最初的参考视图以进行初始姿势估计。自适应多尺度炼油厂通过迭代更新旋转和基于多尺度特征和自适应重量的翻译残差而进一步完善了姿势。基准数据集和我们可靠的测试数据集RBMOP的广泛实验表明，GRPOSENET实现了最新的性能，显示出极好的概括和鲁棒性，可对看不见的对象和稀疏视图。这些代码和数据集可在： https://github.com/kiers.com/kiersas/grposenet 。]]></description>
      <guid>https://link.springer.com/article/10.1007/s00371-025-03852-6</guid>
      <pubDate>Tue, 11 Mar 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LFVGS：轻巧的高斯拆卸方法，用于几个镜头综合</title>
      <link>https://link.springer.com/article/10.1007/s11227-025-07114-z</link>
      <description><![CDATA[尽管通过3D高斯拆卸实现了新型视图的显着进步，但其依赖于致密的输入视图和高存储需求限制了其适用性。为了应对这一挑战，这项研究提出了LFVGS，这是一个基于3DGS技术的轻量级小说综合框架。 LFVGS可以实现低成本，高质量的新型视图综合，并限制了有限的输入视图（只有三种），同时大大降低了存储要求。为了通过稀疏输入来实现高性能，我们引入了两种关键策略。首先，为了减轻初始输入不足的问题，我们利用距离得分和不透明度阈值在动态而密集地将新高斯人插入最初的高斯原始人中，从而避免了在稀疏视图约束下表示不足表示的问题。其次，为了加强因稀疏输入视图所施加的几何约束，我们将深度先验纳入了监督，利用全球到本地的深度正规化，以减少渲染深度和深度先验之间的差异，从而纠正场景几何形状。最后，通过使用简单的MLP表示依赖视图的颜色，复杂反射区域和局部对象轮廓的合成质量得到显着改善，而模型存储开销显着降低。实验结果表明，LFVGS在LLFF，MIPNERF360和SHINY数据集上实现了出色的总体性能，从而实现了完全端到端的轻质优化过程。该代码可在： https://github.com/leexiaotong1/lfvgs   ]]></description>
      <guid>https://link.springer.com/article/10.1007/s11227-025-07114-z</guid>
      <pubDate>Wed, 05 Mar 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Phydiisp：弱光机构视觉的物理学导致管道</title>
      <link>https://link.springer.com/article/10.1007/s11760-025-03918-x</link>
      <description><![CDATA[在弱光环境中，机器视觉任务通常会遭受性能退化，因为传统的图像信号处理（ISP）管道主要针对图像质量指标进行优化，例如峰值信噪比和结构相似性指数，这些指数无法充分满足这些应用程序的特定需求。在挑战性照明条件下，现有方法在增强计算机视觉任务所需的关键图像特征方面缺乏。为了解决这个问题，我们介绍了Phydiisp，这是一条物理引导的，可区分的ISP管道，旨在在弱光场景中提高机器视觉性能。 Phydiisp将传统的ISP设计原理与物理见解相结合，包括用于原始RGB转换的表演，全球音调映射以调整整体亮度以及基于多尺度视网膜的增强功能，以应对低光挑战。实验结果表明，通过有效增强关键图像特征，Phydiisp在对象检测准确性中的现有ISP方法优于现有的ISP方法。此外，当经过L1损失训练并与黑光环境的数据集和真正的原始型RGB转换相符时，它表明了竞争性的图像质量。这些结果证实了Phydiisp是现实世界中低光机器视觉应用的可行有效解决方案。]]></description>
      <guid>https://link.springer.com/article/10.1007/s11760-025-03918-x</guid>
      <pubDate>Wed, 05 Mar 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>关于二十年代深立体声匹配的调查</title>
      <link>https://link.springer.com/article/10.1007/s11263-024-02331-0</link>
      <description><![CDATA[立体声匹配即将达到半个世纪的历史，但由于深度学习，在过去十年中迅速发展。尽管2010年代末的先前调查涵盖了这次革命的第一阶段，但最后五年的研究为该领域带来了进一步的突破性进步。本文旨在以两倍的方式填补这一空白：首先，我们对深度立体声匹配的最新发展进行了深入的检查，重点是在2020年代重新定义领域的开创性建筑设计和开创性的范式；其次，我们对与这些进步一起出现的关键挑战进行了详尽的分析，为这些问题提供了全面的分类法，并探索了为解决这些问题而提出的最先进的技术。通过审查建筑创新和主要挑战，我们提供了深入立体声匹配的整体视野，并突出了需要进一步调查的特定领域。为了随附这项调查，我们维护了一个定期更新的项目页面，该页面在我们很棒的匹配存储库中对Deep Stereo匹配的论文进行了分类。]]></description>
      <guid>https://link.springer.com/article/10.1007/s11263-024-02331-0</guid>
      <pubDate>Wed, 26 Feb 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>教机器人建立自己的模拟</title>
      <link>https://link.springer.com/article/10.1038/s42256-025-01006-w</link>
      <description><![CDATA[视觉的出现催化了关键的进化进步，使生物不仅能够感知，而且可以与环境聪明地互动。机器人系统的演变反映了这种转变，在该演变中，利用视力模拟和预测自己的动态的能力标志着朝着自主性和自我意识飞跃。人类利用愿景来记录经验并内部模拟潜在的动作。例如，我们可以想象，如果我们站起来并举起手臂，身体将形成“ T”形状而无需身体运动。同样，仿真允许机器人计划和预测潜在动作的结果而无需执行。在这里，我们介绍了一个自制的学习框架，以使机器人仅使用简短的原始视频数据来建模和预测其形态，运动学和运动控制，从而消除了对广泛的现实数据收集和运动学先验的需求。通过观察自己的动作，类似于人类在镜子中观看反射，机器人学会了模拟自己并预测各种任务的空间运动的能力。我们的结果表明，这种自学模拟不仅可以实现准确的运动计划，而且还允许机器人检测异常并从损害中恢复。]]></description>
      <guid>https://link.springer.com/article/10.1038/s42256-025-01006-w</guid>
      <pubDate>Tue, 25 Feb 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>单阶段卷积神经辐射场</title>
      <link>https://link.springer.com/article/10.1007/s10044-025-01427-8</link>
      <description><![CDATA[从多个图像捕获的新型视图综合是计算机视觉和计算摄影的关键研究主题，因为其应用范围很广。神经辐射场通过使用多层感知器优化连续体积场景函数来显着提高性能。尽管神经辐射场及其修改提供了高质量的场景，但由于其层次结构包括粗网络，它们在优化精确的辐射场方面有限制。它们还需要许多参数，通常不考虑射线上样本之间的局部和全球关系。本文提出了一个统一的单阶段范式，该范式共同了解了使用卷积神经网络的三维射线的相对位置及其对复杂场景的相对颜色和密度的相对位置，以减少噪声和无关的特征并防止过度拟合。包括消融测试在内的实验结果验证了所提出的方法比当前最新模型合成新观点的鲁棒性。该代码可在 https://github.com/xkdytk/scorf 。]]></description>
      <guid>https://link.springer.com/article/10.1007/s10044-025-01427-8</guid>
      <pubDate>Fri, 21 Feb 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>一个循环中的图像垫和3D重建</title>
      <link>https://link.springer.com/article/10.1007/s11263-024-02341-y</link>
      <description><![CDATA[最近的3D对象重建方法依靠用户输入alpha哑光来删除背景并重建对象，因为自动预测的alpha mattes不够准确。为了实现自动3D对象重建，我们提出了一个用于图像垫和3D对象重建（关节MR）的联合框架。它迭代地将所有图像的信息整合到对象提示图中，以帮助图像垫模型预测每个图像的更好的alpha哑光，进而改善3D对象重建性能。从理论上讲，我们的框架的融合是可以保证的。我们进一步提出了一种将任意图像矩阵模型转换为基于提示的方法的方法。我们从多视图图像和来自单眼视频的3D动态对象重建的3D对象重建进行实验。还测试了3D对象重建模型和图像底漆模型的不同组合。实验结果表明，我们的框架仅略微增加了计算成本，但显着提高了所有模型组合的性能，表明其兼容性和效率。我们的代码，模型和数据可在 https://github.com/xinshuangl/jointmr/jointmr 。]]></description>
      <guid>https://link.springer.com/article/10.1007/s11263-024-02341-y</guid>
      <pubDate>Fri, 21 Feb 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>报告</title>
      <link>https://link.springer.com/article/10.1007/s41064-025-00335-0</link>
      <description><![CDATA[]]></description>
      <guid>https://link.springer.com/article/10.1007/s41064-025-00335-0</guid>
      <pubDate>Wed, 12 Feb 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MBS-NERF：从运动毛线稀疏图像中重建尖锐的神经辐射场</title>
      <link>https://link.springer.com/article/10.1038/s41598-025-88614-z</link>
      <description><![CDATA[使用多层感知器（MLP）进行隐式场景表示，神经辐射场（NERF）的最新进展可以从新的角度综合现实观点。但是，输入图像的数量和质量的降解可能会导致场景重建失败，并且难以合成高质量的视图。为了解决这些局限性，本文提出了基于NERF的框架（MBS-NERF），该框架可以从有限数量的运动型输入图像中重建尖锐的NERF，以进行高质量的视图合成。该框架将深度信息集成为限制，以应对缺乏足够的视图信息，并引入运动模糊模拟模块（MBSM）以模拟运动模糊的物理形成过程。我们在曝光过程中进一步介绍摄像头轨迹优化，以稳健地摄像机位置。考虑到光度一致性和深度监督，MBS-NERF经过彻底训练。关于合成和真实数据集的综合实验验证了该模型在重建尖锐的NERF和从稀疏，运动毛发输入中实现高质量视图合成的有效性。]]></description>
      <guid>https://link.springer.com/article/10.1038/s41598-025-88614-z</guid>
      <pubDate>Wed, 12 Feb 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于NERF的单眼胸腔镜3D场景重建框架</title>
      <link>https://link.springer.com/article/10.1007/s11517-025-03316-y</link>
      <description><![CDATA[抽象的
              随着在医疗程序中越来越多地使用基于图像的3D重建，准确的场景重建在手术导航和辅助治疗中起着至关重要的作用。但是，单调的颜色，有限的图像特征以及胸腔镜场景的明显亮度波动使特征点匹配过程在于传统的3D重建方法依赖，不稳定和不可靠的过程。它为准确的3D重建带来了巨大的挑战。在这项研究中，提出了一种单眼胸腔镜面场景的隐式3D重建的新方法。该方法将预训练的度量深度估计模型与神经辐射场（NERF）技术相结合，并使用密集的猛击来准确计算相机姿势。为了确保深度值的准确性以及重建场景的结构一致性，将深度和正常约束添加到NERF网络的原始颜色约束中，以实现高质量的场景重建结果。我们在害怕的数据集和临床数据集上进行了实验。在与其他方法进行比较之后，本文的深度估计精度和点云重建质量优于现有方法。本文中的方法可以提供更准确的3D重建，对复杂的胸外科手术场景进行了更大的重建，这可以显着提高手术导航的准确性和治疗功效。
            
              图形摘要
               ]]></description>
      <guid>https://link.springer.com/article/10.1007/s11517-025-03316-y</guid>
      <pubDate>Sat, 08 Feb 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用量化图像对ORB-SLAM3的性能评估</title>
      <link>https://link.springer.com/article/10.1007/s10015-025-01006-4</link>
      <description><![CDATA[视觉同时定位和映射（SLAM）是机器人进行高精度导航的关键技术，从而增加了研究人员之间的重点以提高其准确性。但是，SLAM准确性的提高总是以增加内存足迹为代价，这限制了在约束硬件资源下运行的设备的长期操作。量化方法的应用被提出是解决此问题的有前途解决方案。由于量化会导致绩效降解，因此定量评估潜在降解和存储器节省之间的权衡至关重要，以评估其对视觉大满贯的实用性。本文介绍了一种评估量化方法对视觉猛击的影响的机制，并将其应用于评估三种不同量化方法对ORB-SLAM3的影响。具体而言，我们检查了两种静态量化方法和一种称为误差扩散的动态量化方法，该方法可以伪造图像阴影信息。本文得出的结论是，错误扩散在误差扩散滤波器中具有受控的权重参数可以抑制降解并减少内存足迹，从而在动态环境中证明了其有效性。]]></description>
      <guid>https://link.springer.com/article/10.1007/s10015-025-01006-4</guid>
      <pubDate>Fri, 07 Feb 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>单眼3D人类姿势估计中的深度学习：当代技术和应用的系统评价</title>
      <link>https://link.springer.com/article/10.1007/s11042-024-20495-2</link>
      <description><![CDATA[ 3D人姿势估计是应用不可或缺的，包括活动识别，动画生成和绩效分析。深度学习技术已大大推进了3D人类姿势估计的领域，从而获得了更精确和准确的结果。至关重要的是，尽管有这些进步，但在现实生活中如何使用这些技术仍然存在局限性。准确地计算出多个受试者或具有挑战性的情况，例如户外环境，迅速发展的场景或受试者太小或离相机太远的情况，仍然是一个挑战。当使用单眼相机设置时，这些问题尤其明显，这可能会使获得精确的结果变得更加困难。该系统评价综合了单眼3D姿势估计的最新趋势，详细介绍了过去十年中使用的工具，技术，方法和策略。在432个首次出版物中，选择了103份来自学术数据库的同行评审论文，从而提供了对该领域的进步和当前趋势的见解。该研究详细介绍了方法论的演变，重点是基于回归和基于检测的方法，并讨论了普遍的数据集和性能指标。这些发现强调了需要解决深度歧义和遮挡现实世界适用性等挑战的必要性。这项全面的综述旨在了解3D人类姿势估计的轨迹和前景，对各种应用的影响。]]></description>
      <guid>https://link.springer.com/article/10.1007/s11042-024-20495-2</guid>
      <pubDate>Thu, 06 Feb 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>机器学习随机森林模型用于构建与库陶化相关的基因签名，以预测胃癌的预后</title>
      <link>https://link.springer.com/article/10.1038/s41598-025-88812-9</link>
      <description><![CDATA[胃癌（GC）是最常见的肿瘤之一。其预后不佳的原因之一是GC细胞可以抵抗正常的细胞死亡过程，因此会发展远处转移。昆虫吞噬是一种新型的细胞死亡类型，已经对GC中与库相关的基因（CRG）之间的关系进行了有限的研究。本研究的目的是建立CRG的预后模型，并提供诊断和治疗的方向。从癌症基因组图集和基因表达综合数据集收集了GC患者的转录组和临床数据。单样品基因集富集分析（GSEA）和随机森林方法用于建立预后模型。使用Kaplan-Meier生存曲线，接收器操作特征图和nom图来评估模型的可靠性。 GSEA和基因集变异分析（GSVA）用于检查高风险组和低风险组之间的富集途径。最后，使用免疫组织化学分析来检查GC样品中的Ephrin 4（EFNA4）表达，并根据EFNA4的表达模式确定GC患者的预后。建立了与CRG相关的7种预测模型（RTKN2，INO80B，EFNA4，ELF2，NUSTN，KRTAP4和ARHGEF40）。该模型可以用作独立的预后因素，以预测GC患者的预后。 GSEA和GSVA结果表明，高风险患者的高风险患者主要与血管生成和TGF_BETA_SIGNALING途径的富集有关。最后，GC中的EFNA4表达明显高于正常组织中的EFNA4，而GC和高EFNA4表达的患者表现出改善的预后。总之，基于CRG的预后模型可以用作预测GC患者潜在预后的基础，并为治疗GC提供新的见解。]]></description>
      <guid>https://link.springer.com/article/10.1038/s41598-025-88812-9</guid>
      <pubDate>Tue, 04 Feb 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>青春期女孩对其人口中低情绪和焦虑率高的解释：一项共同制作的定性研究</title>
      <link>https://link.springer.com/article/10.1186/s12905-024-03517-x</link>
      <description><![CDATA[背景
                从青春期开始，女孩面对与男孩相对于男孩的情绪低落和焦虑的风险，最近证据表明这可能会恶化。精神健康研究很少有意义地发展对这些性别差异的理解，包括吸引青少年女孩自己的观点，限制了我们指导进一步研究并增强干预方法的能力。
              
                目标
                我们从青春期女孩的角度检查了情绪低落和焦虑，问：青春期女孩认为是什么导致他们的人口高度低的情绪和焦虑率？ 
              
                方法
                我们采用了由生态系统理论指导的共同制作的定性设计，在2022年进行了焦点小组，在英国，有32名16至18岁的青少年女孩。使用反思性主题分析分析了数据。
              
                分析
                参与者将青春期女孩的情绪低落和焦虑视为“正常”，并讨论了潜在的解释，包括对性别规范的持续重申和期望，以性别的方式，同伴关系中的困难以及社交媒体环境中的比较和不安全感的方式，以性别的困难和不安全感。在整个过程中，参与者强调了这些问题的复杂程度，包括围绕个体差异，社会人口统计学环境和社会背景的细微差别。
              
                结论
                这项研究为低情绪和焦虑中的性别不平等的证据提供了至关重要的贡献，引起人们对女孩生活的编织和复杂性的关注，并阐明了将从更大的研究中受益的各个方面。通过与女孩自己探索获得的见解，以增强系统以满足女孩需求的系统。]]></description>
      <guid>https://link.springer.com/article/10.1186/s12905-024-03517-x</guid>
      <pubDate>Tue, 04 Feb 2025 00:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>