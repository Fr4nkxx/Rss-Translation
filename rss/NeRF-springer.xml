<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最新结果</title>
    <link>http://link.springer.com</link>
    <description>Springer 提供的最新内容</description>
    <lastBuildDate>Mon, 29 Jan 2024 03:11:37 GMT</lastBuildDate>
    <item>
      <title>基于实时距离场加速的大型运动场自由视点视频合成</title>
      <link>http://link.springer.com/10.1007/s41095-022-0323-3</link>
      <description><![CDATA[摘要
自由视点视频允许用户从任何虚拟角度观看物体，创造身临其境的视觉体验。该技术增强了多媒体表演的交互性和自由度。然而，许多自由视点视频合成方法很难满足实时、高精度的要求，特别是对于面积较大、运动物体较多的运动场。为了解决这些问题，我们提出了一种基于距离场加速的自由视点视频合成方法。其中心思想是融合多视点距离场信息并利用其自适应调整搜索步长。自适应步长搜索有两种用途：用于多目标三维表面的快速估计，以及基于全局遮挡判断的合成视图渲染。我们使用并行计算进行交互式显示、使用 CUDA 和 OpenGL 框架来实现我们的想法，并使用真实世界和模拟实验数据集进行评估。结果表明，所提出的方法可以在大型运动场上以 25 fps 渲染具有多个对象的自由视点视频。此外，我们合成的新颖视点图像的视觉质量超过了最先进的基于神经渲染的方法。
      



]]></description>
      <guid>http://link.springer.com/10.1007/s41095-022-0323-3</guid>
      <pubDate>Mon, 01 Apr 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于可微渲染的动态海洋反建模</title>
      <link>http://link.springer.com/10.1007/s41095-023-0338-4</link>
      <description><![CDATA[摘要
学习和推断捕获的 2D 场景的潜在运动模式，然后重新创建与现实世界自然现象一致的动态演化，这对图形和动画具有很高的吸引力。为了弥合虚拟和现实环境之间的技术差距，我们专注于视觉一致和属性可验证的海洋的逆向建模和重建，利用深度学习和可微物理来学习几何并以自我监督的方式构成波浪。首先，我们使用两个网络推断分层几何，这两个网络通过可微渲染器进行了优化。我们通过配备可微分海洋模型的网络从推断的几何序列中提取波浪分量。然后，可以使用重建的波浪分量来演化海洋动力学。通过大量的实验，我们验证了我们的新方法在几何重建和波浪估计方面都能产生令人满意的结果。此外，新框架具有逆向建模潜力，可促进大量图形应用，例如快速生成物理精确的场景动画以及由真实海洋场景引导的编辑。
      



]]></description>
      <guid>http://link.springer.com/10.1007/s41095-023-0338-4</guid>
      <pubDate>Mon, 01 Apr 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MusicFace：音乐驱动的富有表现力的歌脸合成</title>
      <link>http://link.springer.com/10.1007/s41095-023-0343-7</link>
      <description><![CDATA[摘要
合成由音乐驱动的生动逼真的歌声仍然是一个有趣且具有挑战性的问题。在本文中，我们提出了一种完成此任务的方法，其中包括嘴唇、面部表情、头部姿势和眼睛的自然运动。由于常见音乐音频信号中人声和背景音乐的混合信息耦合，我们设计了一种解耦和融合策略来应对这一挑战。我们首先将输入的音乐音频分解为人声流和背景音乐流。由于两个流输入信号与面部表情、头部运动和眼睛状态的动态之间存在隐式且复杂的相关性，我们用注意力方案对它们的关系进行建模，其中两个流的效果无缝融合。此外，为了提高生成结果的表现力，我们将头部运动生成分解为速度和方向，并将眼睛状态生成分解为短期眨眼和长期闭眼，并分别建模。我们还构建了一个新颖的数据集 SingingFace，以支持该任务的模型训练和评估，包括该主题的未来工作。大量的实验和用户研究表明，我们提出的方法能够合成生动的歌声面孔，在质量和数量上都优于现有技术。
      



]]></description>
      <guid>http://link.springer.com/10.1007/s41095-023-0343-7</guid>
      <pubDate>Thu, 01 Feb 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>以更细粒度解析对象：一项调查</title>
      <link>http://link.springer.com/10.1007/s11633-022-1404-6</link>
      <description><![CDATA[摘要
细粒度视觉解析，包括细粒度部分分割和细粒度对象识别，由于其在农业等许多实际应用中的重要性而引起了相当大的关注、遥感和空间技术。主要的研究工作遵循不同的范式来处理这些细粒度的子任务，而忽略了这些任务之间的内在关系。此外，鉴于大多数研究仍然碎片化，我们从学习零件关系的新角度对先进工作进行了深入研究。从这个角度来看，我们首先将最近的研究和基准综合与新的分类法相结合。在此基础上，我们重新审视细粒度零件分割和识别任务中的普遍挑战，并通过零件关系学习针对这些重要挑战提出新的解决方案。此外，我们还总结了细粒度视觉解析方面的几个有前景的研究方向，以供未来研究使用。]]></description>
      <guid>http://link.springer.com/10.1007/s11633-022-1404-6</guid>
      <pubDate>Fri, 12 Jan 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于跨模态哈希检索的无监督多视角融合语义对齐</title>
      <link>http://link.springer.com/10.1007/s11042-023-18048-0</link>
      <description><![CDATA[摘要
无监督深度跨模态哈希方法因其低计算成本、优异的存储容量和高效的检索性能而受到广泛关注。然而，现有的无监督方法仍然存在一些挑战：（1）由于缺乏标签语义，单模态和间模态实例的邻域结构信息可能无法完全集成，导致忽略深层语义相似性交互信息。 (2)无监督哈希码既不能有效解决模态实例原始特征之间的语义一致性，也不能弥合哈希码异构模态之间的差距。为了解决这些问题，我们提出了一种新的无监督深度跨模式哈希方法，称为多视角融合语义对齐哈希（MPFSAH）。主要包括两个方面。首先，为了增强跨模式通信，构建了多级语义相似性交互测量（MSSIM）。通过融合不同模态的邻域结构并增加模态内实例之间的距离，可以深度挖掘语义交互相似性，以获得有区别的语义信息。此外，我们还提出了一种新颖的多视角语义对齐机制（MPSAM）。通过最小化多视角相似度中元素的一致性量化误差，学习模态间相似度一致性。 MPSAM包括相似性一致性对齐、结构语义对齐和排序对齐。它实现了结构语义一致性，充分保证了跨模态数据相似性的有效连接，弥合了哈希码过程中的模态鸿沟。通过对三个跨模态检索数据集的实验，我们证明了我们提出的方法的有效性，该方法优于一些最先进的方法。]]></description>
      <guid>http://link.springer.com/10.1007/s11042-023-18048-0</guid>
      <pubDate>Tue, 09 Jan 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过深度学习和组织学肿瘤映射到手术部位对基底细胞癌进行术中切缘评估</title>
      <link>http://link.springer.com/10.1038/s41698-023-00477-7</link>
      <description><![CDATA[摘要
实体癌的成功治疗依赖于肿瘤的完全手术切除，无论是用于明确治疗还是在辅助治疗之前。术中和术后径向切片是最常见的切缘评估形式，可能导致切除不完全并增加复发和重复手术的风险。莫氏显微手术通过对 100% 的外周和深层边缘进行实时边缘评估，彻底切除基底细胞癌和鳞状细胞癌。许多肿瘤类型的实时评估受到组织大小、复杂性和全身麻醉期间标本处理/评估时间的限制。我们开发了一个人工智能平台，通过自动粗略建议、肿瘤到手术标本的映射和定位来减少组织预处理和组织学评估时间。使用基底细胞癌作为模型系统，结果表明该方法可以解决手术实验室效率瓶颈，实现快速、完整的术中切缘评估。]]></description>
      <guid>http://link.springer.com/10.1038/s41698-023-00477-7</guid>
      <pubDate>Wed, 03 Jan 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>非视距成像技术研究进展</title>
      <link>http://link.springer.com/10.1007/s12204-023-2686-8</link>
      <description><![CDATA[摘要
非视距成像通过分析携带隐藏场景信息的中继表面上的漫反射光来恢复拐角处的隐藏物体。非视距成像由于其在自动驾驶、国防、医学成像、灾后救援等领域的巨大应用潜力，特别是近年来引起了国内外研究人员的广泛关注。非视距成像的研究主要集中在成像系统、正演模型和重建算法上。本文系统总结了现有主动和被动场景下的非视距成像技术，分析了非视距成像技术面临的挑战和未来方向。]]></description>
      <guid>http://link.springer.com/10.1007/s12204-023-2686-8</guid>
      <pubDate>Tue, 02 Jan 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多重多色抗病毒检测适合高通量研究</title>
      <link>http://link.springer.com/10.1038/s41467-023-44339-z</link>
      <description><![CDATA[摘要
为了遏制病毒流行和大流行，需要针对整个病毒属或病毒家族的抗病毒药物。在这里，我们开发了一种基于细胞的多重抗病毒测定，可同时对多种病毒进行高通量筛选，正如使用三种远缘相关的正黄病毒（登革热、日本脑炎和黄热病病毒）所证明的那样。每种病毒都标有独特的荧光蛋白，从而能够通过高内涵成像对细胞培养物进行单独监测。采用特定的抗血清和小分子抑制剂来验证多重方法产生与单病毒感染测定相当的抑制谱。为了便于下游分析，开发了一个内核来对多维定量数据进行解卷积并将其减少到三个笛卡尔坐标。该方法适用于不同科的病毒，例如基孔肯雅病毒、副流感病毒和布尼亚姆维拉病毒的共同感染。正如对大约 1200 种药物样小分子的初步筛选所示，多重方法有望促进更广谱抗病毒药物的发现。]]></description>
      <guid>http://link.springer.com/10.1038/s41467-023-44339-z</guid>
      <pubDate>Tue, 02 Jan 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过多平面 NeRF 进行点云渲染</title>
      <link>http://link.springer.com/10.1007/978-3-031-50072-5_16</link>
      <description><![CDATA[摘要
我们结合点云多平面投影和 NeRF 提出了一种新的神经点云渲染方法[https://github.com/Mayxmu/PCMP-NeRF .]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-50072-5_16</guid>
      <pubDate>Mon, 01 Jan 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>神经网络作为摄影测量的替代方案。使用即时 NeRF 和体积渲染</title>
      <link>http://link.springer.com/10.1007/978-3-031-36155-5_30</link>
      <description><![CDATA[摘要
人工智能 (AI) 和机器学习算法的使用最近给许多领域带来了革命性的变化，包括通过数字孪生增强遗产及其在 VR 维度中的使用。本文讨论了各种人工智能技术（生成对抗网络（GAN））在开发交互式和沉浸式 VR 严肃游戏以增强遗产方面的潜在用途。 GAN 可用于生成空间、物体和人脸的真实且完全人工的图像，可应用于构建交互式环境的设计和概念过程。此外，机器学习算法可以提高游戏对用户的适应性，例如根据用户的动作自动构建游戏的难度级别或情节。然而，近年来，新的、更高性能的人工智能过程已经出现，它们已经超越了 GAN 算法的生成能力，后者主要用于生成不存在元素的 2D 图像。 NeRF（神经辐射场）是 NVIDIA 开发的一项技术，由最近由名为 Instant NeRF 的专有代码优化的复杂神经网络提供支持。与不直接支持人工智能的替代照片建模技术相比，该技术能够使用更少的摄影数据快速准确地生成物理环境的详细 3D 模型。未来，该技术可用于生成与现实无区别的虚拟环境，也可积极用于遗产保护。]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-36155-5_30</guid>
      <pubDate>Mon, 01 Jan 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>T(G)V-NeRF：规则化神经辐射场的强大基线，训练视图很少</title>
      <link>http://link.springer.com/10.1007/978-3-031-47765-2_12</link>
      <description><![CDATA[摘要
诸如神经辐射场 (NeRF) 之类的隐式表示已成为新颖视图领域的事实上标准3D 场景合成。然而，他们令人惊叹的结果通常意味着使用数十张训练图像，并将相应的摄像机很好地定位在场景中。本文研究了新的、基于全变分的正则化方法，用于在很少（少于 10 个）训练图像的情况下训练 NeRF。它利用 NeRF 反向传播算法来评估推断深度图上的一阶和二阶导数项，以增强场景底层表面的平滑度。通过标准真实图像基准上最先进的性能，我们表明所提出的方法（称为 TV-NeRF 和 TGV-NeRF）在很少的训练视图的新颖视图合成中建立了强大的基线。]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-47765-2_12</guid>
      <pubDate>Mon, 01 Jan 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MVD-NeRF：通过减轻视图依赖性解决形状辐射模糊性</title>
      <link>http://link.springer.com/10.1007/978-3-031-53308-2_27</link>
      <description><![CDATA[摘要
我们提出了 MVD-NeRF，一种从神经辐射场 (NeRF) 恢复高保真网格的方法。形状辐射模糊现象，即从不同角度观察时，点的辐射明显变化，导致几何形状不正确。我们提出有向视图外观编码，通过优化每个输入图像的外观嵌入来实现所需的视点不变性，使网络能够学习整个图像集的共享外观表示。此外，我们利用网络架构中的跳跃连接和层规模模块来捕获复杂且多方面的场景信息。层尺度模块的引入使得网络的浅层信息能够更准确地传递到深层，保持特征的一致性。大量实验表明，尽管形状-辐射模糊不可避免，但所提出的方法可以有效地最小化其对几何形状的影响，从而从本质上减轻与视图相关的变化的影响。提取的几何图形和纹理可以部署在任何传统图形引擎中以执行下游任务。]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-53308-2_27</guid>
      <pubDate>Mon, 01 Jan 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CaSE-NeRF：神经辐射场的相机设置编辑</title>
      <link>http://link.springer.com/10.1007/978-3-031-50072-5_8</link>
      <description><![CDATA[摘要
神经辐射场 (NeRF) 通过从多视图图像合成新颖的视图，在三维 (3D) 重建方面表现出了卓越的质量。然而，之前基于 NeRF 的方法不允许用户在场景中执行用户控制的摄像机设置编辑。虽然现有的工作提出了修改辐射场的方法，但这些修改仅限于训练集中的相机设置。因此，我们提出了神经辐射场的相机设置编辑（CaSE-NeRF），以从具有不同相机设置的一组视图中恢复辐射场。在我们的方法中，我们允许用户在场景上执行受控的相机设置编辑，并合成编辑场景的新颖视图图像，而无需重新训练网络。我们方法的关键在于分别对每个相机参数进行建模，并根据薄镜头成像原理渲染各种 3D 散焦效果。通过遵循真实相机的图像处理，我们对其进行隐式建模并学习在潜在空间中连续且独立于图像的增益。色温和曝光的控制是即插即用的，并且可以轻松集成到基于 NeRF 的框架中。因此，我们的方法允许对 3D 场景的视点和相机设置进行手动和自由的捕获后控制。通过对两个真实场景数据集的广泛实验，我们证明了我们的方法在重建具有一致的 3D 几何和外观的正常 NeRF 方面的成功。我们的相关代码和数据可以在 https://github.com/CPREgroup/CaSE-NeRF 获取.]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-50072-5_8</guid>
      <pubDate>Mon, 01 Jan 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>计算机图形学的进展</title>
      <link>http://link.springer.com/10.1007/978-3-031-50072-5</link>
      <description><![CDATA[]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-50072-5</guid>
      <pubDate>Mon, 01 Jan 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>模式识别和计算机视觉</title>
      <link>http://link.springer.com/10.1007/978-981-99-8432-9</link>
      <description><![CDATA[]]></description>
      <guid>http://link.springer.com/10.1007/978-981-99-8432-9</guid>
      <pubDate>Mon, 01 Jan 2024 00:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>