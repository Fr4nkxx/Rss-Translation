<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最新结果</title>
    <link>http://link.springer.com</link>
    <description>Springer 提供的最新内容</description>
    <lastBuildDate>Sun, 24 Nov 2024 15:12:59 GMT</lastBuildDate>
    <item>
      <title>Deblur e-NeRF：高速或低光条件下运动模糊事件中的 NeRF</title>
      <link>http://link.springer.com/10.1007/978-3-031-73232-4_11</link>
      <description><![CDATA[摘要
事件相机的独特设计理念使其成为高速、高动态范围和低光环境的理想选择，而标准相机在这些环境中表现不佳。然而，与大多数人的想法相反，事件相机也存在运动模糊，尤其是在这些具有挑战性的条件下。这是由于事件传感器像素的带宽有限，而带宽主要与光强度成正比。因此，为了确保事件相机能够真正在这种条件下表现出色，使其比标准相机更具优势，必须在下游任务（尤其是重建）中考虑事件运动模糊。然而，之前没有关于从事件重建神经辐射场 (NeRF) 的研究，也没有事件模拟器考虑过事件运动模糊的全部影响。为此，我们提出了 Deblur e-NeRF，这是一种新方法，可以直接有效地从高速或低光条件下产生的运动模糊事件中重建模糊最小的 NeRF。这项工作的核心部分是一个物理上精确的像素带宽模型，该模型考虑了事件运动模糊。我们还引入了阈值归一化总变分损失，以更好地规范大型无纹理斑块。在真实和新颖的现实模拟序列上进行的实验验证了我们的有效性。我们的代码、事件模拟器和合成事件数据集都是开源的。]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-73232-4_11</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>KFD-NeRF：使用卡尔曼滤波器重新思考动态 NeRF</title>
      <link>http://link.springer.com/10.1007/978-3-031-72995-9_1</link>
      <description><![CDATA[摘要
我们引入了 KFD-NeRF，这是一种新型动态神经辐射场，集成了基于卡尔曼滤波的高效高质量运动重建框架。我们的主要思想是将动态辐射场建模为一个动态系统，其随时间变化的状态基于两个知识来源进行估计：观察和预测。我们引入了一种新型插件卡尔曼滤波器引导变形场，可以从场景观察和预测中准确估计变形。我们使用浅层多层感知器 (MLP) 进行观察，并将运动建模为局部线性，以使用运动方程计算预测。为了进一步提高观察 MLP 的性能，我们在规范空间中引入了正则化，以促进网络学习不同帧的扭曲的能力。此外，我们采用高效的三平面表示来编码规范空间，实验证明它可以快速高质量地收敛。这使我们能够使用更浅的观察 MLP，在我们的实现中仅包含两层。我们对合成数据和真实数据进行实验，并与过去的动态 NeRF 方法进行比较。我们的 KFD-NeRF 在可比的计算时间内展示了相似甚至更优异的渲染性能，并通过全面的训练实现了最先进的视图合成性能。Github 页面：https://github.com/Yifever20002/KFD-NeRF。]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-72995-9_1</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AG-NeRF：用于多高度大规模户外场景渲染的注意力引导神经辐射场</title>
      <link>http://link.springer.com/10.1007/978-981-97-8508-7_8</link>
      <description><![CDATA[摘要
现有的基于神经辐射场 (NeRF) 的大规模室外场景新视图合成方法主要建立在单一高度上。此外，它们通常需要先验相机拍摄高度和场景范围，导致相机高度发生变化时应用效率低下且不切实际。在这项工作中，我们提出了一个端到端框架，称为 AG-NeRF，并寻求通过基于不同场景高度合成自由视点图像来降低构建良好重建的训练成本。具体而言，为了解决从低空（无人机级）到高空（卫星级）的细节变化问题，开发了一种源图像选择方法和一种基于注意的特征融合方法，以从多高度图像中提取和融合目标视图的最相关特征，以实现高保真渲染。大量实验表明，AG-NeRF 在 56 Leonard 和 Transamerica 基准测试中取得了 SOTA 性能，并且与最新的 BungeeNeRF 相比，仅需要半小时的训练时间即可达到具有竞争力的 PSNR。]]></description>
      <guid>http://link.springer.com/10.1007/978-981-97-8508-7_8</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>改进 NeRF 表征，无需姿势先验，实现结肠镜检查中的新型视图合成</title>
      <link>http://link.springer.com/10.1007/978-3-031-73748-0_15</link>
      <description><![CDATA[摘要
结肠镜检查是治疗胃肠道恶性肿瘤的黄金标准程序。然而，一些限制会影响筛查过程的质量。对被调查区域进行可靠的 3D 重建可以减轻这些限制并改善诊断和治疗结果。大多数 3D 重建框架依赖于两个基本任务：a) 可靠的相机深度预测，以及 b) 准确的相机姿势估计。虽然这些框架在自然场景中表现出色，但由于缺乏带注释的地面真实数据，它们对结肠镜检查数据的影响受到极大限制。我们提出了一种新颖的射线采样技术来指导神经辐射场 (NeRF) 系统的优化，而无需姿势先验来联合估计相机姿势预测和新颖的视图合成 (NVS)。我们的方法建立在 NoPe-NeRF [4] 的基础上，该方法在 NVS 和相机姿态估计方面表现出色，但目前仅限于具有大量纹理的自然场景。为了解决这一限制，我们引入了新的深度加权块聚焦随机光线采样 (DW-PFRRS) 技术，并在 C3VD 数据集上评估了我们的方法。]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-73748-0_15</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过地球移动距离进行深度引导的 NeRF 训练</title>
      <link>http://link.springer.com/10.1007/978-3-031-73039-9_1</link>
      <description><![CDATA[摘要

神经辐射场 (NeRF) 经过训练，可最大限度地减少预测视点的渲染损失。然而，光度损失通常不能提供足够的信息来消除产生相同图像的不同可能几何形状之间的歧义。因此，先前的研究在 NeRF 训练期间加入了深度监督，利用来自预训练深度网络的密集预测作为伪地面实况。虽然这些深度先验在过滤噪声后被认为是完美的，但在实践中，它们的准确性更难捕捉。这项工作提出了一种用于 NeRF 监督的深度先验不确定性的新方法。我们使用现成的预训练扩散模型来预测深度​​并在去噪过程中捕获不确定性，而不是使用定制训练的深度或不确定性先验。因为我们知道深度先验容易出错，所以我们建议用 Earth Mover’s Distance 来监督射线终止距离分布，而不是强制渲染深度通过 
\(L_2\)
-loss 精确复制深度先验。我们的深度引导 NeRF 在标准深度指标上的表现远胜于所有基线，同时保持了光度测量的性能。

]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-73039-9_1</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>NeRFect Match：探索 NeRF 的视觉定位功能</title>
      <link>http://link.springer.com/10.1007/978-3-031-72691-0_7</link>
      <description><![CDATA[摘要
在这项工作中，我们建议使用神经辐射场 (NeRF) 作为视觉定位的场景表示。最近，NeRF 已被用于通过扩充训练数据库、通过渲染图像提供辅助监督或作为迭代细化模块来增强姿势回归和场景坐标回归模型。我们扩展了其公认的优势——它能够提供具有逼真外观和准确几何形状的紧凑场景表示——通过探索 NeRF 的内部特征在建立精确的 2D-3D 匹配以进行定位方面的潜力。为此，我们对通过视图合成获得的 NeRF 的隐性知识进行了全面检查，以便在各种条件下进行匹配。这包括探索不同的匹配网络架构、在多个层提取编码器特征以及不同的训练配置。值得注意的是，我们引入了 NeRFMatch，这是一种先进的 2D-3D 匹配函数，它利用通过视图合成学习到的 NeRF 的内部知识。我们在基于结构的管道中对标准定位基准上的 NeRFMatch 进行了评估，在剑桥地标的定位性能方面取得了有竞争力的结果。我们将发布所有模型和代码。]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-72691-0_7</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RS-NeRF：来自滚动快门图像的神经辐射场</title>
      <link>http://link.springer.com/10.1007/978-3-031-72952-2_10</link>
      <description><![CDATA[摘要
神经辐射场 (NeRF) 因其令人印象深刻的新颖视图合成能力而变得越来越流行。然而，它们的有效性受到大多数相机系统中常见的滚动快门 (RS) 效应的阻碍。为了解决这个问题，我们提出了 RS-NeRF，这是一种使用具有 RS 失真的输入从新颖视图合成正常图像的方法。这涉及一个物理模型，该模型复制 RS 条件下的图像形成过程并联合优化 NeRF 参数和每个图像行的相机外部参数。我们通过深入研究 RS 特性并开发算法来增强其功能，进一步解决了基本 RS-NeRF 模型的固有缺陷。首先，我们施加平滑度正则化以更好地估计轨迹并提高合成质量，与相机运动先验保持一致。我们还通过引入多采样算法来识别和解决 vanilla RS 模型中的一个根本缺陷。这种新方法通过全面利用每个中间相机姿势的不同行中的 RGB 数据来提高模型的性能。通过严格的实验，我们证明 RS-NeRF 在合成和真实场景中都超越了以前的方法，证明了它能够有效纠正与 RS 相关的失真。可用的代码和数据：https://github.com/MyNiuuu/RS-NeRF。]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-72952-2_10</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RING-NeRF：重新思考多功能高效神经场的归纳偏差</title>
      <link>http://link.springer.com/10.1007/978-3-031-72761-0_9</link>
      <description><![CDATA[摘要
神经领域的最新进展主要依赖于开发特定于任务的监督，这通常会使模型复杂化。与开发难以组合和特定的模块不同，另一种通常被忽视的方法是将场景表示的通用先验（也称为归纳偏差）直接注入 NeRF 架构。基于这个想法，我们提出了 RING-NeRF 架构，其中包括两个归纳偏差：场景的连续多尺度表示和解码器潜在空间在空间和尺度域上的不变性。我们还设计了一个利用这些归纳偏差的单一重建过程，并通过实验证明了在多个任务（抗锯齿、少量视图重建、没有场景特定初始化的 SDF 重建）上与专用架构在质量方面的性能相当，同时效率更高。此外，RING-NeRF 具有动态提高模型分辨率的独特能力，为自适应重建开辟了道路。项目页面位于：https://cea-list.github.io/RING-NeRF]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-72761-0_9</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>NeRF-MAE：用于神经辐射场自监督 3D 表示学习的蒙版自动编码器</title>
      <link>http://link.springer.com/10.1007/978-3-031-73223-2_24</link>
      <description><![CDATA[摘要
神经场在计算机视觉和机器人领域表现出色，因为它们能够理解 3D 视觉世界，例如推断语义、几何和动态。鉴于神经场能够从 2D 图像密集地表示 3D 场景，我们提出了一个问题：我们是否可以扩展它们的自监督预训练，特别是使用蒙版自动编码器，以从摆放的 RGB 图像生成有效的 3D 表示。由于将 Transformer 扩展到新数据模式取得了惊人的成功，我们使用标准的 3D 视觉 Transformer 来适应 NeRF 的独特配方。我们利用 NeRF 的体积网格作为 Transformer 的密集输入，将其与其他 3D 表示（如点云）进行对比，其中信息密度可能不均匀，并且表示不规则。由于将掩蔽自动编码器应用于隐式表示（例如 NeRF）的难度，我们选择通过使用摄像机轨迹进行采样来提取显式表示，该表示可跨域规范化场景。我们的目标是通过从 NeRF 的辐射度和密度网格中屏蔽随机斑块并使用标准 3D Swin Transformer 重建掩蔽斑块来实现的。通过这样做，模型可以学习完整场景的语义和空间结构。我们在我们提出的精选 posed-RGB 数据上大规模预训练此表示，总计超过 180 万张图像。预训练后，编码器可用于有效的 3D 迁移学习。我们针对 NeRF 的新型自监督预训练 NeRF-MAE 具有非常好的扩展性，并提高了各种具有挑战性的 3D 任务的性能。 NeRF-MAE 利用未标记的 2D 数据进行预训练，在 Front3D 和 ScanNet 数据集上的表现明显优于自监督 3D 预训练和 NeRF 场景理解基线，3D 物体检测的绝对性能提升超过 20% AP50 和 8% AP25。项目页面：nerf-mae.github.io]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-73223-2_24</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Freditor：通过频率分解实现高保真、可转移的 NeRF 编辑</title>
      <link>http://link.springer.com/10.1007/978-3-031-72940-9_5</link>
      <description><![CDATA[摘要
本文通过频率分解实现了高保真、可迁移的 NeRF 编辑。最近的 NeRF 编辑流程将 2D 风格化结果提升到 3D 场景，但结果模糊，并且无法捕捉到由 2D 编辑之间的不一致导致的细节结构。我们的关键见解是，与高频部分相比，图像的低频成分在编辑后具有更高的多视图一致性。此外，外观风格主要表现在低频分量上，内容细节尤其存在于高频部分。这促使我们对低频分量进行编辑，从而产生高保真编辑的场景。此外，编辑是在低频特征空间中执行的，可以实现稳定的强度控制和新颖的场景转移。在真实感数据集上进行的全面实验证明了高保真和可迁移的 NeRF 编辑的卓越性能。项目页面位于https://aigc3d.github.io/freditor。]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-72940-9_5</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>URS-NeRF：神经辐射场的无序滚动快门束调整</title>
      <link>http://link.springer.com/10.1007/978-3-031-72761-0_26</link>
      <description><![CDATA[摘要
本文提出了一种新的神经辐射场（NeRF）滚动快门束调整方法，该方法利用无序滚动快门（RS）图像来获得隐式三维表示。现有的 NeRF 方法由于图像中的 RS 效应而存在图像质量低和初始相机姿势不准确的问题。此外，以前将 RS 图像合并到 NeRF 中的方法需要严格的顺序数据输入，从而限制了其广泛的适用性。相比之下，我们的方法通过估计相机姿势和速度来恢复 RS 图像的物理形态，从而消除了对顺序数据的输入限制。此外，我们采用由粗到细的训练策略，其中场景图中成对帧的 RS 极线约束用于检测落入局部最小值的相机姿势。检测到的异常姿势通过邻近姿势的插值方法进行校正。实验结果验证了我们的方法相对于最先进方法的有效性，并表明 3D 表示的重建不受视频序列输入要求的限制。]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-72761-0_26</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>TriNeRFLet：基于小波的三平面 NeRF 表示</title>
      <link>http://link.springer.com/10.1007/978-3-031-72986-7_21</link>
      <description><![CDATA[摘要
近年来，神经辐射场 (NeRF) 模型因其恢复复杂 3D 场景的能力而广受欢迎。在其成功之后，许多方法提出了不同的 NeRF 表示，以进一步改善运行时间和性能。Triplane 就是这样一个例子，其中 NeRF 使用三个 2D 特征平面表示。这使得在此框架中轻松使用现有的 2D 神经网络来生成三个平面成为可能。尽管三平面表示具有优势，但与 NeRF 解决方案相比，它在 3D 恢复质量方面落后。在这项工作中，我们提出了 TriNeRFLet 框架，我们在其中学习三平面的小波表示并对其进行正则化。这种方法具有多个优点：(i) 它允许跨尺度共享信息和高频正则化；(ii) 它有助于以多尺度方式进行学习； （iii）它为执行 NeRF 超分辨率 (SR) 提供了一个“自然”框架，这样就可以从提供的低分辨率多视图图像中计算出低分辨率小波系数，并在预先训练的 2D 扩散模型的指导下获取高频。我们在 Blender 和 LLFF 数据集上展示了 SR 方法的优势。]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-72986-7_21</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Deceptive-NeRF/3DGS：扩散生成的伪观测，用于高质量稀疏视图重建</title>
      <link>http://link.springer.com/10.1007/978-3-031-72640-8_19</link>
      <description><![CDATA[摘要
通过神经辐射场 (NeRF) 或 3D 高斯溅射 (3DGS) 进行新颖的视图合成通常需要对数百张输入图像进行密集观察以避免伪影。我们引入了Deceptive-NeRF/3DGS（在和声进行中，Deceptive Cadence 可能会扰乱和弦进行的预期，但会丰富音乐的情感表达。我们的 Deceptive-X，其中“X”可以是 NeRF、3DGS 或相关的 3D 重建框架，通过密集合成一致的伪观察来抵消对稀疏输入视图的过度拟合，将原始稀疏输入丰富五到十倍。），通过利用从多视图数据集预先训练的扩散模型，仅使用一组有限的输入图像来增强稀疏视图重建。与使用扩散先验来正则化表示优化不同，我们的方法直接使用扩散生成的图像来训练 NeRF/3DGS，就好像它们是真实的输入视图一样。具体来说，我们提出了一个欺骗性扩散模型，将由少视图重建渲染的噪声图像转换为高质量的照片级真实感伪观测。为了解决伪观测和真实输入视图之间的一致性问题，我们开发了一种不确定性度量来指导扩散模型的生成。我们的系统逐步将扩散生成的伪观测纳入训练图像集，最终将稀疏的输入观测密集化 5 到 10 倍。在各种具有挑战性的数据集上进行的大量实验验证了我们的方法优于现有的最先进方法，并且能够在少视图设置中合成具有超分辨率的新视图。项目页面：https://xinhangliu.com/deceptive-nerf-3dgs。]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-72640-8_19</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Structured-NeRF：具有神经表征的分层场景图</title>
      <link>http://link.springer.com/10.1007/978-3-031-72761-0_11</link>
      <description><![CDATA[摘要
我们提出了一种结构化神经辐射场 (Structured-NeRF)，用于室内场景表示，该模型基于一种新颖的分层场景图结构来组织神经辐射场。现有的以对象为中心的方法仅关注对象的固有特性，而忽略了它们之间的语义和物理关系。我们的场景图擅长管理场景中对象之间复杂的现实世界相关性，从而实现超越新颖视图合成的功能，例如场景重新排列。基于分层结构，我们引入了基于语义和物理关系的优化策略，从而简化了场景编辑所涉及的操作，并确保了效率和准确性。此外，我们对对象进行阴影渲染，以进一步增强渲染图像的真实感。实验结果表明，我们的结构化表示不仅在对象级和场景级渲染中实现了最佳（SOTA）性能，而且还与LLM/VLM结合推进了下游应用，例如自动和指令/图像条件场景重新排列，从而方便且可控地将NeRF扩展到交互式编辑。]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-72761-0_11</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>改进的基于端到端多级 NeRF 的密集 RGB-D SLAM</title>
      <link>http://link.springer.com/10.1007/978-981-97-8792-0_10</link>
      <description><![CDATA[摘要
得益于神经辐射场（NeRF）技术在三维重建中的出色表现，将其集成到同步定位和地图绘制（SLAM）任务中进行地图表示已成为近年来广受认可的新颖方法。本文在当前最先进的NICE-SLAM基础上，提出了一种改进的基于端到端多级NeRF的密集RGB-D SLAM。首先，我们增强了多级MLP的结构设计，提高了其表示高级细节的能力并增强了网络的可扩展性。其次，我们改进了关键帧选择策略以缓解网络遗忘问题。最后，在消除深度不确定性和改进多级权重设置方面进行了改进，以进一步提高系统性能。在多个数据集上的大量实验验证了我们的方法与NICE-SLAM相比的准确性改进。]]></description>
      <guid>http://link.springer.com/10.1007/978-981-97-8792-0_10</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>