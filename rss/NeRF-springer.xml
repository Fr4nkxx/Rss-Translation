<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最新结果</title>
    <link>http://link.springer.com</link>
    <description>Springer可用的最新内容</description>
    <lastBuildDate>Thu, 10 Apr 2025 01:11:11 GMT</lastBuildDate>
    <item>
      <title>表示表示，优化策略和全向视觉应用的调查</title>
      <link>https://link.springer.com/article/10.1007/s11263-025-02391-w</link>
      <description><![CDATA[全向图像（ODI）数据被$$ 360^\ circ \ times 180^\ circ $$捕获，比销孔摄像机宽得多，并且捕获了周围环境详细信息的详细信息，而不是传统的透视图。近年来，客户级$$ 360^\ CIRC $$相机的可用性使全向视觉变得更加流行，并且深度学习的进步（DL）显着引发了其研究和应用。本文对DL的最新进展进行了全面的综述和分析。它描述了将DL应用于全向图像而不是传统观点图像时遇到的独特挑战和复杂性。我们的工作涵盖了四个主要内容：（i）全面成像原理的彻底介绍以及通常探索的ODI投影； （ii）对针对ODI量身定制的各种表示的学习方法有条不紊的回顾； （iii）对全向视觉特定的优化策略进行深入研究； （iv）从视觉增强（ e  g  g 。，图像生成和超级分辨率）到3D几何和运动估算（ e&gt; e&gt; e&gt; e  g  g  g  g  g  g  g  g  g ，方向； （v）尖端应用程序的概述（ e 。
]]></description>
      <guid>https://link.springer.com/article/10.1007/s11263-025-02391-w</guid>
      <pubDate>Thu, 10 Apr 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>分段3D中的任何东西都带有辐射场</title>
      <link>https://link.springer.com/article/10.1007/s11263-025-02421-7</link>
      <description><![CDATA[段的任何模型（SAM）作为一个强大的视觉基础模型出现，以生成高质量的2D分割结果。本文旨在将SAM推广到细分3D对象。我们设计一个有效的解决方案，而不是复制昂贵的数据采集和注释过程，而是将辐射字段作为便宜且现成的先验，将多视图2D图像连接到3D空间。我们将提出的解决方案称为 sa3d ，缩短了3D中的任何段。使用SA3D，仅需要用户为A 单个视图中的目标对象提供2D分割提示（例如粗糙点），该目标用于使用SAM生成其相应的2D掩码。接下来，SA3D交替执行 bask倒渲染和跨视图自我启动     遍及迭代地完善目标对象的3D掩码。对于一个视图，掩模逆渲染项目由SAM获得的2D掩码进入3D空间，并在Radiance Field通过3D掩码细化的辐射场学习的密度分布进行了指导。然后，跨视图自我提取提取可靠的提示会自动提示，作为从不准确3D蒙版的渲染2D掩码中的SAM输入，以获取新视图。我们在实验中表明，SA3D会在几秒钟内适应各种场景并实现3D分割。我们的研究揭示了一种将2D分割模型提高到3D的能力的潜在方法。我们的代码可在 https://github.com/jumpat/sementanythingin3d 。上获得。]]></description>
      <guid>https://link.springer.com/article/10.1007/s11263-025-02421-7</guid>
      <pubDate>Wed, 09 Apr 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>avatarstudio：高保真和动画3D化身从文本中创建</title>
      <link>https://link.springer.com/article/10.1007/s11263-025-02423-5</link>
      <description><![CDATA[我们研究仅从文本描述中创建高保真和动画3D化身的问题。现有的文本到阿瓦塔尔方法要么仅限于无法动画动画的静态化身，要么难以生成具有有希望的质量和精确姿势控制的动画化身。为了解决这些限制，我们提出了Avatarstudio，这是一种生成模型，可为动画人类化身提供明确的纹理3D网格。具体而言，Avatarstudio建议将发音建模纳入显式网格表示中，以支持高分辨率渲染和头像动画。为了确保查看所得化身的一致性和构成可控性，我们引入了一个简单的2D扩散模型，该模型以致密性为条件，以进行得分蒸馏采样监督。通过有效利用清晰的网格表示和密集的条件扩散模型之间的协同作用，Avatarstudio可以从准备好动画的文本中创建高质量的化身。此外，它具有许多应用程序，例如 ，例如多模式化身动画和样式引导的化身创建。请参阅我们的项目页面以获取更多结果。
]]></description>
      <guid>https://link.springer.com/article/10.1007/s11263-025-02423-5</guid>
      <pubDate>Mon, 07 Apr 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>扩散模型和生成人工智能：框架，应用和挑战</title>
      <link>https://link.springer.com/article/10.1007/s11831-025-10266-z</link>
      <description><![CDATA[扩散模型（DMS）最近已成为深层生成模型的高效类别，在各种领域（包括图像合成，视频生成和分子设计）中取得了非凡的结果。这项调查对有关该主题的研究扩展进行了全面分析。这项研究的主要目的是研究生成人工智能系统的结构和要求。最初，对生成AI系统的实施的先决条件和前沿思想进行了分析。为了阐明该方法的运行机制，对DMS的设计选择进行了彻底检查，涵盖了诸如细化，平行生成，编辑，贴上，镶嵌和跨域产生等方面。这项研究广泛回顾了基本的DMS及其在诸如计算机视觉（CV），自然语言处理（NLP），图像合成和跨学科应用（场景产生，3D视觉，视频建模，医学图像诊断，时间表诊断，时间序列分析，音频分析，3D分子产生等）等领域的不同应用。对所有使用生成AI方法用于每个域中各种下游任务的所有作品进行了比较研究。还对数据集进行了全面研究。最后，它讨论了当前方法的局限性，以及对其他技术和未来方向的需求，以便在这方面取得有意义的进步。]]></description>
      <guid>https://link.springer.com/article/10.1007/s11831-025-10266-z</guid>
      <pubDate>Wed, 02 Apr 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过使用改进的Orb-Slam和深度学习视觉大满贯算法，改善医院物流机器人在复杂照明变化下的导航优化</title>
      <link>https://link.springer.com/article/10.1007/s42452-025-06775-y</link>
      <description><![CDATA[在复杂的照明条件下，医院物流机器人在定位和导航方面面临严重的挑战。传统的球（定向快速和旋转的简短简短）算法通常存在诸如不稳定的特征点提取，位置准确性差，定位准确性差，并且长期导航路径计划在环境中的长期照明变化，这会极大地影响机器人的导航效率和准确性。在本文中，使用了改进的ORB-SLAM3算法来改善机器人在具有复杂照明的医院环境中的导航性能。改进的ORB-SLAM3算法提取物通过构造图像金字塔来确保在不同的照明条件下可以稳定获得有效的视觉信息，从而具有不同尺度的点；结合自适应阈值和双阈值方法的策略用于优化特征点提取的准确性，并且通过四树模型有效地管理特征点，以确保特征点的均匀分布。这些措施显着提高了特征点提取的质量和匹配精度；该算法还通过结合惯性测量单元数据，进一步提高定位准确性和系统稳定性，从而紧密结合视觉和惯性信息。实验结果表明，快速光明的环境变化，平均定位误差，导航图构建完整性和改进的Orb-Slam 3 algorithm的效率为0.26 m，80％和7.26 ms，不相差。医院物流机器人的效率，但也提高了其在剧烈照明变化的环境中的稳定性和可靠性。提高医院内部物流系统的智能水平是非常重要的。]]></description>
      <guid>https://link.springer.com/article/10.1007/s42452-025-06775-y</guid>
      <pubDate>Wed, 02 Apr 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于单个RGB-LIDAR视图的结构化3D高斯裂口，用于新型视图合成</title>
      <link>https://link.springer.com/article/10.1007/s10489-025-06494-2</link>
      <description><![CDATA[ 3D场景重建是计算机视觉和图形中的一项关键任务，最近在3D高斯碎片（3DG）中取得了进步，展示了令人印象深刻的新型视图综合（NVS）结果。但是，大多数3DGS方法都依赖于多视图图像，这些图像并非总是可用的，尤其是在室外环境中。在本文中，我们仅使用单视数据探索3D场景重建，包括RGB图像和LIDAR传感器的稀疏点云。为了解决有限的参考和激光雷达传感器不足点云所带来的挑战，我们提出了一个基于体素的结构化3DGS框架，并随着深度预测增强了。我们引入了一个新的深度，先前的向导Voxel生长和修剪算法，该算法利用了深度图来完善场景结构并提高渲染质量。此外，我们设计了一种具有自适应体素尺寸的虚拟背景拟合方法，以适应室外场景中LIDAR数据的稀疏分布。我们的方法超过了现有的方法，包括脚手架，高斯式PRO，3DGS，MIPSPLATTING和UNIDEPTH，就PSNR，SSIM，LPIPS和FID指标而言，在KITTI和Waymo数据集上，在单个ViewPoint 3D Recoluction和NVS和NVS上的有效性展示了其有效性。]]></description>
      <guid>https://link.springer.com/article/10.1007/s10489-025-06494-2</guid>
      <pubDate>Mon, 31 Mar 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AAGS：外观感知3D高斯裂开，无约束的照片集</title>
      <link>https://link.springer.com/article/10.1007/s00530-025-01742-4</link>
      <description><![CDATA[从无限制的野外照片收藏中重建3D场景一直是一个挑战性的问题。主要难度在于不同的外观条件和不受控制的图像样本的瞬态遮挡器。随着神经辐射领域（NERF）的发展，以前的作品制定了一些有效的策略来解决此问题。但是，受深网和体积渲染技术的限制，这些方法通常需要大量的时间成本。最近，3D高斯脱落（3DGS）的出现大大加快了3D重建任务的训练和渲染速度。然而，香草3DGS难以区分野外照片集的不同外观。为了解决上述问题，我们提出了出现感知的3D高斯裂片（AAGS），这是3DGS的新型扩展到无约束的照片集。具体而言，我们采用一个外观提取器来捕获图像样本的全局特征，从而使视觉条件的区别，例如，例如，照明和天气，跨不同的观测值。此外，为了减轻瞬态遮挡器的影响，我们设计了一个瞬态驱动模块，该模块可自适应地学习2D可见性图，从而从复杂的现实世界场景中分解静态目标。进行了广泛的实验，以验证我们的AAG的有效性和优势。与以前的作品相比，我们的方法不仅可以更好地重建和渲染质量，而且大大降低了培训和渲染开销。代码将在&lt;a href =“ https://github.com/zhang-wencong/aags”上发布。]]></description>
      <guid>https://link.springer.com/article/10.1007/s00530-025-01742-4</guid>
      <pubDate>Fri, 28 Mar 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>纹理驱动的姿势引导的人类图像合成</title>
      <link>https://link.springer.com/article/10.1007/s10044-025-01452-7</link>
      <description><![CDATA[随着计算机视觉和人工智能的快速发展，在角色图像合成领域已经取得了重大突破。尽管现有方法可以综合目标姿势图像，但处理复杂的纹理和姿势比对仍存在局限性，例如纹理失真，姿势错位和缺失的信息。为了解决这个问题，本文提出了一种姿势引导的人类图像合成方法，称为人姿势转移生成对抗网络（HPT-GAN）。该模型通过引入Resblocks模块，设计纹理传输模块（TTM）和TORGB模块来显着提高合成图像的质量和效率。具体而言，重新建筑增强了梯度稳定性，同时保留上下文信息，TTM通过多头注意机制有效地对齐纹理，并且TORGB模块优化了多分辨率特征的融合。与类似方法相比，HPT-GAN具有少量参数，同时达到更快的处理速度。此外，它在DeepFashion和Market-1501数据集上取得了良好的成果。]]></description>
      <guid>https://link.springer.com/article/10.1007/s10044-025-01452-7</guid>
      <pubDate>Fri, 28 Mar 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>3D神经风格化的进步：一项调查</title>
      <link>https://link.springer.com/article/10.1007/s11263-025-02403-9</link>
      <description><![CDATA[现代人工智能提供了一种新颖而变革的方法，可以跨越图像，视频和3D数据（释放创造力的力量）跨越各种样式和方式创建数字艺术，并彻底改变了我们感知并与视觉内容互动的方式。本文报道了使用神经网络的表达能力进行风格化的3D资产创造和操纵的最新进展。我们考虑了关键的设计选择，例如场景表示，指导数据，优化策略和输出样式，以建立神经风格风格化的分类学。在此类分类法的基础上，我们的调查首先重新审视了2D图像上神经风化的背景，然后对3D数据的最新神经风格化方法进行了深入的讨论，并伴随着评估选定的网格和神经场风格化方法的基准测试。根据调查中获得的见解，我们强调了实际意义，开放挑战，未来的研究以及神经风格的潜在影响，这促进了研究人员和从业人员使用现代人工智能的3D内容创造的迅速发展的景观。 。]]></description>
      <guid>https://link.springer.com/article/10.1007/s11263-025-02403-9</guid>
      <pubDate>Fri, 28 Mar 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>来自多视图特征立体匹配先验的健壮的小说视图综合</title>
      <link>https://link.springer.com/article/10.1007/s00530-025-01757-x</link>
      <description><![CDATA[ nerf（神经辐射场）表现出从未知视图中合成图像的能力。但是，它面临着诸如闭塞，非斜体表面，稀疏输入以及多视图图像中通常遇到的弱质地等因素所面临的挑战。这些复杂性通常会导致拟合错误的场景几何形状，从而导致次优的新型视图综合质量。本文通过利用基于功能的多视立体匹配（MVS）先验的潜力来解决这一挑战。该方法的区别是其基于MVS估算的深度值，不确定性和深度间隔的自适应构建高斯函数的区别，从而为任意缩放场景提供了灵活性和适应性。在此基础上，通过比较该分布之间的差异与量渲染射线上采样点的重量分布之间的差异来实现NERF训练过程的优化。此外，我们提出了一种有效的Riemann和近似策略，以进一步提高深度损失的性能。适用于三个实际场景数据集的定量指标，即LLFF，IBRNET和DTU，表明本文提供的方法显着提高了与当前的先进方法相比，新型视图合成的质量，可实现3.8％至26.9％的增强。可视化实验揭示了强大的优化结果，尤其是在常规NERF遇到困难的挑战区域中。
                图形摘要
                
]]></description>
      <guid>https://link.springer.com/article/10.1007/s00530-025-01757-x</guid>
      <pubDate>Tue, 25 Mar 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>传输图引导的深层展开网络，用于增强水下图像</title>
      <link>https://link.springer.com/article/10.1007/s11227-025-07155-4</link>
      <description><![CDATA[近年来，随着海洋行业的发展，水下图像增强和恢复的重要性变得越来越突出。然而，由于介质在不同波长下的光吸收和光吸收，水下图像通常会遭受颜色失真和低对比度的影响。但是，大多数现有网络都采用了一种端到端的映射方法，该方法忽略了图像增强过程中的先前信息，从而导致缺乏可解释性。为了应对这些挑战，我们提出了一个传输图引导的深层展开的网络，以增强水下图像。我们的方法由三个核心组成部分组成：自适应面膜照明动态先验（AMIDP），传输引导的多尺度卷积词典（TGMCD）和恒定的空间聚合模块（CSAM）。 AMIDP通过掩码自动编码器和动态卷积提取图像的照明特性，从而使照明和反射信息的单独建模分别为共享和独特的特征。然后将这些功能输入到TGMCD模块中，该模块由传输图指导以进行迭代优化。在此过程中，我们用可学习的多尺度残差模块替换传统的近端运算符，并结合了先前的信息和约束以增强模型性能。此外，CSAM旨在加强跨功能的信息融合，确保最终增强的图像在保留关键细节的同时纠正扭曲。在多个水下数据集上进行的广泛实验表明，我们的方法可实现最先进的性能，从而验证其有效性和优势。我们的代码可在 https://github.com/makabala/tgdu-master。]]></description>
      <guid>https://link.springer.com/article/10.1007/s11227-025-07155-4</guid>
      <pubDate>Sun, 23 Mar 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>对基于社区的夏季干预措施进行营养辅助组件的范围审查，旨在改善儿童与体重相关的结果</title>
      <link>https://link.springer.com/article/10.1186/s12889-025-22241-1</link>
      <description><![CDATA[背景
                儿童，尤其是来自低收入家庭的孩子，在夏季，体重增加和粮食不安全。夏季干预措施包括通过免费或补贴食品或食物的钱提供营养援助，可以很好地解决粮食不安全和肥胖。但是，尚无对夏季干预措施的特征和发现的全面审查，旨在改善儿童与体重相关的结果，包括粮食安全，饮食摄入，体育锻炼和体重。这项研究旨在用包括与儿童体重相关的结果在内的营养成分来描述夏季干预的特征和发现。
              
                方法
                使用该术语“夏季”，“夏季”，“食物”，“营养”，“用餐”，“午餐”，“午餐”，“午餐”或“不安全感”，搜索了此范围评论，Cinahl，Eric，Ovid Medline和Scopus数据库。三名独立审阅者筛选了手稿以获得资格。
              
                结果
                确定了13个手稿。除营养援助外，大多数夏季干预措施的大多数（ n  = 10，77％）提供了营养教育和/或体育活动参与或教育的活动。大多数干预措施（69％）是通过夏令营或学校提供的，而60％的干预措施通过夏季食品服务计划提供了营养援助，以免费餐或小吃的形式提供营养援助。粮食不安全是研究最少的结果。这些夏季干预措施与儿童与体重相关的结果之间的关联是使用各种措施和研究设计研究的，只有三项随机对照研究，其中两项没有足够的动力样本。一些准实验研究记录了干预参与与果实和蔬菜摄入，中度至剧烈的体育锻炼与BMI Z分数或百分位数之间的积极关联，但发现不一致。 
              
                结论
                需要进行更严格的设计和足够动力的样品进行进一步的研究，以评估具有营养辅助的多组分夏季干预措施的影响，以最大程度地利用与儿童体重相关的健康和平等的干预益处。
              
                临床试验号
                不适用。]]></description>
      <guid>https://link.springer.com/article/10.1186/s12889-025-22241-1</guid>
      <pubDate>Sat, 22 Mar 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LIDAR，IMU和相机融合用于同时本地化和映射：系统评价</title>
      <link>https://link.springer.com/article/10.1007/s10462-025-11187-w</link>
      <description><![CDATA[同时本地化和映射（SLAM）是智能无名系统估算其运动和重建未知环境的至关重要技术。但是，由于传感器本身的缺陷，具有一个传感器的SLAM系统仅具有稳健性和稳定性。最近的研究表明，由于不同传感器的相互补偿，具有多个传感器（主要由LIDAR，摄像机和IMU）的SLAM系统具有更好的性能。本文研究了多传感器融合大满贯的最新进展。该综述包括对不同传感器的优势和缺点的系统分析以及多传感器解决方案的命令。它通过融合传感器将多传感器融合大满贯系统分为四种主要类型：LIDAR-IMU SLAM，Visual-Imu Slam，Lidar-Visual-Visual-Visual-visual Slam和Lidar-Imu-Visual-Visual Sllam，并进行了详细的分析以及对管道和原理的讨论。同时，该论文调查常用数据集并引入评估指标。最后，总结了多传感器融合大满贯的现有挑战和未来的机会。。]]></description>
      <guid>https://link.springer.com/article/10.1007/s10462-025-11187-w</guid>
      <pubDate>Wed, 19 Mar 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>胺碘酮治疗引起的罕见神经病毒性：病例报告</title>
      <link>https://link.springer.com/article/10.1186/s43044-025-00631-5</link>
      <description><![CDATA[背景
                胺碘酮是一种以其潜在副作用而闻名的抗心律失常药物，其中一种是神经肌病，尽管它仍然相对较少。这种情况可能带有肌肉无力，疼痛和震颤，可能导致功能障碍。尚不完全了解胺碘酮诱导的神经瘤性的确切机制，但可能涉及直接肌肉毒性和对神经传导的影响。
              
                案例表现
                我们介绍了一个68岁的男性患有症状心律失常的右心室发育不良，患有长期胺碘酮，经历了双侧腿部疼痛和与胺碘酮使用相关的弱点。在临床检查中，下肢的运动强度为2/5，触觉降低。生物学评估显示肌酸激酶和C反应蛋白的正常水平。脊柱MRI正常。肌电图的“ EMG”揭示了非长度依赖性感觉运动脱髓鞘性多神经病。停用胺碘酮后，迁移率和功能都显示出显着改善。
              
                结论
                这些观察结果强调了在接受胺碘酮治疗的患者中进行神经系统检查的重要性，以鉴定罕见的并发症，例如神经瘤病。重要的是，在停用药物后，神经瘤通常是可逆的。]]></description>
      <guid>https://link.springer.com/article/10.1186/s43044-025-00631-5</guid>
      <pubDate>Wed, 19 Mar 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Easyvis：用于腹腔镜手术盒培训师的实时3D可视化软件系统</title>
      <link>https://link.springer.com/article/10.1007/s13304-025-02153-w</link>
      <description><![CDATA[ easyvis是一种新兴的沉浸式3D腹腔镜可视化系统，可提高腹腔镜手术的效率。它将多个微型摄像头和光源与手术端口整合在一起，以在所需的角度提供手术内手术的视觉。在这项工作中，我们在腹腔镜手术训练盒环境中使用Easyvis微型摄像机组装来开发一种可视化算法，并具有简化的训练任务，以验证这种新技术的可行性。由于大多数腹腔镜手术工具是刚体的对象，因此可以离线获取它们的3D形状。我们开发了2D对象检测和跟踪算法，以获取每个对象的2D姿势和3D融合算法，以使用估计的2D姿势来估计和跟踪每个对象的3D姿势。然后，与每个对象的获得的3D模型一起，我们能够使用3D表面模型（离线获取）和从单个微型胶片中获取的图像在所需视图处渲染每个对象。除前景刚性对象外，背景3D模型是使用结构化的灯光和运动结构来获取的。与前景物体的快速运动相比，假定背景变化缓慢。因此，背景3D模型仅需要偶尔更新。我们的渲染算法能够整合前景和背景3D模型，以促进从理想的视角渲染基于图像的渲染。我们进行了实验以验证渲染图像的准确性和质量。]]></description>
      <guid>https://link.springer.com/article/10.1007/s13304-025-02153-w</guid>
      <pubDate>Sun, 16 Mar 2025 00:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>