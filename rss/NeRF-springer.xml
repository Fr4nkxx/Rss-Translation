<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最新结果</title>
    <link>http://link.springer.com</link>
    <description>Springer 提供的最新内容</description>
    <lastBuildDate>Thu, 15 Aug 2024 06:17:45 GMT</lastBuildDate>
    <item>
      <title>一种基于注意力机制的轻量级图像去雾网络</title>
      <link>http://link.springer.com/10.1007/s11760-024-03392-x</link>
      <description><![CDATA[摘要
在当前基于卷积的图像去雾网络中，增加卷积层的深度和宽度是提高网络性能的常用策略。然而，这种方法显著增加了去雾网络的复杂性和计算成本。为了解决这个问题，本文提出了一种U形多尺度自适应选择网络（UMA-Net）。在不引入额外参数和计算成本的情况下，该网络利用不同尺度的卷积核对感受野的影响。它将标准卷积和扩张卷积结合到前馈网络（FFN）中，提出了一个多尺度自适应（MA）去雾模块，进一步扩展了感受野并关注FFN内重要的空间和通道信息。为了充分利用MA模块的多尺度特性，提出了一个轻量级的通道注意引导融合（CAGF）模块，实现了从雾蒙蒙图像中恢复高质量的去雾图像。大量实验证明了所提模块的有效性，在 Reside SOTS 数据集上，仅用 0.816M 参数和 8.794G FLOPs 就取得了最佳性能。]]></description>
      <guid>http://link.springer.com/10.1007/s11760-024-03392-x</guid>
      <pubDate>Sun, 01 Sep 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于局部图像风格化的音频引导隐式神经表征</title>
      <link>http://link.springer.com/10.1007/s41095-024-0413-5</link>
      <description><![CDATA[摘要
我们提出了一种音频引导局部图像风格化的新框架。声音通常提供有关场景特定背景的信息，并且与场景或对象的某个部分密切相关。然而，现有的图像风格化工作专注于使用图像或文本输入对整个图像进行风格化。基于音频输入对图像的特定部分进行风格化是自然但具有挑战性的。这项工作提出了一个框架，其中用户提供音频输入以在输入图像中定位目标，并提供另一个音频输入以局部风格化目标对象或场景。我们首先使用利用 CLIP 嵌入空间的视听定位网络生成精细定位图。然后，我们利用隐式神经表征 (INR) 以及预测的定位图根据声音信息对目标进行风格化。INR 操纵局部像素值以与提供的音频输入在语义上一致。我们的实验表明，所提出的框架优于其他音频引导风格化方法。此外，我们观察到我们的方法构建了简洁的定位图，并根据给定的音频输入自然地操纵目标对象或场景。




]]></description>
      <guid>http://link.springer.com/10.1007/s41095-024-0413-5</guid>
      <pubDate>Wed, 14 Aug 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>FMGS：基础模型嵌入 3D 高斯溅射，用于整体 3D 场景理解</title>
      <link>http://link.springer.com/10.1007/s11263-024-02183-8</link>
      <description><![CDATA[摘要
准确感知现实世界 3D 对象的几何和语义属性对于增强现实和机器人应用的持续发展至关重要。为此，我们提出了基础模型嵌入高斯分层 (FMGS)，它将基础模型的视觉语言嵌入合并到 3D 高斯分层 (GS) 中。这项工作的主要贡献是一种重建和表示 3D 视觉语言模型的有效方法。这是通过将基于图像的基础模型生成的特征图提炼为从我们的 3D 模型渲染的特征图来实现的。为了确保高质量的渲染和快速的训练，我们通过整合 GS 和多分辨率哈希编码 (MHE) 的优势引入了一种新颖的场景表示。我们有效的训练过程还引入了像素对齐损失，使得相同语义实体的渲染特征距离接近，遵循像素级语义边界。我们的结果表明，多视图语义一致性非常出色，有助于完成各种下游任务，以 
\({10.2}\)
 的速度超越了最先进的方法，尽管我们的推理速度 
\({851\times }\)
 更快。​​这项研究探索了视觉、语言和 3D 场景表示的交集，为在不受控制的现实世界环境中增强场景理解铺平了道路。我们计划在[项目页面]上发布代码。]]></description>
      <guid>http://link.springer.com/10.1007/s11263-024-02183-8</guid>
      <pubDate>Mon, 12 Aug 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于对抗模仿学习的网络进行类别级 6D 物体姿态估计</title>
      <link>http://link.springer.com/10.1007/s00138-024-01592-6</link>
      <description><![CDATA[摘要
类别级6D物体姿态估计是计算机视觉领域中一项非常基础和关键的研究。为了摆脱对物体3D模型的依赖，分析综合型物体姿态估计方法近年来得到了广泛的研究。虽然这些方法在泛化方面有一定的提升，但类别级物体姿态估计的准确性仍有待提高。本文提出了一种基于对抗模仿学习的类别级6D物体姿态估计网络AIL-Net。AIL-Net采用状态-动作分布匹配准则，能够执行数据集中未出现过的专家动作，防止物体姿态估计陷入不良状态。我们进一步设计了一个通过生成对抗模仿学习估计物体姿态的框架，该方法能够区分AIL-Net中的专家策略和模仿策略。实验结果表明，我们的方法在REAL275数据集和Cars数据集上取得了具有竞争力的类别级物体姿态估计性能。]]></description>
      <guid>http://link.springer.com/10.1007/s00138-024-01592-6</guid>
      <pubDate>Mon, 12 Aug 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>EPSM 2023，医学工程与物理科学</title>
      <link>http://link.springer.com/10.1007/s13246-024-01460-7</link>
      <description><![CDATA[]]></description>
      <guid>http://link.springer.com/10.1007/s13246-024-01460-7</guid>
      <pubDate>Mon, 12 Aug 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>一种多任务有效性度量和自适应协同训练方法，用于通过少量样本提高学习效果</title>
      <link>http://link.springer.com/10.1007/s10845-024-02475-3</link>
      <description><![CDATA[摘要
将深度学习 (DL) 集成到视觉检测方法中，越来越多地被认为是一种可大幅提高适应性和鲁棒性的宝贵方法。然而，众所周知，高性能神经网络通常需要具有高质量手动注释的大量训练数据集，而这在许多制造过程中很难获得。为了提高 DL 方法在样本较少的情况下执行视觉任务的性能，本文提出了一种称为辅助任务有效性 (EAT) 的新指标，并提出了一种多任务学习方法，利用该指标来选择有效的辅助任务分支并自适应地将它们与主任务一起训练。在两个少量样本的视觉任务上进行的实验表明，所提方法有效地消除了无效的任务分支，并增强了所选任务对主任务的贡献：在姿势关键点检测中将平均归一化像素误差从 0.0613 降低到 0.0143，在表面缺陷分割中将交并比 (IoU) 从 0.6383 提升到 0.6921。值得注意的是，这些增强是在不需要额外的手动标记工作的情况下实现的。]]></description>
      <guid>http://link.springer.com/10.1007/s10845-024-02475-3</guid>
      <pubDate>Mon, 12 Aug 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于神经辐射场的支气管镜导航方法</title>
      <link>http://link.springer.com/10.1007/s11548-024-03243-7</link>
      <description><![CDATA[摘要

目的
我们介绍了一种新颖的支气管镜导航方法，该方法利用神经辐射场 (NeRF) 仅从支气管镜图像中被动定位内窥镜。该方法旨在克服当前依赖外部基础设施或需要主动调整支气管镜的支气管镜导航工具的局限性和挑战。


方法
为了应对挑战，我们利用 NeRF 进行支气管镜导航，从而实现从支气管镜图像中进行被动内窥镜定位。我们开发了一个两阶段流程：使用术前数据进行离线训练和手术期间进行在线被动姿势估计。为了提高性能，我们采用 Anderson 加速并结合语义外观迁移来处理训练和推理阶段之间的模拟到现实差距。


结果
我们通过对虚拟支气管镜图像和物理模型进行测试来评估我们方法的可行性，以对抗基于 SLAM 的方法。我们的虚拟数据集中的平均旋转误差约为 3.18
\(^\circ \)
，平移误差约为 4.95 毫米。在物理幻影测试中，平均旋转和平移误差约为 5.14
\(^\circ \)
 和 13.12 毫米。


结论
我们基于 NeRF 的支气管镜导航方法消除了对外部基础设施和主动调整的依赖，为支气管镜导航带来了有希望的进步。在模拟和真实世界幻影模型上的实验验证证明了其在应对低纹理和具有挑战性的照明条件等挑战方面的有效性。
]]></description>
      <guid>http://link.springer.com/10.1007/s11548-024-03243-7</guid>
      <pubDate>Wed, 07 Aug 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DialogueNeRF：实现逼真的虚拟面对面对话视频生成</title>
      <link>http://link.springer.com/10.1007/s44267-024-00057-8</link>
      <description><![CDATA[摘要
对话是虚拟角色在元宇宙中活动的重要组成部分。随着自然语言处理的发展，文本和语音对话生成取得了重大突破。然而，面对面的对话占日常对话的绝大部分，而现有的大多数方法都集中在单人说话头像的生成上。在这项工作中，我们更进一步，考虑生成逼真的面对面对话视频。对话生成比单人说话头像生成更具挑战性，因为它不仅需要生成照片般逼真的单个说话头像，还需要听众对说话者的回应。在本文中，我们提出了一种基于神经辐射场 (NeRF) 的新型统一框架来应对这些挑战。具体而言，我们在不同条件下使用 NeRF 框架对说话者和听众进行建模，以控制个人表情。说话者由音频信号驱动，而听众的响应取决于视觉和听觉信息。通过这种方式，人类虚拟形象之间可以生成面对面的对话视频，所有对话者都在同一网络中建模。此外，为了方便今后对该任务的研究，我们还收集了一个包含 34 个视频片段的新人类对话数据集。定量和定性实验从不同方面评估了我们的方法，例如图像质量、姿势序列趋势和生成的视频中场景的自然渲染。实验结果表明，生成的视频中的虚拟形象能够进行逼真的对话，并保持个人风格。]]></description>
      <guid>http://link.springer.com/10.1007/s44267-024-00057-8</guid>
      <pubDate>Wed, 07 Aug 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>PIDSNeRF：姿势插值深度监督神经辐射场，用于从具有挑战性的输入中进行视图合成</title>
      <link>http://link.springer.com/10.1007/s11042-024-19978-z</link>
      <description><![CDATA[摘要
最近，神经辐射场（NeRF）在通过多视图进行新视图合成的任务中表现出色。本研究引入了一种先进的优化框架，称为姿势插值深度监督神经辐射场（PIDSNeRF），旨在解决 NeRF 在新视图合成中遇到的挑战。这些挑战表现为伪影、纹理细节丢失和几何不一致，特别是在以不同的光照条件、无纹理区域和稀疏图像为输入的场景中。PIDSNeRF 的原理涉及基于已知相机在 3D 空间域中插值虚拟相机位置，随后，将相机姿势估计期间形成的稀疏点云重新投影到这些虚拟姿势上，采用反角度加权策略，从而生成深度监督射线。此外，我们提出了一种深度扩散方法，将深度监督的射线沿像素平面扩散，根据扩散距离形成具有不同方差的高斯函数。最后，通过优化每条射线沿线采样点的权重分布与相应高斯函数沿该射线的概率密度函数之间的 Kullback-Leibler（KL）散度来实现体绘制时的深度监督。上述过程可以更全面地优化与射线沿线采样点对齐的多分辨率网格特征。在DTU、LLFF和DL3DV-10K数据集上的实验表明，PIDSNeRF可以在几分钟内合成完整的新颖视图，并且合成图像的各项指标都达到了最优性能。]]></description>
      <guid>http://link.springer.com/10.1007/s11042-024-19978-z</guid>
      <pubDate>Tue, 06 Aug 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于野外细粒度单目 3D 人脸重建的自监督学习</title>
      <link>http://link.springer.com/10.1007/s00530-024-01436-3</link>
      <description><![CDATA[摘要
由于传统 3DMM（3D 可变形模型）的局限性以及缺乏高保真 3D 面部扫描数据，从单目图像重建 3D 人脸是一项具有挑战性的计算机视觉任务。为了解决这个问题，我们提出了一种新颖的从粗到细的自监督学习框架，用于从野外单目图像重建细粒度 3D 人脸。在粗阶段，从单个图像中提取的人脸参数用于通过 3DMM 重建粗 3D 人脸。在细化阶段，我们设计了一个小波变换感知模型，从输入图像中提取不同频域中的面部细节。此外，我们提出了一个基于小波变换感知模型的深度位移模块，从输入图像和渲染的粗面部的展开 UV 纹理生成细化的位移图，可用于合成详细的 3D 人脸几何形状。此外，我们提出了一种基于小波变换感知模型的新型反照率图模块，以捕获高频纹理信息并生成与面部照明一致的详细反照率图。详细的面部几何形状和反照率图用于重建细粒度的 3D 面部，而无需任何标记数据。我们已经进行了大量实验，证明了我们的方法优于现有的最先进的 3D 面部重建方法，这些方法在四个公共数据集（包括 CelebA、LS3D、LFW 和 NoW 基准）上进行。实验结果表明，我们的方法实现了更高的准确性和鲁棒性，特别是在遮挡、大姿势和变化的照明等具有挑战性的条件下。]]></description>
      <guid>http://link.springer.com/10.1007/s00530-024-01436-3</guid>
      <pubDate>Mon, 05 Aug 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ReliTalk：通过单个视频生成可重新点亮的会说话的肖像</title>
      <link>http://link.springer.com/10.1007/s11263-024-02007-9</link>
      <description><![CDATA[摘要
近年来，在从单目视频创建生动的音频驱动肖像方面取得了巨大进展。然而，如何将创建的视频头像无缝地适应具有不同背景和光照条件的其他场景仍未解决。另一方面，现有的重新照明研究大多依赖于动态照明或多视图数据，这对于创建视频肖像来说太昂贵了。为了弥补这一差距，我们提出了ReliTalk，这是一个用于从单目视频生成可重新照明的音频驱动说话肖像的新颖框架。我们的主要见解是从隐式学习的音频驱动面部法线和图像中分解肖像的反射率。具体而言，我们涉及从音频特征中得出的 3D 面部先验，以通过隐式函数预测精细的法线图。然后，这些最初预测的法线通过动态估计给定视频的光照条件在反射率分解中发挥关键作用。此外，在模拟的多种光照条件下，使用身份一致性损失来改进立体人脸表征，解决了由于单目视频的视图有限而导致的不适定问题。大量实验验证了我们提出的框架在真实数据集和合成数据集上的优越性。我们的代码发布在 (https://github.com/arthur-qiu/ReliTalk)。]]></description>
      <guid>http://link.springer.com/10.1007/s11263-024-02007-9</guid>
      <pubDate>Thu, 01 Aug 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>航拍图像中微小物体检测的图像增强方法：综述</title>
      <link>http://link.springer.com/10.1007/s11042-024-19768-7</link>
      <description><![CDATA[摘要
即使采用先进的检测方法，检测小型和微小物体的任务与检测中型和大型物体相比也没有显示出显着的性能改进。造成这种情况的因素有几个，包括物体本身的尺寸小、小规模数据集的可用性有限、物体的聚类以及物体与图像的比率低等。然而，已经开发了各种图像增强技术来应对这些挑战。在本研究中，总结了以前的调查和评论，概述了用于实现各种增强方法的增强库。它还对传统和最先进的增强方法进行了简要回顾，概述了它们各自的优点和缺点。重点是更多地探索传统和最先进的增强方法在性能改进方面对小型和微小物体检测任务的有效性。这篇评论论文与以前的论文不同，它涵盖了专门用于检测航空图像中小型和微小物体检测任务的图像增强方法的深入研究，而以前的文献中并没有如此大规模地涉及这个主题。本文还进行了讨论，使读者能够辨别哪种方法或方法组合适合解决与小型和微小物体检测相关的特定挑战。这将有助于读者建立良好的知识并培养该领域的批判和评估技能。此外，它为当前的挑战提供了可能的解决方案，并概述了未来的方向。]]></description>
      <guid>http://link.springer.com/10.1007/s11042-024-19768-7</guid>
      <pubDate>Thu, 01 Aug 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于双平面血管造影的傅里叶特征网络三维血管重建</title>
      <link>http://link.springer.com/10.1007/s00138-024-01585-5</link>
      <description><![CDATA[摘要
由于深度信息的丢失和输入图像之间未知的像素相关性，双平面脑血管造影的 3D 重建仍然是一个具有挑战性的、尚未解决的研究问题。仅由两个视图引起的遮挡使精细血管细节的重建和固有缺失信息的同时处理变得复杂。在本文中，我们通过使用双平面 1D 图像数据重建脑血管造影的相应 2D 切片，逐步解决了这个问题。我们开发了一个基于坐标的神经网络，该网络对 1D 图像数据以及来自给定输入点的确定性傅立叶特征映射进行编码，从而实现更空间精确的切片重建。我们的傅里叶特征网络仅使用一行 1D 双平面图像数据，就重建了相应的体积切片，其峰值信噪比 (PSNR) 为 26.32 ± 0.36，结构相似性指数度量 (SSIM) 为 61.38 ± 1.79，均方误差 (MSE) 为 0.0023 ± 0.0002，平均绝对误差 (MAE) 为 0.0364 ± 0.0029。我们的研究对未来的工作具有重要意义，旨在通过首先检查 1D 信息中的各个切片作为先决条件来改进基于反投影的重建。]]></description>
      <guid>http://link.springer.com/10.1007/s00138-024-01585-5</guid>
      <pubDate>Thu, 01 Aug 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>全球激光雷达定位综述：挑战、进展和未解决的问题</title>
      <link>http://link.springer.com/10.1007/s11263-024-02019-5</link>
      <description><![CDATA[摘要
了解自身姿势是所有移动机器人应用的关键。因此，姿势估计是移动机器人核心功能的一部分。在过去的二十年里，LiDAR 扫描仪已成为机器人定位和测绘的标准传感器。本文旨在概述基于 LiDAR 的全球定位的最新进展和进步。我们首先提出问题并探索应用范围。然后，我们回顾该方法，包括地图、描述符提取和跨机器人定位等几个主题的最新进展。本文的内容分为三个主题。第一个主题涉及全局位置检索和局部姿势估计的结合。第二个主题是将单次测量升级为连续测量，以实现连续全局定位。最后，第三个主题侧重于将单机器人全局定位扩展到多机器人系统中的跨机器人定位。我们通过讨论全球 LiDAR 定位的开放挑战和有希望的方向来结束调查。据我们所知，这是第一次对移动机器人全球 LiDAR 定位进行全面调查。]]></description>
      <guid>http://link.springer.com/10.1007/s11263-024-02019-5</guid>
      <pubDate>Thu, 01 Aug 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>复杂结构中基础设施元素分类的机器学习算法评估</title>
      <link>http://link.springer.com/10.1007/s12205-024-2062-8</link>
      <description><![CDATA[摘要
3D 竣工模型在技术基础设施项目中的城市动态中起着至关重要的作用。在动态城市区域启用 3D 数据分析有利于施工流程和管理任务，包括生产监控和布局规划。点云通过部署包含每个点的位置和颜色信息的 3D 点集合来表示场景。为这些点分配语义信息（称为点云分类 (PCC)）对于 3D 环境的记录和监控至关重要。使用每个点的多尺度几何特征的机器学习 (ML) 分类器经常用于点云分类 (PCC)。本研究旨在评估 ML 分类器在复杂基础设施领域的分类性能，并确定最有效的识别目标场景的几何特征。两个案例研究中使用了随机森林 (RF)、极端梯度提升机 (XGB) 和轻梯度提升机 (LGBM) 分类器。根据实验测试，XGB 的准确率高于 RF 和 LGBM。此外，尽管采用了不同的方法，但这些分类器在特定几何特征的重要性上总体上是一致的。我们的研究结果为在现实场景中对技术基础设施元素进行分类提供了指导。]]></description>
      <guid>http://link.springer.com/10.1007/s12205-024-2062-8</guid>
      <pubDate>Thu, 01 Aug 2024 00:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>