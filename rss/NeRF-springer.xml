<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最新结果</title>
    <link>http://link.springer.com</link>
    <description>Springer 提供的最新内容</description>
    <lastBuildDate>Mon, 30 Sep 2024 01:06:36 GMT</lastBuildDate>
    <item>
      <title>Deblur e-NeRF：高速或低光条件下运动模糊事件中的 NeRF</title>
      <link>http://link.springer.com/10.1007/978-3-031-73232-4_11</link>
      <description><![CDATA[摘要
事件相机的独特设计理念使其成为高速、高动态范围和低光环境的理想选择，而标准相机在这些环境中表现不佳。然而，与大多数人的想法相反，事件相机也存在运动模糊，尤其是在这些具有挑战性的条件下。这是由于事件传感器像素的带宽有限，而带宽主要与光强度成正比。因此，为了确保事件相机能够真正在这种条件下表现出色，比标准相机更具优势，必须在下游任务（尤其是重建）中考虑事件运动模糊。然而，之前没有关于从事件重建神经辐射场 (NeRF) 的研究，也没有事件模拟器考虑过事件运动模糊的全部影响。为此，我们提出了 Deblur e-NeRF，这是一种新方法，可以直接有效地从高速或低光条件下产生的运动模糊事件中重建模糊最小的 NeRF。这项工作的核心部分是物理上精确的像素带宽模型，该模型考虑了事件运动模糊。我们还引入了阈值归一化总变分损失，以更好地规范大型无纹理斑块。在真实和新颖的现实模拟序列上进行的实验验证了我们的有效性。我们的代码、事件模拟器和合成事件数据集都是开源的。]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-73232-4_11</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RING-NeRF：重新思考多功能高效神经场的归纳偏差</title>
      <link>http://link.springer.com/10.1007/978-3-031-72761-0_9</link>
      <description><![CDATA[摘要
神经领域的最新进展主要依赖于开发特定于任务的监督，这通常会使模型复杂化。与开发难以组合和特定的模块不同，另一种通常被忽视的方法是将场景表示的通用先验（也称为归纳偏差）直接注入 NeRF 架构。基于这个想法，我们提出了 RING-NeRF 架构，其中包括两个归纳偏差：场景的连续多尺度表示和解码器潜在空间在空间和尺度域上的不变性。我们还设计了一个利用这些归纳偏差的单一重建过程，并通过实验证明了在多个任务（抗锯齿、少量视图重建、没有场景特定初始化的 SDF 重建）上与专用架构在质量方面的性能相当，同时效率更高。此外，RING-NeRF 具有动态提高模型分辨率的独特能力，为自适应重建开辟了道路。项目页面位于：https://cea-list.github.io/RING-NeRF]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-72761-0_9</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>URS-NeRF：针对神经辐射场的无序滚动快门束调整</title>
      <link>http://link.springer.com/10.1007/978-3-031-72761-0_26</link>
      <description><![CDATA[摘要
本文提出了一种新的神经辐射场（NeRF）滚动快门束调整方法，该方法利用无序滚动快门（RS）图像来获得隐式三维表示。现有的 NeRF 方法由于图像中的 RS 效应而存在图像质量低和初始相机姿势不准确的问题。此外，以前将 RS 图像合并到 NeRF 中的方法需要严格的顺序数据输入，从而限制了其广泛的适用性。相比之下，我们的方法通过估计相机姿势和速度来恢复 RS 图像的物理形态，从而消除了对顺序数据的输入限制。此外，我们采用由粗到细的训练策略，其中场景图中成对帧的 RS 极线约束用于检测落入局部最小值的相机姿势。检测到的异常姿势通过邻近姿势的插值方法进行校正。实验结果验证了我们的方法相对于最先进方法的有效性，并表明 3D 表示的重建不受视频序列输入要求的限制。]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-72761-0_26</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Structured-NeRF：具有神经表征的分层场景图</title>
      <link>http://link.springer.com/10.1007/978-3-031-72761-0_11</link>
      <description><![CDATA[摘要
我们提出了一种结构化神经辐射场 (Structured-NeRF)，用于室内场景表示，该结构基于一种新颖的分层场景图结构来组织神经辐射场。现有的以对象为中心的方法仅关注对象的固有特征，而忽略了它们之间的语义和物理关系。我们的场景图擅长管理场景内对象之间复杂的现实世界相关性，从而实现超越新颖视图合成的功能，例如场景重新排列。基于分层结构，我们引入了基于语义和物理关系的优化策略，从而简化了场景编辑所涉及的操作并确保了效率和准确性。此外，我们对对象进行阴影渲染，以进一步增强渲染图像的真实感。实验结果表明，我们的结构化表示不仅在对象级和场景级渲染中实现了最佳（SOTA）性能，而且还与LLM/VLM结合推进了下游应用，例如自动和指令/图像条件场景重新排列，从而方便且可控地将NeRF扩展到交互式编辑。]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-72761-0_11</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>计算机视觉 – ECCV 2024</title>
      <link>http://link.springer.com/10.1007/978-3-031-72761-0</link>
      <description><![CDATA[]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-72761-0</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>计算机视觉 – ECCV 2024</title>
      <link>http://link.springer.com/10.1007/978-3-031-72670-5</link>
      <description><![CDATA[]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-72670-5</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>计算机视觉 – ECCV 2024</title>
      <link>http://link.springer.com/10.1007/978-3-031-73232-4</link>
      <description><![CDATA[]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-73232-4</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>计算机视觉 – ECCV 2024</title>
      <link>http://link.springer.com/10.1007/978-3-031-72784-9</link>
      <description><![CDATA[]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-72784-9</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>计算机视觉 – ECCV 2024</title>
      <link>http://link.springer.com/10.1007/978-3-031-72998-0</link>
      <description><![CDATA[]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-72998-0</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>神经辐射场的物理合理色彩校正</title>
      <link>http://link.springer.com/10.1007/978-3-031-72784-9_10</link>
      <description><![CDATA[摘要
神经辐射场已成为许多 3D 计算机视觉和计算机图形应用的首选表示，例如新颖的视图合成和 3D 重建。多摄像头系统通常用作基于 NeRF 的多视图任务（例如动态场景采集或逼真的头像动画）中的图像捕获设置。然而，这种设置中经常被忽视的一个关键问题是多个摄像头之间的颜色响应存在明显差异，这会对 NeRF 重建性能产生不利影响。多个输入图像之间的这些颜色差异源于两个方面：1) 场景的隐式属性，例如反射和阴影，以及 2) 相机设置和光照条件的外部差异。在本文中，我们通过提出一种新颖的色彩校正模块来解决这个问题，该模块模拟相机中的物理色彩处理并嵌入到 NeRF 中，从而实现统一的色彩 NeRF 重建。除了用于外部差异的独立于视图的色彩校正模块之外，我们还预测了一个与视图相关的函数来最小化色彩残差（包括 例如 镜面反射和阴影），以消除固有属性的影响。我们进一步描述了如何使用参考图作为指导来扩展该方法，以在新颖的视图上实现美观的色彩一致性和色彩转换。实验验证了我们的方法在色彩校正和色彩一致性的定量和定性评估方面均优于基线方法。
]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-72784-9_10</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>NGP-RT：融合多级哈希特征和轻量级注意力机制，实现实时新颖视图合成</title>
      <link>http://link.springer.com/10.1007/978-3-031-72670-5_9</link>
      <description><![CDATA[摘要
本文介绍了 NGP-RT，这是一种提高 Instant-NGP 渲染速度以实现实时新视图合成的新方法。作为一种经典的基于 NeRF 的方法，Instant-NGP 将隐式特征存储在多级网格或哈希表中，并应用浅层 MLP 将隐式特征转换为显式颜色和密度。虽然它实现了快速的训练速度，但由于隐式多级特征聚合的每点 MLP 执行，其渲染速度仍有很大提升空间，尤其是对于实时应用。为了应对这一挑战，我们提出的 NGP-RT 明确将颜色和密度存储为哈希特征，并利用轻量级注意机制来消除哈希冲突的歧义，而不是使用计算密集型 MLP。在渲染阶段，NGP-RT 将预先计算的占用距离网格纳入光线行进策略，以告知到最近占用体素的距离，从而减少行进点的数量和全局内存访问。实验结果表明，在具有挑战性的 Mip-NeRF 360 数据集上，NGP-RT 实现了比以前基于 NeRF 的方法更好的渲染质量，在单个 Nvidia RTX 3090 GPU 上以 1080p 分辨率实现了 108 fps。我们的方法对于需要高效高质量渲染的基于 NeRF 的实时应用很有前景。]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-72670-5_9</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>G $$^2$$ fR：基于网格的特征编码神经辐射场中的频率正则化</title>
      <link>http://link.springer.com/10.1007/978-3-031-72670-5_11</link>
      <description><![CDATA[摘要
神经辐射场 (NeRF) 方法引起了广泛关注，尤其是随着基于网格的特征编码 (GFE) 方法（例如 Instant-NGP 和 TensoRF）的引入。传统的 NeRF 采用位置编码 (PE) 并使用多层感知器 (MLP) 表示场景。频率正则化已被确定为克服基于 PE 的 NeRF 中主要挑战的有效策略，包括对已知相机姿势的依赖和对大量图像数据集的要求。虽然有几项研究试图将频率正则化扩展到 GFE 方法，但这些方法仍然缺乏基本的理论基础。因此，我们首先阐明频率正则化的潜在机制。随后，我们对基于 GFE 的 NeRF 的表达能力进行了全面研究，并尝试将频率正则化与 GFE 方法联系起来。此外，我们提出了一种通用策略，G
\(^2\)
 fR：基于广义网格的频率正则化，用于解决使用 GFE 方法进行相机姿态优化和少样本重建的问题。我们通过一系列在不同场景中采用各种表示的实验来验证我们方法的有效性。]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-72670-5_11</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>内容感知辐射场：通过学习位宽量化将模型复杂性与场景复杂性相结合</title>
      <link>http://link.springer.com/10.1007/978-3-031-72775-7_14</link>
      <description><![CDATA[摘要
最近流行的辐射场模型，例如神经辐射场 (NeRF)、Instant-NGP 和 3D 高斯溅射，旨在通过为每个场景训练模型来表示 3D 内容。场景表示和每个场景训练的独特特性将辐射场模型与其他神经模型区分开来，因为复杂的场景需要具有更高表示能力的模型，反之亦然。在本文中，我们提出了内容感知辐射场，通过对抗性内容感知量化 (A-CAQ) 将模型复杂性与场景复杂性相结合。具体而言，我们使参数的位宽可区分和可训练，以适应特定场景和要求的独特特征。所提出的框架已在众所周知的 NeRF 变体 Instant-NGP 上进行了评估，并使用各种数据集进行了评估。实验结果表明，计算复杂度显著降低，同时保留了必要的重建和渲染质量，有利于辐射场模型的实际部署。代码可在https://github.com/WeihangLiu2024/Content_Aware_NeRF获取。
]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-72775-7_14</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>计算机视觉 – ECCV 2024</title>
      <link>http://link.springer.com/10.1007/978-3-031-72775-7</link>
      <description><![CDATA[]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-72775-7</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于体素的神经辐射场的单掩模修复</title>
      <link>http://link.springer.com/10.1007/978-3-031-72998-0_7</link>
      <description><![CDATA[摘要
3D 修复是计算机视觉和图形领域的一项具有挑战性的任务，旨在移除物体并用视觉上连贯且完整的背景表示填充缺失区域。已经提出了一些方法来解决这个问题，并在修复方面取得了显著的成果。然而，这些方法并没有完美地解决依赖每个视图的蒙版的局限性。获取每个视图的蒙版可能很耗时，并且会降低质量，尤其是在具有大量视图或复杂场景的场景中。为了解决这一限制，我们提出了一种创新方法，该方法消除了对每个视图蒙版的需求，并使用来自选定视图的单个蒙版。我们专注于提高前向场景修复的质量。通过将单个 2D 蒙版投影到 NeRFs 空间中，我们在三维中定义需要修复的区域。我们引入了一个两步优化过程。首先，我们利用 2D 修复器为选定视图生成颜色和深度先验。这为要修复的区域提供了粗略的监督。其次，我们结合了 2D 扩散模型来提高修复区域的质量，减少扭曲并提高整体视觉保真度。通过大量实验，我们证明了单掩模修复框架的有效性。结果表明，我们的方法成功地修复了复杂的几何图形，并产生了视觉上合理且逼真的结果。]]></description>
      <guid>http://link.springer.com/10.1007/978-3-031-72998-0_7</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>