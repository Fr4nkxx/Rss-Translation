<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最新结果</title>
    <link>http://link.springer.com</link>
    <description>Springer 提供的最新内容</description>
    <lastBuildDate>Wed, 20 Mar 2024 21:10:49 GMT</lastBuildDate>
    <item>
      <title>基于实时距离场加速的大型运动场自由视点视频合成</title>
      <link>http://link.springer.com/10.1007/s41095-022-0323-3</link>
      <description><![CDATA[摘要
自由视点视频允许用户从任何虚拟角度观看物体，创造身临其境的视觉体验。该技术增强了多媒体表演的交互性和自由度。然而，许多自由视点视频合成方法很难满足实时、高精度的要求，特别是对于面积较大、运动物体较多的运动场。为了解决这些问题，我们提出了一种基于距离场加速的自由视点视频合成方法。其中心思想是融合多视点距离场信息并利用其自适应调整搜索步长。自适应步长搜索有两种用途：用于多目标三维表面的快速估计，以及基于全局遮挡判断的合成视图渲染。我们使用并行计算进行交互式显示、使用 CUDA 和 OpenGL 框架来实现我们的想法，并使用真实世界和模拟实验数据集进行评估。结果表明，所提出的方法可以在大型运动场上以 25 fps 渲染具有多个对象的自由视点视频。此外，我们合成的新颖视点图像的视觉质量超过了最先进的基于神经渲染的方法。
      



]]></description>
      <guid>http://link.springer.com/10.1007/s41095-022-0323-3</guid>
      <pubDate>Mon, 01 Apr 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>FFEINR：时空超分辨率的流特征增强隐式神经表示</title>
      <link>http://link.springer.com/10.1007/s12650-024-00959-1</link>
      <description><![CDATA[摘要
大规模数值模拟能够生成高达 TB 甚至 PB 的数据。作为一种有前途的数据缩减方法，超分辨率（SR）已在科学可视化界得到广泛研究。然而，它们大多数都是基于深度卷积神经网络或生成对抗网络，需要在构建网络之前确定比例因子。导致单次训练仅支持固定因子，泛化能力较差。为了解决这些问题，本文提出了一种用于流场数据时空超分辨率的流特征增强隐式神经表示（FFEINR）。它可以在模型结构和采样分辨率方面充分利用隐式神经表示。神经表示基于具有周期性激活函数的全连接网络，这使我们能够获得轻量级模型。学习到的连续表示可以将低分辨率流场输入数据解码为任意空间和时间分辨率，从而允许灵活的上采样。通过引入输入层的特征增强来促进 FFEINR 的训练过程，这补充了流场的上下文信息。为了证明该方法的有效性，通过设置不同的超参数在不同的数据集上进行了一系列实验。结果表明，FFEINR取得了明显优于三线性插值方法的结果。

图形摘要






]]></description>
      <guid>http://link.springer.com/10.1007/s12650-024-00959-1</guid>
      <pubDate>Mon, 01 Apr 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于可微渲染的动态海洋反建模</title>
      <link>http://link.springer.com/10.1007/s41095-023-0338-4</link>
      <description><![CDATA[摘要
学习和推断捕获的 2D 场景的潜在运动模式，然后重新创建与现实世界自然现象一致的动态演化，这对图形和动画具有很高的吸引力。为了弥合虚拟和现实环境之间的技术差距，我们专注于视觉一致且属性可验证的海洋的逆向建模和重建，利用深度学习和可微物理来学习几何并以自我监督的方式构成波浪。首先，我们使用两个网络推断分层几何，这两个网络通过可微渲染器进行了优化。我们通过配备可微分海洋模型的网络从推断的几何序列中提取波浪分量。然后，可以使用重建的波浪分量来演化海洋动力学。通过大量的实验，我们验证了我们的新方法在几何重建和波浪估计方面都能产生令人满意的结果。此外，新框架具有逆向建模潜力，可促进大量图形应用，例如快速生成物理精确的场景动画以及由真实海洋场景引导的编辑。
      



]]></description>
      <guid>http://link.springer.com/10.1007/s41095-023-0338-4</guid>
      <pubDate>Mon, 01 Apr 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>机器视觉中的综合数据增强方法综述</title>
      <link>http://link.springer.com/10.1007/s11633-022-1411-7</link>
      <description><![CDATA[摘要
解决计算机视觉问题的标准方法是使用代表目标任务的大规模图像数据集来训练深度卷积神经网络 (CNN) 模型。然而，在许多场景中，为目标任务获取足够的图像数据通常具有挑战性。数据增强是缓解这一挑战的一种方法。常见的做法是以所需的方式显式地转换现有图像，以创建实现良好泛化性能所需的训练数据量和可变性。在无法访问目标域数据的情况下，一个可行的解决方法是从头开始合成训练数据，即合成数据增强。本文对合成数据增强技术进行了广泛的回顾。它涵盖了基于真实 3D 图形建模、神经风格迁移 (NST)、差分神经渲染以及使用生成对抗网络 (GAN) 和变分自动编码器 (VAE) 的生成建模的数据合成方法。对于每一类方法，我们重点关注重要的数据生成和增强技术、一般应用范围和特定用例，以及现有的限制和可能的解决方法。此外，我们还提供了用于训练计算机视觉模型的常见合成数据集的摘要，重点介绍了主要功能、应用领域和支持的任务。最后，我们讨论合成数据增强方法的有效性。由于这是第一篇详细探讨合成数据增强方法的论文，我们希望为读者提供必要的背景信息以及对现有方法及其随之而来的问题的深入了解。]]></description>
      <guid>http://link.springer.com/10.1007/s11633-022-1411-7</guid>
      <pubDate>Wed, 20 Mar 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过学习自适应多模态先验来生成形状</title>
      <link>http://link.springer.com/10.1007/s00371-024-03303-8</link>
      <description><![CDATA[摘要
使用深度生成模型进行图像创建的最新进展引起了人们的极大兴趣和进展，但自动三维形状创建领域在很大程度上尚未开发，并激发了巨大的兴趣跨多个学科的研究活动。我们使用被描述为体积网格的几何数据将一种先前命名的后验变分混合添加到对抗网络中。我们的主要贡献是将一种称为后验变分混合先验的新型先验引入到对抗性网络中，称为VampPrior-3DGAN，以数学原理的方式。具体来说，我们利用编码器作为正则化器来惩罚缺失模式，同时引入后验先验的变分混合作为 GAN 的潜变量分布，以动态自适应地更新其先验分布。这种架构背后的关键直觉是，潜在变量应该保留有关数据的信息，以尽量减少先前假设的不当影响。这种对 GAN 框架看似简单的修改却出人意料地有效，尽管使用有限的数据进行训练，但所产生的模型仍可实现生成样本的多样性。通过对 VampPrior-3DGAN 的潜在概率流形进行采样，可以轻松生成逼真的 3D 对象。为了验证，我们将我们的方法应用于三维体积生成、单个 RGB 图像的重建和单个透视图的部分形状完成等领域的任务，并表明它与状态相同或优于状态 -定量和定性方面的最先进方法。]]></description>
      <guid>http://link.springer.com/10.1007/s00371-024-03303-8</guid>
      <pubDate>Wed, 20 Mar 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>门诊全髋关节和全膝关节置换术：文献综述和围手术期注意事项</title>
      <link>http://link.springer.com/10.1007/s12630-024-02699-0</link>
      <description><![CDATA[摘要

目的
全关节置换术 (TJA)，特别是髋关节和膝关节置换术，是最常进行的外科手术之一。手术和麻醉技术的进步/发展使得 TJA 能够在门诊/当天出院的基础上进行。在这个持续专业发展模块中，我们综合了围手术期证据，这些证据可能有助于开发成功的门诊 TJA 路径。


来源
我们搜索了 MEDLINE、Embase、CENTRAL 和 Cochrane 系统评价数据库中的动态或快速通道 TJA 文章。在缺乏流动环境的直接证据的情况下，我们从住院 TJA 文献中推断出证据。


主要发现
涵盖患者、医疗和社会因素的患者选择是 TJA 患者当天成功出院的基础。术中麻醉类型的证据有利于椎管内技术，以达到当天出院标准并减少围手术期并发症。用于椎管内麻醉的短效局部麻醉剂的可用性将影响麻醉剂的选择。尽管如此，可以考虑在精心挑选的人群中采用多模式镇痛和抗血栓药物的现代全身麻醉。区域镇痛是多模式镇痛方案的一个组成部分，可减少阿片类药物的消耗并促进当天出院，从而减少再入院的情况。对于门诊全膝关节置换术，收肌管阻滞与关节周围局麻药浸润相结合是一种合适的区域镇痛方案。


结论
TJA 麻醉已经发展到当天出院将成为特定患者的常态。必须建立早期出院途径，以防止该人群产生不良影响和再次入院。随着越来越多的动态 TJA 产生更多数据，将会出现更强有力的证据来证明理想的麻醉成分可优化结果。
]]></description>
      <guid>http://link.springer.com/10.1007/s12630-024-02699-0</guid>
      <pubDate>Tue, 19 Mar 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于实时轻量级辐射场渲染的频率重要性高斯分布</title>
      <link>http://link.springer.com/10.1007/s11042-024-18679-x</link>
      <description><![CDATA[摘要
最近，依赖辐射场的新颖视图合成领域取得了重大进展。通过结合 Splatting 技术，一种名为高斯 Splatting 的新方法实现了卓越的渲染质量和实时性能。然而，该方法的训练过程会产生很大的性能开销，并且训练得到的模型非常庞大。为了应对这些挑战，我们改进了高斯分布并提出了频率重要性高斯分布。我们的方法通过提取场景的频率特征来降低性能开销。首先，我们从采样理论的角度分析了高斯分布法空间采样策略的优点和局限性。其次，我们设计了增强高斯以更有效地表达高频信息，同时降低性能开销。第三，我们构建了频率敏感损失函数，以增强网络感知频域的能力并优化场景的空间结构。最后，我们提出了一种基于场景背景重建程度的动态自适应密度控制策略，根据训练结果动态自适应空间样本点生成策略，防止模型中产生冗余数据。我们在几个常用的数据集上进行了实验，结果表明，我们的方法在内存开销和存储使用方面比原始方法具有显着优势，并且能够保持原始方法的图像质量。]]></description>
      <guid>http://link.springer.com/10.1007/s11042-024-18679-x</guid>
      <pubDate>Tue, 12 Mar 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用生成深度神经网络通过嘴唇运动实现音频视频同步</title>
      <link>http://link.springer.com/10.1007/s11042-024-18695-x</link>
      <description><![CDATA[摘要
随着元宇宙的展开，音频与视频的实时同步变得至关重要。许多模型（例如 Wav2Lip、Sync Net 和 Lip Gan）已被开发用于同步音频视频以呈现高影响力的内容。选择合适的损失函数直接影响音视频同步的结果和准确性。像 Wav2Lip 这样的模型，通过 Huber Loss 函数得到增强，成为该领域的领跑者。本文进行了全面的比较分析，证明 Huber Loss 在收敛效率和同步质量方面优于 L1、L2 和 SmoothL1 损失。实证结果明确主张将 Huber Loss 集成到 Wav2Lip 模型中，强调其能够使嘴唇运动与音频更加连贯和自然地集成。实验结果表明，Huber Loss 在 61,500 个步骤中实现了 0.00091 的平均训练损失和 0.00141 的评估损失，同时显着降低了 2.20669 的同步损失。这些结果代表了同步精度的显着提高，与当代损失函数相比提高了 20% 到 30%。]]></description>
      <guid>http://link.springer.com/10.1007/s11042-024-18695-x</guid>
      <pubDate>Mon, 11 Mar 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>全球激光雷达定位调查：挑战、进展和未决问题</title>
      <link>http://link.springer.com/10.1007/s11263-024-02019-5</link>
      <description><![CDATA[摘要
了解自身姿态是所有移动机器人应用的关键。因此，姿态估计是移动机器人核心功能的一部分。在过去的二十年中，激光雷达扫描仪已成为机器人定位和测绘的标准传感器。本文旨在概述基于激光雷达的全球定位的最新进展和进展。我们首先提出问题并探索应用范围。然后，我们对该方法进行回顾，包括地图、描述符提取和跨机器人定位等多个主题的最新进展。本文的内容分为三个主题。第一个主题涉及全局位置检索和局部姿态估计的结合。第二个主题是将单次测量升级为连续测量，以实现连续的全局定位。最后，第三个主题侧重于将单机器人全局定位扩展到多机器人系统中的跨机器人定位。我们在调查结束时讨论了全球激光雷达本地化的开放挑战和有希望的方向。据我们所知，这是首次针对移动机器人全球激光雷达定位的全面调查。]]></description>
      <guid>http://link.springer.com/10.1007/s11263-024-02019-5</guid>
      <pubDate>Wed, 06 Mar 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>量化鲁棒性：在噪声域中使用智能树进行 3D 树点云骨架化</title>
      <link>http://link.springer.com/10.1007/s10044-024-01238-3</link>
      <description><![CDATA[摘要
从 3D 树点云中提取树骨架受到噪声和不完整数据的挑战。虽然我们之前的工作（Dobbs 等人，在：伊比利亚模式识别和图像分析会议，施普林格，柏林，第 351-362 页，2023 年）引入了一种用于近似树枝中轴的深度学习方法，但其对各种类型的鲁棒性噪声的影响尚未得到彻底评估。本文解决了这一差距。具体来说，我们通过引入 3D Perlin 噪声（代表减性噪声）和高斯噪声（模拟加性噪声）来模拟现实世界的噪声挑战。为了促进此评估，我们引入了一个新的合成树点云数据集，可在  获取https://github.com/uc-vision/synthetic-trees-II。我们的结果表明，我们基于深度学习的骨架化方法能够容忍加性和减性噪声。]]></description>
      <guid>http://link.springer.com/10.1007/s10044-024-01238-3</guid>
      <pubDate>Tue, 05 Mar 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于 NeRF 的 GAN 的对应蒸馏</title>
      <link>http://link.springer.com/10.1007/s11263-023-01903-w</link>
      <description><![CDATA[摘要
神经辐射场 (NeRF) 在保留物体和场景的精细细节方面显示出了良好的结果。然而，与显式形状表示（例如网格）不同，在同一类别的不同 NeRF 之间建立密集对应关系仍然是一个悬而未决的问题，这在许多下游任务中至关重要。这个问题的主要困难在于 NeRF 的隐式性质和缺乏真实对应注释。在本文中，我们展示了通过利用基于 NeRF 的预训练 GAN 中封装的丰富语义和结构先验，可以绕过这些挑战。具体来说，我们从三个方面利用这些先验，即（1）将潜在代码作为全局结构指标的双变形场，（2）将生成器特征视为几何感知局部描述符的学习目标，以及（3）源无限的特定于对象的 NeRF 样本。我们的实验表明，这样的先验可以产生准确、平滑且稳健的 3D 密集对应。我们还表明，跨 NeRF 建立的密集对应关系可以有效地启用许多基于 NeRF 的下游应用，例如纹理传输。]]></description>
      <guid>http://link.springer.com/10.1007/s11263-023-01903-w</guid>
      <pubDate>Fri, 01 Mar 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RDNeRF：用于密集自由视图合成的相对深度引导 NeRF</title>
      <link>http://link.springer.com/10.1007/s00371-023-02863-5</link>
      <description><![CDATA[摘要
在本文中，我们专注于室内场景中自由移动的密集视图合成，以实现比稀疏视图更好的用户交互。神经辐射场 (NeRF) 可以很好地处理稀疏和球形捕获的场景，但它在具有密集自由视图的场景中表现不佳。我们扩展 NeRF 来处理这些室内场景视图。我们提出了一种名为相对深度引导 NeRF (RDNeRF) 的基于学习的方法，该方法联合渲染 RGB 图像并在密集的自由视图中恢复场景几何形状。为了在没有真实深度的情况下恢复每个视图的几何形状，我们建议通过隐式函数直接学习相对深度，并将其转换为几何体边界，用于几何感知采样和 NeRF 集成。通过正确的场景几何，我们进一步对输入的隐式内部相关性进行建模，以增强 NeRF 在密集自由视图中的表示能力。我们在室内场景中进行了大量的实验，以实现密集的自由视图合成。 RDNeRF 优于当前最先进的方法，达到 24.95 PSNR 分数和 0.77 SSIM 分数。此外，它比基本模型恢复更准确的几何形状。]]></description>
      <guid>http://link.springer.com/10.1007/s00371-023-02863-5</guid>
      <pubDate>Fri, 01 Mar 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenDIBR：开放基于深度图像的 VR 光场视频实时渲染器</title>
      <link>http://link.springer.com/10.1007/s11042-023-16250-8</link>
      <description><![CDATA[摘要
在这项工作中，我们提出了一种新颖的光场渲染框架，允许观看者在从具有视觉和深度信息的多视图图像/视频数据集重建的虚拟场景中行走。考虑到沉浸式媒体应用，该框架旨在通过输入视频支持动态场景，让观看者在大范围内充分自由移动，并实现实时渲染，甚至在虚拟现实 (VR) 中也是如此。本文探讨了基于深度图像的渲染 (DIBR) 如何成为少数能够满足所有要求的最先进技术之一。因此，我们实施了 OpenDIBR（一种公开可用的 DIBR）作为该框架的概念证明。它使用 Nvidia 的视频编解码器 SDK 在 GPU 上快速解码颜色和深度视频。然后，解码后的深度图和颜色帧将变形为 OpenGL 中的输出视图。根据输入和输出相机位置，每个输入贡献通过每像素加权平均值混合在一起。视觉质量比较实验得出结论，OpenDIBR 在客观和主观上与 TMIV 相似，但优于 NeRF。在性能方面，OpenDIBR 在桌面上以 90 Hz 运行，最多可播放 4 个全高清输入视频，在 VR 中可播放 2-4 个全高清输入视频，并且可以选择通过降低视频比特率、降低深度图分辨率或动态减少视频数量来进一步提高此性能。渲染的输入视频。]]></description>
      <guid>http://link.springer.com/10.1007/s11042-023-16250-8</guid>
      <pubDate>Fri, 01 Mar 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于神经辐射场的机器人辅助微创手术动态表面重建</title>
      <link>http://link.springer.com/10.1007/s11548-023-03016-8</link>
      <description><![CDATA[摘要

目的
本研究的目的是通过解决重建高度动态手术场景的挑战来改善手术场景感知。我们提出了一种新颖的深度估计网络和结合神经辐射场的重建框架，为手术任务自动化和 AR 导航提供更准确的场景信息。


方法
我们添加了空间金字塔池化模块和 Swin-Transformer 模块来增强立体深度估计的鲁棒性。我们还通过添加最佳传输的独特匹配约束来提高深度精度。为了避免高动态场景中的变形失真，我们使用神经辐射场在时间维度上隐式表示场景，并以基于学习的方式利用深度和颜色信息对其进行优化。


结果
我们在 KITTI 和 SCARED 数据集上的实验表明，所提出的深度估计网络在自然图像上的表现接近最先进的方法，并且在医学图像上超越了 SOTA 方法3 px 误差为 1.12%，EPE 误差为 0.45 px。所提出的动态重建框架成功地在完全内窥镜冠状动脉搭桥视频上重建了动态心脏表面，实现了 SOTA 性能，PSNR 为 27.983 dB，SSIM 为 0.812，LPIPS 为 0.189。


结论
我们提出的深度估计网络和重建框架为手术场景感知领域做出了重大贡献。该框架在医学数据集上取得了比 SOTA 方法更好的结果，减少了深度图上的不匹配，并产生更准确、边缘更清晰的深度图。所提出的 ER 框架在一系列动态心脏手术图像上得到了验证。未来的工作重点将集中在提高训练速度和解决视野有限的问题上。
]]></description>
      <guid>http://link.springer.com/10.1007/s11548-023-03016-8</guid>
      <pubDate>Fri, 01 Mar 2024 00:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大会报告：第36届ICMART大会（2023年9月29日至10月1日，荷兰阿姆斯特丹）</title>
      <link>http://link.springer.com/10.1007/s00052-024-00108-9</link>
      <description><![CDATA[]]></description>
      <guid>http://link.springer.com/10.1007/s00052-024-00108-9</guid>
      <pubDate>Fri, 01 Mar 2024 00:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>