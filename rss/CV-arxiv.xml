<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>CS.CV更新arxiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.cv更新arxiv.org e-print存档。</description>
    <lastBuildDate>Thu, 13 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>电影编织者：带有锚定提示的无调多概念视频个性化</title>
      <link>https://arxiv.org/abs/2502.07802</link>
      <description><![CDATA[ARXIV：2502.07802V1公告类型：新 
摘要：使用参考图像生成自定义视频的视频个性化引起了极大的关注。但是，先前的方法通常集中于单概念个性化，限制了需要多概念集成的更广泛的应用程序。尝试将这些模型扩展到多个概念的尝试通常会导致身份混合，这导致复合字符具有来自多个来源的融合属性。由于缺乏将每个概念与其特定参考图像联系起来的机制，因此出现了这一挑战。我们使用锚定的提示来解决此问题，将图像锚定为文本提示中的独特令牌，从而指导生成过程中准确的引用。此外，我们介绍概念嵌入以编码参考图像的顺序。我们的方法，电影编织者，无缝编织多个概念，包括面部，身体和动物图像 - 一个视频，可以在单个模型中进行灵活的组合。评估表明，电影编织者的表现优于现有的方法，用于在身份保存和整体质量方面的多概念视频个性化。]]></description>
      <guid>https://arxiv.org/abs/2502.07802</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CrossVideomae：使用蒙版自动编码器的自我监督图像视频表示学习</title>
      <link>https://arxiv.org/abs/2502.07811</link>
      <description><![CDATA[ARXIV：2502.07811V1公告类型：新 
摘要：当前基于视频的掩盖自动编码器（MAE）主要从视觉角度专注于学习有效时空表示，这可能导致模型优先考虑一般的时空模式，但通常会忽略细微的语义属性，例如特定的交互或定义了定义动作的特定互动或序列 - 定义了 - 定义了动作 - 定义了 - 定义了动作 - 定义了 - 定义了动作 - 定义了 - 定义了 - 定义了 - 定义了 - 定义了 - 定义了 - 定义了 - 定义了 - 定义了 - 定义了 - 定义了 - 定义了 - 定义了 - 例如，特定于动作的特征，这些特征与人类在时空对应关系中更紧密地保持一致。这可能会限制模型捕获某些行动的本质的能力。人类能够绘制视觉概念，对象视图不变性以及静态实例中可用的语义属性，以理解自然动态场景或视频。现有用于视频和静态图像的MAE依靠用于视频和图像的单独数据集，这可能缺乏充分理解学习概念所需的丰富语义属性，尤其是与使用视频和相应的采样帧图像相比。为此，我们提出了CrossVideomae一个端到端的自我监管的交叉模式对比学习MAE，该学习有效地学习了视频级别和框架级别丰富的时空表示和语义属性。我们的方法将视频中的相互时空信息与来自功能不变空间中采样帧的空间信息整合在一起，同时鼓励不变性来增加视频域内的增强。通过共同嵌入可见令牌的特征并结合跨模态内和跨模态的特征对应关系，这对于从视频和框架图像模式以一种自我监督的方式获取了丰富的，无标签的指导信号至关重要。广泛的实验表明，我们的方法超过了先前的最新方法和消融研究，证明了我们方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2502.07811</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过kolmogorov-arnold的潜在特征转换，不属于不成对的图像除狂物</title>
      <link>https://arxiv.org/abs/2502.07812</link>
      <description><![CDATA[ARXIV：2502.07812V1公告类型：新 
摘要：本文提出了一个创新的框架，用于通过称为UID-KAT的Kolmogorov-Arnold Transformation进行无监督的图像除去。 Dimage Dehazing被认为是一项具有挑战性且不足的视觉任务，需要在功能空间中进行复杂的转换和解释。最近的进步引入了受Kolmogorov-Arnold代表定理的启发的Kolmogorov-Arnold网络（KANS），作为多层perceptrons（MLP）的有希望的替代方案，因为KANS可以利用其多项式的基础，同时需要更有效的复杂功能，同时需要更有效的复杂功能。 MLP。在这种潜力的推动下，本文探讨了坎斯的使用与对抗性训练和对比度学习，以建模朦胧和清晰图像之间的复杂关系。对抗性训练是由于其产生高保真图像的能力而进行的，并且对比度学习促进了模型对重要特征的重点，同时抑制了无关信息的影响。提出的UID-KAT框架在无监督的环境中进行了训练，以利用丰富的现实数据，并应对准备配对的朦胧/清洁图像的挑战。实验结果表明，UID-KAT在多个数据集和场景中实现最新的飞行性能，在降低模型复杂性的同时，表现优于现有的未配对方法。这项工作的源代码可在https://github.com/tranleanh/uid-kat上公开获得。]]></description>
      <guid>https://arxiv.org/abs/2502.07812</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>失忆症是增强黑匣子像素攻击图像分类和对象检测的催化剂</title>
      <link>https://arxiv.org/abs/2502.07821</link>
      <description><![CDATA[ARXIV：2502.07821V1公告类型：新 
摘要：众所周知，基于查询的攻击往往在对抗黑盒攻击中具有相对较高的成功率。尽管正在积极进行有关黑盒攻击的研究，但相对较少的研究集中在仅针对有限数量像素的像素攻击上。在图像分类中，基于查询的像素攻击通常依赖于补丁，这在很大程度上取决于随机性并忽略了散射像素更适合对抗攻击的事实。此外，据我们所知，在对象检测领域尚未探索基于查询的像素攻击。为了解决这些问题，我们提出了一种新型基于像素的黑盒攻击，称为记住，并忘记了使用增强学习（RFPAR）的像素攻击（RFPAR），由两个主要组成部分组成：记住和忘记过程。 RFPAR通过利用通过一步RL算法产生的奖励来避免依赖贴片的依赖性，从而避免了贴片的依赖性。 RFPAR有效地创建了扰动的图像，在粘附有限的像素约束时，可以最大程度地减少置信度得分。此外，我们将提出的攻击超出图像分类将其提高到对象检测，其中RFPAR降低了检测到的对象的置信度得分以避免检测。用于分类的ImagEnet-1K数据集上的实验表明，RFPAR的表现优于最新的基于查询的像素攻击。为了进行对象检测，使用Yolov8和DDQ的MSCOCO数据集，RFPAR显示出可比的地图减少到最新的基于查询的攻击，同时需要更少的查询。使用Yolov8在Argoverse数据集上进行的进一步实验确认RFPAR可以有效地删除大型数据集上的对象。我们的代码可在https://github.com/kau-quantumailab/rfpar上找到。]]></description>
      <guid>https://arxiv.org/abs/2502.07821</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>PDM-SSD：单阶段的三维对象检测器随点扩张</title>
      <link>https://arxiv.org/abs/2502.07822</link>
      <description><![CDATA[ARXIV：2502.07822V1公告类型：新 
摘要：当前基于点的检测器只能从提供的点中学习，并且对此类目标的全球学习能力不足。在本文中，我们提出了一种利用这两种表示的单阶段3D检测（PDM-SSD）的新颖点扩张机制。具体而言，我们首先使用PointNet风格的3D主干来进行有效的特征编码。然后，使用点扩张机构（PDM）的颈部扩展特征空间，该空间涉及两个关键步骤：点扩张和特征填充。前者扩大了一个尺寸的网格，以欧几里得空间中的采样点为中心。后者用球形谐波系数和高斯密度函数在方向和规模方面填充了空置网格的功能。接下来，我们将多个扩张中心和融合系数关联，以通过高度压缩获得稀疏的网格特征。最后，我们设计了一个混合检测头进行联合学习，一方面，预测场景的热图可以补充设定的投票点以提高检测准确性，另一方面，通过功能融合对检测到的盒子的目标概率进行校准。在具有挑战性的Karlsruhe技术研究所和丰田技术学院（KITTI）数据集上，PDM-SSD在单模式方法中获得了最先进的结果，用于具有68帧的单模式方法。我们还证明了PDM-SSD在通过许多对象级实例中检测稀疏和不完整的对象方面的优势。此外，PDM可以用作辅助网络，以在采样点和对象中心之间建立连接，从而在不牺牲推理速度的情况下提高模型的准确性。我们的代码将在https://github.com/alanliangc/pdm-ssd.git上找到。]]></description>
      <guid>https://arxiv.org/abs/2502.07822</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>作为世界模拟器的预训练的视频生成模型</title>
      <link>https://arxiv.org/abs/2502.07825</link>
      <description><![CDATA[ARXIV：2502.07825V1公告类型：新 
摘要：在大规模互联网数据集上预先训练的视频生成模型取得了巨大的成功，在制作现实的合成视频方面表现出色。但是，它们通常会根据静态提示（例如文本或图像）生成剪辑，从而限制了它们建模交互式和动态场景的能力。在本文中，我们提出了动态世界模拟（DWS），这是一种新颖的方法，将预训练的视频生成模型转换为能够执行指定动作轨迹的可控世界模拟器。为了在条件动作和生成的视觉变化之间实现精确的对齐方式，我们引入了一个轻巧的，通用的动作条件模块，该模块将无缝集成到任何现有模型中。我们没有专注于复杂的视觉细节，而是证明一致的动态过渡建模是构建强大的世界模拟器的关键。在这种见解的基础上，我们进一步引入了运动增强的损失，该损失通过强迫模型更有效地捕获动态变化来增强动作可控性。实验表明，DWS可以应用于扩散和自动回归变压器模型，从而在跨游戏和机器人域中生成可控制的，动态一致的视频方面取得了重大改进。此外，为了促进学识渊博的世界模拟器在下游任务（例如基于模型的强化学习）中的应用，我们提出了优先的想象力以提高样本效率，与最先进的方法相比表明了竞争性能。]]></description>
      <guid>https://arxiv.org/abs/2502.07825</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>自动化电源线检查中的深度学习检查：评论</title>
      <link>https://arxiv.org/abs/2502.07826</link>
      <description><![CDATA[ARXIV：2502.07826V1公告类型：新 
摘要：近年来，通过朝着计算机视觉驱动的自动化检查迈进，电力线维护范围已经发生了范式的转变。大量视频和图像的利用对于维持电力传输的可靠性，安全性和可持续性至关重要。在最近的研究中，观察到了将深度学习技术应用于增强电力线检查过程的重要重点。本文已经对现有研究进行了全面综述，以帮助研究人员和行业开发改进的基于深度学习的系统，以分析电力线数据。已经检查了电力线检查中数据分析的常规步骤，并且当前研究的主体已系统地分为两个主要领域：组件的检测和故障诊断。已经封装了这些领域中采用的各种方法和技术的详细摘要，从而提供了对其功能和用例的见解。特别注意探索基于深度学习的方法，用于分析电源线检查数据，并阐述了其基本原理和实际应用。此外，已经概述了对未来研究方向的愿景，强调了对Edge-Cloud协作以及多模式分析等进步的需求。因此，本文是研究人员深入学习电力线分析的综合资源，阐明了当前知识的程度和未来研究的潜在领域。]]></description>
      <guid>https://arxiv.org/abs/2502.07826</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>扩散模型的偏好一致性：图像生成和编辑的全面调查</title>
      <link>https://arxiv.org/abs/2502.07829</link>
      <description><![CDATA[ARXIV：2502.07829V1公告类型：新 
摘要：偏好对齐与扩散模型（DMS）的集成已成为增强图像生成和编辑功能的变革方法。尽管将扩散模型与偏好一致性策略相结合，在此交叉路口对新手构成了重大挑战，但对此主题的全面和系统评价仍然显然缺乏。为了弥合这一差距，本文在图像生成和编辑中广泛调查了与扩散模型的偏好对齐。首先，我们系统地回顾了最先进的优化技术，例如使用人类反馈（RLHF），直接偏好优化（DPO）等进行增强学习，并强调了它们在与DMS保持偏好相结合中的关键作用。然后，我们彻底探讨了在自动驾驶，医学成像，机器人技术等方面与DMS对齐偏好的应用。最后，我们全面讨论了与DMS的偏好一致性的挑战。据我们所知，这是第一次以与DMS的偏好对齐为中心的调查，提供了见解，以推动这个动态领域的未来创新。]]></description>
      <guid>https://arxiv.org/abs/2502.07829</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>由字幕捕获：关于记忆及其在剪辑模型中的缓解</title>
      <link>https://arxiv.org/abs/2502.07830</link>
      <description><![CDATA[ARXIV：2502.07830V1公告类型：新 
摘要：多模式模型（例如剪辑）在对齐视觉和文本表示方面表现出了很强的性能，在图像检索和零照片分类等任务中表现出色。尽管取得了成功，但这些模型利用训练数据的机制，尤其是记忆的作用，尚不清楚。在指导和自我监督的单模式模型中，记忆已被证明对于概括至关重要。但是，尚不清楚这些发现将如何适用于剪辑，这些发现将两者通过字幕提供了与标签相似的监督信号的元素，以及通过对比度目标的自我监督学习的元素。为了弥合理解差距，我们提出了对剪辑（Clipmem）中记忆的形式定义，并使用它来量化剪辑模型中的记忆。我们的结果表明，剪辑的记忆行为落在受监督和自我监督的范式之间，“错误捕获”样本表现出最高水平的记忆。此外，我们发现文本编码器比图像编码器对记忆的贡献更大，这表明缓解策略应集中在文本域上。在这些见解的基础上，我们提出了多种策略来减少记忆，同时改善公用事业 - 在传统学习范式之前没有展示过，在传统学习范式中，降低记忆通常会导致公用事业减少。]]></description>
      <guid>https://arxiv.org/abs/2502.07830</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Nanovlms：我们可以走多小，仍然制作连贯的视觉语言模型？</title>
      <link>https://arxiv.org/abs/2502.07838</link>
      <description><![CDATA[ARXIV：2502.07838V2公告类型：新 
摘要：视觉模型（VLMS），例如GPT-4V和Llama 3.2 Vision，它因其在多模式任务中利用大语言模型（LLM）的能力而引起了重大的研究关注。但是，它们的潜力受到固有挑战的限制，包括专有限制，实质性的计算需求和有限的可访问性。诸如GIT和BLIP之类的较小模型表现出明显的局限性，即使经过广泛的培训，也无法生成连贯和一致的文本。这强调了一个关键的查询：VLM可以很小而仍然产生流利且一致的文本？从3-4岁的孩子的出色学习过程中汲取灵感，他们严重依赖于理解和交流的视觉提示，我们介绍了两个新颖的数据集：ShortDESC（具有简洁的图像描述）和Longdesc（包含更详细的图像描述）。这些数据集由图像文本对组成，其中文本仅限于通常由幼儿使用的简单词汇和语法，并以缩放模型GPT-4O产生。使用这些数据集，我们证明可以训练明显较小的VLM，比最大的vlms（SOTA）小VLM小10倍，同时保持体系结构的简单性。为了评估输出，我们利用GPT-4O来对文本进行评分，好像由学生写的故事，关于创造力，有意义和一致性，分配10分的分数。此方法通过适应非结构​​化的输出并提供A来解决标准基准的局限性模型功能的多维评估。我们的发现有助于开发用于资源约束环境的轻质，可访问的多模式模型。]]></description>
      <guid>https://arxiv.org/abs/2502.07838</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>移植：表面嵌入引导的3D高斯裂缝以进行透明对象操纵</title>
      <link>https://arxiv.org/abs/2502.07840</link>
      <description><![CDATA[ARXIV：2502.07840V1公告类型：新 
摘要：由于难以获取准确且密集的深度测量值，透明的物体操纵仍然是机器人技术的重要挑战。常规的深度传感器通常会因透明对象而失败，从而导致完整或错误的深度数据。现有的深度完成方法与框架一致性相比，将透明的对象作为兰伯特表面，导致深度重建不良。为了应对这些挑战，我们提出了移植，这是针对透明物体量身定制的嵌入表面引导的3D高斯裂缝方法。 Transplat使用潜在扩散模型生成提供一致和连续表示的表面嵌入，从而使其对视点和照明的变化进行了鲁棒。通过将这些表面嵌入与输入RGB图像集成，移植有效地捕获了透明表面的复杂性，增强了3D高斯人的分裂并改善了深度完成。对合成和现实世界的透明对象基准的评估以及机器人掌握任务，表明移植可以实现准确且密集的深度完成，这表明了其在实际应用中的有效性。我们开放源合成数据集和模型：https：// github。 com/jeongyun0609/移植]]></description>
      <guid>https://arxiv.org/abs/2502.07840</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>将它们分开：朝着生成的内容的强大水印</title>
      <link>https://arxiv.org/abs/2502.07845</link>
      <description><![CDATA[ARXIV：2502.07845V1公告类型：新 
摘要：近年来可以产生逼真图像的生成模型有了显着改善。生成内容的质量急剧提高，因此有时很难区分真实图像和生成图像。这样的改进是针对生成模型的使用的道德问题的代价：生成模型的用户可以不当地索取受许可保护的生成内容的所有权。在本文中，我们提出了一种将水印嵌入生成的内容中的方法，以将来对生成的用户的生成内容和确定生成的用户的识别。在模型的推断期间，水印是嵌入的，因此提出的方法不需要后者的重新训练。我们证明，嵌入的水印可以确保与有界大小的累加扰动具有鲁棒性。我们将我们的方法应用于水印扩散模型，并表明它与最先进的水印方案相匹配，以鲁棒性与不同类型的合成水印去除攻击相匹配。]]></description>
      <guid>https://arxiv.org/abs/2502.07845</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>关于在协变量偏移下校准视觉语言模型的技术说明</title>
      <link>https://arxiv.org/abs/2502.07847</link>
      <description><![CDATA[ARXIV：2502.07847V1公告类型：新 
摘要：尽管是新兴能力的成功例子，但视力语言基础模型用于低声视觉分类的模型具有有限的能力，可以充分推广到由于样本贫困而导致目标数据分布的能力，从而导致对数据变化的敏感性。流行的缓解策略是在多个数据集上进行填充，但是以这种方式实践的域概括是昂贵的。这项工作研究了训练数据和未指定的目标数据之间的协方差，以及\ textit {置信度未对准}，其中模型的预测置信度被有限的数据可用性放大。我们提出\ textit {置信度校准的协变量移位校正（$ c3sc $）}，这是一个统一的框架，以减轻协方差偏移和置信度未对准。 $ C3SC $利用Fisher信息罚款，用于协变性轮班校正和信心错位罚款（CMP），以降低对错误分类示例的信心。各种视觉和协变量数据集中的实验结果表明，$ C3SC $在最大最大的校准（ECE）上显着提高了$ 5.82 \％$。 $ C3SC $通过在挑战协变量偏移数据集上显示出$ 3.5 \％$的准确度量，这也显示出更好的鲁棒性，这使得$ c3sc $成为可靠的现实世界视觉低声量应用程序中的有希望的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2502.07847</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>边缘网络的视觉语言模型：一项全面调查</title>
      <link>https://arxiv.org/abs/2502.07855</link>
      <description><![CDATA[ARXIV：2502.07855V1公告类型：新 
摘要：视觉大语模型（VLM）将视觉理解与自然语言处理结合在一起，启用了图像字幕，视觉询问和视频分析等任务。尽管VLM在跨自动驾驶汽车，智能监视和医疗保健等领域表现出令人印象深刻的功能，但由于处理能力，内存和能源限制，它们在资源受限的边缘设备上的部署仍然具有挑战性。这项调查探讨了在优化边缘环境的VL​​M方面的最新进步，重点关注模型压缩技术，包括修剪，量化，知识蒸馏以及提高效率的专业硬件解决方案。我们提供了有关有效培训和微调方法，边缘部署挑战和隐私考虑的详细讨论。此外，我们讨论了在医疗保健，环境监测和自主系统中轻量级VLM的各种应用，以说明它们不断增长的影响。通过强调关键的设计策略，当前的挑战和为将来的方向提供建议，该调查旨在激发对VLM的实际部署的进一步研究，最终使高级AI在资源有限的设置中访问。]]></description>
      <guid>https://arxiv.org/abs/2502.07855</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MRS：基于ODE和SDE求解器的平均恢复扩散的快速采样器</title>
      <link>https://arxiv.org/abs/2502.07856</link>
      <description><![CDATA[ARXIV：2502.07856V2公告类型：新 
摘要：在扩散模型的应用中，可控制的生成具有实际意义，但也具有挑战性。可控生成的当前方法主要集中于修改扩散模型的得分函数，而平均恢复（MR）扩散直接修改了随机微分方程（SDE）的结构，从而使图像条件的结合更加简单，更自然。但是，当前无训练的快速采样器并不直接适用于MR扩散。因此，MR扩散需要数百个NFE（功能评估数）才能获得高质量的样品。在本文中，我们提出了一种名为MRS MRS（MR Sampler）的新算法，以减少MR扩散的采样NFE。我们解决了反向时间的SDE和与MR扩散相关的普通微分方程（PF-ode），并得出半分析溶液。该解决方案由分析函数和由神经网络进行参数的积分组成。基于此解决方案，我们可以以更少的步骤生成高质量的样本。我们的方法不需要培训，并支持所有主流参数化，包括噪声预测，数据预测和速度预测。广泛的实验表明，MR采样器在十个不同的图像恢复任务中的加速速度为10至20倍，保持高采样质量。我们的算法加速了MR扩散的采样程序，使其在可控生成中更加实用。]]></description>
      <guid>https://arxiv.org/abs/2502.07856</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>