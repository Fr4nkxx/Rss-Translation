<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CV 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Thu, 10 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>HiRT：利用分层机器人变压器增强机器人控制</title>
      <link>https://arxiv.org/abs/2410.05273</link>
      <description><![CDATA[arXiv:2410.05273v1 公告类型：新
摘要：大型视觉-语言-动作 (VLA) 模型利用强大的预训练视觉-语言模型 (VLM) 后端，由于其令人印象深刻的泛化能力，在机器人控制方面显示出良好的前景。然而，成功是有代价的。它们对具有数十亿个参数的 VLM 后端的依赖导致了高计算成本和推理延迟，将测试场景限制在主要的准静态任务上，并阻碍了需要快速交互的动态任务的性能。为了解决这些限制，本文提出了 HiRT，这是一个分层机器人变压器框架，可以实现灵活的频率和性能权衡。HiRT 让 VLM 保持低频运行以捕获暂时不变的特征，同时通过由缓慢更新的特征引导的高频基于视觉的策略实现实时交互。模拟和真实世界环境中的实验结果都表明与基线方法相比有显着的改进。从经验上讲，在静态任务中，我们将控制频率加倍并实现了相当的成功率。此外，在之前的 VLA 模型所面临的挑战——新颖的现实世界动态操作任务中，HiRT 将成功率从 48% 提高到了 75%。]]></description>
      <guid>https://arxiv.org/abs/2410.05273</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过统一全局-局部上下文的自适应卷积进行尺度不变物体检测</title>
      <link>https://arxiv.org/abs/2410.05274</link>
      <description><![CDATA[arXiv:2410.05274v1 公告类型：新
摘要：密集特征对于检测图像中的微小物体非常重要。不幸的是，尽管 CNN 模型在多尺度物体检测方面具有显著的效果，但由于在池化过程中密集特征的丢失，CNN 模型通常无法检测到图像中的较小物体。空洞卷积通过应用稀疏核解决了这个问题。然而，稀疏核往往会失去 CNN 模型的多尺度检测功效。在本文中，我们提出了一种基于 efficientDet 模型的可切换（自适应）空洞卷积网络 (SAC-Net) 的物体检测模型。固定的空洞速率限制了 CNN 模型在卷积层中的性能。为了克服这个限制，我们引入了一种可切换机制，允许在前向传递期间动态调整空洞速率。所提出的 SAC-Net 融合了低级和高级特征的优点，以在多尺度物体检测任务上实现更高的性能，而不会丢失密集特征。此外，我们将深度可切换的空洞率应用于所提出的网络，以改进尺度不变特征。最后，我们将全局上下文应用于所提出的模型。我们在基准数据集上进行的大量实验表明，所提出的 SAC-Net 在准确率方面远远优于最先进的模型。]]></description>
      <guid>https://arxiv.org/abs/2410.05274</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ShieldDiff：通过强化学习抑制传播模型中的色情内容生成</title>
      <link>https://arxiv.org/abs/2410.05309</link>
      <description><![CDATA[arXiv:2410.05309v1 公告类型：新
摘要：随着生成式人工智能的发展，文本转图像 (T2I) 模型能够生成各种内容。然而，生成的内容无法完全控制。T2I 模型可能会生成包含令人不适内容的不安全图像，这是一个潜在的风险。在我们的工作中，我们专注于通过强化学习对预训练的扩散模型进行微调，通过优化精心设计的内容安全奖励函数，从 T2I 模型中消除 NSFW（不适合工作）内容生成，同时保持生成图像的高质量。所提出的方法利用由 CLIP（对比语言-图像预训练）和裸体奖励组成的定制奖励函数来修剪符合预训练模型的裸体内容，并将相应的语义含义保持在安全的一面。这样，T2I 模型对不安全的对抗性提示具有鲁棒性，因为不安全的视觉表示已从潜在空间中缓解。在不同数据集上进行的大量实验证明了所提出的方法在缓解不安全内容生成方面的有效性，同时保留了良性图像以及不安全提示生成的图像的高保真度。我们与五种现有的最先进 (SOTA) 方法进行了比较，并在色情内容删除和图像质量保留方面取得了有竞争力的表现。在鲁棒性方面，我们的方法优于 SOTA 黑盒攻击模型下的同类方法。此外，我们构建的方法可以作为具有语义相关安全对齐的反 NSFW 生成的基准。]]></description>
      <guid>https://arxiv.org/abs/2410.05309</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>噪声结晶和液体噪声：使用图像扩散模型的零样本视频生成</title>
      <link>https://arxiv.org/abs/2410.05322</link>
      <description><![CDATA[arXiv:2410.05322v1 公告类型：新
摘要：尽管对于图像生成来说功能强大，但一致且可控的视频是扩散模型的长期问题。视频模型需要大量的训练和计算资源，导致成本高昂和对环境的影响大。此外，视频模型目前对输出运动的控制有限。本文介绍了一种通过增强图像扩散模型来创建连续动画帧同时保持精细细节的新视频生成方法。这些技术可以应用于现有的图像模型，而无需通过改变潜在扩散模型中的输入噪声来训练任何视频参数（零样本）。提出了两种互补的方法。噪声结晶确保一致性，但由于潜在嵌入尺寸减小，仅限于大运动。液体噪声以一致性换取更大的灵活性，而不受分辨率限制。核心概念还允许其他应用，例如重新照明、无缝升级和改进的视频风格转换。此外，还对用于潜在扩散模型的 VAE 嵌入进行了探索，从而产生了有趣的理论见解，例如一种人类可解释的潜在空间方法。]]></description>
      <guid>https://arxiv.org/abs/2410.05322</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>EgoOops：带有程序文本的自我中心视频错误动作检测数据集</title>
      <link>https://arxiv.org/abs/2410.05343</link>
      <description><![CDATA[arXiv:2410.05343v1 公告类型：新
摘要：从以自我为中心的视频中检测错误动作对于开发检测工人错误并提供反馈的智能档案至关重要。以前的研究仅限于特定领域，专注于从没有程序文本的视频中检测错误，并分析动作是否是错误。为了解决这些限制，在本文中，我们提出了 EgoOops 数据集，其中包括以自我为中心的视频、程序文本和三种类型的注释：视频文本对齐、错误标签和错误描述。EgoOops 涵盖五个程序领域，包括 50 个以自我为中心的视频。视频文本对齐允许模型根据视频和程序文本检测错误。错误标签和描述可以对现实世界的错误进行详细分析。基于 EgoOops，我们解决了两个任务：视频文本对齐和错误检测。对于视频文本对齐，我们增强了最近的 StepFormer 模型，并增加了微调损失。基于对齐结果，我们提出了一个多模态分类器来预测错误标签。在我们的实验中，所提出的方法比基线取得了更高的性能。此外，我们的消融研究证明了将视频和文本结合起来的有效性。我们将在发布后发布数据集和代码。]]></description>
      <guid>https://arxiv.org/abs/2410.05343</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>迈向世界模拟器：制定基于物理常识的视频生成基准</title>
      <link>https://arxiv.org/abs/2410.05363</link>
      <description><![CDATA[arXiv:2410.05363v1 公告类型：新
摘要：像 Sora 这样的文本到视频 (T2V) 模型在可视化复杂提示方面取得了重大进展，这越来越被视为构建通用世界模拟器的有希望的道路。认知心理学家认为，实现这一目标的基础是理解直觉物理的能力。然而，这些模型准确表示直觉物理的能力在很大程度上仍未得到探索。为了弥补这一差距，我们引入了 PhyGenBench，这是一个全面的 \textbf{Phy}sics \textbf{Gen}eration \textbf{Ben} 基准，旨在评估 T2V 生成中的物理常识正确性。PhyGenBench 包含 160 个精心设计的提示，涵盖 27 个不同的物理定律，涵盖四个基本领域，可以全面评估模型对物理常识的理解。除了 PhyGenBench，我们还提出了一种名为 PhyGenEval 的新型评估框架。该框架采用分层评估结构，利用适当的高级视觉语言模型和大型语言模型来评估物理常识。通过 PhyGenBench 和 PhyGenEval，我们可以对 T2V 模型对物理常识的理解进行大规模自动评估，这与人类反馈密切相关。我们的评估结果和深入分析表明，当前的模型难以生成符合物理常识的视频。此外，简单地扩大模型规模或采用快速工程技术不足以完全解决 PhyGenBench 提出的挑战（例如动态场景）。我们希望这项研究能够激励社区优先考虑这些模型中物理常识的学习，而不仅仅是娱乐应用。我们将在 https://github.com/OpenGVLab/PhyGenBench 发布数据和代码]]></description>
      <guid>https://arxiv.org/abs/2410.05363</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用迁移学习从有限数据中实现自适应数字孪生框架内基于深度学习的视觉测量提取</title>
      <link>https://arxiv.org/abs/2410.05403</link>
      <description><![CDATA[arXiv:2410.05403v1 公告类型：新
摘要：数字孪生技术通过将模型和模拟与实时数据相结合，彻底改变了科学研究中的决策。与传统的结构健康监测方法不同，传统的结构健康监测方法依赖于计算密集型的数字图像相关，并且在实时数据集成方面存在局限性，这项研究提出了一种使用人工智能的新方法。具体而言，卷积神经网络用于通过将数字图像相关散斑图案图像与变形场相关联来实时分析结构行为。该研究最初侧重于二维散斑图案，后来扩展到使用立体配对图像进行全面变形分析的三维应用。该方法通过利用合成生成的散斑图案图像和真实散斑图案图像的混合来训练卷积神经网络，从而克服了计算挑战。这些模型设计得非常强大且用途广泛，为传统测量技术提供了一种有希望的替代方案，并为三维建模的高级应用铺平了道路。这一进步标志着通过利用人工智能进行实时模拟和分析，结构健康监测将向更高效、更动态的方向转变。]]></description>
      <guid>https://arxiv.org/abs/2410.05403</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过模仿真实场景的对齐来增强超分辨率训练</title>
      <link>https://arxiv.org/abs/2410.05410</link>
      <description><![CDATA[arXiv:2410.05410v1 公告类型：新
摘要：借助深度学习技术和大量训练数据，图像超分辨率方法取得了重大进展。然而，由于现实世界数据集中低分辨率 (LR) 和高分辨率 (HR) 对之间固有的错位，它们面临着挑战。在本研究中，我们提出了一种新颖的即插即用模块，旨在通过在训练期间将 LR 输入与 HR 图像对齐来缓解这些错位问题。具体而言，我们的方法涉及模拟与 HR 对齐的新型 LR 样本，同时保留原始 LR 样本的退化特性。该模块可与任何 SR 模型无缝集成，增强对错位的鲁棒性。重要的是，它可以在推理过程中轻松删除，因此无需在传统 SR 模型上引入任何参数。我们在合成和现实世界数据集上全面评估了我们的方法，证明了其在一系列 SR 模型中的有效性，包括传统的 CNN 和最先进的 Transformers。源代码将在 https://github.com/omarAlezaby/Mimicked_Ali 上公开发布。]]></description>
      <guid>https://arxiv.org/abs/2410.05410</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>发现生物医学数据集的独特元素以实现高性能探索</title>
      <link>https://arxiv.org/abs/2410.05436</link>
      <description><![CDATA[arXiv:2410.05436v1 公告类型：新
摘要：人类大脑用小元素表示物体，并根据元素的差异区分两个物体。因此，发现高维数据集的独特元素对于众多感知驱动的生物医学和临床研究至关重要。然而，目前还没有可靠的方法提取高维生物医学和临床数据集的独特元素。在这里，我们提出了一种无监督的深度学习技术，即独特元素分析（DEA），它使用数据集的高维相关信息提取独特的数据元素。DEA 首先计算数据的大量独特部分，然后采用独特的核驱动三重优化网络将这些部分过滤并浓缩为 DEA 元素。在医学图像疾病检测、基因排序和单细胞 RNA 序列（scRNA-seq）数据集细胞识别等应用中，与传统技术相比，DEA 的准确率提高了 45%。此外，DEA 允许用户指导操作中间计算过程，从而提供具有更好可解释性的中间结果。]]></description>
      <guid>https://arxiv.org/abs/2410.05436</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DAAL：面向多模态深度度量学习的密度感知自适应线边距损失</title>
      <link>https://arxiv.org/abs/2410.05438</link>
      <description><![CDATA[arXiv:2410.05438v1 公告类型：新
摘要：多模态深度度量学习对于有效捕获面部验证、细粒度对象识别和产品搜索等任务中的多样化表示至关重要。传统的度量学习方法，无论是基于距离还是边际度量，都主要强调类别分离，往往忽略了多模态特征学习所必需的类内分布。在这种情况下，我们提出了一种称为密度感知自适应边际损失（DAAL）的新型损失函数，它保留了嵌入的密度分布，同时鼓励在每个类中形成自适应子簇。通过采用自适应线策略，DAAL 不仅可以增强类内方差，还可以确保稳健的类间分离，从而促进有效的多模态表示。在基准细粒度数据集上的综合实验证明了 DAAL 的卓越性能，凸显了其在推进检索应用和多模态深度度量学习方面的潜力。]]></description>
      <guid>https://arxiv.org/abs/2410.05438</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于深度学习的红树林监测方法</title>
      <link>https://arxiv.org/abs/2410.05443</link>
      <description><![CDATA[arXiv:2410.05443v1 公告类型：新
摘要：红树林是动态的沿海生态系统，对环境健康、经济稳定和气候适应力至关重要。红树林的监测和保护具有全球重要性，遥感技术在这些工作中发挥着关键作用。尖端人工智能与卫星数据的结合为生态监测开辟了新的途径，在保护自然资源比以往任何时候都更加重要的时代，有可能彻底改变保护策略。这项工作的目的是对红树林分割任务的最新深度学习模型进行全面评估。我们首先介绍并提供一个新的开源数据集 MagSet-2，它结合了来自全球红树林观察站的红树林注释和来自 Sentinel-2 的卫星图像，这些图像来自世界各地的红树林位置。然后，我们使用创建的数据集对三个架构组（即卷积、Transformer 和 Mamba 模型）进行基准测试。实验结果进一步验证了深度学习社区对 Mamba 模型的兴趣，该模型在所有指标上都超越其他架构。]]></description>
      <guid>https://arxiv.org/abs/2410.05443</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用有限数据进行人工智能早期心理健康筛查：分析孕妇自拍照</title>
      <link>https://arxiv.org/abs/2410.05450</link>
      <description><![CDATA[arXiv:2410.05450v1 公告类型：新
摘要：重度抑郁症和焦虑症影响着全球数百万人，大大增加了精神健康问题的负担。早期筛查对于有效干预至关重要，因为及时发现心理健康问题可以显著改善治疗结果。人工智能 (AI) 可以改善精神障碍的筛查，实现早期干预和更好的治疗结果。人工智能驱动的筛查可以利用多种数据源的分析，包括数字图像中的面部特征。然而，现有的方法通常依赖于受控环境或专门的设备，限制了它们的广泛适用性。这项研究探讨了人工智能模型在以面部为中心的自拍照下进行普遍抑郁-焦虑筛查的潜力。该调查的重点是高危孕妇，这一群体特别容易受到心理健康问题的影响。为了应对临床设置导致的训练数据有限问题，我们以两种不同的方式使用了预训练模型：微调最初设计用于面部表情识别的卷积神经网络 (CNN)，以及采用视觉语言模型 (VLM) 对面部表情进行零样本分析。实验结果表明，基于 VLM 的方法明显优于 CNN，准确率为 77.6%，F1 得分为 56.0%。尽管还有很大的改进空间，但结果表明 VLM 可以成为一种有前途的心理健康筛查方法，尤其是在数据有限的情况下。]]></description>
      <guid>https://arxiv.org/abs/2410.05450</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>增强中的从众心理——不是一个好主意！一种强大的多阶段 Deepfake 检测方法</title>
      <link>https://arxiv.org/abs/2410.05466</link>
      <description><![CDATA[arXiv:2410.05466v1 公告类型：新
摘要：深度伪造技术的快速发展引发了人们对数字媒体完整性的重大担忧。检测深度伪造对于保护数字媒体至关重要。然而，大多数标准图像分类器无法区分假脸和真脸。我们的分析表明，这种失败是由于该模型无法明确关注深度伪造中常见的伪影。我们提出了一种基于 GenConViT 模型的增强架构，该模型结合了加权损失和更新增强技术，并包括蒙面眼预训练。该模型在 Celeb-DF v2 数据集上将 F1 得分提高了 1.71%，准确率提高了 4.34%。我们模型的源代码可在 https://github.com/Monu-Khicher-1/multi-stage-learning 上找到]]></description>
      <guid>https://arxiv.org/abs/2410.05466</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>PH-Dropout：视图合成的实用认知不确定性量化</title>
      <link>https://arxiv.org/abs/2410.05468</link>
      <description><![CDATA[arXiv:2410.05468v1 公告类型：新
摘要：使用神经辐射场 (NeRF) 和高斯溅射 (GS) 的视图合成在渲染真实世界场景时表现出令人印象深刻的保真度。然而，在视图合成中缺乏准确和有效的认知不确定性量化 (UQ) 的实用方法。现有的 NeRF 方法要么引入了大量的计算开销（例如，“训练时间增加 10 倍”或“重复训练 10 倍”），要么仅限于特定的不确定性条件或模型。值得注意的是，GS 模型缺乏任何全面的认知 UQ 的系统方法。这种能力对于提高神经视图合成的稳健性和可扩展性、实现主动模型更新、误差估计和基于不确定性的可扩展集成建模至关重要。在本文中，我们从函数近似的角度重新审视 NeRF 和基于 GS 的方法，确定 3D 表示学习中的关键差异和联系。基于这些见解，我们引入了 PH-Dropout（Post hoc Dropout），这是第一种实时且准确的认知不确定性估计方法，可直接在预训练的 NeRF 和 GS 模型上运行。大量评估验证了我们的理论发现并证明了 PH-Dropout 的有效性。]]></description>
      <guid>https://arxiv.org/abs/2410.05468</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>R-Bench：您的大型多模式模型是否能够抵御现实世界的破坏？</title>
      <link>https://arxiv.org/abs/2410.05474</link>
      <description><![CDATA[arXiv:2410.05474v1 公告类型：新
摘要：大型多模态模型（LMM）的出色表现使其广泛应用于视觉相关任务。然而，现实世界中的各种损坏意味着图像不会像模拟中那样理想，这对 LMM 的实际应用提出了重大挑战。为了解决这个问题，我们引入了 R-Bench，这是一个专注于 **LMM 的真实世界稳健性** 的基准测试。具体来说，我们：（a）对从用户捕获到 LMM 接收的完整链路进行建模，包括 33 个损坏维度，包括根据损坏顺序的 7 个步骤和基于低级属性的 7 个组；（b）收集损坏前/后的参考/扭曲图像数据集，包括 2,970 个带有人工标记的问答对；（c）提出绝对/相对稳健性的综合评估并对 20 个主流 LMM 进行基准测试。结果表明，虽然 LMM 可以正确处理原始参考图像，但面对扭曲图像时其性能不稳定，并且与人类视觉系统相比，其稳健性存在明显差距。我们希望 R-Bench 能够激发人们提高 LMM 的稳健性，**将其从实验模拟扩展到实际应用**。有关详细信息，请查看 https://q-future.github.io/R-Bench。]]></description>
      <guid>https://arxiv.org/abs/2410.05474</guid>
      <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>