<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CV 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Tue, 06 Aug 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>用于点云分割的可训练逐点解码器模块</title>
      <link>https://arxiv.org/abs/2408.01548</link>
      <description><![CDATA[arXiv:2408.01548v1 公告类型：新
摘要：点云分割（PCS）旨在进行逐点预测，使机器人和自动驾驶汽车能够理解环境。距离图像是大型室外点云的密集表示，基于图像构建的分割模型通常执行效率高。然而，点云到距离图像上的投影不可避免地会导致丢点，因为在每个图像坐标上，尽管有多个点投影到同一位置，但只保留了一个点。更重要的是，为属于与保留点类别不同的​​类别的丢弃点分配正确的预测具有挑战性。此外，现有的后处理方法，如K最近邻（KNN）搜索和核点卷积（KPConv），不能以端到端的方式与模型进行训练，或者不能很好地处理密度变化的室外点云，从而使模型达到次优性能。为了缓解这个问题，我们提出了一种可训练的逐点解码器模块 (PDM) 作为后处理方法，该方法从邻居收集加权特征，然后对查询点进行最终预测。此外，我们在数据增强中引入了虚拟范围图像引导的复制-旋转-粘贴 (VRCrop) 策略。VRCrop 限制了点云中的总点数并消除了增强点云中不需要的伪影。借助 PDM 和 VRCrop，现有的基于范围图像的分割模型在 SemanticKITTI、SemanticPOSS 和 nuScenes 数据集上的表现始终优于同类模型。]]></description>
      <guid>https://arxiv.org/abs/2408.01548</guid>
      <pubDate>Wed, 07 Aug 2024 03:14:22 GMT</pubDate>
    </item>
    <item>
      <title>通过基于 GAN 的无监督操作进行多任务 SAR 图像处理</title>
      <link>https://arxiv.org/abs/2408.01553</link>
      <description><![CDATA[arXiv:2408.01553v1 公告类型：新
摘要：生成对抗网络（GAN）通过学习数据分布中的模式，在合成大量逼真的SAR图像方面表现出巨大的潜力。一些GAN可以通过引入潜在代码来实现图像编辑，在SAR图像处理中显示出巨大的前景。与传统的SAR图像处理方法相比，基于GAN潜在空间控制的编辑完全是无监督的，允许在没有任何标记数据的情况下进行图像处理。此外，从数据中提取的信息更具可解释性。本文提出了一种新的SAR图像处理框架，称为基于GAN的无监督编辑（GUE），旨在解决以下两个问题：（1）解开GAN潜在空间中的语义方向并找到有意义的方向；（2）建立一个全面的SAR图像处理框架，同时实现多种图像处理功能。在GUE的实现中，我们通过训练精心设计的网络来分解GAN潜在空间中纠缠的语义方向。此外，我们可以在一次训练过程中完成多项SAR图像处理任务（包括去斑、定位、辅助识别和旋转编辑），无需任何形式的监督。大量实验验证了所提方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2408.01553</guid>
      <pubDate>Wed, 07 Aug 2024 03:14:22 GMT</pubDate>
    </item>
    <item>
      <title>图像质量的守护者：对图像质量指标进行基准测试，以防御对抗性攻击</title>
      <link>https://arxiv.org/abs/2408.01541</link>
      <description><![CDATA[arXiv:2408.01541v1 公告类型：新
摘要：在图像质量评估 (IQA) 领域，指标的对抗鲁棒性是一个关键问题。本文对各种防御机制进行了全面的基准测试研究，以应对 IQA 对抗攻击的增加。我们系统地评估了 25 种防御策略，包括对抗净化、对抗训练和经过认证的鲁棒性方法。我们在非自适应和自适应设置中应用了 14 种不同类型的对抗攻击算法，并针对它们测试了这些防御措施。我们分析了防御措施之间的差异及其对 IQA 任务的适用性，考虑到它们应该保留 IQA 分数和图像质量。提出的基准旨在指导未来的发展并接受新方法的提交，最新结果可在线获取：https://videoprocessing.ai/benchmarks/iqa-defenses.html。]]></description>
      <guid>https://arxiv.org/abs/2408.01541</guid>
      <pubDate>Wed, 07 Aug 2024 03:14:21 GMT</pubDate>
    </item>
    <item>
      <title>基于非线性分析的心血管疾病心电图分类</title>
      <link>https://arxiv.org/abs/2408.01542</link>
      <description><![CDATA[arXiv:2408.01542v1 公告类型：新
摘要：基于多通道心电图的心脏疾病检测对心脏护理和治疗有影响。现有方法的局限性包括由于电极位置导致的心电图波形变化、信号的高度非线性以及毫伏幅度测量。本研究报告了一种基于非线性分析的方法，该方法利用了复发图可视化。可以使用复发图有效地利用明确结构（例如 QRS 复合波）的模式化出现。这种基于复发的方法应用于 PhysioNet 数据库中公开的 Physikalisch-Technische Bundesanstalt (PTB) 数据集，我们在其中研究了四类不同的心脏疾病（心肌梗死、束支传导阻滞、心肌病和心律失常）和健康对照，实现了令人印象深刻的 100% 分类准确率。此外，从复发图和复发量化分析特征得出的潜在空间嵌入的 t-SNE 图可视化揭示了所考虑的心脏疾病与健康个体之间的明确界限，证明了这种方法的潜力。]]></description>
      <guid>https://arxiv.org/abs/2408.01542</guid>
      <pubDate>Wed, 07 Aug 2024 03:14:21 GMT</pubDate>
    </item>
    <item>
      <title>SceneMotion：从以代理为中心的嵌入到场景范围的预测</title>
      <link>https://arxiv.org/abs/2408.01537</link>
      <description><![CDATA[arXiv:2408.01537v1 公告类型：新
摘要：自动驾驶汽车依靠多模态运动预测来有效地与环境互动并规划安全的操作。我们引入了SceneMotion，这是一种基于注意力的模型，用于预测多个交通代理的场景范围运动模式。我们的模型使用新颖的潜在上下文模块将本地以代理为中心的嵌入转换为场景范围的预测。该模块从多个以代理为中心的嵌入中学习场景范围的潜在空间，从而实现联合预测和交互建模。Waymo Open Interaction Prediction Challenge 中的竞争表现证明了我们方法的有效性。此外，我们在时间和空间上对未来的航点进行聚类，以量化代理之间的交互。我们合并所有模式并独立分析每个模式，以确定哪些集群通过交互解决或导致冲突。我们的实现可在以下位置获得：https://github.com/kit-mrt/future-motion]]></description>
      <guid>https://arxiv.org/abs/2408.01537</guid>
      <pubDate>Wed, 07 Aug 2024 03:14:20 GMT</pubDate>
    </item>
    <item>
      <title>使用 CNN 模型评估视觉艺术作品的创造力</title>
      <link>https://arxiv.org/abs/2408.01481</link>
      <description><![CDATA[arXiv:2408.01481v1 公告类型：新
摘要：评估艺术创造力长期以来一直困扰着研究人员，传统方法非常耗时。最近的研究已经将机器学习应用于评估绘画中的创造力，但并未应用于绘画。我们的研究通过开发 CNN 模型来解决这一差距，该模型可以自动评估学生绘画的创造力。使用专业人士和儿童的 600 幅绘画数据集，我们的模型实现了 90% 的准确率，并且评估时间比人类评估者更快。这种方法展示了机器学习在推进艺术创造力评估方面的潜力，为传统方法提供了一种更有效的替代方案。]]></description>
      <guid>https://arxiv.org/abs/2408.01481</guid>
      <pubDate>Wed, 07 Aug 2024 03:14:19 GMT</pubDate>
    </item>
    <item>
      <title>使用改进的栅格式楼层平面图语义分割进行多单元楼层平面图识别和重建</title>
      <link>https://arxiv.org/abs/2408.01526</link>
      <description><![CDATA[arXiv:2408.01526v1 公告类型：新
摘要：数字孪生具有成为城市应急规划管理的重要组成部分的巨大潜力，因为它们可以更有效地设计逃生路线，在特殊情况下更好地定位，并更快地进行救援干预。然而，由于缺乏 3D 表示，创建孪生仍然是一项很大的手动工作，只有一些新建筑的 3D 表示数量有限。因此，在本文中，我们旨在从常见的 2D 建筑平面图中合成 3D 信息。我们提出了两种基于 MDA-Unet 和 MACU-Net 架构的新型像素分割方法，改进了跳过连接、注意机制和训练目标，以及管道的重建部分，将分割的计划矢量化以创建 3D 模型。将提出的方法与其他两种最先进的技术和几个基准数据集进行了比较。在常用的 CubiCasa 基准数据集上，我们的方法在五个检查类别中取得了 0.86 的平均 F1 分数，优于其他测试的逐像素方法。我们还公开了我们的代码，以支持该领域的研究。]]></description>
      <guid>https://arxiv.org/abs/2408.01526</guid>
      <pubDate>Wed, 07 Aug 2024 03:14:19 GMT</pubDate>
    </item>
    <item>
      <title>Img2CAD：通过 VLM 辅助条件分解从图像逆向工程 3D CAD 模型</title>
      <link>https://arxiv.org/abs/2408.01437</link>
      <description><![CDATA[arXiv:2408.01437v1 公告类型：新 
摘要：从图像中逆向工程 3D 计算机辅助设计 (CAD) 模型是许多下游应用的重要任务，包括交互式编辑、制造、建筑、机器人等。这项任务的难点在于 CAD 输出和图像输入之间存在巨大的表征差异。CAD 模型是精确的程序化构造，涉及将离散命令结构与连续属性相结合的顺序操作——这使得以端到端方式学习和优化变得具有挑战性。同时，输入图像引入了固有的挑战，例如光度变化和传感器噪声，使逆向工程过程复杂化。在这项工作中，我们介绍了一种新方法，有条件地将任务分解为两个子问题。首先，我们利用大型基础模型，特别是 GPT-4V，用语义信息预测全局离散基础结构。其次，我们提出了 TrAssembler，它以具有语义的离散结构为条件来预测连续属性值。为了支持 TrAssembler 的训练，我们进一步构建了来自 ShapeNet 的带注释的常见物体 CAD 数据集。综合起来，我们的方法和数据表明，我们朝着在野外实现 CAD 图像化迈出了重要的第一步。我们的项目页面：https://anonymous123342.github.io/]]></description>
      <guid>https://arxiv.org/abs/2408.01437</guid>
      <pubDate>Wed, 07 Aug 2024 03:14:18 GMT</pubDate>
    </item>
    <item>
      <title>利用标清地图增强在线路网感知与推理</title>
      <link>https://arxiv.org/abs/2408.01471</link>
      <description><![CDATA[arXiv:2408.01471v1 公告类型：新
摘要：城市和高速公路驾驶应用中的自动驾驶通常需要高清 (HD) 地图来生成导航计划。然而，在大规模生成和维护高清地图时会出现各种挑战。虽然最近的在线地图绘制方法已经开始出现，但它们的性能，尤其是在较长距离下的性能，受到动态环境中严重遮挡的限制。考虑到这些因素，我们的工作重点是利用轻量级和可扩展的先验——标准清晰度 (SD) 地图——来开发在线矢量化高清地图表示。我们首先研究将原型栅格化 SD 地图表示集成到各种在线地图架构中。此外，为了确定轻量级策略，我们使用 OpenStreetMaps 扩展了 OpenLane-V2 数据集并评估了图形 SD 地图表示的好处。设计 SD 地图集成组件的一个关键发现是 SD 地图编码器与模型无关，可以快速适应利用鸟瞰 (BEV) 编码器的新架构。我们的结果表明，利用 SD 地图作为在线地图绘制任务的先验可以显著加快收敛速度​​，并将在线中心线感知任务的性能提高 30% (mAP)。此外，我们表明，引入 SD 地图可以通过利用 SD 地图图形减少感知和推理任务中的参数数量，同时提高整体性能。项目页面：https://henryzhangzhy.github.io/sdhdmap/。]]></description>
      <guid>https://arxiv.org/abs/2408.01471</guid>
      <pubDate>Wed, 07 Aug 2024 03:14:18 GMT</pubDate>
    </item>
    <item>
      <title>评估和提高 LLM 在感知任务中的可信度</title>
      <link>https://arxiv.org/abs/2408.01433</link>
      <description><![CDATA[arXiv:2408.01433v1 公告类型：新 
摘要：当今的高级驾驶辅助系统 (ADAS)，如自适应巡航控制或后方碰撞警告，正在各种车辆中得到更广泛的应用。在车辆上集成这种先进的多模态大型语言模型 (LLM)，能够处理文本、图像、音频和其他数据类型，可能会大大提高乘客的舒适度。然而，LLM 的幻觉仍然是一个需要解决的主要挑战。在本文中，我们以行人检测和定位为例，系统地评估了此类 LLM 在基于视觉的数据中的对象检测背景下的潜在幻觉检测策略。我们在两个数据集（Waymo/US 和 PREPER CITY/Sweden）上评估了应用于两个最先进的 LLM（专有的 GPT-4V 和开放的 LLaVA）的三种幻觉检测策略。我们的结果表明，这些 LLM 可以非常详细地描述交通状况，但在进一步的分析活动（例如物体定位）方面仍面临挑战。在将这些 LLM 应用于行人检测示例中的视频序列时，我们评估并扩展了幻觉检测方法。我们的实验表明，目前，最先进的专有 LLM 的性能远远优于开放 LLM。此外，基于投票的一致性增强技术（例如 Best-of-Three (BO3) 方法）无法有效减少 LLM 中的幻觉，因为 LLM 在检测行人时往往会表现出较高的假阴性。但是，通过包含过去的信息来扩展幻觉检测有助于改善结果。]]></description>
      <guid>https://arxiv.org/abs/2408.01433</guid>
      <pubDate>Wed, 07 Aug 2024 03:14:17 GMT</pubDate>
    </item>
    <item>
      <title>一种基于聚类的无人机建筑检测视图规划新方法</title>
      <link>https://arxiv.org/abs/2408.01435</link>
      <description><![CDATA[arXiv:2408.01435v1 公告类型：新
摘要：随着无人机技术的快速发展，搭载视觉传感器的无人机在建筑检查和监视中的应用备受关注。视图规划旨在为视觉相关任务找到一组接近最优的视点，以实现视觉覆盖目标。本文提出了一种新的基于聚类的两步计算方法，使用谱聚类、局部势场法和超启发式算法来寻找接近最优的视图来覆盖目标建筑表面。在第一步中，所提出的方法基于谱聚类生成候选视点，并基于我们新提出的局部势场法校正候选视点的位置。在第二步中，将优化问题转换为集合覆盖问题（SCP），并使用我们提出的超启发式算法求解最优视点子集。实验结果表明，所提出的方法能够以更少的视点和更高的覆盖率获得更好的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2408.01435</guid>
      <pubDate>Wed, 07 Aug 2024 03:14:17 GMT</pubDate>
    </item>
    <item>
      <title>SUSTechGAN：自动驾驶恶劣条件下的物体识别图像生成</title>
      <link>https://arxiv.org/abs/2408.01430</link>
      <description><![CDATA[arXiv:2408.01430v1 公告类型：新 
摘要：自动驾驶显著受益于数据驱动的深度神经网络。然而，自动驾驶中的数据通常符合长尾分布，其中恶劣条件下的关键驾驶数据很难收集。虽然生成对抗网络 (GAN) 已被用于增强自动驾驶数据，但在恶劣条件下生成驾驶图像仍然具有挑战性。在这项工作中，我们提出了一种具有双注意模块和多尺度生成器的新型 SUSTechGAN 来生成驾驶图像，以提高恶劣条件下自动驾驶的物体识别能力。我们测试了 SUSTechGAN 和现有的知名 GAN，以在雨天和夜晚的恶劣条件下生成驾驶图像，并将生成的图像应用于重新训练物体识别网络。具体而言，我们将生成的图像添加到训练数据集中以重新训练众所周知的 YOLOv5，并评估重新训练的 YOLOv5 在恶劣条件下物体识别的改进。实验结果表明，我们的 SUSTechGAN 生成的驾驶图像显著提高了重新训练的 YOLOv5 在雨天和夜间条件下的性能，优于众所周知的 GAN。开源代码、视频说明和数据集可在第 1 页找到，以促进恶劣条件下自动驾驶图像生成的开发。]]></description>
      <guid>https://arxiv.org/abs/2408.01430</guid>
      <pubDate>Wed, 07 Aug 2024 03:14:16 GMT</pubDate>
    </item>
    <item>
      <title>VLG-CBM：使用视觉语言指导训练概念瓶颈模型</title>
      <link>https://arxiv.org/abs/2408.01432</link>
      <description><![CDATA[arXiv:2408.01432v1 公告类型：新
摘要：概念瓶颈模型 (CBM) 通过引入中间概念瓶颈层 (CBL) 来提供可解释的预测，该层对人类可理解的概念进行编码以解释模型的决策。最近的研究提出利用大型语言模型 (LLM) 和预训练的视觉语言模型 (VLM) 来自动化 CBM 的训练，使其更具可扩展性和自动化。然而，现有的方法在两个方面仍然存在不足：首先，CBL 预测的概念通常与输入图像不匹配，从而引发对解释忠实性的怀疑。其次，已经证明概念值编码了非预期信息：即使是一组随机概念也可以实现与最先进的 CBM 相当的测试精度。为了解决这些关键的限制，在这项工作中，我们提出了一个称为视觉语言引导概念瓶颈模型 (VLG-CBM) 的新框架，以实现忠实的可解释性并提高性能。我们的方法利用现成的开放域接地物体检测器来提供基于视觉的概念注释，这大大提高了概念预测的忠实度，同时进一步提高了模型性能。此外，我们提出了一种称为有效概念数量（NEC）的新指标来控制信息泄漏并提供更好的可解释性。在五个标准基准上进行的广泛评估表明，我们的方法 VLG-CBM 在 NEC=5 的准确率上比现有方法至少高出 4.27% 和高达 51.09%，在不同 NEC 的平均准确率上至少高出 0.45% 和高达 29.78%，同时保留了所学概念的忠实度和可解释性，这在大量实验中得到了证明。]]></description>
      <guid>https://arxiv.org/abs/2408.01432</guid>
      <pubDate>Wed, 07 Aug 2024 03:14:16 GMT</pubDate>
    </item>
    <item>
      <title>用于小样本图像分类的 Siamese Transformer 网络</title>
      <link>https://arxiv.org/abs/2408.01427</link>
      <description><![CDATA[arXiv:2408.01427v1 公告类型：新
摘要：人类在视觉分类任务中表现出非凡的能力，能够用最少的例子准确识别和分类新图像。这种能力归因于他们专注于细节并识别以前看到的图像和新图像之间的共同特征的能力。相比之下，现有的少样本图像分类方法通常强调全局特征或局部特征，很少有研究考虑两者的结合。为了解决这一限制，我们提出了一种基于 Siamese Transformer 网络 (STN) 的新方法。我们的方法采用两个并行分支网络，利用预先训练的 Vision Transformer (ViT) 架构分别提取全局和局部特征。具体而言，我们实现了 ViT-Small 网络架构，并使用通过自监督学习获得的预训练模型参数初始化分支网络。我们将欧几里得距离测量应用于全局特征，将 Kullback-Leibler (KL) 散度测量应用于局部特征。为了整合这两个指标，我们首先采用 L2 归一化，然后对归一化结果进行加权以获得最终的相似度得分。该策略充分利用了全局和局部特征的优势，同时确保了它们的互补性。在训练阶段，我们采用元学习方法来微调整个网络。我们的策略有效地利用了全局和局部特征在小样本图像分类中的潜力，避免了对复杂特征自适应模块的需求并增强了模型的泛化能力。大量实验表明，我们的框架简单而有效，在 5 次和 1 次场景中的四个流行的小样本分类基准上实现了比最先进的基线更好的性能。]]></description>
      <guid>https://arxiv.org/abs/2408.01427</guid>
      <pubDate>Wed, 07 Aug 2024 03:14:15 GMT</pubDate>
    </item>
    <item>
      <title>可转移的对抗性面部图像用于隐私保护</title>
      <link>https://arxiv.org/abs/2408.01428</link>
      <description><![CDATA[arXiv:2408.01428v1 公告类型：新 
摘要：深度人脸识别 (FR) 系统的成功引发了严重的隐私问题，因为它们能够在数字世界中对用户进行未经授权的跟踪。先前的研究提出在人脸图像中引入不可察觉的对抗性噪声来欺骗那些人脸识别模型，从而实现增强人脸隐私保护的目的。然而，它们严重依赖用户选择的参考来指导对抗性噪声的生成，并且无法在黑盒场景中同时构建自然且高度可迁移的对抗性人脸图像。鉴于此，我们提出了一种新颖的人脸隐私保护方案，该方案在保持高视觉质量的同时提高了可迁移性。我们建议直接塑造整个人脸空间，而不是利用一种面部特征（如化妆信息）来整合对抗性噪声。为了实现这一目标，我们首先利用全局对抗性潜在搜索来遍历生成模型的潜在空间，从而创建具有高可迁移性的自然对抗性人脸图像。然后，我们引入了一个关键的地标正则化模块来保留视觉身份信息。最后，我们研究了各种潜在空间的影响，发现 $\mathcal{F}$ 潜在空间有利于视觉自然性和对抗性可迁移性之间的权衡。在两个数据集上进行的大量实验表明，我们的方法在保持高视觉质量的同时显著提高了攻击可迁移性，在深度 FR 模型中的表现比最先进的方法平均提高了 25%，在商业 FR API（包括 Face++、阿里云和腾讯）中的表现比最先进的方法提高了 10%。]]></description>
      <guid>https://arxiv.org/abs/2408.01428</guid>
      <pubDate>Wed, 07 Aug 2024 03:14:15 GMT</pubDate>
    </item>
    </channel>
</rss>