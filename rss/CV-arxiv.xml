<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CV 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Wed, 06 Nov 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>TypeScore：文本到图像生成模型的文本保真度度量</title>
      <link>https://arxiv.org/abs/2411.02437</link>
      <description><![CDATA[arXiv:2411.02437v1 公告类型：新
摘要：尽管文本到图像生成模型的整体性能取得了显著进步，但评估它们仍然是一个挑战。虽然现有的指标（如 CLIPScore）适用于粗略评估，但随着模型性能的快速提高，它们缺乏区分更细微差异的灵敏度。在这项工作中，我们专注于这些模型的文本渲染方面，这为评估生成模型的细粒度指令遵循能力提供了一个视角。为此，我们引入了一个名为 TypeScore 的新评估框架，以敏感地评估模型通过遵循精确指令生成具有高保真嵌入文本的图像的能力。我们认为这种文本生成能力可以作为图像合成中一般指令遵循能力的代理。TypeScore 使用额外的图像描述模型，并利用原始文本和提取文本之间的集成差异度量来评估渲染文本的保真度。我们提出的指标比 CLIPScore 具有更高的分辨率，可以区分具有多种文本样式的一系列指令中的流行图像生成模型。我们的研究还评估了这些视觉语言模型 (VLM) 对风格指令的遵循程度，将风格评估与嵌入文本保真度区分开来。通过人工评估研究，我们定量地元评估了该指标的有效性。进行了全面的分析，以探索文本长度、字幕模型以及目前在这项任务上与人类平起平坐的进展等因素。该框架提供了对嵌入文本图像生成指令遵循方面仍然存在的差距的洞察。]]></description>
      <guid>https://arxiv.org/abs/2411.02437</guid>
      <pubDate>Wed, 06 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>熵异联想记忆</title>
      <link>https://arxiv.org/abs/2411.02438</link>
      <description><![CDATA[arXiv:2411.02438v1 公告类型：新
摘要：熵联想记忆使用有限表作为媒介，以 2D 关系或“记忆平面”保存对象。记忆对象通过同时强化提示使用的单元来存储，从而实现 Hebb 学习规则的一种形式。存储的对象在介质上“重叠”，因此记忆是不确定的，并且在每个状态下都有一个熵值。检索操作根据提示和这种不确定的内容构造一个对象。在本文中，我们介绍了异联想情况的扩展，其中保留了这些属性。成对的异联想对象（可能属于不同的领域和/或模态）以 4D 关系保存。记忆检索操作选择一个很大程度上不确定的 2D 记忆平面，该平面特定于输入提示；但是，没有剩余的提示可以从后者平面检索对象。我们提出了三种增量方法来解决这种缺失线索问题，我们称之为随机、抽样和测试以及搜索和测试。该模型使用由分别从 MNIST 和 EMNIST 语料库中选择的手稿数字和字母组成的复合回忆进行评估，这样线索数字就可以检索其相关字母，反之亦然。我们展示了记忆性能，并说明了使用这三种方法的记忆检索操作。该系统有望以非常有限的计算资源存储、识别和检索非常大的对象集。]]></description>
      <guid>https://arxiv.org/abs/2411.02438</guid>
      <pubDate>Wed, 06 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Cross-D Conv：通过傅里叶移位操作实现跨维度可转移知识库</title>
      <link>https://arxiv.org/abs/2411.02441</link>
      <description><![CDATA[arXiv:2411.02441v1 公告类型：新
摘要：在生物医学成像分析中，2D 和 3D 数据之间的二分法带来了重大挑战。虽然 3D 体积提供了出色的现实世界适用性，但它们对每种模态的可用性较低，并且不易进行大规模训练，而 2D 样本丰富但不太全面。本文介绍了 Cross-D Conv 操作，这是一种通过学习傅里叶域中的相移来弥合维度差距的新方法。我们的方法实现了 2D 和 3D 卷积操作之间的无缝权重转移，有效地促进了跨维学习。所提出的架构利用丰富的 2D 训练数据来增强 3D 模型性能，为 3D 医学模型预训练中的多模态数据稀缺挑战提供了实用的解决方案。在 RadImagenet（2D）和多模态（3D）集上的实验验证表明，我们的方法在特征质量评估方面实现了与传统方法相当或更优异的性能。增强的卷积运算为开发医学成像中的高效分类和分割模型提供了新的机会。这项工作代表了跨维度和多模态医学图像分析的进步，为在 3D 模型预训练中使用 2D 先验或反之亦然提供了一个强大的框架，同时保持了计算效率。]]></description>
      <guid>https://arxiv.org/abs/2411.02441</guid>
      <pubDate>Wed, 06 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>WiCV@CVPR2024：年度 CVPR 大会第十三届计算机视觉女性研讨会</title>
      <link>https://arxiv.org/abs/2411.02445</link>
      <description><![CDATA[arXiv:2411.02445v1 公告类型：新
摘要：在本文中，我们介绍了与 CVPR 2024 一起在美国华盛顿州西雅图举办的计算机视觉女性研讨会 - WiCV 2024 的详细信息。WiCV 旨在扩大计算机视觉社区中代表性不足的女性的声音，提高学术界和工业界的知名度。我们相信，此类活动在解决该领域的性别不平衡问题方面发挥着至关重要的作用。一年一度的 WiCV@CVPR 研讨会提供 a)~少数群体研究人员之间的合作机会，b) 为女性初级研究人员提供指导，c) 为演讲者提供经济支持以减轻经济负担，d)~各种各样的榜样，可以在职业生涯的起步阶段激励年轻的研究人员。在本文中，我们全面报告了研讨会计划、过去 WiCV@CVPR 活动的历史趋势以及 WiCV 2024 研讨会的演讲者、与会者和赞助商相关的统计数据摘要。]]></description>
      <guid>https://arxiv.org/abs/2411.02445</guid>
      <pubDate>Wed, 06 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用场景图进行无线视觉问答的目标导向语义通信</title>
      <link>https://arxiv.org/abs/2411.02452</link>
      <description><![CDATA[arXiv:2411.02452v1 公告类型：新 
摘要：随着对通信和计算能力的需求不断增加，传统的面向比特的通信已无法满足这些严格的要求，尤其是对于任务关键型和计算密集型应用程序而言。代表性应用是视觉问答 (VQA)，它采用边缘计算来缓解局部计算约束并加速自然语言的视觉感知。然而，它面临着带宽有限、传输功率降低和噪声水平增加等重大通信挑战，导致图像和问题传输的延迟较大、效率降低。我们提出了一个面向目标的语义通信 (GSC) 框架，专注于有效提取和传输与 VQA 目标最相关的语义信息，提高回答准确性并提高有效性和效率。目标是最大限度地提高回答准确性，我们提出了一种基于场景图 (SG) 的图像语义提取和排序方法，根据问题的目标对语义信息进行优先排序。实验结果表明，与传统的面向位的传输相比，我们的 GSC 框架在瑞利信道下可将应答准确率提高高达 59%，同时将总延迟降低高达 65%。]]></description>
      <guid>https://arxiv.org/abs/2411.02452</guid>
      <pubDate>Wed, 06 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用深度学习克服伤口分类数据稀缺性的数据增强技术研究</title>
      <link>https://arxiv.org/abs/2411.02456</link>
      <description><![CDATA[arXiv:2411.02456v1 公告类型：新
摘要：慢性伤口对个人和医疗保健系统来说是一个沉重的负担，影响数百万人并产生高昂的费用。使用深度学习技术对伤口进行分类是一种有前途的方法，可以更快地进行诊断和治疗。然而，缺乏高质量的数据来训练 ML 模型是实现 ML 在伤口护理中的潜力的主要挑战。事实上，数据限制是当今使用医学或法医成像进行研究的最大挑战。我们研究可用于克服数据稀缺限制并释放基于深度学习的解决方案潜力的数据增强技术。在我们的研究中，我们探索了一系列数据增强技术，从伤口图像的几何变换到高级 GAN，以丰富和扩展数据集。使用 Keras、Tensorflow 和 Pandas 库，我们实现了可以生成逼真伤口图像的数据增强技术。我们表明，几何数据增强可以在几种主要伤口类别中，在最先进的模型的基础上将分类性能 F1 分数提高高达 11%。我们对基于 GAN 的增强进行的实验证明了使用 DE-GAN 生成具有更丰富变化的伤口图像的可行性。我们的研究和结果表明，数据增强是一种有价值的隐私保护工具，具有克服数据稀缺限制的巨大潜力，我们相信它将成为任何现实世界的基于 ML 的伤口护理系统的一部分。]]></description>
      <guid>https://arxiv.org/abs/2411.02456</guid>
      <pubDate>Wed, 06 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用人机对齐评估对 XAI 解释进行基准测试</title>
      <link>https://arxiv.org/abs/2411.02470</link>
      <description><![CDATA[arXiv:2411.02470v1 公告类型：新
摘要：在本文中，我们介绍了 PASTA（人工智能解释的感知评估系统），这是一种以人为本的计算机视觉 XAI 技术评估新框架。我们的第一个关键贡献是对四个不同数据集（COCO、Pascal Parts、Cats Dogs Cars 和 MonumAI）上的 XAI 解释进行人工评估，这构成了 XAI 的第一个大规模基准数据集，在图像和概念级别都有注释。该数据集允许对各种 XAI 方法进行稳健的评估和比较。我们的第二个主要贡献是基于数据的指标，用于评估解释的可解释性。它模仿人类的偏好，基于 PASTA 数据集中人类对解释的评估数据库。凭借其数据集和指标，PASTA 框架以可扩展但仍与人类评估保持一致的方式提供 XAI 技术之间的一致和可靠比较。此外，我们的基准测试允许对不同模态的解释进行比较，这是以前未解决的一个问题。我们的研究结果表明，人类倾向于喜欢显着性图而不是其他解释类型。此外，我们提供的证据表明，人类评估与通过探测模型进行数字模拟的现有 XAI 指标的相关性较低。]]></description>
      <guid>https://arxiv.org/abs/2411.02470</guid>
      <pubDate>Wed, 06 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>建立合成血管模型：颅内动脉瘤检测场景中的评估</title>
      <link>https://arxiv.org/abs/2411.02477</link>
      <description><![CDATA[arXiv:2411.02477v1 公告类型：新
摘要：我们在此提出一个完整的合成模型，能够模拟脑血管树的各种组成部分，包括脑动脉、分叉和颅内动脉瘤。该模型旨在提供大量的脑动脉数据集，可供 3D 卷积神经网络使用，以有效检测颅内动脉瘤。脑动脉瘤最常发生在血管树的特定结构上，称为 Willis 环。已经进行了各种研究来检测和监测动脉瘤，而基于深度学习的研究取得了最佳效果。具体而言，在这项工作中，我们提出了一个完整的合成 3D 模型，能够模拟通过磁共振血管造影、飞行时间原理获得的脑血管。在各种 MRI 模式中，后者可以很好地呈现血管并且是非侵入性的。我们的模型旨在同时模拟动脉的几何形状、动脉瘤形状和背景噪声。血管树几何形状通过 3D 样条函数插值建模，背景噪声的统计特性从血管造影采集中收集并在模型中重现。在这项工作中，我们详细描述了合成血管模型，建立了一个用于动脉瘤分割和检测的神经网络，最后，我们对合成模型数据增强所带来的性能差距进行了深入评估。]]></description>
      <guid>https://arxiv.org/abs/2411.02477</guid>
      <pubDate>Wed, 06 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>INQUIRE：自然世界文本到图像检索基准</title>
      <link>https://arxiv.org/abs/2411.02537</link>
      <description><![CDATA[arXiv:2411.02537v1 公告类型：新
摘要：我们推出了 INQUIRE，这是一种文本到图像检索基准，旨在挑战专家级查询的多模态视觉语言模型。INQUIRE 包括 iNaturalist 2024 (iNat24)，这是一个包含 500 万张自然世界图像的新数据集，以及 250 个专家级检索查询。这些查询与 iNat24 中全面标记的所有相关图像配对，总共包含 33,000 个匹配项。查询涵盖物种识别、背景、行为和外观等类别，强调需要细致入微的图像理解和领域专业知识的任务。我们的基准评估了两个核心检索任务：(1) INQUIRE-Fullrank，一个完整的数据集排名任务，以及 (2) INQUIRE-Rerank，一个用于优化前 100 个检索的重新排名任务。对一系列近期多模态模型的详细评估表明，INQUIRE 带来了巨大的挑战，最好的模型未能实现 50% 以上的 mAP@50。此外，我们表明，使用更强大的多模态模型进行重新排序可以提高检索性能，但仍有很大的改进空间。通过专注于科学驱动的生态挑战，INQUIRE 旨在弥合 AI 能力与现实世界科学探究需求之间的差距，鼓励开发有助于加速生态和生物多样性研究的检索系统。我们的数据集和代码可在 https://inquire-benchmark.github.io 上找到]]></description>
      <guid>https://arxiv.org/abs/2411.02537</guid>
      <pubDate>Wed, 06 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>TripletCLIP：通过合成视觉语言负样本改进 CLIP 的组合推理</title>
      <link>https://arxiv.org/abs/2411.02545</link>
      <description><![CDATA[arXiv:2411.02545v1 公告类型：新
摘要：对比语言-图像预训练 (CLIP) 模型最大化文本和视觉模态之间的相互信息来学习表示。这使得训练数据的性质成为 CLIP 对下游任务有效性的重要因素。然而，当代图像文本数据集缺乏组合多样性限制了 CLIP 的组合推理能力。我们表明，通过上下文学习生成“硬”负面字幕并使用文本到图像生成器合成相应的负面图像提供了一种解决方案。我们引入了一种新颖的对比预训练策略，该策略交替利用这些硬负面字幕和图像来训练 CLIP。我们证明，当将我们的方法 TripletCLIP 应用于现有数据集（例如 CC3M 和 CC12M）时，可以增强 CLIP 的组合能力，在同等计算预算的情况下，使 SugarCrepe 基准测试的绝对性能提高 9% 以上，并且零样本图像分类和图像检索也得到了改进。我们的代码、模型和数据可在以下网址获取：https://tripletclip.github.io]]></description>
      <guid>https://arxiv.org/abs/2411.02545</guid>
      <pubDate>Wed, 06 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Map++：面向高效地图扩展和共享的用户参与式视觉 SLAM 系统</title>
      <link>https://arxiv.org/abs/2411.02553</link>
      <description><![CDATA[arXiv:2411.02553v1 公告类型：新
摘要：构建精确的 3D 地图对于未来基于地图的系统（例如自动驾驶和导航）的开发至关重要。然而，在复杂的环境中生成这些地图（例如多层停车场或购物中心）仍然是一项艰巨的挑战。在本文中，我们介绍了一种参与式感知方法，将地图构建任务委托给地图用户，从而实现经济高效且持续的数据收集。所提出的方法利用用户的集体努力，随着环境的发展促进地图的扩展和持续更新。
我们通过开发 Map++ 实现了这种方法，Map++ 是一种高效的系统，可作为即插即用的扩展，支持基于现有 SLAM 算法的参与式地图构建。Map++ 通过提出一组轻量级的应用层协议解决了此参与式地图构建系统中的大量可扩展性问题。我们在四个代表性场景中评估了 Map++：室内车库、室外广场、公共 SLAM 基准和模拟环境。结果表明，Map++ 可以将交通量减少约 46%，而地图绘制精度的下降可以忽略不计，即与基线系统相比，误差不到 0.03 米。在相同的网络带宽下，它可以支持大约 $2 \times$ 倍于基线的并发用户数。此外，对于在已绘制的轨迹上行驶的用户，他们可以直接利用现有地图进行定位，并节省 47% 的 CPU 使用率。]]></description>
      <guid>https://arxiv.org/abs/2411.02553</guid>
      <pubDate>Wed, 06 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用电子显微镜对树突进行分割</title>
      <link>https://arxiv.org/abs/2411.02562</link>
      <description><![CDATA[arXiv:2411.02562v1 公告类型：新
摘要：电子显微镜 (EM) 图像中的细胞结构分割对于分析健康和患病脑组织中神经元和神经胶质细胞的形态至关重要。当前的神经元分割应用基于卷积神经网络 (CNN)，无法有效捕捉图像中的全局关系。在这里，我们介绍了基于 Segment Anything 的视觉基础模型 DendriteSAM，用于交互式和自动分割 EM 图像中的树突。该模型在健康大鼠海马的高分辨率 EM 数据上进行训练，并在患病大鼠和人类数据上进行测试。我们的评估结果表明，与原始模型和其他微调模型相比，利用训练期间学习到的特征，掩模质量更好。这项研究介绍了视觉基础模型在树突分割中的首次实现，为计算机辅助诊断神经元异常铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2411.02562</guid>
      <pubDate>Wed, 06 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>持续 LLaVA：大型视觉语言模型中的持续指令调整</title>
      <link>https://arxiv.org/abs/2411.02564</link>
      <description><![CDATA[arXiv:2411.02564v1 公告类型：新
摘要：指令调整是一种流行的技术，用于定制大型视觉语言模型 (LVLM) 以满足单个任务要求。迄今为止，大多数现有方法仅限于单任务适应，而现实世界场景中的要求本质上是多种多样且不断发展的。因此，理想的 LVLM 应该在面对流任务分布（即不同领域、新兴能力和新数据集）时维持持续的指令调整，同时尽量减少对先前获得的知识的遗忘。为了实现这一点，我们提出了一个新的 LVLM 持续指令调整基准 (COAST)，它涵盖了前面提到的领域增量、能力增量和数据集增量配置。在方法论方面，我们提出了 Continual LLaVA，这是一种无需排练的方法，专为 LVLM 中的持续指令调整而量身定制。为了避免与经验重放相关的额外开销，我们冻结了 LVLM 并为每个输入指令构建了双增量嵌入，以便于进行参数高效的调整。具体而言，增量嵌入可以分解为两个主要成分：1) 内在增量嵌入，用于编码特定于任务的特征。为此，我们建立了一个包含候选嵌入的低秩池，从中根据它们与用户指令的相似性选择相关嵌入；2) 上下文增量嵌入，用于研究跨任务的相互依赖关系。在这方面，在先前任务中选择的低秩嵌入通过可学习的加权和进行聚合，以提供补充提示。大量实验表明，所提出的 Continual LLaVA 优于以前的方法，因为它显著减少了持续指令调整过程中的遗忘。]]></description>
      <guid>https://arxiv.org/abs/2411.02564</guid>
      <pubDate>Wed, 06 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>TI-PREGO：用于程序性自我中心视频中在线错误检测的思路链和情境学习</title>
      <link>https://arxiv.org/abs/2411.02570</link>
      <description><![CDATA[arXiv:2411.02570v1 公告类型：新
摘要：在线识别以自我为中心的视频中的程序错误是一项关键而又具有挑战性的任务，涉及制造业、医疗保健和基于技能的培训等各个领域。此类错误的性质本质上是开放集的，因为可能会发生不可预见的或新的错误，因此需要不依赖于先前失败示例的强大检测系统。然而，目前还没有一种技术能够有效地在线检测开放集程序错误。
我们提出了一种双分支架构来在线解决这个问题：一个分支连续从输入的以自我为中心的视频中执行步骤识别，而另一个分支根据识别模块的输出预测未来的步骤。错误被检测为当前识别的动作与预期模块预测的动作之间的不匹配。识别分支获取输入帧，预测当前动作，并将帧级结果聚合为动作标记。具体而言，预测分支利用大型语言模型 (LLM) 的可靠模式匹配功能，根据先前预测的动作标记预测动作标记。
鉴于该任务的在线性质，我们还彻底评估了与每帧评估相关的困难，特别是在动态在线场景中需要准确和及时的预测。
在两个程序数据集上进行的大量实验证明了利用双分支架构进行错误检测的挑战和机遇，展示了我们提出的方法的有效性。在包括识别和预测变体以及最先进模型的全面评估中，我们的方法揭示了其在在线应用中的稳健性和有效性。]]></description>
      <guid>https://arxiv.org/abs/2411.02570</guid>
      <pubDate>Wed, 06 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>小型无人机实时检测：结合 YOLO 与多帧运动分析</title>
      <link>https://arxiv.org/abs/2411.02582</link>
      <description><![CDATA[arXiv:2411.02582v1 公告类型：新
摘要：无人机（UAV）检测技术在军事和民用应用中对降低安全风险和保护隐私起着至关重要的作用。然而，传统的检测方法在远距离识别具有极小像素的无人机目标方面面临重大挑战。针对这一问题，我们提出了全局-局部YOLO-Motion（GL-YOMO）检测算法，该算法将YOLO目标检测与多帧运动检测技术相结合，显著提高了小型无人机目标检测的准确性和稳定性。YOLO检测算法通过多尺度特征融合和注意机制进行优化，而Ghost模块的集成进一步提高了效率。此外，正在开发一种基于模板匹配的运动检测方法，以增强对微小无人机目标的检测能力。该系统采用全局-局部协同检测策略，实现高精度和高效率。在自行构建的固定翼无人机数据集上的实验结果表明，GL-YOMO算法显著提高了检测精度和稳定性，彰显了其在无人机检测应用方面的潜力。]]></description>
      <guid>https://arxiv.org/abs/2411.02582</guid>
      <pubDate>Wed, 06 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>