<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CV 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Mon, 04 Nov 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>我们做得怎么样？利用 Human-in-the-Loop 丰富技术评估肾病理学中的 Cell AI 基础模型</title>
      <link>https://arxiv.org/abs/2411.00078</link>
      <description><![CDATA[arXiv:2411.00078v1 公告类型：新
摘要：训练 AI 基础模型已成为一种有前途的大规模学习方法，用于解决现实世界的医疗保健挑战，包括数字病理学。虽然许多此类模型都是使用广泛而多样的训练数据集为疾病诊断和组织量化等任务开发的，但它们是否适合部署在一些可以说是最简单的任务上，例如单个器官（例如肾脏）内的细胞核分割，仍不确定。本文试图通过彻底评估最近的细胞基础模型在精选的多中心、多疾病和多物种外部测试数据集上的表现来回答这个关键问题“我们有多好？”。此外，我们通过开发和评估旨在提高模型性能同时最大限度地减少对像素级人工注释的依赖的人机数据丰富策略来解决一个更具挑战性的问题“我们如何改进？”。为了解决第一个问题，我们整理了一个由 2,542 张肾脏全切片图像 (WSI) 组成的多中心、多疾病和多物种数据集。选择了三种最先进的 (SOTA) 细胞基础模型 - Cellpose、StarDist 和 CellViT - 进行评估。为了解决第二个问题，我们探索了数据丰富算法，通过使用人机交互框架从不同的基础模型中提取预测，旨在以最少的人力进一步提高基础模型的性能。我们的实验结果表明，通过使用丰富数据进行模型微调，所有三种基础模型都比其基线有所改进。有趣的是，F1 得分最高的基线模型在微调后并没有产生最佳分割结果。这项研究为开发和部署针对现实世界数据应用量身定制的细胞视觉基础模型建立了基准。]]></description>
      <guid>https://arxiv.org/abs/2411.00078</guid>
      <pubDate>Mon, 04 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>肌肉随时间变化：通过模拟肌肉活动来学习理解人体运动</title>
      <link>https://arxiv.org/abs/2411.00128</link>
      <description><![CDATA[arXiv:2411.00128v1 公告类型：新
摘要：探索肌肉和骨骼结构之间复杂的动态对于理解人体运动至关重要。这个领域面临着巨大的挑战，主要归因于获取真实肌肉激活数据所需的大量资源，导致数据集稀缺。在这项工作中，我们通过建立大规模合成肌肉激活数据集 Muscles in Time (MinT) 来解决这个问题。为了创建 MinT，我们通过使用 OpenSim 平台结合从生物力学人体模型中得出的肌肉激活模拟来丰富现有的运动捕捉数据集，这是生物力学和人体运动研究中的常用方法。从简单的姿势序列开始，我们的流程使我们能够提取有关人体肌肉骨骼系统内肌肉激活时间的详细信息。Muscles in Time 包含超过 9 小时的模拟数据，涵盖 227 名受试者和 402 条模拟肌肉束。我们通过展示基于神经网络的肌肉激活估计结果来证明该数据集的实用性，该结果基于两种不同的序列到序列架构的人体姿势序列。数据和代码位于 https://simplexsigil.github.io/mint。]]></description>
      <guid>https://arxiv.org/abs/2411.00128</guid>
      <pubDate>Mon, 04 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>自组装高斯溅射用于少样本新颖视图合成</title>
      <link>https://arxiv.org/abs/2411.00144</link>
      <description><![CDATA[arXiv:2411.00144v1 公告类型：新
摘要：3D 高斯溅射 (3DGS) 已证明对新视图合成 (NVS) 具有显著的效果。然而，3DGS 模型在使用稀疏姿势视图进行训练时往往会过度拟合，从而限制了其对更广泛姿势变化的泛化能力。在本文中，我们通过引入自组装高斯溅射 (SE-GS) 方法来缓解过度拟合问题。我们提出了两个高斯溅射模型，分别称为 $\mathbf{\Sigma}$ 模型和 $\mathbf{\Delta}$ 模型。$\mathbf{\Sigma}$ 模型是推理过程中生成新视图图像的主要模型。在训练阶段，$\mathbf{\Sigma}$ 模型通过不确定性感知扰动策略引导远离特定的局部最优值。我们根据不同训练步骤中新视图渲染的不确定性动态扰动 $\mathbf{\Delta}$ 模型，从而从高斯参数空间采样出不同的时间模型，而无需额外的训练成本。通过惩罚 $\mathbf{\Sigma}$ 模型与时间样本之间的差异来正则化 $\mathbf{\Sigma}$ 模型的几何形状。因此，我们的 SE-GS 在大量高斯 Splatting 模型中进行了有效且高效的正则化，从而产生了一个稳健的集成，即 $\mathbf{\Sigma}$ 模型。在 LLFF、Mip-NeRF360、DTU 和 MVImgNet 数据集上的实验结果表明，我们的方法通过少量训练视图提高了 NVS 质量，优于现有的最先进方法。代码发布在 https://github.com/sailor-z/SE-GS。]]></description>
      <guid>https://arxiv.org/abs/2411.00144</guid>
      <pubDate>Mon, 04 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>NIMBA：利用 SSM 实现点云的稳健且有原则的处理</title>
      <link>https://arxiv.org/abs/2411.00151</link>
      <description><![CDATA[arXiv:2411.00151v1 公告类型：新
摘要：Transformers 已成为各个领域的大规模深度学习任务中的主导，包括文本、2D 和 3D 视觉。然而，随着序列长度的增加，其注意力机制的二次复杂性限制了它们的效率，特别是在点云等高分辨率 3D 数据中。最近，像 Mamba 这样的状态空间模型 (SSM) 已经成为有前途的替代方案，在长序列任务中提供线性复杂性、可扩展性和高性能。SSM 在该领域应用的关键挑战在于协调点云的非序列结构与 Mamba 等循环模型固有的方向性（或双向）顺序相关处理。为了实现这一点，先前的研究提出在 3D 空间中沿多个方向或预定路径重新组织点云，将结果连接起来以生成捕获不同视图的单个 1D 序列。在我们的工作中，我们引入了一种将点云转换为 1D 序列的方法，该序列保持 3D 空间结构，无需数据复制，从而允许以几乎置换不变的方式有效应用 Mamba 顺序处理。与其他工作相比，我们发现我们的方法不需要位置嵌入，并且允许更短的序列长度，同时仍然在 ModelNet40 和 ScanObjectNN 数据集中实现最先进的结果，并在准确性和效率方面超越基于 Transformer 的模型。]]></description>
      <guid>https://arxiv.org/abs/2411.00151</guid>
      <pubDate>Mon, 04 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用深度神经网络量化停车停留时间</title>
      <link>https://arxiv.org/abs/2411.00158</link>
      <description><![CDATA[arXiv:2411.00158v1 公告类型：新
摘要：在智慧城市中，通常的做法是为给定的停车位定义最大停留时间，以增加停车位的轮换性并阻止使用单独的交通解决方案。然而，从图像中自动确定单个汽车的停留时间面临着挑战，例如从低分辨率摄像机收集的图像、照明变化和天气影响。在这项工作中，我们提出了一种结合两个深度神经网络来计算停车场中每辆车的停留时间的方法。所提出的方法首先使用深度分类网络定义停车位状态，即占用和空置。然后，它使用 Siamese 网络来检查停放的汽车是否与之前的图像相同。使用专注于跨数据集场景的实验协议，我们表明，如果使用完美的分类器，所提出的系统可以生成 75% 的完美停留时间预测，其中预测值与汽车停放的时间完全匹配。然而，我们的实验表明，当使用真实世界分类器来预测停车位状态时，预测质量会下降，完美预测率达到 49%，这表明所提出的孪生网络是有前景的，但受到管道开始时使用的分类器质量的影响。]]></description>
      <guid>https://arxiv.org/abs/2411.00158</guid>
      <pubDate>Mon, 04 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>几何感知 3D 网格变换器的配方</title>
      <link>https://arxiv.org/abs/2411.00164</link>
      <description><![CDATA[arXiv:2411.00164v1 公告类型：新
摘要：利用基于块的变换器处理非结构化几何数据（例如多边形网格）面临重大挑战，主要是因为缺乏规范排序和输入大小变化。处理 3D 网格和点云的先前方法要么依赖于计算密集型节点级标记来处理大型对象，要么诉诸重采样来标准化块大小。此外，这些方法通常缺乏几何感知的稳定结构嵌入 (SE)，通常依赖于简单的绝对 SE（例如 3D 坐标），这会损害语义分割等任务所必需的等距不变性。在我们的研究中，我们仔细检查了几何感知的 3D 网格变换器的各个组件，从标记化到结构编码，评估每个组件的贡献。首先，我们引入了一种基于代数多网格方法的保留频谱的标记化。随后，我们详细介绍了一种在块级嵌入特征的方法，以适应具有可变节点数的块。通过与采用简单逐点多层感知器 (MLP) 的基线模型进行比较分析，我们的研究突出了关键见解：1) 由热扩散促进的结构和位置嵌入在一般 3D 网格变压器中的重要性；2) 诸如测地线掩蔽和通过交叉注意进行的特征交互等新组件在增强学习方面的有效性；3) 我们提出的方法在具有挑战性的分割和分类任务中具有卓越的性能和效率。]]></description>
      <guid>https://arxiv.org/abs/2411.00164</guid>
      <pubDate>Mon, 04 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用基于注意力机制的精细调整架构对南亚洪水易发国家进行空中洪水场景分类</title>
      <link>https://arxiv.org/abs/2411.00169</link>
      <description><![CDATA[arXiv:2411.00169v1 公告类型：新
摘要：南亚国家经常发生许多灾难性的洪水事件。通过图像分类，可以对洪水区域（包括房屋和人类）进行分类，从而加快搜索和救援行动。我们创建了一个新的数据集，收集了南亚国家洪水事件的航拍图像。对于分类，我们提出了一种基于微调的紧凑卷积变压器 (CCT) 的方法和其他一些基于变压器和卷积神经网络的尖端架构 (CNN)。我们还实现了 YOLOv8 对象检测模型，并在我们提出的数据集的图像中检测房屋和人类，然后将性能与我们的基于分类的方法进行比较。由于南亚国家具有相似的地形、住房结构、洪水颜色和植被，因此与世界其他地区相比，这项工作更适用于这样的地区。这些图像被均匀地分为四类：“洪水”、“有住所的洪水”、“有人的洪水”和“无洪水”。在我们经过微调的 CCT 模型上试验我们提出的数据集后，该模型的权重参数数量比许多其他为计算机视觉设计的基于 Transformer 的架构要少，其准确率和宏观平均精度分别为 98.62% 和 98.50%。我们实现的其他基于 Transformer 的架构是 Vision Transformer (ViT)、Swin Transformer 和外部注意 Transformer (EANet)，它们的准确率分别为 88.66%、84.74% 和 66.56%。我们还实现了 DCECNN（深度自定义集成卷积神经网络），这是我们通过结合 MobileNet、InceptionV3 和 EfficientNetB0 创建的自定义集成模型，我们获得了 98.78% 的准确率。我们实现的架构经过微调，以在我们的数据集上实现最佳性能。]]></description>
      <guid>https://arxiv.org/abs/2411.00169</guid>
      <pubDate>Mon, 04 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SeafloorAI：用于海底地质调查的大规模视觉语言数据集</title>
      <link>https://arxiv.org/abs/2411.00172</link>
      <description><![CDATA[arXiv:2411.00172v1 公告类型：新
摘要：机器学习模型在海洋科学（特别是在声纳图像分析）中进步的主要障碍是 AI 就绪数据集的稀缺。虽然人们一直在努力使 AI 就绪的声纳图像数据集公开可用，但它们在环境设置和规模方面受到限制。为了弥补这一差距，我们推出了 SeafloorAI，这是第一个用于跨 5 个地质层进行海底测绘的广泛 AI 就绪数据集，由海洋科学家合作策划。我们通过合并语言组件将数据集进一步扩展到 SeafloorGenAI，以促进开发用于声纳图像的视觉和语言机器学习模型。该数据集包括 62 个地理分布式数据调查，覆盖 17,300 平方公里，包含 696K 声纳图像、827K 带注释的分割掩码、696K 详细语言描述和大约 7M 个问答对。通过公开我们的数据处理源代码，我们旨在让海洋科学界参与进来，丰富数据库，并激励机器学习界开发更强大的模型。这种协作方法将增强我们的数据集在这两个领域的功能和应用。]]></description>
      <guid>https://arxiv.org/abs/2411.00172</guid>
      <pubDate>Mon, 04 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>缺失数据的行人轨迹预测：数据集、归纳和基准测试</title>
      <link>https://arxiv.org/abs/2411.00174</link>
      <description><![CDATA[arXiv:2411.00174v1 公告类型：新
摘要：行人轨迹预测对于机器人和自动驾驶汽车等多种应用至关重要。过去十年，由于行人轨迹数据集的出现，取得了重大进展，这些数据集使轨迹预测方法能够从行人过去的动作中学习并预测未来的轨迹。然而，这些数据集和方法通常假设观察到的轨迹序列是完整的，而忽略了现实世界的问题，例如传感器故障、遮挡和视野有限，这些问题可能导致观察到的轨迹中出现缺失值。为了应对这一挑战，我们提出了 TrajImpute，这是一个行人轨迹预测数据集，可模拟观察到的轨迹中缺失的坐标，从而增强现实世界的适用性。TrajImpute 在观察到的轨迹中保持缺失数据的均匀分布。在这项工作中，我们全面研究了几种用于重建缺失坐标的插补方法，并对其进行了基准测试，以用于插补行人轨迹。此外，我们还对最近的轨迹预测方法进行了全面分析，并评估了这些模型在插补轨迹上的性能。我们对插补和轨迹预测方法的实验评估提供了一些有价值的见解。我们的数据集为未来插补感知行人轨迹预测的研究提供了基础资源，有可能加速这些方法在实际应用中的部署。数据集和代码文件的公开链接可在 https://github.com/Pranav-chib/TrajImpute 上找到。]]></description>
      <guid>https://arxiv.org/abs/2411.00174</guid>
      <pubDate>Mon, 04 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>医学图像合成的临床评估：无线胶囊内窥镜的案例研究</title>
      <link>https://arxiv.org/abs/2411.00178</link>
      <description><![CDATA[arXiv:2411.00178v1 公告类型：新
摘要：共享回顾性获取的数据对于临床研究和培训都至关重要。使用人工智能 (AI) 模型的合成数据生成 (SDG) 可以克服共享临床数据中的隐私障碍，从而推动医学诊断的发展。本研究重点关注医学 SDG 的临床评估，并对使用无线胶囊内窥镜 (WCE) 图像诊断炎症性肠病 (IBD) 进行了概念验证调查。本文的贡献包括：a) 提出一种由医学专家对合成图像进行系统评估的协议；b) 将其应用于评估 TIDE-II，这是一种基于变分自动编码器的新型高分辨率 WCE 图像合成模型，由 10 位国际 WCE 专家进行了全面的定性评估，重点关注图像质量、多样性、真实性和临床决策。结果表明，TIDE-II 可生成临床相关的 WCE 图像，有助于解决数据稀缺问题并增强诊断工具。所提出的协议可为未来医学图像生成技术的研究提供参考。]]></description>
      <guid>https://arxiv.org/abs/2411.00178</guid>
      <pubDate>Mon, 04 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>光学镜头对自动驾驶单目深度估计的攻击</title>
      <link>https://arxiv.org/abs/2411.00192</link>
      <description><![CDATA[arXiv:2411.00192v1 公告类型：新
摘要：单目深度估计 (MDE) 是基于视觉的自动驾驶 (AD) 系统的关键组件，使车辆能够使用单个摄像头图像估计周围物体的深度。这种估计指导了基本的驾驶决策，例如在障碍物前刹车或变道以避免碰撞。在本文中，我们探讨了 AD 系统中 MDE 算法的漏洞，提出了一种新颖的物理攻击 LensAttack，它策略性地将光学镜头放置在自动驾驶汽车的摄像头上以操纵感知到的物体深度。LensAttack 包含两种攻击形式：凹透镜攻击和凸透镜攻击，每种攻击形式都利用不同的光学透镜来诱导错误的深度感知。我们首先开发一个概述攻击参数的数学模型，然后进行模拟和真实世界评估，以评估其对最先进的 MDE 模型的有效性。此外，我们采用攻击优化方法，通过优化攻击焦距来进一步提高攻击成功率。为了更好地评估 LensAttack 对 AD 的影响，我们使用 CARLA 平台进行了全面的端到端系统模拟。结果表明，LensAttack 可以严重破坏 AD 系统中的深度估计过程，对其可靠性和安全性构成严重威胁。最后，我们讨论了一些潜在的防御方法来减轻所提攻击的影响。]]></description>
      <guid>https://arxiv.org/abs/2411.00192</guid>
      <pubDate>Mon, 04 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用无人机数据估计整群大象的姿势以进行集体行为分析</title>
      <link>https://arxiv.org/abs/2411.00196</link>
      <description><![CDATA[arXiv:2411.00196v1 公告类型：新
摘要：这项研究代表了利用无人机数据自动估计姿势的开创性应用，利用从肯尼亚桑布鲁国家保护区拍摄的视频片段来研究野生大象的行为。该研究评估了两种姿势估计工作流程：DeepLabCut，以其在实验室环境和新兴野生动物实地工作中的应用而闻名，以及 YOLO-NAS-Pose，这是一种新发布的姿势估计模型，以前未应用于野生动物行为研究。这些模型经过训练可以分析大象群的行为，专注于低分辨率（$\sim$50 像素）的主体，以检测帧内多头大象的头部、脊柱和耳朵等关键点。这两个工作流程在测试集上都表现出可接受的姿势估计质量，有助于自动检测对研究大象群动态至关重要的基本行为。对于测试集上选择的姿势估计评估指标——均方根误差 (RMSE)、正确关键点百分比 (PCK) 和对象关键点相似度 (OKS)——YOLO-NAS-Pose 工作流程的表现优于 DeepLabCut。此外，YOLO-NAS-Pose 在对象检测评估方面也超过了 DeepLabCut。这种方法为野生动物行为研究引入了一种新方法，包括蓬勃发展的野生动物无人机监测领域，对野生动物保护具有重要意义。]]></description>
      <guid>https://arxiv.org/abs/2411.00196</guid>
      <pubDate>Mon, 04 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>评估 YOLO（You Only Look Once）模型的演进：对 YOLO11 及其前身的全面基准研究</title>
      <link>https://arxiv.org/abs/2411.00201</link>
      <description><![CDATA[arXiv:2411.00201v1 公告类型：新
摘要：本研究对各种 YOLO（You Only Look Once）算法进行了全面的基准分析，从 YOLOv3 到最新版本。这是首次全面评估 YOLO 家族最新成员 YOLO11 的性能的研究。它在三个不同的数据集上评估它们的性能：交通标志（具有不同的物体大小）、非洲野生动物（具有不同的纵横比，每幅图像至少有一个物体实例）以及船舶和船只（具有单一类别的小型物体），确保对具有不同挑战的数据集进行全面评估。为了确保进行可靠的评估，我们采用了一套全面的指标，包括精度、召回率、平均精度 (mAP)、处理时间、GFLOP 计数和模型大小。我们的分析突出了每个 YOLO 版本的独特优势和局限性。例如：YOLOv9 表现出相当高的准确率，但在检测小物体和效率方面存在困难；而 YOLOv10 的准确率相对较低，这是由于架构选择影响了其在重叠物体检测中的性能，但在速度和效率方面表现出色。此外，YOLO11 系列在准确率、速度、计算效率和模型大小方面始终表现出色。YOLO11m 在准确率和效率之间取得了显著的平衡，在交通标志、非洲野生动物和船舶数据集上分别获得了 0.795、0.81 和 0.325 的 mAP50-95 分数，同时保持了 2.4ms 的平均推理时间、38.8Mb 的模型大小和平均约 67.6 GFLOP。这些结果为工业界和学术界提供了重要的见解，有助于为各种应用选择最合适的 YOLO 算法并指导未来的改进。]]></description>
      <guid>https://arxiv.org/abs/2411.00201</guid>
      <pubDate>Mon, 04 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>语义知识蒸馏在卫星对地观测图像分类中的应用</title>
      <link>https://arxiv.org/abs/2411.00209</link>
      <description><![CDATA[arXiv:2411.00209v1 公告类型：新
摘要：本研究提出了一种创新的动态加权知识蒸馏 (KD) 框架，专门用于在资源受限的环境中实现高效的地球观测 (EO) 图像分类 (IC)。利用 EfficientViT 和 MobileViT 作为教师模型，该框架使轻量级学生模型（尤其是 ResNet8 和 ResNet16）的准确率、精确度和召回率超过 90%，并遵守可靠分类任务所需的严格置信度阈值。与依赖静态权重分布的传统 KD 方法不同，我们的自适应加权机制响应每个教师模型的置信度，允许学生模型动态地优先考虑更可靠的知识来源。值得注意的是，ResNet8 实现了显着的效率提升，与 MobileViT 相比，参数减少了 97.5%，FLOP 减少了 96.7%，功耗降低了 86.2%，推理速度提高了 63.5%。这种对复杂性和资源需求的显著优化使 ResNet8 成为 EO 任务的最佳候选者，将强大的性能与部署的可行性相结合。基于置信度的适应性 KD 方法强调了动态提炼策略的潜力，可以产生针对基于卫星的 EO 应用量身定制的高性能、资源高效的模型。可重现的代码可在我们的 GitHub 存储库中访问。]]></description>
      <guid>https://arxiv.org/abs/2411.00209</guid>
      <pubDate>Mon, 04 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>资源约束下的卫星图像尺度感知识别</title>
      <link>https://arxiv.org/abs/2411.00210</link>
      <description><![CDATA[arXiv:2411.00210v1 公告类型：新
摘要：卫星图像（森林、游泳池等）中特征的识别在很大程度上取决于概念的空间尺度，因此也取决于图像的分辨率。这带来了两个挑战：哪种分辨率最适合识别给定的概念，以及应该在何时何地获取更昂贵的高分辨率 (HR) 图像？我们提出了一种新颖的方案来解决这些挑战，通过引入三个组件：(1) 一种将知识从在 HR 图像上训练的模型中提取到在低分辨率 (LR) 图像上运行的识别模型的技术，(2) 基于模型分歧的 HR 图像采样策略，以及 (3) 一种基于 LLM 的推断概念“尺度”的方法。利用这些组件，我们提出了一个系统，可以有效地在卫星图像中执行尺度感知识别，在遵循预算限制的同时提高单尺度推理的准确性。我们的新方法比整个 HR 基线提高了 26.3%，同时使用了 76.3% 更少的 HR 图像。]]></description>
      <guid>https://arxiv.org/abs/2411.00210</guid>
      <pubDate>Mon, 04 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>