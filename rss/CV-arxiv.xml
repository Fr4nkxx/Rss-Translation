<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CV 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Mon, 25 Nov 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>dc-GAN：双条件 GAN，用于从单一变形进行人脸去变形</title>
      <link>https://arxiv.org/abs/2411.14494</link>
      <description><![CDATA[arXiv:2411.14494v1 公告类型：新
摘要：面部变形是通过组合属于两个不同身份的两张面部图像而创建的图像。面部变形会反转该过程并尝试恢复构成面部变形的原始图像。虽然可以使用变形攻击检测 (MAD) 技术来标记变形图像，但它们不会泄露有关用于创建它们的面部的任何视觉信息。变形有助于解决这个问题。现有的变形技术要么非常严格（在测试期间假设身份），要么产生微弱的输出（两个输出看起来非常相似）。在本文中，我们通过提出 dc-GAN（一种基于 GAN 的新型变形方法，以变形图像为条件）来克服这些问题。我们的方法克服了变形复制并生成用于创建变形的真实图像的高质量重建。此外，我们的方法在变形范式（差分/无参考）中具有高度可推广性。我们对 AMSL、FRLL-Morphs 和 MorDiff 数据集进行了实验，以展示我们方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2411.14494</guid>
      <pubDate>Mon, 25 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过去噪扩散模型实现 3D 点云测试时间自适应</title>
      <link>https://arxiv.org/abs/2411.14495</link>
      <description><![CDATA[arXiv:2411.14495v1 公告类型：新
摘要：3D 点云的测试时间自适应 (TTA) 对于缓解现实场景中训练和测试样本之间的差异至关重要，特别是在处理损坏的点云时。例如，LiDAR 数据可能会受到传感器故障或环境因素的影响，从而导致域间隙。在线使模型适应这些分布变化至关重要，因为针对每种可能的变化进行训练是不切实际的。现有方法通常侧重于基于自监督学习或伪标记对预训练模型进行微调，这可能导致随着时间的推移忘记有价值的源域知识并降低未来测试的泛化能力。在本文中，我们介绍了一种新颖的 3D 测试时间自适应方法，称为 3DD-TTA，代表 3D 去噪扩散测试时间自适应。该方法使用扩散策略，将输入点云样本适配到源域，同时保持源模型参数不变。该方法使用变分自动编码器 (VAE) 将损坏的点云编码为形状潜在和潜在点。这些潜在点被高斯噪声破坏，并经过去噪扩散过程。在此过程中，形状潜在和潜在点都会更新以保持保真度，从而引导去噪生成与源域更紧密一致的一致样本。我们在 ShapeNet 数据集上进行了广泛的实验，并研究了它在 ModelNet40 和 ScanObjectNN 上的通用性，取得了最先进的结果。代码已在 \url{https://github.com/hamidreza-dastmalchi/3DD-TTA} 发布。]]></description>
      <guid>https://arxiv.org/abs/2411.14495</guid>
      <pubDate>Mon, 25 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Delta-NAS：基于预测器的进化神经架构搜索的架构编码差异</title>
      <link>https://arxiv.org/abs/2411.14498</link>
      <description><![CDATA[arXiv:2411.14498v1 公告类型：新
摘要：神经架构搜索 (NAS) 继续在任务特定部署的神经网络的设计和开发中发挥关键作用。现代 NAS 技术难以应对不断增加的搜索空间复杂性和计算成本约束。现有方法可分为两类：细粒度计算昂贵的 NAS 和粗粒度低成本 NAS。我们的目标是设计一种能够以低成本执行细粒度 NAS 的算法。我们建议通过预测一对相似网络的准确度差异将问题投射到较低维空间。这种范式转变允许将计算复杂度从指数降低到线性，与搜索空间的大小有关。除了在一系列常见 NAS 基准测试中提供的大量实验结果外，我们还为我们的算法提供了强大的数学基础。我们的方法明显优于现有方法，实现了更好的性能和更高的样本效率。]]></description>
      <guid>https://arxiv.org/abs/2411.14498</guid>
      <pubDate>Mon, 25 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>U-Motion：使用 U 结构运动估计进行学习点云视频压缩</title>
      <link>https://arxiv.org/abs/2411.14501</link>
      <description><![CDATA[arXiv:2411.14501v1 公告类型：新
摘要：点云视频 (PCV) 是一种多功能的动态场景 3D 表示，具有许多新兴应用。本文介绍了 U-Motion，这是一种基于学习的 PCV 几何和属性压缩方案。我们提出了一个 U-Structured 多尺度帧间预测框架 U-Inter，它以不同的尺度和不同的细节级别执行逐层显式运动估计和补偿 (ME/MC)。除了当前帧和先前帧的信息外，它还集成了更高和更低尺度的运动特征，以便在当前尺度上进行准确的运动估计。此外，我们设计了一个级联空间预测编码模块来捕获 U-Inter 预测后剩余的尺度间空间冗余。我们进一步提出了一种有效的上下文分离和恢复方案，以减少运动和潜在比特流中的时空冗余并提高压缩性能。我们按照 MPEG 通用测试条件进行实验，并证明 U-Motion 在几何和属性压缩方面比 MPEG G-PCC-GesTM v3.0 和最近发布的基于学习的方法取得显著的进步。]]></description>
      <guid>https://arxiv.org/abs/2411.14501</guid>
      <pubDate>Mon, 25 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过照明降级解缠实现夜间翻译</title>
      <link>https://arxiv.org/abs/2411.14504</link>
      <description><![CDATA[arXiv:2411.14504v1 公告类型：新
摘要：夜间翻译（Night2Day）旨在实现夜间场景的白天视觉。然而，在非配对条件下，处理具有复杂退化的夜间图像仍然是一项重大挑战。以前统一缓解这些退化的方法已被证明不足以同时恢复日间域信息并保留底层语义。在本文中，我们提出了 \textbf{N2D3}（\textbf{N}ight-to-\textbf{D}ay via \textbf{D}egradation \textbf{D}isentanglement）来识别夜间图像中的不同退化模式。具体来说，我们的方法包括退化解缠结模块和退化感知对比学习模块。首先，我们从基于 Kubelka-Munk 理论的光度模型中提取物理先验。然后，在这些物理先验的指导下，我们设计了一个解缠结模块来区分不同的照明退化区域。最后，我们引入了退化感知对比学习策略，以保持不同退化区域的语义一致性。我们的方法在两个公共数据集上进行了评估，结果显示视觉质量显著提高，并且对下游任务有很大的益处。]]></description>
      <guid>https://arxiv.org/abs/2411.14504</guid>
      <pubDate>Mon, 25 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLaVA-MR：用于视频时刻检索的大型语言和视觉助手</title>
      <link>https://arxiv.org/abs/2411.14505</link>
      <description><![CDATA[arXiv:2411.14505v1 公告类型：新
摘要：多模态大型语言模型 (MLLM) 广泛用于视觉感知、理解和推理。然而，由于 LLM 的上下文大小有限和帧提取粗糙，长视频处理和精确时刻检索仍然具有挑战性。我们提出了用于时刻检索的大型语言和视觉助手 (LLaVA-MR)，它使用 MLLM 在视频中实现准确的时刻检索和上下文基础。LLaVA-MR 结合了密集帧和时间编码 (DFTE) 用于时空特征提取、信息帧选择 (IFS) 用于捕获简短的视觉和运动模式，以及动态标记压缩 (DTC) 来管理 LLM 上下文限制。在 Charades-STA 和 QVHighlights 等基准测试中的评估表明，LLaVA-MR 的表现优于 11 种最先进的方法，在 QVHighlights 数据集上实现了 R1@0.5 1.82% 的提升和 mAP@0.5 1.29% 的提升。我们的实现将在被接受后开源。]]></description>
      <guid>https://arxiv.org/abs/2411.14505</guid>
      <pubDate>Mon, 25 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>NexusSplats：在野外实现高效的 3D 高斯溅射</title>
      <link>https://arxiv.org/abs/2411.14514</link>
      <description><![CDATA[arXiv:2411.14514v1 公告类型：新
摘要：虽然 3D 高斯分层 (3DGS) 最近在 3D 场景重建中表现出色，但其在实际场景中难以应对变化的光照条件和偶然遮挡。为了适应变化的光照条件，现有的 3DGS 扩展将颜色映射应用于具有单独优化外观嵌入的大量高斯基元。为了处理遮挡，它们通过 2D 图像特征预测像素不确定性以进行遮挡捕获。然而，这种大规模的颜色映射和像素不确定性预测策略不仅需要额外的计算成本，还需要粗粒度的光照和遮挡处理。在这项工作中，我们提出了一种称为 NexusSplats 的 nexus 核驱动方法，用于在复杂的光照和遮挡条件下实现高效、更精细的 3D 场景重建。具体来说，NexusSplats 利用了一种新颖的光解耦策略，其中基于 nexus 核而不是大量高斯基元来优化外观嵌入，从而加快了重建速度，同时确保了更精细纹理的局部颜色一致性。此外，还开发了一种高斯不确定性机制，将 3D 结构与 2D 图像特征对齐，以实现细粒度遮挡处理。实验结果表明，与目前最好的质量相比，NexusSplats 实现了最先进的渲染质量，同时将重建时间缩短了 70.4%。]]></description>
      <guid>https://arxiv.org/abs/2411.14514</guid>
      <pubDate>Mon, 25 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CLIP 的双椭球几何</title>
      <link>https://arxiv.org/abs/2411.14517</link>
      <description><![CDATA[arXiv:2411.14517v1 公告类型：新
摘要：对比语言-图像预训练 (CLIP) 在各种领域的机器学习应用中都发挥着重要作用。我们研究了这种嵌入的几何形状，但这种几何形状仍未得到很好的理解。我们检查了原始的非规范化嵌入，并表明文本和图像位于线性可分的椭圆体壳上，而不是以原点为中心。我们解释了这种结构的好处，允许在对比训练期间根据实例的不确定性更好地嵌入实例。数据集中频繁出现的概念会产生更多的假阴性，从而导致更大的不确定性。引入了一种新的一致性概念，它测量一个实例与代表性数据集中任何其他实例的平均余弦相似度。我们表明，只需计算与模态均值向量的余弦相似度，就可以准确估计这个度量。此外，我们发现 CLIP 的模态间隙优化了图像和文本一致性分布的匹配。]]></description>
      <guid>https://arxiv.org/abs/2411.14517</guid>
      <pubDate>Mon, 25 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MyTimeMachine：个性化面部年龄转换</title>
      <link>https://arxiv.org/abs/2411.14521</link>
      <description><![CDATA[arXiv:2411.14521v1 公告类型：新
摘要：面部衰老是一个复杂的过程，高度依赖于性别、种族、生活方式等多种因素，因此，学习全局衰老先验以准确预测任何个体的衰老都极具挑战性。现有技术通常可以产生逼真且合理的衰老结果，但重新衰老的图像通常与目标年龄的人的外表不相似，因此需要个性化。在虚拟衰老的许多实际应用中，例如电影和电视节目中的视觉特效，通常可以访问用户在一小段时间间隔内（20$\sim$40 年）描绘衰老的个人照片集。然而，在个人照片集上个性化全局衰老技术的天真尝试往往会失败。因此，我们提出了 MyTimeMachine (MyTM)，它将全局衰老先验与个人照片集（使用少至 50 张图像）相结合，以学习个性化的年龄转换。我们引入了一种新颖的适配器网络，它将个性化衰老特征与全局衰老特征相结合，并使用 StyleGAN2 生成重新衰老的图像。我们还引入了三个损失函数，通过个性化衰老损失、外推正则化和自适应 w 范数正则化来个性化适配器网络。我们的方法还可以扩展到视频，实现高质量、身份保留和时间一致的衰老效果，这些效果类似于目标年龄的实际外观，证明了其优于最先进方法。]]></description>
      <guid>https://arxiv.org/abs/2411.14521</guid>
      <pubDate>Mon, 25 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>GMAI-VL 和 GMAI-VL-5.5M：面向通用医疗 AI 的大型视觉语言模型和综合多模态数据集</title>
      <link>https://arxiv.org/abs/2411.14522</link>
      <description><![CDATA[arXiv:2411.14522v1 公告类型：新 
摘要：尽管 GPT-4 等通用人工智能取得了重大进展，但由于缺乏专门的医学知识，它们在医学领域（通用医学 AI，GMAI）的有效性仍然受到限制。为了应对这一挑战，我们提出了 GMAI-VL-5.5M，这是一个全面的多模态医学数据集，通过将数百个专门的医学数据集转换为精心构建的图像-文本对而创建。该数据集具有全面的任务覆盖、多样化的模态和高质量的图像-文本数据。在此多模态数据集的基础上，我们提出了 GMAI-VL，这是一种具有渐进式三阶段训练策略的通用医学视觉语言模型。这种方法通过整合视觉和文本信息显着增强了模型的能力，从而提高了其处理多模态数据和支持准确诊断和临床决策的能力。实验评估表明，GMAI-VL 在各种多模态医学任务（例如视觉问答和医学图像诊断）中取得了最佳效果。我们的贡献包括开发 GMAI-VL-5.5M 数据集、引入 GMAI-VL 模型以及在多个医学领域建立新的基准。代码和数据集将在 https://github.com/uni-medical/GMAI-VL 发布。]]></description>
      <guid>https://arxiv.org/abs/2411.14522</guid>
      <pubDate>Mon, 25 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用空间点模式统计增强 GeoAI 和位置编码：地形特征分类案例研究</title>
      <link>https://arxiv.org/abs/2411.14560</link>
      <description><![CDATA[arXiv:2411.14560v1 公告类型：新
摘要：本研究通过将空间点模式统计数据纳入深度学习模型，引入了一种新的地形特征分类方法。受位置编码概念的启发，该概念旨在捕捉位置特征以增强 GeoAI 决策能力，我们通过知识驱动的方法改进 GeoAI 模型，以整合点模式的一阶和二阶效应。本文研究了这些空间背景如何影响地形特征预测的准确性。结果表明，通过利用空间关系的不同表示，结合空间点模式统计数据可显著提高模型性能。]]></description>
      <guid>https://arxiv.org/abs/2411.14560</guid>
      <pubDate>Mon, 25 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>隐私保护视频异常检测：一项调查</title>
      <link>https://arxiv.org/abs/2411.14565</link>
      <description><![CDATA[arXiv:2411.14565v1 公告类型：新
摘要：视频异常检测（VAD）旨在自动分析从开放空间收集的监控视频中的时空模式，以检测可能在没有物理接触的情况下造成伤害的异常事件。然而，基于视觉的监控系统（如闭路电视）通常会捕获个人身份信息。视频传输和使用缺乏透明度和可解释性，引发了公众对隐私和道德的担忧，限制了VAD的实际应用。最近，研究人员通过从数据、特征和系统等各个角度进行系统研究，重点关注VAD中的隐私问题，使隐私保护视频异常检测（P2VAD）成为AI社区的热点。然而，目前对P2VAD的研究比较零散，先前的综述大多集中在使用RGB序列的方法上，忽略了隐私泄露和外观偏差的考虑。为了弥补这一空白，本文首次系统地回顾了P2VAD的进展，定义了其范围并提供了直观的分类法。我们概述了各种方法的基本假设、学习框架和优化目标，分析了它们的优势、劣势和潜在相关性。此外，我们还开放了基准数据集和可用代码等研究资源。最后，我们从 AI 开发和 P2VAD 部署的角度讨论了关键挑战和未来机遇，旨在指导该领域的未来工作。]]></description>
      <guid>https://arxiv.org/abs/2411.14565</guid>
      <pubDate>Mon, 25 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>解决零样本 3D 视觉基础作为约束满足问题</title>
      <link>https://arxiv.org/abs/2411.14594</link>
      <description><![CDATA[arXiv:2411.14594v1 公告类型：新
摘要：3D 视觉定位 (3DVG) 旨在使用自然语言描述在 3D 场景中定位对象。监督方法已经取得了不错的准确率，但词汇量有限，语言理解能力有限。零样本方法主要利用大型语言模型 (LLM) 来处理自然语言描述，但推理速度较慢。为了解决这些问题，在这项工作中，我们提出了一种零样本方法，将 3DVG 任务重新表述为约束满足问题 (CSP)，其中变量和约束分别表示对象及其空间关系。这允许对所有相关对象进行全局推理，从而产生目标和锚对象的定位结果。此外，我们通过仅需少量额外编码工作即可处理基于否定和计数的查询来展示我们框架的灵活性。我们的系统约束满足视觉接地 (CSVG) 已在公共数据集 ScanRefer 和 Nr3D 数据集上进行了广泛评估，仅使用开源 LLM。结果表明，CSVG 的有效性和接地精度优于当前最先进的零样本 3DVG 方法，在 ScanRefer 和 Nr3D 数据集上分别提高了 $+7.0\%$（Acc@0.5 分数）和 $+11.2\%$。我们系统的代码可在 https://github.com/sunsleaf/CSVG 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2411.14594</guid>
      <pubDate>Mon, 25 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>热点：符号距离函数优化的筛选泊松方程</title>
      <link>https://arxiv.org/abs/2411.14628</link>
      <description><![CDATA[arXiv:2411.14628v1 公告类型：新
摘要：我们提出了一种基于筛选泊松方程解与距离函数之间的关系来优化神经符号距离函数的方法 HotSpot。现有的损失（例如艾科纳损失）不能保证恢复的隐式函数是距离函数，即使隐式函数几乎处处满足艾科纳方程。此外，艾科纳损失在优化中存在稳定性问题，引入面积或散度最小化的补救措施可能会导致过度平滑。我们通过设计一个损失函数来解决这些挑战，该损失函数在最小化时可以收敛到真实距离函数，是稳定的，并且自然会惩罚大表面积。我们对具有挑战性的 2D 和 3D 数据集进行了理论分析和实验，并表明我们的方法提供了更好的表面重建和更准确的距离近似。]]></description>
      <guid>https://arxiv.org/abs/2411.14628</guid>
      <pubDate>Mon, 25 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过噪声聚合嵌入实现扩散模型的差异化隐私自适应</title>
      <link>https://arxiv.org/abs/2411.14639</link>
      <description><![CDATA[arXiv:2411.14639v1 公告类型：新 
摘要：我们引入了在差异隐私 (DP) 约束下调整扩散模型的新方法，无需微调即可实现隐私保护风格和内容传输。传统的隐私适应方法，例如 DP-SGD，在应用于大型复杂模型时会产生大量计算开销并降低模型性能。我们的方法利用基于嵌入的技术：通用指导和文本反转 (TI)，并通过差异隐私机制进行调整。我们将这些方法应用于稳定扩散，使用两个隐私数据集进行风格适应：单个艺术家的作品集和来自 2024 年巴黎奥运会的象形图。实验结果表明，基于 TI 的适应即使在强大的隐私保证下也能实现出色的风格转换保真度，而两种方法都通过采用校准的噪声和子采样策略保持了较高的隐私弹性。我们的研究结果展示了一种可行且有效的隐私保护扩散模型自适应途径，平衡了数据保护和生成图像的保真度，并为生成 AI 应用中 DP 的嵌入驱动方法提供了见解。]]></description>
      <guid>https://arxiv.org/abs/2411.14639</guid>
      <pubDate>Mon, 25 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>