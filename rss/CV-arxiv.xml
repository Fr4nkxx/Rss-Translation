<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CV 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Thu, 13 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>Movie Weaver：无需调音，通过锚定提示实现多概念视频个性化</title>
      <link>https://arxiv.org/abs/2502.07802</link>
      <description><![CDATA[arXiv:2502.07802v1 公告类型：新
摘要：视频个性化使用参考图像生成定制视频，引起了广泛关注。然而，之前的方法通常侧重于单概念个性化，限制了需要多概念集成的更广泛应用。尝试将这些模型扩展到多个概念通常会导致身份混合，从而产生具有来自多个来源的融合属性的复合角色。这一挑战是由于缺乏将每个概念与其特定参考图像链接起来的机制而产生的。我们使用锚定提示来解决这个问题，它将图像锚点作为唯一标记嵌入文本提示中，在生成过程中指导准确引用。此外，我们引入了概念嵌入来编码参考图像的顺序。我们的方法 Movie Weaver 将多个概念（包括面部、身体和动物图像）无缝编织到一个视频中，允许在单个模型中进行灵活组合。评估表明，Movie Weaver 在身份保存和整体质量方面优于现有的多概念视频个性化方法。]]></description>
      <guid>https://arxiv.org/abs/2502.07802</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CrossVideoMAE：使用蒙版自动编码器进行自监督图像视频表征学习</title>
      <link>https://arxiv.org/abs/2502.07811</link>
      <description><![CDATA[arXiv:2502.07811v1 公告类型：新
摘要：当前基于视频的蒙版自动编码器 (MAE) 主要侧重于从视觉角度学习有效的时空表示，这可能导致模型优先考虑一般的时空模式，但往往忽略细微的语义属性，如定义动作的特定交互或序列 - 例如与人类对时空对应的认知更紧密相关的动作特定特征。这可能会限制模型捕捉某些上下文丰富且连续的动作本质的能力。人类能够映射静态实例中可用的视觉概念、对象视图不变性和语义属性，以理解自然动态场景或视频。现有的视频和静态图像的 MAE 依赖于视频和图像的单独数据集，这些数据集可能缺乏充分理解学习概念所必需的丰富语义属性，尤其是与一起使用视频和相应的采样帧图像相比时。为此，我们提出了 CrossVideoMAE，这是一种端到端的自监督跨模态对比学习 MAE，可以有效地学习视频级和帧级丰富的时空表示和语义属性。我们的方法将来自视频的相互时空信息与来自特征不变空间内采样帧的空间信息相结合，同时鼓励视频域内的增强不变性。该目标是通过联合嵌入可见标记的特征并结合模态内和模态之间的特征对应来实现的，这对于以自监督的方式从视频和帧图像模态中获取丰富的无标签引导信号至关重要。大量实验表明，我们的方法超越了以前最先进的方法，消融研究验证了我们方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2502.07811</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过潜在特征的 Kolmogorov-Arnold 变换实现非配对图像去雾</title>
      <link>https://arxiv.org/abs/2502.07812</link>
      <description><![CDATA[arXiv:2502.07812v1 公告类型：新
摘要：本文提出了一种通过 Kolmogorov-Arnold 变换进行无监督图像去雾的创新框架，称为 UID-KAT。图像去雾被认为是一项具有挑战性且不适定的视觉任务，需要在特征空间中进行复杂的转换和解释。最近的进展引入了受 Kolmogorov-Arnold 表示定理启发的 Kolmogorov-Arnold 网络 (KAN)，作为多层感知器 (MLP) 的有希望的替代方案，因为 KAN 可以利用其多项式基础更有效地近似复杂函数，同时需要比 MLP 更少的层。受这种潜力的启发，本文探讨了使用 KAN 结合对抗性训练和对比学习来模拟模糊图像和清晰图像之间的复杂关系。由于对抗性训练能够生成高保真图像，因此被采用，而对比学习则促进模型强调重要特征，同时抑制无关信息的影响。所提出的 UID-KAT 框架在无监督环境中进行训练，以利用丰富的真实世界数据并解决准备成对的模糊/清晰图像的挑战。实验结果表明，UID-KAT 在多个数据集和场景中实现了最先进的去雾性能，优于现有的非配对方法，同时降低了模型复杂性。这项工作的源代码可在 https://github.com/tranleanh/uid-kat 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2502.07812</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>健忘症作为增强图像分类和物体检测中黑盒像素攻击的催化剂</title>
      <link>https://arxiv.org/abs/2502.07821</link>
      <description><![CDATA[arXiv:2502.07821v1 公告类型：新
摘要：众所周知，基于查询的攻击在对抗性黑盒攻击中往往具有相对较高的成功率。虽然对黑盒攻击的研究正在积极开展，但相对较少的研究关注仅针对有限数量像素的像素攻击。在图像分类中，基于查询的像素攻击通常依赖于补丁，而补丁严重依赖于随机性，忽略了分散像素更适合对抗性攻击的事实。此外，据我们所知，基于查询的像素攻击尚未在对象检测领域进行探索。为了解决这些问题，我们提出了一种新的基于像素的黑盒攻击，称为使用强化学习的记忆和忘记像素攻击（RFPAR），它由两个主要部分组成：记忆和忘记过程。RFPAR 通过利用通过一步 RL 算法生成的奖励来扰乱像素，从而减轻随机性并避免补丁依赖性。RFPAR 有效地创建了扰动图像，以最小化置信度得分，同时遵守有限的像素约束。此外，我们将我们提出的攻击从图像分类推进到对象检测，其中 RFPAR 降低检测到的对象置信度分数以避免检测。在 ImageNet-1K 数据集上进行的分类实验表明，RFPAR 优于最先进的基于查询的像素攻击。对于对象检测，使用带有 YOLOv8 和 DDQ 的 MSCOCO 数据集，RFPAR 表现出与最先进的基于查询的攻击相当的 mAP 减少，同时需要更少的查询。使用 YOLOv8 在 Argoverse 数据集上进行的进一步实验证实，RFPAR 有效地从更大规模的数据集中删除了对象。我们的代码可在 https://github.com/KAU-QuantumAILab/RFPAR 获得。]]></description>
      <guid>https://arxiv.org/abs/2502.07821</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>PDM-SSD：具有点扩张的单级三维物体检测器</title>
      <link>https://arxiv.org/abs/2502.07822</link>
      <description><![CDATA[arXiv:2502.07822v1 公告类型：新
摘要：目前基于点的检测器只能从提供的点中学习，其感受野有限，对此类目标的全局学习能力不足。在本文中，我们提出了一种利用这两种表示的单阶段3D检测的新型点扩张机制（PDM-SSD）。具体而言，我们首先使用PointNet风格的3D骨干进行有效的特征编码。然后，使用具有点扩张机制（PDM）的颈部来扩展特征空间，这涉及两个关键步骤：点扩张和特征填充。前者将点扩展到欧几里得空间中以采样点为中心的一定大小的网格。后者使用球面谐波系数和高斯密度函数在方向和尺度上用特征填充未占用的网格以进行反向传播。接下来，我们关联多个扩张中心并融合系数以通过高度压缩获得稀疏网格特征。最后，我们设计了一个混合检测头进行联合学习，一方面通过预测场景热图来补充投票点集以提高检测精度，另一方面通过特征融合来校准检测到的框的目标概率。在具有挑战性的卡尔斯鲁厄理工学院和丰田技术学院 (KITTI) 数据集上，PDM-SSD 在单模态方法中实现了多类检测的最佳结果，推理速度为 68 帧。我们还通过大量对象级实例展示了 PDM-SSD 在检测稀疏和不完整对象方面的优势。此外，PDM 可以作为辅助网络在采样点和对象中心之间建立连接，从而在不牺牲推理速度的情况下提高模型的准确性。我们的代码将在 https://github.com/AlanLiangC/PDM-SSD.git 上提供。]]></description>
      <guid>https://arxiv.org/abs/2502.07822</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>预训练视频生成模型作为世界模拟器</title>
      <link>https://arxiv.org/abs/2502.07825</link>
      <description><![CDATA[arXiv:2502.07825v1 公告类型：新
摘要：在大型互联网数据集上预训练的视频生成模型取得了显著的成功，擅长制作逼真的合成视频。然而，它们通常基于静态提示（例如文本或图像）生成剪辑，限制了它们对交互式和动态场景进行建模的能力。在本文中，我们提出了动态世界模拟 (DWS)，这是一种将预训练的视频生成模型转换为可控制的世界模拟器的新方法，能够执行指定的动作轨迹。为了实现条件动作和生成的视觉变化之间的精确对齐，我们引入了一个轻量级的通用动作条件模块，可以无缝集成到任何现有模型中。我们证明了一致的动态转换建模是构建强大的世界模拟器的关键，而不是专注于复杂的视觉细节。基于这一见解，我们进一步引入了运动强化损失，通过强制模型更有效地捕捉动态变化来增强动作的可控性。实验表明，DWS 可以广泛应用于扩散和自回归变换模型，在游戏和机器人领域生成动作可控、动态一致的视频方面取得了显著的进步。此外，为了促进学习世界模拟器在基于模型的强化学习等下游任务中的应用，我们提出了优先想象来提高样本效率，与最先进的方法相比，其性能具有竞争力。]]></description>
      <guid>https://arxiv.org/abs/2502.07825</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>深度学习在自动电力线巡检中的应用：综述</title>
      <link>https://arxiv.org/abs/2502.07826</link>
      <description><![CDATA[arXiv:2502.07826v1 公告类型：新
摘要：近年来，电力线维护已发生范式转变，转向计算机视觉驱动的自动检查。大量视频和图像的利用对于维持电力传输的可靠性、安全性和可持续性至关重要。最近的研究发现，人们非常关注应用深度学习技术来增强电力线检查过程。本文对现有研究进行了全面回顾，以帮助研究人员和行业开发改进的基于深度学习的电力线数据分析系统。本文研究了电力线检查中数据分析的常规步骤，并将当前研究的主体系统地分为两个主要领域：组件检测和故障诊断。本文对这些领域采用的各种方法和技术进行了详细总结，深入了解了它们的功能和用例。本文特别关注了基于深度学习的电力线检查数据分析方法的探索，并阐述了它们的基本原理和实际应用。此外，本文还概述了未来研究方向的愿景，强调了边缘云协作、多模态分析等进步的必要性。因此，本文为深入研究电力线分析深度学习的研究人员提供了全面的资源，阐明了当前知识的范围和未来研究的潜在领域。]]></description>
      <guid>https://arxiv.org/abs/2502.07826</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>扩散模型上的偏好对齐：图像生成和编辑的综合调查</title>
      <link>https://arxiv.org/abs/2502.07829</link>
      <description><![CDATA[arXiv:2502.07829v1 公告类型：新
摘要：偏好对齐与扩散模型 (DM) 的集成已成为增强图像生成和编辑能力的一种变革性方法。尽管将扩散模型与偏好对齐策略相结合对这一交叉领域的新手提出了重大挑战，但对这一主题的全面系统的评论仍然明显缺乏。为了弥补这一差距，本文广泛调查了图像生成和编辑中偏好与扩散模型的对齐。首先，我们系统地回顾了强化学习与人类反馈 (RLHF)、直接偏好优化 (DPO) 等前沿优化技术，强调了它们在将偏好与 DM 对齐方面的关键作用。然后，我们彻底探讨了将偏好与 DM 对齐在自动驾驶、医学成像、机器人技术等领域的应用。最后，我们全面讨论了偏好与 DM 对齐的挑战。据我们所知，这是第一项以偏好与 DM 对齐为中心的调查，为推动这一充满活力的领域未来创新提供了见解。]]></description>
      <guid>https://arxiv.org/abs/2502.07829</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>被字幕捕获：关于 CLIP 模型中的记忆及其缓解</title>
      <link>https://arxiv.org/abs/2502.07830</link>
      <description><![CDATA[arXiv:2502.07830v1 公告类型：新
摘要：多模态模型（例如 CLIP）在对齐视觉和文本表示方面表现出色，在图像检索和零样本分类等任务中表现出色。尽管取得了成功，但这些模型利用训练数据的机制，尤其是记忆的作用，仍不清楚。在单模态模型中，无论是监督模型还是自监督模型，记忆都已被证明对于泛化至关重要。然而，人们还不太了解这些发现如何应用于 CLIP，它结合了通过提供类似于标签的监督信号的标题进行的监督学习和通过对比目标进行的自监督学习的元素。为了弥合这一理解上的差距，我们提出了 CLIP 中记忆的正式定义 (CLIPMem)，并使用它来量化 CLIP 模型中的记忆。我们的结果表明，CLIP 的记忆行为介于监督和自监督范式之间，其中“错误字幕”样本表现出最高的记忆水平。此外，我们发现文本编码器对记忆的贡献大于图像编码器，这表明缓解策略应该侧重于文本域。基于这些见解，我们提出了多种减少记忆同时提高效用的策略——这在传统学习范式中从未被证明过，因为减少记忆通常会导致效用降低。]]></description>
      <guid>https://arxiv.org/abs/2502.07830</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>NanoVLM：我们可以将其缩小到多小，同时还能制作出连贯的视觉语言模型？</title>
      <link>https://arxiv.org/abs/2502.07838</link>
      <description><![CDATA[arXiv:2502.07838v1 公告类型：新 
摘要：视觉语言模型 (VLM)，例如 GPT-4V 和 Llama 3.2 vision，因其在多模态任务中利用大型语言模型 (LLM) 的能力而引起了广泛的研究关注。然而，它们的潜力受到固有挑战的限制，包括专有限制、大量计算需求和有限的可访问性。较小的模型，例如 GIT 和 BLIP，表现出明显的局限性，即使经过大量训练，也常常无法生成除几个标记之外的连贯一致的文本。这强调了一个关键的探究：VLM 可以有多小，同时仍然能够生成流畅一致的文本？从 3-4 岁儿童的特殊学习过程中汲取灵感，他们严重依赖视觉线索来理解和交流，我们引入了两个新的数据集：ShortDesc（具有简洁的图像描述）和 LongDesc（包含更详细的图像描述）。这些数据集由图像-文本对组成，其中文本仅限于幼儿通常使用的简单词汇和语法，由缩小版模型 GPT-4o 生成。使用这些数据集，我们证明可以训练比最先进 (SOTA) 小型 VLM 小得多的 VLM，同时保持架构简单性。为了评估输出，我们利用 GPT-4o 对文本（就像学生写的故事一样）进行评分，评分标准为 10 分制，评分内容包括创造力、意义和一致性。此方法通过适应非结构​​化输出并提供对模型功能的多维评估来解决标准基准的局限性。我们的研究结果有助于为资源受限的环境开发轻量级、可访问的多模态模型。]]></description>
      <guid>https://arxiv.org/abs/2502.07838</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>TranSplat：用于透明物体操作的表面嵌入引导 3D 高斯分层</title>
      <link>https://arxiv.org/abs/2502.07840</link>
      <description><![CDATA[arXiv:2502.07840v1 公告类型：新
摘要：由于难以获取准确且密集的深度测量，透明物体的操作仍然是机器人技术中的一项重大挑战。传统的深度传感器经常无法处理透明物体，导致深度数据不完整或错误。现有的深度完成方法难以实现帧间一致性，并且错误地将透明物体建模为朗伯表面，导致深度重建效果不佳。为了应对这些挑战，我们提出了 TranSplat，这是一种针对透明物体定制的表面嵌入引导 3D 高斯溅射方法。TranSplat 使用潜在扩散模型来生成提供一致和连续表示的表面嵌入，使其对视点和光照的变化具有鲁棒性。通过将这些表面嵌入与输入的 RGB 图像相结合，TranSplat 可以有效捕捉透明表面的复杂性，增强 3D 高斯溅射并提高深度完成度。在合成和真实世界透明物体基准以及机器人抓取任务上的评估表明，TranSplat 实现了准确且密集的深度补全，证明了其在实际应用中的有效性。我们开源合成数据集和模型：https://github. com/jeongyun0609/TranSplat]]></description>
      <guid>https://arxiv.org/abs/2502.07840</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>将它们分开：实现生成内容的稳健水印</title>
      <link>https://arxiv.org/abs/2502.07845</link>
      <description><![CDATA[arXiv:2502.07845v1 公告类型：新
摘要：近年来，能够生成逼真图像的生成模型得到了显着改进。生成内容的质量大幅提高，因此有时很难区分真实图像和生成图像。这种改进是以对生成模型使用的道德担忧为代价的：生成模型的用户可以不正当地声称拥有受许可保护的生成内容的所有权。在本文中，我们提出了一种将水印嵌入生成内容的方法，以便将来检测生成的内容并识别生成该内容的用户。水印是在模型推理过程中嵌入的，因此所提出的方法不需要对后者进行重新训练。我们证明嵌入的水印保证对有限幅度的加性扰动具有鲁棒性。我们将我们的方法应用于水印扩散模型，并表明它在对不同类型的合成水印去除攻击的鲁棒性方面与最先进的水印方案相匹配。]]></description>
      <guid>https://arxiv.org/abs/2502.07845</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>关于在协变量偏移下校准视觉语言模型的技术说明</title>
      <link>https://arxiv.org/abs/2502.07847</link>
      <description><![CDATA[arXiv:2502.07847v1 公告类型：新
摘要：尽管视觉语言基础模型是新兴能力的一个成功例子，但由于样本贫乏，低样本视觉分类的视觉语言基础模型对目标数据分布的充分推广能力有限，导致对数据变化的敏感性。一种流行的缓解策略是对多个数据集进行微调，但以这种方式进行领域泛化成本高昂。这项工作研究了预训练数据和未指定目标数据之间的协变量偏移，以及 \textit{置信度错位}，其中模型的预测置信度因有限的数据可用性而放大。我们提出了 \textit{置信度校准的协变量偏移校正 ($C3SC$)}，这是一个统一的框架，用于缓解协变量偏移和置信度错位。$C3SC$ 利用 Fisher 信息惩罚进行协变量偏移校正，并利用置信度错位惩罚 (CMP) 来降低对错误分类示例的置信度。在各种视觉和协变量偏移数据集上的实验结果表明，$C3SC$ 在校准 (ECE) 方面显著提高了 $5.82\%$。$C3SC$ 还表现出更好的鲁棒性，在具有挑战性的协变量偏移数据集上显示出准确度指标提高了 $3.5\%$，这使得 $C3SC$ 成为分布偏移下可靠的现实世界视觉语言低样本应用的有前途的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2502.07847</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>边缘网络的视觉语言模型：综合综述</title>
      <link>https://arxiv.org/abs/2502.07855</link>
      <description><![CDATA[arXiv:2502.07855v1 公告类型：新
摘要：视觉大型语言模型 (VLM) 将视觉理解与自然语言处理相结合，可实现图像字幕、视觉问答和视频分析等任务。虽然 VLM 在自动驾驶汽车、智能监控和医疗保健等领域表现出令人印象深刻的功能，但由于处理能力、内存和能源限制，它们在资源受限的边缘设备上的部署仍然具有挑战性。本调查探讨了针对边缘环境优化 VLM 的最新进展，重点关注模型压缩技术，包括修剪、量化、知识提炼和提高效率的专用硬件解决方案。我们详细讨论了有效的训练和微调方法、边缘部署挑战和隐私考虑。此外，我们还讨论了轻量级 VLM 在医疗保健、环境监测和自主系统方面的多种应用，说明了它们日益增长的影响力。通过强调关键的设计策略、当前的挑战以及为未来的发展方向提供建议，本次调查旨在激发对 VLM 实际部署的进一步研究，最终使先进的 AI 在资源有限的环境中也能使用。]]></description>
      <guid>https://arxiv.org/abs/2502.07855</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MRS：基于 ODE 和 SDE 求解器的均值回复扩散快速采样器</title>
      <link>https://arxiv.org/abs/2502.07856</link>
      <description><![CDATA[arXiv:2502.07856v1 Announce Type: new 
摘要：在扩散模型的应用中，可控生成具有实际意义，但也具有挑战性。当前的可控生成方法主要侧重于修改扩散模型的得分函数，而均值回归（MR）扩散则直接修改随机微分方程（SDE）的结构，使图像条件的融入更加简单和自然。然而，目前的免训练快速采样器并不直接适用于MR扩散。因此MR扩散需要数百个NFE（函数评估次数）才能获得高质量的样本。在本文中，我们提出了一种名为MRS（MR采样器）的新算法来减少MR扩散的采样NFE。我们求解与MR扩散相关的逆时间SDE和概率流常微分方程（PF-ODE），并推导出半解析解。该解由一个解析函数和一个由神经网络参数化的积分组成。基于此解决方案，我们可以用更少的步骤生成高质量的样本。我们的方法不需要训练，并且支持所有主流的参数化，包括噪声预测、数据预测和速度预测。大量实验表明，MR Sampler 在十个不同的图像恢复任务中保持了较高的采样质量，速度提高了 10 到 20 倍。我们的算法加速了 MR Diffusion 的采样过程，使其在可控生成方面更加实用。]]></description>
      <guid>https://arxiv.org/abs/2502.07856</guid>
      <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>