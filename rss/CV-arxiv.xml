<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CV 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Tue, 29 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>使用动态记忆融合框架的自适应实时多损失函数优化：乳腺癌分割案例研究</title>
      <link>https://arxiv.org/abs/2410.19745</link>
      <description><![CDATA[arXiv:2410.19745v1 公告类型：新
摘要：深度学习已被证明是一种适用于广泛应用的高效工具，尤其是在利用多损失函数的强大功能同时优化多个标准的性能时。然而，深度学习任务中的最佳选择和加权损失函数会显著影响模型性能，而手动调整这些函数通常效率低下且不灵活。为了解决这个问题，我们提出了一种称为动态内存融合的新框架，用于实时自适应多损失函数惩罚。该框架利用历史损失值数据在整个训练过程中动态调整多个损失函数的权重。此外，该框架还集成了一个辅助损失函数，以在早期阶段增强模型性能。为了进一步研究，我们引入了类平衡骰子损失函数，旨在通过优先考虑代表性不足的类别来解决类别不平衡问题。乳腺超声数据集上的实验表明，该框架提高了跨各种指标的分割性能。这些结果证明了我们提出的框架的有效性，它确保模型动态调整其焦点以优先考虑最相关的标准，从而提高不断变化的环境中的性能。我们提出的方法的源代码已在 GitHub 上公开提供。]]></description>
      <guid>https://arxiv.org/abs/2410.19745</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>C^2DA：对比和上下文感知领域自适应语义分割</title>
      <link>https://arxiv.org/abs/2410.19748</link>
      <description><![CDATA[arXiv:2410.19748v1 公告类型：新
摘要：无监督域自适应语义分割 (UDA-SS) 旨在在源域数据（例如合成数据）上训练模型，并使模型适应预测目标域数据（例如真实世界），而无需访问目标注释数据。大多数现有的 UDA-SS 方法仅关注域间知识以缓解数据转移问题。然而，学习图像的固有结构和探索两个域的固有像素分布被忽略，这使得 UDA-SS 方法无法产生像监督学习那样令人满意的性能。此外，结合上下文知识也经常被忽视。考虑到这些问题，在这项工作中，我们提出了一个 UDA-SS 框架，它可以学习域内和上下文感知知识。为了学习域内知识，我们在两个域中都加入了对比损失，它将相似类别的像素拉到一起并将其余的像素推开，从而促进图像内像素间的相关性。为了学习上下文感知知识，我们通过利用类之间的上下文依赖关系来修改混合技术。此外，我们调整了蒙版图像建模 (MIM) 技术，以正确使用上下文线索进行稳健的视觉识别，使用有关蒙版图像的有限信息。综合实验验证了我们提出的方法在 GTA-V-&gt;Cityscapes 和 Synthia-&gt;Cityscapes 的适应性中分别将最先进的 UDA-SS 方法提高了 0.51% mIoU 和 0.54% mIoU。我们开源了我们的 C2DA 代码。代码链接：github.com/Masrur02/C-Squared-DA]]></description>
      <guid>https://arxiv.org/abs/2410.19748</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于 SAM 的半自动食品注释工具</title>
      <link>https://arxiv.org/abs/2410.19756</link>
      <description><![CDATA[arXiv:2410.19756v1 公告类型：新
摘要：人工智能 (AI) 在食品和营养研究中的进步受到一个关键瓶颈的阻碍：缺乏带注释的食品数据。尽管为食品分割和分类等任务而设计的高效 AI 模型不断涌现，但它们的实际应用可能需要精通 AI 和机器学习原理，这对营养科学领域的非 AI 专家来说是一个挑战。或者，它强调了将 AI 模型转化为所有人都可以使用的用户友好型工具的必要性。为了解决这个问题，我们展示了一个利用 Segment Anything 模型 (SAM) 的半自动食品图像注释工具的演示。该工具通过用户交互实现基于提示的食物分割，促进用户参与，并允许他们进一步对餐食图像中的食物进行分类，并在必要时指定重量/体积。此外，我们还发布了 SAM 掩码解码器的微调版本，称为 MealSAM，其 ViT-B 主干是专门为食品图像分割量身定制的。我们的目标不仅是通过鼓励参与、协作和收集更多带注释的食品数据来为该领域做出贡献，而且还通过将 AI 转化为实用工具，让更广泛的受众能够使用 AI 技术。]]></description>
      <guid>https://arxiv.org/abs/2410.19756</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>PINNing 脑血流：使用物理信息神经网络分析婴儿灌注 MRI</title>
      <link>https://arxiv.org/abs/2410.19759</link>
      <description><![CDATA[arXiv:2410.19759v1 公告类型：新
摘要：动脉自旋标记 (ASL) 磁共振成像 (MRI) 可以测量脑灌注，这对于检测和管理早产或围产期并发症婴儿的神经系统问题至关重要。然而，使用 ASL 估计婴儿的脑血流量 (CBF) 仍然具有挑战性，因为网络生理学的复杂相互作用涉及心输出量和脑灌注之间的动态相互作用，以及参数不确定性和数据噪声问题。我们提出了一种新的基于空间不确定性的物理信息神经网络 (PINN)，SUPINN，用于从婴儿 ASL 数据中估计 CBF 和其他参数。SUPINN 采用多分支架构来同时估计多个体素的区域和全局模型参数。它计算区域空间不确定性来加权信号。 SUPINN 可以可靠地估计 CBF（相对误差 $-0.3 \pm 71.7$）、推注到达时间 (AT) ($30.5 \pm 257.8$）和血液纵向弛豫时间 ($T_{1b}$) ($-4.4 \pm 28.9$），超过使用最小二乘法或标准 PINN 进行的参数估计。此外，SUPINN 可生成生理上合理的空间平滑 CBF 和 AT 图。我们的研究表明，成功修改了 PINN，以便从婴儿嘈杂且有限的 ASL 数据中准确估计多参数灌注。像 SUPINN 这样的框架有可能增进我们对复杂心脑网络生理学的理解，有助于检测和管理疾病。源代码位于：https://github.com/cgalaz01/supinn。]]></description>
      <guid>https://arxiv.org/abs/2410.19759</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用多模态预训练特征进行电影预告片类型分类</title>
      <link>https://arxiv.org/abs/2410.19760</link>
      <description><![CDATA[arXiv:2410.19760v1 公告类型：新
摘要：我们引入了一种新颖的电影类型分类方法，利用了一组易于访问的预训练模型。这些模型提取与视觉场景、物体、角色、文本、语音、音乐和音频效果相关的高级特征。为了智能地融合这些预训练特征，我们训练了时间和内存要求较低的小型分类器模型。采用 Transformer 模型，我们的方法利用电影预告片的所有视频和音频帧而不执行任何时间池化，有效地利用了所有元素之间的对应关系，而不是传统方法通常使用的固定和少量帧。与当前方法相比，我们的方法融合了来自不同任务和模态、具有不同维度、不同时间长度和复杂依赖关系的特征。我们的方法在精度、召回率和平均精度 (mAP) 方面优于最先进的电影类型分类模型。为了促进未来的研究，我们公开了整个 MovieNet 数据集的预训练特征以及我们的类型分类代码和训练有素的模型。]]></description>
      <guid>https://arxiv.org/abs/2410.19760</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>可靠、可路由、可重复：全州范围内的行人通道集合</title>
      <link>https://arxiv.org/abs/2410.19762</link>
      <description><![CDATA[arXiv:2410.19762v1 公告类型：新
摘要：虽然包括自动驾驶汽车和多模式导航系统在内的移动技术的进步可以提高残疾人的移动公平性，但这些技术主要依赖于准确、标准化和完整的人行道网络。临时收集工作导致数据记录稀疏、不可靠且不可互操作。
本文介绍了一种社会技术方法，用于在全州范围内收集、管理、服务和维护人行道数据。结合应用于航空图像和现有道路网络数据的计算机视觉方法所提供的自动化与交互式工具所提供的质量控制，我们的目标是在大约两年内为整个华盛顿州制作可路由的人行道。我们从航空图像中提取大规模的路径、交叉口和路缘坡道，将多输入分割方法与道路拓扑数据相结合，以确保连接、可路由的网络。然后，我们将预测结果组织到根据其对公众利益的价值而选定的项目区域中，其中每个项目区域被划分为交叉点规模的任务。这些任务通过管理并发性、进度、反馈和数据管理的交互式工具进行分配和跟踪。
我们证明，我们的自动化系统在生成可路由的通道网络方面优于最先进的方法，从而大大减少了人工审查所需的时间。我们的结果证明了在整个州的范围内生成准确、强大的行人通道网络的可行性。
本文旨在通过提供行人公平、安全和可达性以及改善所有用户的城市环境，为全国范围的 ADA 合规程序提供信息。]]></description>
      <guid>https://arxiv.org/abs/2410.19762</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>小数据的大模型：跨模态射频人体活动识别的基础模型</title>
      <link>https://arxiv.org/abs/2410.19766</link>
      <description><![CDATA[arXiv:2410.19766v1 公告类型：新
摘要：基于射频 (RF) 的人类活动识别 (HAR) 成为一种有前途的解决方案，适用于无法使用计算机视觉技术的应用。然而，由于标记的 RF 数据不可解释，因此其稀缺性构成了重大障碍。得益于基础模型 (FM) 的最新突破，从未标记的视觉数据中提取深度语义洞察变得可行，但这些基于视觉的 FM 在应用于小型 RF 数据集时却不够好。为了弥补这一差距，我们引入了 FM-Fi，这是一种创新的跨模态框架，旨在将基于视觉的 FM 的知识转化为增强基于 RF 的 HAR 系统。FM-Fi 涉及一种新颖的跨模态对比知识蒸馏机制，使 RF 编码器能够继承 FM 的解释能力以实现零样本学习。它还利用 FM 和 RF 的内在能力来消除无关特征，以更好地在两种模态之间进行对齐。该框架通过基于度量的少样本学习技术得到进一步完善，旨在提高预定义 HAR 任务的性能。综合评估明显表明 FM-Fi 的有效性可与基于视觉的方法相媲美，评估结果为 FM-Fi 在各种环境中的通用性提供了实证验证。]]></description>
      <guid>https://arxiv.org/abs/2410.19766</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用高分辨率卫星物体检测技术开发网格化排放清单，以改进空气质量预报</title>
      <link>https://arxiv.org/abs/2410.19773</link>
      <description><![CDATA[arXiv:2410.19773v1 公告类型：新
摘要：本研究提出了一种创新方法，用于创建动态的、基于人工智能的排放清单系统，该系统与天气研究和预报模型结合使用，并结合化学（WRF Chem），旨在模拟卫星可探测分辨率下的车辆和其他人为排放。该方法利用最先进的基于深度学习的计算机视觉模型，主要采用 YOLO（You Only Look Once）架构（v8 到 v10）和 T Rex，实现高精度物体检测。通过大量的数据收集、模型训练和微调，该系统在检测精度方面取得了显着的提高，F1 分数从最初的 0.15（置信度为 0.131）提高到 0.72（置信度为 0.414）。自定义管道将模型输出转换为存储纬度、经度和车辆计数数据的 netCDF 文件，从而实现排放模式的实时处理和可视化。由此产生的系统在排放量估算方面提供了前所未有的时间和空间分辨率，有助于更准确地预测短期空气质量并深入了解城市排放动态。这项研究不仅增强了 WRF Chem 模拟，还弥合了人工智能技术与大气科学方法之间的差距，有可能改善城市空气质量管理和环境政策制定。未来的工作将侧重于将系统的功能扩展到非车辆污染源，并进一步提高在具有挑战性的环境条件下的检测准确性。]]></description>
      <guid>https://arxiv.org/abs/2410.19773</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Copula 链接并行 ICA：一种耦合结构和功能 MRI 脑网络的方法</title>
      <link>https://arxiv.org/abs/2410.19774</link>
      <description><![CDATA[arXiv:2410.19774v1 公告类型：新
摘要：不同的大脑成像模式提供了对大脑功能和结构的独特见解。将它们结合起来可以增强我们对神经机制的理解。融合功能性磁共振成像 (fMRI) 和结构性磁共振成像 (sMRI) 的先前多模态研究已经证明了这种方法的好处。由于 sMRI 缺乏时间数据，现有的融合方法通常会将 fMRI 时间信息压缩为摘要度量，从而牺牲丰富的时间动态。受在 sMRI 和静息态 fMRI 中都识别出共变网络的观察启发，我们开发了一种新颖的融合方法，结合了深度学习框架、copula 和独立成分分析 (ICA)，称为 copula 链接并行 ICA (CLiP-ICA)。该方法估计每种模态的独立源，并使用基于 copula 的模型链接 fMRI 和 sMRI 的空间源，以更灵活地集成时间和空间数据。我们使用来自阿尔茨海默病神经成像计划 (ADNI) 的数据测试了 CLiP-ICA。我们的结果表明，CLiP-ICA 可以有效捕获强链接和弱链接的 sMRI 和 fMRI 网络，包括小脑、感觉运动、视觉、认知控制和默认模式网络。它揭示了更多有意义的成分和更少的伪影，解决了 ICA 中长期存在的最佳模型顺序问题。CLiP-ICA 还检测到了认知衰退各个阶段的复杂功能连接模式，认知正常的受试者在感觉运动和视觉网络中的连接性通常比阿尔茨海默病患者更高，并且这些模式表明存在潜在的补偿机制。]]></description>
      <guid>https://arxiv.org/abs/2410.19774</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于卫星雷达图像的数据驱动不确定性感知鄂毕湾海冰状况预测</title>
      <link>https://arxiv.org/abs/2410.19782</link>
      <description><![CDATA[arXiv:2410.19782v1 公告类型：新
摘要：由于快速变暖和大量海冰损失导致北极海洋活动增加，需要高度可靠的短期海冰预报以确保海上安全和运营效率。在这项工作中，我们提出了一种新颖的数据驱动方法，用于预测鄂毕湾的海冰状况，利用 Sentinel-1 的雷达图像序列、天气观测和 GLORYS 预报。我们的方法将最初为视觉任务开发的高级视频预测模型与针对北极海冰动力学独特挑战而定制的领域特定数据预处理和增强技术相结合。我们方法的核心是使用不确定性量化来评估预测的可靠性，确保在安全关键应用中做出稳健的决策。此外，我们提出了一种基于置信度的模型混合机制，以提高预测准确性和模型稳健性，这对于在动荡的北极环境中可靠运行至关重要。我们的结果表明，与基线方法相比，我们有了实质性的改进，强调了不确定性量化和专门的数据处理对于有效、安全的操作和可靠的预测的重要性。]]></description>
      <guid>https://arxiv.org/abs/2410.19782</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>增强 Apple 的缺陷分类：来自可见光谱和窄光谱带成像的见解</title>
      <link>https://arxiv.org/abs/2410.19784</link>
      <description><![CDATA[arXiv:2410.19784v1 公告类型：新
摘要：本研究探讨了苹果缺陷分类，这是减轻经济损失和优化食品供应链的重要措施。采用创新方法，整合可见光谱和 660 nm 光谱波长的图像，以提高缺陷分类的准确性和效率。该方法基于使用单输入和多输入卷积神经网络 (CNN) 来验证所提出的策略。步骤包括图像采集和预处理、分类模型训练和性能评估。结果表明，使用 660 nm 光谱波长进行缺陷分类可以揭示整个可见光谱中不可见的细节。可以看出，在分类过程中使用适当的光谱范围略优于整个可见光谱。MobileNetV1 模型在验证数据集上的准确率为 98.80\%，而使用整个可见光谱的准确率为 98.26\%。结论强调了通过使用滤光片捕捉特定光谱范围的图像来增强该方法的潜力，从而可以更有效地进行分类任务的网络训练。这些改进可以进一步增强系统识别和分类苹果缺陷的能力。]]></description>
      <guid>https://arxiv.org/abs/2410.19784</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用隐式神经表征增强欠采样光声显微镜图像的分辨率</title>
      <link>https://arxiv.org/abs/2410.19786</link>
      <description><![CDATA[arXiv:2410.19786v1 公告类型：新
摘要：声学分辨率光声显微镜 (AR-PAM) 有望用于皮下血管成像，但其空间分辨率受到点扩展函数 (PSF) 的限制。传统的反卷积方法（如 Richardson-Lucy 和基于模型的反卷积）使用 PSF 来提高分辨率。然而，准确测量 PSF 很困难，导致依赖于不太准确的盲反卷积技术。此外，AR-PAM 的扫描时间较长，可以通过下采样来减少，但这需要从欠采样数据中有效地恢复图像，这是一项传统插值方法无法完成的任务，尤其是在高欠采样率下。为了应对这些挑战，我们提出了一种基于隐式神经表征 (INR) 的方法。该方法学习从空间坐标到初始声压的连续映射，克服了离散成像的局限性并提高了 AR-PAM 的分辨率。通过将 PSF 视为 INR 框架内的可学习参数，我们的技术减轻了与 PSF 估计相关的不准确性。我们在模拟血管数据上评估了我们的方法，结果显示峰值信噪比 (PSNR) 和结构相似性指数 (SSIM) 比传统方法有显著改善。在叶脉和小鼠体内脑微血管图像中也观察到了定性增强。当应用于定制 AR-PAM 系统时，用铅笔芯进行的实验表明，我们的方法可以提供更清晰、更高分辨率的结果，表明它有潜力推动光声显微镜的发展。]]></description>
      <guid>https://arxiv.org/abs/2410.19786</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用多时相 Sentinel 1 和 2 卫星数据通过深度学习估算叶面积指数</title>
      <link>https://arxiv.org/abs/2410.19787</link>
      <description><![CDATA[arXiv:2410.19787v1 公告类型：新
摘要：叶面积指数 (LAI) 是了解生态系统健康和植被动态的关键参数。在本文中，我们提出了一种新的像素级 LAI 预测方法，该方法利用 Sentinel 1 雷达数据和 Sentinel 2 多光谱数据在多个时间戳的互补信息。我们的方法使用基于多个 U-net 的深度神经网络，专门针对此任务量身定制。为了处理不同输入模态的复杂性，它由几个模块组成，这些模块经过单独预训练以表示公共潜在空间中的所有输入数据。然后，我们使用一个通用解码器对它们进行端到端微调，该解码器还考虑了季节性，我们发现季节性起着重要作用。我们的方法在公开数据上实现了 0.06 RMSE 和 0.93 R2 分数。我们将我们的贡献发布在 https://github.com/valentingol/LeafNothingBehind 上，以便将来进一步改进我们目前的进展。]]></description>
      <guid>https://arxiv.org/abs/2410.19787</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>异种学习：基于深度学习的光谱图像分析中的跨物种知识转移</title>
      <link>https://arxiv.org/abs/2410.19789</link>
      <description><![CDATA[arXiv:2410.19789v1 公告类型：新
摘要：新型光学成像技术，例如高光谱成像 (HSI) 与基于机器学习 (ML) 的分析相结合，有可能彻底改变临床外科成像。然而，这些新模式面临着训练 ML 算法的大规模、有代表性的临床数据短缺的问题，而临床前动物数据通过标准化实验大量提供，并允许控制诱导病理组织状态，这在伦理上对患者来说是不可能的。为了利用这种情况，我们提出了一个称为“异种学习”的新概念，这是一种受异种移植启发的跨物种知识转移范式，其中供体物种的器官被移植到受体物种中。使用来自人类以及猪和大鼠模型的总共 11,268 张 HSI 图像，我们表明，尽管器官的光谱特征在不同物种之间有所不同，但共同的病理生理机制表现为不同物种之间可比的相对光谱变化。因此，通过一种新颖的“基于生理学的数据增强”方法，可以将在一个物种中学到的变化转移到新物种中，从而实现对人类临床前动物数据的大规模二次利用。拟议的知识转移模式所带来的伦理、经济和绩效效益有望对该领域的未来发展产生重大影响。]]></description>
      <guid>https://arxiv.org/abs/2410.19789</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DiffGAN：一种用于深度神经网络差分测试的测试生成方法</title>
      <link>https://arxiv.org/abs/2410.19794</link>
      <description><![CDATA[arXiv:2410.19794v1 公告类型：新
摘要：深度神经网络 (DNN) 越来越多地部署在应用程序中。然而，确保它们的可靠性仍然是一个挑战，在许多情况下，具有类似功能和准确性的替代模型是可用的。传统的基于准确性的评估通常无法捕捉模型之间的行为差​​异，尤其是在测试数据集有限的情况下，这使得难以有效地选择或组合模型。差异测试通过生成暴露 DNN 模型行为差异的测试输入来解决这个问题。然而，现有的方法面临着很大的限制：许多方法依赖于模型内部或受到可用种子输入的限制。为了应对这些挑战，我们提出了 DiffGAN，一种用于 DNN 模型差异测试的黑盒测试图像生成方法。DiffGAN 利用生成对抗网络 (GAN) 和非支配排序遗传算法 II 来生成多样化和有效的触发输入，揭示模型之间的行为差​​异。 DiffGAN 采用​​两个自定义适应度函数，分别侧重于多样性和发散性，以指导对 GAN 输入空间的探索并识别模型输出之间的差异。通过策略性地搜索该空间，DiffGAN 生成具有特定特征的输入，这些特征会触发模型行为的差异。DiffGAN 是黑盒模型，因此适用于更多情况。我们在八个 DNN 模型对上对 DiffGAN 进行了评估，这些模型对是在广泛使用的图像数据集上训练的。我们的结果表明，DiffGAN 的表现明显优于 SOTA 基线，在相同预算内生成了四倍以上的触发输入，具有更高的多样性和有效性。此外，生成的输入提高了基于机器学习的模型选择机制的准确性，该机制根据输入特征选择性能最佳的模型，并在使用替代模型时可用作智能输出投票机制。]]></description>
      <guid>https://arxiv.org/abs/2410.19794</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>