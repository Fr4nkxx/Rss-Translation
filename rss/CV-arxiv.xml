<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CV 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Wed, 04 Sep 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>评估深度学习模型中可解释的人工智能方法，以早期发现脑瘫</title>
      <link>https://arxiv.org/abs/2409.00001</link>
      <description><![CDATA[arXiv:2409.00001v1 公告类型：新
摘要：早期发现脑瘫 (CP) 对于有效干预和监测至关重要。本文使用深度学习方法测试可解释人工智能 (XAI) 方法的可靠性和适用性，该方法通过分析从婴儿运动视频记录中提取的骨骼数据来预测 CP。具体来说，我们使用 XAI 评估指标（即忠实度和稳定性）来定量评估类激活映射 (CAM) 和梯度加权类激活映射 (Grad-CAM) 在此特定医疗应用中的可靠性。我们利用独特的婴儿运动数据集并应用骨骼数据扰动，而不会扭曲婴儿运动的原始动态。我们的 CP 预测模型采用集成方法，因此我们评估整体集成和单个模型的 XAI 指标性能。我们的研究结果表明，这两种 XAI 方法都能有效地识别影响 CP 预测的关键身体点，并且解释对轻微的数据扰动具有鲁棒性。 Grad-CAM 在 RISv 指标（衡量速度方面的稳定性）方面明显优于 CAM。相比之下，CAM 在与骨骼稳定性相关的 RISb 指标和评估内部表示稳健性的 RRS 指标方面表现更好。集成中的各个模型显示出不同的结果，CAM 和 Grad-CAM 的表现都不是始终优于对方，集成方法提供了其组成模型的结果表示。]]></description>
      <guid>https://arxiv.org/abs/2409.00001</guid>
      <pubDate>Wed, 04 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>应用深度神经网络自动对航空航天中的手动支架安装进行视觉验证</title>
      <link>https://arxiv.org/abs/2409.00006</link>
      <description><![CDATA[arXiv:2409.00006v1 公告类型：新
摘要：在这项工作中，我们探索了一种基于深度学习的自动视觉检查和验证算法，该算法基于暹罗神经网络架构。还考虑了输入图像对如何影响暹罗神经网络的性能。暹罗神经网络与卷积神经网络一起进行了探索。除了研究这些模型架构外，还探索了其他方法，包括迁移学习和集成方法，目的是提高模型性能。我们开发了一种针对暹罗神经网络的新型投票方案，该方案让单个模型对多个参考图像进行投票。这不同于多个模型对同一数据样本进行投票的典型集成方法。所得结果表明，当训练数据稀缺时，暹罗神经网络在自动视觉检查和验证任务中的应用潜力巨大。应用的其他方法，包括新颖的相似性投票，也被认为可以显着提高模型的性能。我们利用公开的 omniglot 数据集来验证我们的方法。据我们所知，这是首次通过深度神经网络对航空航天领域安装的支架进行自动验证的详细研究。]]></description>
      <guid>https://arxiv.org/abs/2409.00006</guid>
      <pubDate>Wed, 04 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DivDiff：用于多样化人体运动预测的条件扩散模型</title>
      <link>https://arxiv.org/abs/2409.00014</link>
      <description><![CDATA[arXiv:2409.00014v1 公告类型：新
摘要：多样化人体运动预测 (HMP) 旨在根据观察到的人体运动序列预测多种合理的未来运动。这是一项具有挑战性的任务，因为潜在的人体运动具有多样性，同时要确保准确描述未来的人体运动。当前的解决方案要么多样性低，要么表达能力有限。最近的去噪扩散模型 (DDPM) 在生成任务中具有潜在的生成能力。然而，将 DDPM 直接引入多样化的 HMP 会产生一些问题。虽然 DDPM 可以增加人体运动潜在模式的多样性，但由于 DDPM 前向过程中的显著噪声干扰，预测的人体运动随着时间的推移变得难以置信。这种现象导致预测的人体运动难以控制，严重影响预测运动的质量并限制其在现实场景中的实际适用性。为了缓解这种情况，我们提出了一种基于条件扩散的新型生成模型 DivDiff，以预测更加多样化和逼真的人体运动。具体来说，DivDiff 采用 DDPM 作为主干，并结合离散余弦变换 (DCT) 和变压器机制将观察到的人体运动序列编码为条件，以指示 DDPM 的逆过程。更重要的是，我们设计了一个多样化强化采样函数 (DRSF) 来对预测的人体运动施加人体骨骼约束。DRSF 利用从人体骨骼中获得的信息作为先验知识，从而减少在前向过程中引入的重大干扰。在两个广泛使用的数据集（Human3.6M 和 HumanEva-I）上进行的实验中获得的大量结果表明，我们的模型在多样性和准确性方面都获得了具有竞争力的性能。]]></description>
      <guid>https://arxiv.org/abs/2409.00014</guid>
      <pubDate>Wed, 04 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用机器学习和云计算进行农作物物候估计的新型光学和雷达卫星数据融合方法</title>
      <link>https://arxiv.org/abs/2409.00020</link>
      <description><![CDATA[arXiv:2409.00020v1 公告类型：新
摘要：作物物候决定作物的生长阶段，是决策者种植和调整农业管理策略以提高粮食安全的宝贵信息。在地球观测大数据无处不在的时代，人们已经尝试基于遥感 (RS) 数据准确预测作物物候。然而，大多数研究要么侧重于物候的大规模解释，要么开发的方法不足以帮助作物建模者社区利用使用更准确和更可靠的方法评估的 RS 数据的价值。在这里，我们使用一个新框架估计了德国 8 种主要作物和 13 个物候阶段的物候发展情况，该框架融合了 Landsat 和 Sentinel 2（协调的 Landsat 和 Sentinel 数据库；HLS）和 Sentinel 1 的雷达与机器学习 (ML) 模型。我们提出了一项全面的特征融合分析，以 2017 年至 2021 年期间德国国家物候网络（德国气象局；DWD）为基础，找到用于检测物候发展的最佳 RS 数据组合。30 米分辨率的全国范围农作物物候预测结果显示 R2 &gt; 0.9 的精度非常高，平均绝对误差 (MAE) &lt; 2（天）非常低。这些结果表明，我们的光学和雷达数据集融合策略性能卓越，其精度也与实际应用高度相关。随后的不确定性分析表明，融合光学和雷达数据可提高 RS 预测作物生长阶段的可靠性。这些改进有望用于作物模型校准和评估，促进明智的农业决策，并有助于可持续粮食生产以满足日益增长的全球粮食需求。]]></description>
      <guid>https://arxiv.org/abs/2409.00020</guid>
      <pubDate>Wed, 04 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>超越相干景深的瞳孔自适应 3D 全息术</title>
      <link>https://arxiv.org/abs/2409.00028</link>
      <description><![CDATA[arXiv:2409.00028v1 公告类型：新
摘要：最近由深度学习推动的全息显示方法在实现高保真全息投影方面取得了显著成功。然而，这些显示器仍然无法展示真实的焦点线索，相干光全息显示器可能产生的散焦效果与现实世界中非相干光所表现出的散焦效果之间仍然存在很大差距。此外，现有方法没有考虑观察者瞳孔大小变化对 3D 投影感知质量的影响，尤其是对由于眼睛景深变化而导致的散焦模糊的影响。
在这项工作中，我们提出了一个框架，以弥合全息显示器的相干景深与由于非相干光而在现实世界中看到的景象之间的差距。为此，我们研究了瞳孔形状和运动变化对全息投影质量的影响，并设计了一种以瞳孔自适应方式动态改变全息投影景深的方法。具体来说，我们引入了一个学习框架，该框架根据观察者瞳孔的当前状态随时调整感受野，以产生当前计算机生成的全息方法无法实现的图像效果。我们在模拟和实验原型全息显示器上验证了所提出的方法，并展示了景深效果描绘的显著改进，在质量和数量上都优于现有方法，峰值信噪比至少高出 5 dB。]]></description>
      <guid>https://arxiv.org/abs/2409.00028</guid>
      <pubDate>Wed, 04 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>攻击一切：通过通用背景对抗攻击实现盲 DNN</title>
      <link>https://arxiv.org/abs/2409.00029</link>
      <description><![CDATA[arXiv:2409.00029v1 公告类型：新
摘要：深度神经网络 (DNN) 易受对抗性干扰，这一点已得到广泛证实。现有研究主要关注通过破坏目标对象（物理攻击）或图像（数字攻击）进行攻击，这种攻击在直观上是可以接受的，并且从攻击的有效性来看也是可以理解的。相比之下，我们的重点是在数字和物理领域进行背景对抗性攻击，而不会对目标对象本身造成任何破坏。具体来说，我们提出了一种有效的背景对抗性攻击框架来攻击任何东西，通过该框架，攻击效力可以在不同的对象、模型和任务之间很好地推广。从技术上讲，我们将背景对抗性攻击视为一个迭代优化问题，类似于 DNN 学习的过程。此外，我们还在一组温和但充分的条件下对其收敛性进行了理论证明。为了增强攻击效果和可转移性，我们提出了一种针对对抗性扰动量身定制的新集成策略，并引入了改进的平滑约束以实现集成扰动的无缝连接。我们在数字和物理领域针对各种对象、模型和任务进行了全面而严格的实验，证明了所提方法对任何事物的攻击有效性。这项研究的结果证实了人类和机器视觉在背景变化的价值上存在显著差异，这发挥着比以前认识到的更为关键的作用，因此有必要重新评估 DNN 的稳健性和可靠性。代码将在 https://github.com/JiaweiLian/Attack_Anything 上公开提供]]></description>
      <guid>https://arxiv.org/abs/2409.00029</guid>
      <pubDate>Wed, 04 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于 Radon 变换的噪声图像非仿射变形配准方法</title>
      <link>https://arxiv.org/abs/2409.00037</link>
      <description><![CDATA[arXiv:2409.00037v1 公告类型：新
摘要：可变形图像配准是一个标准工程问题，用于通过比较身体在不同状态下的两幅图像来确定身体所经历的变形。本研究介绍了两种新的 DIR 方法，旨在使用基于 Radon 变换的相似性度量和基于线性弹性变形能量的经典正则化器来捕获非仿射变形。它为这两种方法的解的存在性和唯一性建立了条件，并给出了综合实验结果，将它们与基于平方差和相似性度量的标准方法进行了比较。这些方法已经过测试，可以捕获图像中的各种非仿射变形（包括有噪声和无噪声），并分析了它们的收敛速度。此外，还在肺部图像配准场景中评估了这些方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2409.00037</guid>
      <pubDate>Wed, 04 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>PolypDB：用于结肠镜检查 AI 算法开发的精选多中心数据集</title>
      <link>https://arxiv.org/abs/2409.00045</link>
      <description><![CDATA[arXiv:2409.00045v1 公告类型：新
摘要：结肠镜检查是检查、检测和切除息肉的主要方法。定期筛查有助于在早期可治愈阶段检测和预防结直肠癌。然而，内镜医师技能的差异、肠道质量准备和大肠的复杂性等挑战导致大量息肉漏诊。这些漏诊的息肉以后可能会发展成癌症，这凸显了改进检测方法的重要性。计算机辅助诊断系统可以通过协助检测被忽视的息肉来支持医生。然而，开发用于自动息肉检测和分割的新型深度学习模型的重要挑战之一是缺乏公开、多中心的大型和多样化数据集。为了解决这一差距，我们引入了 PolypDB，这是一个大规模的公开数据集，包含 3934 张来自真实结肠镜检查视频的静止息肉图像及其相应的基本事实，以设计有效的息肉检测和分割架构。该数据集由 10 名胃肠病学家组成的团队开发和验证。PolypDB 包含来自五种模式的图像：蓝光成像 (BLI)、柔性成像色彩增强 (FICE)、链接彩色成像 (LCI)、窄带成像 (NBI) 和白光成像 (WLI)，以及来自挪威、瑞典和越南的三家医疗中心。因此，我们根据模式和医疗中心对数据集进行拆分，以进行模式和中心分析。我们使用八种流行的分割方法和六种标准基准息肉检测方法为每种模式提供基准。此外，我们还在联邦学习设置下提供中心基准。我们的数据集是公开的，可以在 \url{https://osf.io/pr7ms/} 下载。]]></description>
      <guid>https://arxiv.org/abs/2409.00045</guid>
      <pubDate>Wed, 04 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于生成对抗网络的 LiDAR 辅助雷达图像增强方法</title>
      <link>https://arxiv.org/abs/2409.00196</link>
      <description><![CDATA[arXiv:2409.00196v1 公告类型：新
摘要：本文提出了一种基于生成对抗网络 (GAN) 的雷达图像增强方法。尽管雷达传感器在恶劣天气条件下仍能保持稳健运行，但它们在自动驾驶汽车 (AV) 中的应用通常受到其产生的低分辨率数据的限制。本研究的主要目标是增强雷达图像以更好地描绘环境的细节和特征，从而促进 AV 中更准确的物体识别。所提出的方法利用高分辨率、二维 (2D) 投影光检测和测距 (LiDAR) 点云作为地面真实图像，并使用低分辨率雷达图像作为输入来训练 GAN。地面真实图像是通过两个主要步骤获得的。首先，通过累积原始 LiDAR 扫描生成 LiDAR 点云图。然后，采用定制的 LiDAR 点云裁剪和投影方法来获得 2D 投影 LiDAR 点云。所提方法的推理过程仅依赖于雷达图像来生成增强版本。定性和定量结果都证明了所提方法的有效性。这些结果表明，即使在恶劣的天气条件下，所提方法也可以生成与输入的雷达图像相比具有更清晰的物体表示的增强图像。]]></description>
      <guid>https://arxiv.org/abs/2409.00196</guid>
      <pubDate>Wed, 04 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RING#：利用旋转平移等变 Gram 学习进行 PR-by-P​​E 全局定位</title>
      <link>https://arxiv.org/abs/2409.00206</link>
      <description><![CDATA[arXiv:2409.00206v1 公告类型：新
摘要：在 GPS 信号不可靠的情况下，使用车载感知传感器（如摄像头和激光雷达）进行全局定位对于自动驾驶和机器人应用至关重要。大多数方法通过顺序位置识别和姿势估计实现全局定位。其中一些方法为每个任务训练单独的模型，而另一些方法则使用具有双头的单个模型，并与单独的任务特定损失联合训练。然而，定位的准确性在很大程度上取决于位置识别的成功，位置识别通常在视点或环境外观发生重大变化的情况下失败。因此，这使得定位的最终姿势估计无效。为了解决这个问题，我们提出了一种新颖的范例，即 PR-by-P​​E 定位，它通过直接从姿势估计中获得位置识别来提高全局定位精度。我们的框架 RING# 是一个在鸟瞰 (BEV) 空间中运行的端到端 PR-by-P​​E 定位网络，旨在支持视觉和激光雷达传感器。它引入了从 BEV 特征中学习两个等变表示的理论基础，从而实现全局收敛且计算效率高的姿势估计。在 NCLT 和 Oxford 数据集上进行的视觉和 LiDAR 模式的综合实验表明，我们的方法优于最先进的方法。此外，我们还提供了广泛的分析来确认我们方法的有效性。代码将公开发布。]]></description>
      <guid>https://arxiv.org/abs/2409.00206</guid>
      <pubDate>Wed, 04 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用对象突出性构建定量图像分析</title>
      <link>https://arxiv.org/abs/2409.00216</link>
      <description><![CDATA[arXiv:2409.00216v1 公告类型：新
摘要：当摄影师和其他图像材料编辑制作图像时，他们会通过将某些对象置于前景而将其他对象置于背景来陈述重要的事情。虽然对象的这种突出性是定性学者的关键分析类别，但最近自动图像分析的定量方法尚未做出这一重要区分，而是以同样的方式处理图像的所有区域。我们建议仔细考虑对象的突出性，这是将图像作为数据进行分析的重要步骤。它的建模需要定义一个对象并操作和测量人眼会关注多少。我们的方法将定性分析与定量方法的可扩展性相结合。通过用不同的实现方式举例说明对象突出性——对象大小和中心性、像素的图像深度和显着的图像区域——我们通过两个应用展示了我们方法的实用性。首先，我们根据图像对八家美国报纸的意识形态进行了扩展。其次，我们分析了 2016 年和 2020 年美国总统竞选视频中女性的突出地位。我们希望我们的文章能够帮助所有热衷于以概念上有意义的方式大规模研究图像数据的人。]]></description>
      <guid>https://arxiv.org/abs/2409.00216</guid>
      <pubDate>Wed, 04 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>自监督学习用于建立稳健的儿科胸部 X 光分类模型</title>
      <link>https://arxiv.org/abs/2409.00231</link>
      <description><![CDATA[arXiv:2409.00231v1 公告类型：新
摘要：医学人工智能深度学习的最新进展表明，模型在成人胸部 X 光 (CXR) 解释方面的诊断能力可以与临床专家相媲美。然而，由于缺乏大量带注释的儿科图像数据集，它们在儿科环境中的应用仍然有限。此外，不同医院的儿科 CXR 图像差异很大，患者年龄范围从 0 岁到 18 岁不等，这也带来了重大挑战。为了应对这些挑战，我们提出了 SCC，这是一种将迁移学习与自监督对比学习相结合的新方法，并辅以无监督对比增强技术。从训练有素的成人 CXR 模型进行迁移学习可以缓解与儿科训练数据稀缺相关的问题。对比学习与对比增强侧重于肺部，减少图像变化的影响，并在不同的儿科 CXR 图像中产生高质量的嵌入。我们在一个儿科 CXR 数据集上训练 SCC，并在来自不同来源的另外两个儿科数据集上评估其性能。我们的结果表明，在两个测试数据集上，SCC 的分布外 (零样本) 性能在 AUC 方面比常规迁移学习高出 13.6% 和 34.6%。此外，通过使用少 10 倍的标记图像进行小样本学习，SCC 的性能可与在整个标记数据集上训练的常规迁移学习相媲美。为了测试该框架的通用性，我们在三个基准乳腺癌数据集上验证了它的性能。从在自然图像上训练并在一个乳腺数据集上进行微调的模型开始，SCC 在 AUC 方面在其他两个数据集上的表现比完全监督学习基线高出 3.6% 和 5.5%（零样本学习）。]]></description>
      <guid>https://arxiv.org/abs/2409.00231</guid>
      <pubDate>Wed, 04 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>面部动作单元识别中基于孪生网络的单帧校准</title>
      <link>https://arxiv.org/abs/2409.00240</link>
      <description><![CDATA[arXiv:2409.00240v1 公告类型：新
摘要：自动面部动作单元 (AU) 识别广泛应用于面部表情分析。大多数现有的 AU 识别系统旨在实现跨参与者的非校准泛化 (NCG)，无需进一步校准即可识别未见过的面部。然而，由于不同身份的面部属性存在多样性，准确从未见过的面部的单个图像推断 AU 激活有时是不可行的，即使对于人类专家来说也是如此——首先了解面部在中性表情下的表现至关重要，否则可能会产生重大偏差。因此，我们建议在 AU 识别中执行单帧校准 (OFC)：对于每一张脸，使用其中性表情的单个图像作为校准的参考图像。通过这种策略，我们开发了一个用于 AU 识别的校准暹罗网络 (CSN)，并通过简单的 iResNet-50 (IR50) 主干展示了其显著的有效性。在 DISFA、DISFA+ 和 UNBC-McMaster 数据集上，我们表明我们的 OFC CSN-IR50 模型 (a) 通过减轻面部属性偏差（包括由于皱纹、眉毛位置、面部毛发等造成的偏差）显著提高了 IR50 的性能，(b) 大大优于基线减法的朴素 OFC 方法以及 (c) 这种朴素 OFC 方法的微调版本，以及 (d) 在 AU 强度估计和 AU 检测方面也优于最先进的 NCG 模型。]]></description>
      <guid>https://arxiv.org/abs/2409.00240</guid>
      <pubDate>Wed, 04 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>医疗报告生成是一个多标签分类问题</title>
      <link>https://arxiv.org/abs/2409.00250</link>
      <description><![CDATA[arXiv:2409.00250v1 公告类型：新
摘要：医疗报告生成是医疗保健中的一项关键任务，涉及从医学图像中自动创建详细而准确的描述。传统上，这项任务被视为序列生成问题，依靠视觉和语言技术来生成连贯且上下文相关的报告。然而，在本文中，我们提出了一个新颖的观点：将医疗报告生成重新思考为多标签分类问题。通过以这种方式构建任务，我们利用常用知识图中的放射学节点，这些节点可以通过分类技术更好地捕获。为了验证我们的论点，我们引入了一个基于 BLIP 的新型报告生成框架，该框架与分类的关键节点集成，从而可以有效地生成报告，并对医学图像中的多个关键方面进行准确分类。这种方法不仅简化了报告生成过程，而且还显着提高了性能指标。我们广泛的实验表明，利用关键节点可以实现最先进的 (SOTA) 性能，超越两个基准数据集上的现有方法。结果强调了用创新方法重新设想传统任务的潜力，为更高效、更准确的医疗报告生成铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2409.00250</guid>
      <pubDate>Wed, 04 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MAPWise：评估高级地图查询的视觉语言模型</title>
      <link>https://arxiv.org/abs/2409.00255</link>
      <description><![CDATA[arXiv:2409.00255v1 公告类型：新
摘要：视觉语言模型 (VLM) 擅长于需要共同理解视觉和语言信息的任务。这些模型的一个特别有前途但尚未得到充分探索的应用是回答基于各种地图的问题。本研究调查了 VLM 在回答基于分级统计图的问题方面的有效性，分级统计图广泛用于数据分析和表示。为了促进和鼓励这一领域的研究，我们引入了一个基于地图的新型问答基准，该基准由来自三个地理区域（美国、印度、中国）的地图组成，每个地图包含 1000 个问题。我们的基准包含 43 个不同的问题模板，需要对相对空间关系、复杂的地图特征和复杂的推理有细致的理解。它还包括具有离散值和连续值的地图，涵盖颜色映射、类别排序和风格模式的变化，从而实现全面分析。我们在此基准上评估了多个 VLM 的性能，强调了它们能力上的差距并提供了改进此类模型的见解。]]></description>
      <guid>https://arxiv.org/abs/2409.00255</guid>
      <pubDate>Wed, 04 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>