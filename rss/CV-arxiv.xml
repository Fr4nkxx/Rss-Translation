<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CV 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Thu, 17 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>一种利用注意和特征增强对抗噪声干扰的稳健多源遥感影像匹配方法</title>
      <link>https://arxiv.org/abs/2410.11848</link>
      <description><![CDATA[arXiv:2410.11848v1 公告类型：新
摘要：图像匹配是多源遥感图像应用的基本和关键任务。然而，遥感图像易受各种噪声影响。因此，如何有效地在噪声图像中实现精确匹配是一个具有挑战性的问题。针对这一问题，我们提出了一种利用注意力机制和特征增强来抵抗噪声干扰的鲁棒多源遥感图像匹配方法。在第一阶段，我们结合深度卷积和Transformer的注意力机制进行密集特征提取，构建具有更高辨别性和鲁棒性的特征描述子。随后，我们采用由粗到细的匹配策略实现密集匹配。在第二阶段，我们引入基于二分类机制的异常值去除网络，该网络可以在图像之间建立有效且几何一致的对应关系；通过对每个对应关系进行加权，进行正常值与异常值分类，并从密集匹配中去除异常值。最终，我们可以实现更高效、更准确的匹配。为了验证所提方法的性能，本文使用多源遥感影像数据集进行实验，并在无噪声、加性随机噪声和周期性条纹噪声等不同场景下与其他最新方法进行了比较。对比结果表明，所提方法具有更均衡的性能和鲁棒性。所提方法为解决噪声图像匹配难题提供了有价值的参考。]]></description>
      <guid>https://arxiv.org/abs/2410.11848</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>神经变形</title>
      <link>https://arxiv.org/abs/2410.11878</link>
      <description><![CDATA[arXiv:2410.11878v1 公告类型：新
摘要：本文介绍了一种称为神经变形（NeuMeta）的新学习范式，旨在构建可自我变形的神经网络。与为不同架构或大小制作单独的模型相反，NeuMeta 直接学习神经网络的连续权重流形。一旦训练完成，我们就可以直接从流形中为任何大小的网络采样权重，即使是以前从未见过的配置，也无需重新训练。为了实现这一雄心勃勃的目标，NeuMeta 将神经隐式函数训练为超网络。它们接受模型空间内的坐标作为输入，并在流形上生成相应的权重值。换句话说，隐式函数的学习方式是，预测的权重在各种模型大小中都表现良好。在训练这些模型时，我们注意到，最终的性能与学习到的流形的平滑度密切相关。为了提高这种平滑度，我们采用了两种策略。首先，我们通过求解最短汉密尔顿路径问题来置换权重矩阵以实现模型内平滑。此外，我们在训练隐式函数时在输入坐标上添加噪声，确保不同大小的模型显示一致的输出。因此，NeuMeta 在合成各种网络配置的参数方面显示出令人鼓舞的结果。我们在图像分类、语义分割和图像生成方面的大量测试表明，即使在 75% 的压缩率下，NeuMeta 也能保持全尺寸性能。]]></description>
      <guid>https://arxiv.org/abs/2410.11878</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于深度学习的木板去皮设备的开发与测试</title>
      <link>https://arxiv.org/abs/2410.11913</link>
      <description><![CDATA[arXiv:2410.11913v1 公告类型：新
摘要：尝试将深度学习方法应用于木板去皮设备，以提高去皮质量和效率是一项重大而具有挑战性的工作。本研究开发并测试了一种基于深度学习的木板去皮设备。根据锯木厂的实际需求，设计了一种配备视觉检测系统的木板去皮设备。基于使用视觉检测系统获得的大量木板图像，构建了第一个通用木板语义分割数据集，用于训练本研究中使用的 BiSeNetV1 模型。此外，详细介绍了去皮过程中所需的关键数据的计算方法和过程。在实验室和锯木厂环境中进行了 BiSeNetV1 模型的对比实验和去皮效果测试。对比实验结果表明，BiSeNetV1 分割模型的应用是合理可行的。去皮效果测试结果表明，去皮质量和效率都有明显提高，研制的设备完全满足了锯木厂对去皮加工精度和效率的要求。]]></description>
      <guid>https://arxiv.org/abs/2410.11913</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有测试时间优化和零发散损失的双帧流体运动估计</title>
      <link>https://arxiv.org/abs/2410.11934</link>
      <description><![CDATA[arXiv:2410.11934v1 公告类型：新
摘要：3D 粒子跟踪测速 (PTV) 是分析湍流的关键技术，湍流是我们这个世纪最具挑战性的计算问题之一。3D PTV 的核心是双帧流体运动估计算法，该算法在两个连续帧中跟踪粒子。最近，基于深度学习的方法在双帧流体运动估计中取得了令人印象深刻的准确性；然而，它们严重依赖于大量标记数据。在本文中，我们介绍了一种完全自监督的新方法，其性能明显优于全监督方法，同时只需要以前方法使用的 1% 的训练样本（无标签）。我们的方法具有一种新型的零散度损失，特定于湍流领域。受 splat 操作在高维滤波和随机场中的成功的启发，我们提出了一种基于 splat 的这种损失实现方法，既高效又有效。我们方法的自监督特性自然支持测试时间优化，从而开发出定制的动态测速增强器 (DVE) 模块。我们证明，通过对看不见的留一合成域和真实物理/生物域进行测试时间优化，可以实现强大的跨域稳健性。代码、数据和模型可在 https://github.com/Forrest-110/FluidMotionNet 上找到。]]></description>
      <guid>https://arxiv.org/abs/2410.11934</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CtrlSynth：可控图像文本合成，实现数据高效的多模态学习</title>
      <link>https://arxiv.org/abs/2410.11963</link>
      <description><![CDATA[arXiv:2410.11963v1 公告类型：新
摘要：预训练稳健视觉或多模态基础模型（例如 CLIP）依赖于可能存在噪声、可能错位且具有长尾分布的大规模数据集。先前的研究已显示出通过生成合成样本来扩充数据集的良好结果。但是，它们仅支持特定领域的临时用例（例如，仅支持图像或文本，但不能同时支持两者），并且由于缺乏对合成过程的细粒度控制，数据多样性受到限制。在本文中，我们设计了一个 \emph{可控} 图像文本合成管道 CtrlSynth，用于数据高效且稳健的多模态学习。关键思想是将图像的视觉语义分解为基本元素，应用用户指定的控制策略（例如，删除、添加或替换操作），然后重新组合它们以合成图像或文本。 CtrlSynth 中的分解和重组功能允许用户通过定义自定义控制策略来操纵基本元素，从而以细粒度的方式控制数据合成。CtrlSynth 利用预训练的基础模型（例如大型语言模型或扩散模型）的功能来推理和重组基本元素，从而使合成样本自然并以多种方式组合。CtrlSynth 是一个闭环、免训练和模块化的框架，可轻松支持不同的预训练模型。通过在涵盖不同视觉和视觉语言任务的 31 个数据集上进行大量实验，我们表明 CtrlSynth 显著提高了 CLIP 模型的零样本分类、图像文本检索和组合推理性能。]]></description>
      <guid>https://arxiv.org/abs/2410.11963</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>集成人工智能模型和合成图像数据以增强资产检查和缺陷识别</title>
      <link>https://arxiv.org/abs/2410.11967</link>
      <description><![CDATA[arXiv:2410.11967v1 公告类型：新
摘要：过去，公用事业公司依靠现场检查来识别资产缺陷。最近，公用事业公司已开始使用基于无人机的检查来增强现场检查过程。我们考虑了庞大的无人机图像库，这些图像提供了有关资产健康和潜在问题的大量信息。但是，要使收集到的图像数据可用于自动缺陷检测，需要大量的手动标记工作。我们提出了一种新颖的解决方案，将合成的资产缺陷图像与手动标记的无人机图像相结合。该解决方案有几个好处：提高了缺陷检测的性能，减少了手动标记所花费的时间，并能够在没有足够真实世界数据的情况下生成罕见缺陷的真实图像。我们采用了一种工作流程，结合了 Maya 和 Unreal Engine 等 3D 建模工具来创建有缺陷资产及其周围环境的逼真的 3D 模型和 2D 渲染。然后将这些合成图像集成到我们的训练管道中，以增强真实数据。本研究实施了一种端到端人工智能解决方案，用于从组合图像库中检测资产和资产缺陷。这项研究的独特贡献在于应用了先进的计算机视觉模型并生成了缺陷资产的逼真的 3D 渲染图，旨在改变资产检查流程。我们的资产检测模型的准确率已达到 92%，在引入约 2,000 张 2k 分辨率的合成图像时，性能提升了 67%。在我们的测试中，缺陷检测模型在两批图像中的准确率达到了 73%。我们的分析表明，合成数据可以成功地代替现实世界的手动标记数据来训练缺陷检测模型。]]></description>
      <guid>https://arxiv.org/abs/2410.11967</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>超越标签：带有蒙面自动编码器和随机裁剪的自监督框架，用于乳腺癌亚型分类</title>
      <link>https://arxiv.org/abs/2410.12006</link>
      <description><![CDATA[arXiv:2410.12006v1 公告类型：新
摘要：这项工作有助于使用组织病理学图像对乳腺癌亚型进行分类。我们利用掩蔽自动编码器 (MAE) 来学习针对该领域计算机视觉任务量身定制的自监督嵌入。此嵌入捕获组织病理学数据的信息表示，促进特征学习而无需大量标记数据集。在预训练期间，我们研究使用随机裁剪技术自动从 WSI 生成大型数据集。此外，我们使用 MAE 学习到的表示来评估线性探针对癌症亚型多类分类任务的性能。我们的方法旨在通过利用 ViT 和自动编码器的互补优势在下游任务上实现出色的性能。我们评估了我们的模型在 BRACS 数据集上的性能并将其与现有基准进行比较。]]></description>
      <guid>https://arxiv.org/abs/2410.12006</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LocoMotion：学习以运动为中心的视频语言表征</title>
      <link>https://arxiv.org/abs/2410.12018</link>
      <description><![CDATA[arXiv:2410.12018v1 公告类型：新
摘要：本文致力于研究以运动为中心的视频语言表征。现有的学习视频语言表征的方法使用以空间为中心的数据，其中识别对象和场景通常足以区分相关标题。我们提出 LocoMotion 从以运动为中心的标题中学习，这些标题描述了局部物体运动的运动和时间进程。我们通过在视频中添加合成运动并使用这些运动的参数来生成相应的标题来实现这一点。此外，我们提出了动词变化释义来增加标题的多样性并学习原始运动和高级动词之间的联系。有了这个，我们能够学习以运动为中心的视频语言表征。实验表明，我们的方法对各种下游任务都有效，特别是在可用于微调的数据有限的情况下。代码可用：https://hazeldoughty.github.io/Papers/LocoMotion/]]></description>
      <guid>https://arxiv.org/abs/2410.12018</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SOE：SO(3)-等变3D MRI编码</title>
      <link>https://arxiv.org/abs/2410.12053</link>
      <description><![CDATA[arXiv:2410.12053v1 公告类型：新
摘要：表征学习变得越来越重要，尤其是当强大的模型已经转向在对下游任务进行微调之前学习潜在表征时。这种方法在利用大脑解剖结构中的结构信息方面特别有价值。然而，最近为 MRI 开发的模型的一个常见限制是它们倾向于忽略或删除几何信息，例如平移和旋转，从而产生几何操作的不变性。我们认为，将这些几何变换的知识融入模型可以显著增强其学习大脑结构内更详细的解剖信息的能力。因此，我们提出了一种编码 3D MRI 的新方法，该方法强制执行 3D 空间中所有旋转的等方差，换句话说，SO(3)-等方差 (SOE)。通过在表示空间中明确建模这种几何等方差，我们确保应用于输入图像空间的任何旋转操作也会反映在嵌入表示空间中。这种方法需要超越传统的表示学习方法，因为我们需要一个表示向量空间，允许在该空间中应用相同的 SO(3) 操作。为了实现这一点，我们利用了向量神经元的概念。我们的方法形成的表示空间可以更有效地捕获大脑的结构和解剖信息。我们评估了在两个公共数据集的结构 MRI 上预训练的 SOE，以及从 ADNI 数据集的 T1 加权脑部扫描中预测年龄和诊断阿尔茨海默病的下游任务。我们证明我们的方法不仅优于其他方法，而且对沿不同轴的不同程度的旋转也具有鲁棒性。代码可在 https://github.com/shizhehe/SOE-representation-learning 获得。]]></description>
      <guid>https://arxiv.org/abs/2410.12053</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>nvTorchCam：一个与相机无关的可微分几何视觉开源库</title>
      <link>https://arxiv.org/abs/2410.12074</link>
      <description><![CDATA[arXiv:2410.12074v1 公告类型：新
摘要：我们引入了 nvTorchCam，这是一个 Apache 2.0 许可下的开源库，旨在使深度学习算法独立于相机模型。nvTorchCam 抽象了关键的相机操作，例如投影和反投影，允许开发人员实现一次算法并将其应用于各种相机模型 - 包括针孔、鱼眼和 360 等距矩形全景图，这些模型通常用于汽车和房地产捕捉应用。nvTorchCam 基于 PyTorch 构建，完全可微分，并支持 GPU 加速和批处理以实现高效计算。此外，针对一种相机类型训练的深度学习模型可以直接转移到其他相机类型，而无需进行额外修改。在本文中，我们概述了 nvTorchCam 及其功能，并提供了各种代码示例和图表来演示其用法。源代码和安装说明可以在 nvTorchCam GitHub 页面 https://github.com/NVlabs/nvTorchCam 上找到。]]></description>
      <guid>https://arxiv.org/abs/2410.12074</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>WeatherDG：用于领域广义语义分割的 LLM 辅助程序天气生成</title>
      <link>https://arxiv.org/abs/2410.12075</link>
      <description><![CDATA[arXiv:2410.12075v1 公告类型：新
摘要：在这项工作中，我们提出了一种新方法，即 WeatherDG，该方法可以基于两个基础模型（即稳定扩散 (SD) 和大型语言模型 (LLM)）的协作生成逼真的、天气多样的和驾驶屏幕图像。具体来说，我们首先使用源数据对 SD 进行微调，使生成的样本的内容和布局与现实世界的驾驶场景保持一致。然后，我们提出了一种基于 LLM 的程序提示生成方法，它可以丰富场景描述并帮助 SD 自动生成更多样化、更详细的图像。此外，我们引入了一种平衡的生成策略，鼓励 SD 在各种天气条件下生成高质量的尾部类别对象，例如骑手和摩托车。这种与分割模型无关的方法可以通过将现有模型与生成的合成数据进行额外调整来提高现有模型的泛化能力。在三个具有挑战性的数据集上进行的实验表明，我们的方法可以显著提高不同最先进模型在目标域上的分割性能。值得注意的是，在“城市景观到 ACDC”的设置中，我们的方法将基线 HRDA 的 mIoU 提高了 13.9%。]]></description>
      <guid>https://arxiv.org/abs/2410.12075</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SplatPose+：基于实时图像的姿势无关 3D 异常检测</title>
      <link>https://arxiv.org/abs/2410.12080</link>
      <description><![CDATA[arXiv:2410.12080v1 公告类型：新
摘要：基于图像的姿势无关 3D 异常检测是工业质量控制中出现的一项重要任务。此任务旨在给定一组无异常对象的参考图像，从测试对象的查询图像中查找异常。挑战在于查询视图（又名姿势）是未知的，并且可能与参考视图不同。目前，出现了诸如 OmniposeAD 和 SplatPose 之类的新方法，通过在查询视图处合成伪参考图像进行像素到像素的比较来弥补这一差距。然而，这些方法都不能实时推断，这对于大规模生产的工业质量控制至关重要。为此，我们提出了 SplatPose+，它采用一种混合表示，由用于定位的运动结构 (SfM) 模型和用于新视图合成的 3D 高斯溅射 (3DGS) 模型组成。尽管我们提出的流程需要计算额外的 SfM 模型，但与 SplatPose 相比，它提供了实时推理速度和更快的训练速度。在质量方面，我们在多姿势异常检测 (MAD-SIM) 数据集的姿势无关异常检测基准上取得了新的 SOTA。]]></description>
      <guid>https://arxiv.org/abs/2410.12080</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>揭开对齐的极限：多模态动态局部融合网络和未对齐 RGBT 视频对象检测的基准</title>
      <link>https://arxiv.org/abs/2410.12143</link>
      <description><![CDATA[arXiv:2410.12143v1 公告类型：新 
摘要：当前的 RGB-热视频对象检测 (RGBT VOD) 方法仍然依赖于在图像级别手动对齐数据，这阻碍了其在实际场景中的实际应用，因为多光谱传感器捕获的图像对在视野和分辨率上通常都不同。为了解决这一限制，我们提出了一种多模态动态局部融合网络 (MDLNet)，旨在处理未对齐的 RGBT 图像对。具体而言，我们提出的多模态动态局部融合 (MDLF) 模块包括一组预定义的框，每个框都用随机高斯噪声增强以生成动态框。每个框从原始高分辨率 RGB 图像中选择一个局部区域。然后将该区域与来自另一种模态的相应信息融合并重新插入到 RGB 中。该方法通过与不同范围内的局部特征交互来适应各种数据对齐场景。同时，我们在端到端架构中引入了级联时间扰码器 (CTS)。该模块利用来自连续帧的一致时空信息来增强当前帧的表示能力，同时保持网络效率。我们为未对齐的 RGBT VOD 整理了一个名为 UVT-VOD2024 的开放数据集。它由 30,494 对未对齐的 RGBT 图像组成，这些图像直接从多光谱相机捕获。我们对 MDLNet 和最先进 (SOTA) 模型进行了全面的评估和比较，证明了 MDLNet 的卓越效果。我们将向公众发布我们的代码和 UVT-VOD2024 以供进一步研究。]]></description>
      <guid>https://arxiv.org/abs/2410.12143</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于 3D 场景理解的 SAM 引导式蒙版标记预测</title>
      <link>https://arxiv.org/abs/2410.12158</link>
      <description><![CDATA[arXiv:2410.12158v2 公告类型：新
摘要：基础模型显著提高了 2D 任务的性能，最近的 Bridge3D 等工作已成功应用这些模型通过知识提炼来提高 3D 场景理解，标志着相当大的进步。尽管如此，2D 和 3D 表示之间的不一致以及 3D 数据集中持续的长尾分布等挑战仍然限制了使用基础模型从 2D 到 3D 知识提炼的有效性。为了解决这些问题，我们引入了一种新颖的 SAM 引导标记化方法，该方法将 3D Transformer 结构与区域级知识提炼无缝对齐，取代了传统的基于 KNN 的标记化技术。此外，我们实施了一种组平衡的重新加权策略，以有效解决知识提炼中的长尾问题。此外，受最近掩码特征预测成功的启发，我们的框架采用了两阶段掩码标记预测过程，其中学生模型预测全局嵌入和从第一阶段训练的教师模型派生的标记式局部嵌入。我们的方法已在多个数据集（包括 SUN RGB-D、ScanNet 和 S3DIS）中得到验证，可用于 3D 对象检测和语义分割等任务。结果表明，与当前最先进的自监督方法相比，该方法有显著改进，为该领域树立了新的标杆。]]></description>
      <guid>https://arxiv.org/abs/2410.12158</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用混合边云解决方案进行双模型蒸馏以实现高效动作分类</title>
      <link>https://arxiv.org/abs/2410.12165</link>
      <description><![CDATA[arXiv:2410.12165v1 公告类型：新
摘要：随着人工智能模型（例如大型视频语言模型 (VLM)）的规模不断扩大，由于硬件限制和计算成本，它们在实际应用中的部署变得越来越具有挑战性。为了解决这个问题，我们设计了一种混合边缘云解决方案，该解决方案利用较小模型的效率进行本地处理，同时在必要时推迟到更大、更准确的基于云的模型。具体来说，我们提出了一种新颖的无监督数据生成方法，即双模型蒸馏 (DMD)，以训练轻量级切换器模型，该模型可以预测边缘模型的输出何时不确定，并有选择地将推理卸载到云中的大型模型。动作分类任务的实验结果表明，与单独使用大型模型相比，我们的框架不仅需要更少的计算开销，而且准确性也更高。我们的框架为资源受限环境中的动作分类提供了可扩展且适应性强的解决方案，其潜在应用范围超出了医疗保健领域。值得注意的是，虽然 DMD 生成的数据用于优化我们管道中的性能和资源使用，但我们希望 DMD 的概念能够进一步支持未来跨多个模型的知识对齐研究。]]></description>
      <guid>https://arxiv.org/abs/2410.12165</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>