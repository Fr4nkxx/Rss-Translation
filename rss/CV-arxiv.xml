<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CV 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Mon, 28 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>使用基于无人机的摄影测量技术进行高分辨率桥梁变形监测</title>
      <link>https://arxiv.org/abs/2410.18984</link>
      <description><![CDATA[arXiv:2410.18984v1 公告类型：新
摘要：对桥梁等基础设施进行准确、高效的结构健康监测是一项重要任务，因为许多现有建筑已经达到或即将达到其计划使用寿命。在本文中，我们讨论了基于无人机的 SHM 监测的适用性问题，特别是关注负载下的几何变形。这种先进的技术因其能够降低繁琐的传统检查方法的成本和风险而变得越来越受欢迎。为此，我们对一座可以通过地锚承受预定义负载的研究钢筋混凝土桥进行了广泛的测试。在施加受控负载之前、期间和之后，已经捕获了非常高分辨率的图像块。从这些图像中，可以监测桥梁上不同点的运动，此外，还计算了密集的图像点云以评估基于表面的数据采集的性能。此外，稳定区域的大地控制网络用作束调整的控制信息。我们采用了不同的传感技术以便能够判断基于图像的变形结果：位移传感器、测速仪和激光剖面测量。作为摄影测量平台，采用了多旋翼无人机 DJI Matrice 600 Pro，配备两个 RTK-GNSS 接收器。安装的相机是 PhaseOne iXM-100 (100MP)，配备 80 毫米镜头。飞行高度距地面 30 米，GSD 为 1.3 毫米，同时保持 80% 的前向和侧向重叠。与参考数据（位移传感器）的比较显示差异小于 1 毫米。我们表明，通过采用引入的基于无人机的监测方法，与传统的点或剖面测量相比，可以对全区域变形进行量化。]]></description>
      <guid>https://arxiv.org/abs/2410.18984</guid>
      <pubDate>Mon, 28 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>VehicleSDF：通过代理建模实现约束工程设计的 3D 生成模型</title>
      <link>https://arxiv.org/abs/2410.18986</link>
      <description><![CDATA[arXiv:2410.18986v1 公告类型：新
摘要：机械设计的主要挑战是在满足工程约束的同时有效探索设计空间。这项工作探索了在车辆开发背景下使用 3D 生成模型探索设计空间，同时估计和执行工程约束。具体来说，我们生成满足给定几何规格的多种汽车 3D 模型，同时还获得性能参数（例如气动阻力）的快速估计。为此，我们采用数据驱动方法（使用 ShapeNet 数据集）来训练 VehicleSDF，这是一种基于 DeepSDF 的模型，它表示潜在空间中的潜在设计，可以解码为 3D 模型。然后，我们训练代理模型以从该潜在空间表示中估计工程参数，使我们能够有效地优化潜在向量以匹配规格。我们的实验表明，我们可以生成不同的 3D 模型，同时匹配指定的几何参数。最后，我们证明可以在可微分管道中估计其他性能参数，例如气动阻力。]]></description>
      <guid>https://arxiv.org/abs/2410.18986</guid>
      <pubDate>Mon, 28 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>形状合成的生成拓扑</title>
      <link>https://arxiv.org/abs/2410.18987</link>
      <description><![CDATA[arXiv:2410.18987v1 公告类型：新
摘要：欧拉特征变换 (ECT) 是一个强大的不变量，用于评估各种对象（包括图形和嵌入的单纯复形）的几何和拓扑特征。尽管 ECT 在理论上是可逆的，但目前尚无针对一般数据集的明确算法。在本文中，我们解决了这一缺陷，并证明了可以学习反演，从而使我们能够开发一种用于点云形状生成任务的新框架。我们的模型在重建和生成任务中表现出高质量，提供高效的潜在空间插值，并且比现有方法快几个数量级。]]></description>
      <guid>https://arxiv.org/abs/2410.18987</guid>
      <pubDate>Mon, 28 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>BIFR_OST：使用语言指令进行 3D 感知图像合成</title>
      <link>https://arxiv.org/abs/2410.19079</link>
      <description><![CDATA[arXiv:2410.19079v1 公告类型：新
摘要：本文介绍了 Bifr\&quot;ost，这是一种基于扩散模型的新型 3D 感知框架，用于执行基于指令的图像合成。以前的方法专注于 2D 级别的图像合成，无法处理复杂的空间关系（例如遮挡）。Bifr\&quot;ost 通过将 MLLM 训练为 2.5D 位置预测器并在生成过程中将深度图作为额外条件进行集成来解决这些问题，以弥合 2D 和 3D 之间的差距，从而增强空间理解并支持复杂的空间交互。我们的方法首先使用自定义反事实数据集对 MLLM 进行微调，以根据语言指令预测复杂背景中的 2.5D 对象位置。然后，图像合成模型经过独特设计，可处理多种类型的输入特征，使其能够执行考虑遮挡、深度模糊和图像协调的高保真图像合成。大量的定性和定量评估表明，Bifr_“ost 的表现明显优于现有方法，为在需要复杂空间理解的场景中生成逼真的合成图像提供了强大的解决方案。这项工作不仅突破了生成图像合成的界限，而且通过以创新方式有效利用现有资源，减少了对昂贵的注释数据集的依赖。]]></description>
      <guid>https://arxiv.org/abs/2410.19079</guid>
      <pubDate>Mon, 28 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>互相关模板匹配中的一个反例</title>
      <link>https://arxiv.org/abs/2410.19085</link>
      <description><![CDATA[arXiv:2410.19085v1 公告类型：新
摘要：采样和量化是信号和图像处理中的标准做法，但对其影响的理论理解并不完整。当底层函数是一维空间受限的分段常数函数时，我们考虑离散图像配准。对于理想的无噪声采样，函数支持的每个区域的样本数量通常取决于采样网格的位置。因此，如果函数的样本有噪声，则图像配准需要对齐和分割数据序列。对齐图像的一种流行策略是从互相关模板匹配中选择最大值。为了激发更稳健、更准确的方法，同时也解决分割问题，我们提供了一个一维空间受限的分段常数函数的示例，对于该函数，互相关技术在噪声样本上表现不佳。虽然早期改进方法的方法涉及规范化，但我们的示例在我们的环境中提出了一种新策略。差异序列、阈值和动态规划是图像处理中众所周知的技术。我们证明，在某些噪声条件下，它们是正确对齐和分割噪声数据序列的工具。我们还解决了在更一般情况下可能出现的一些潜在困难。]]></description>
      <guid>https://arxiv.org/abs/2410.19085</guid>
      <pubDate>Mon, 28 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>VideoWebArena：使用视频理解 Web 任务评估长上下文多模式代理</title>
      <link>https://arxiv.org/abs/2410.19100</link>
      <description><![CDATA[arXiv:2410.19100v1 公告类型：新
摘要：视频通常用于学习或提取完成任务所需的信息，其方式与文本和静态图像本身所能提供的方式不同。然而，许多现有的代理基准测试忽略了长上下文视频理解，而是专注于文本或静态图像输入。为了弥补这一差距，我们引入了 VideoWebArena (VideoWA)，这是一个用于评估长上下文多模态代理视频理解能力的基准测试。VideoWA 由 2,021 个基于手工制作的视频教程的 Web 代理任务组成，总内容近四小时。对于我们的基准测试，我们定义了一个基于长上下文视频的代理任务分类法，主要关注两个领域：技能保留和事实保留。虽然技能保留任务评估代理是否可以使用给定的人类演示来有效地完成任务，但事实保留任务评估代理是否可以从视频中检索与指令相关的信息来完成任务。我们发现，最佳模型在事实记忆任务中的成功率为 13.3%，在事实记忆问答对中的成功率为 45.8%，远低于人类的表现（分别为 73.9% 和 79.3%）。在技能记忆任务中，长上下文模型在有教程的情况下表现比没有教程时更差，在 WebArena 任务中性能下降 5%，在 VisualWebArena 任务中性能下降 10.3%。我们的工作强调了改进长上下文多模态模型的代理能力的必要性，并为未来使用长上下文视频代理进行开发提供了试验台。]]></description>
      <guid>https://arxiv.org/abs/2410.19100</guid>
      <pubDate>Mon, 28 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MoGe：通过最佳训练监督实现开放域图像的精确单目几何估计</title>
      <link>https://arxiv.org/abs/2410.19115</link>
      <description><![CDATA[arXiv:2410.19115v1 公告类型：新
摘要：我们提出了 MoGe，这是一种从单目开放域图像中恢复 3D 几何图形的强大模型。给定一张图像，我们的模型直接使用仿射不变表示预测所捕获场景的 3D 点图，这与真实的全局尺度和偏移无关。这种新的表示排除了训练中的模糊监督并促进了有效的几何学习。此外，我们提出了一组新颖的全局和局部几何监督，使模型能够学习高质量的几何图形。其中包括用于精确全局形状学习的稳健、最佳和高效的点云对齐求解器，以及促进精确局部几何监督的多尺度局部几何损失。我们在大型混合数据集上训练我们的模型，并展示了其强大的通用性和高精度。在我们对各种未见过的数据集的全面评估中，我们的模型在所有任务中的表现都明显优于最先进的方法，包括 3D 点图、深度图和相机视野的单目估计。代码和模型将在我们的项目页面上发布。]]></description>
      <guid>https://arxiv.org/abs/2410.19115</guid>
      <pubDate>Mon, 28 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>视觉文本至关重要：使用视觉文本实体知识感知大型多模式助手改进 Text-KVQA</title>
      <link>https://arxiv.org/abs/2410.19144</link>
      <description><![CDATA[arXiv:2410.19144v1 公告类型：新
摘要：鉴于大型多模态模型 (LMM) 的现代进步，我们重新审视知识感知的基于文本的视觉问答，也称为 Text-KVQA，并做出以下贡献：(i) 我们提出了 VisTEL——一种执行视觉文本实体链接的原则性方法。所提出的 VisTEL 模块利用最先进的视觉文本识别引擎和大型多模态模型的强大功能，使用图像中周围线索获得的文本和视觉上下文进行联合推理，将视觉文本实体链接到正确的知识库实体。(ii) 我们提出了 KaLMA——一个知识感知的大型多模态助手，它使用与图像中的视觉文本实体相关的知识增强 LMM，以得出准确的答案。此外，我们对我们的方法与传统视觉问答、前大型多模态模型和大型多模态模型以及之前表现最佳的方法进行了全面的实验分析和比较。通过对 Text-KVQA 的三个部分进行平均，我们提出的方法在绝对规模上超越了之前的最佳方法，达到了 23.3%，并创造了新的最高水平。我们将我们的实现公开发布。]]></description>
      <guid>https://arxiv.org/abs/2410.19144</guid>
      <pubDate>Mon, 28 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>HUE 数据集：用于低光视觉的高分辨率事件和帧序列</title>
      <link>https://arxiv.org/abs/2410.19164</link>
      <description><![CDATA[arXiv:2410.19164v1 公告类型：新
摘要：低光环境对图像增强方法提出了重大挑战。为了应对这些挑战，在这项工作中，我们引入了 HUE 数据集，这是在各种具有挑战性的低光条件下捕获的高分辨率事件和帧序列的综合集合。我们的数据集包括 106 个序列，涵盖室内、城市景观、黄昏、夜晚、驾驶和受控场景，每个序列都经过精心记录，以解决各种照明水平和动态范围。利用混合 RGB 和事件相机设置。我们收集了一个将高分辨率事件数据与互补帧数据相结合的数据集。我们使用无参考指标进行定性和定量评估，以评估最先进的低光增强和基于事件的图像重建方法。此外，我们在下游物体检测任务上评估这些方法。我们的研究结果表明，虽然基于事件的方法在特定指标上表现良好，但它们在实际应用中可能会产生误报。该数据集和我们的综合分析为未来在低光视觉和混合相机系统方面的研究提供了宝贵的见解。]]></description>
      <guid>https://arxiv.org/abs/2410.19164</guid>
      <pubDate>Mon, 28 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DCT-HistoTransformer：集成 DCT 的高效轻量级视觉变换器，用于组织病理学图像分析</title>
      <link>https://arxiv.org/abs/2410.19166</link>
      <description><![CDATA[arXiv:2410.19166v1 公告类型：新
摘要：近年来，先进成像技术与深度学习方法的结合显著推动了乳腺癌检测和分类的计算机辅助诊断 (CAD) 系统的发展。Transformers 在计算机视觉领域显示出巨大的潜力，现在正应用于医学图像分析。然而，由于需要对全幻灯片图像 (WSI) 进行大量的手动注释，因此它们在组织病理学图像中的应用面临着挑战，因为这些模型需要大量数据才能有效工作，这既昂贵又耗时。此外，视觉变换器 (ViTs) 的二次计算成本对于大型高分辨率组织病理学图像尤其高昂，尤其是在计算资源有限的边缘设备上。在这项研究中，我们介绍了一种使用变换器的新型轻量级乳腺癌分类方法，该方法无需大量数据集即可有效运行。通过结合离散余弦变换 (DCT) 注意力机制和 MobileConv 的并行处理路径，我们将图像数据从空域转换到频域，以利用诸如滤除图像中的高频等优势，从而降低计算成本。这证明了我们的方法在改善组织病理学图像中的乳腺癌分类方面的潜力，提供了一种更有效的解决方案，同时减少对大量带注释的数据集的依赖。我们提出的模型在二元分类中的准确率为 96.00% $\pm$ 0.48%，在多类分类中的准确率为 87.85% $\pm$ 0.93%，这与最先进的模型相当，同时显著降低了计算成本。这证明了我们的方法在改善组织病理学图像中的乳腺癌分类方面的潜力，提供了一种更有效的解决方案，同时减少对大量带注释的数据集的依赖。]]></description>
      <guid>https://arxiv.org/abs/2410.19166</guid>
      <pubDate>Mon, 28 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于摩尔斯电码图像分类的噪声自适应网络</title>
      <link>https://arxiv.org/abs/2410.19180</link>
      <description><![CDATA[arXiv:2410.19180v1 公告类型：新
摘要：信息安全的重要性日益增加，凸显了加密技术在保护通信内容方面的普遍作用。摩尔斯电码是一种成熟有效的加密方法，广泛应用于电报通信和各个领域。然而，摩尔斯电码图像的传输由于各种噪声和失真而面临挑战，从而阻碍了全面的分类结果。现有的方法主要集中在对受单一类型噪声影响的摩尔斯电码图像进行分类，而忽略了噪声污染可能产生的多种情况。为了克服这一限制，我们提出了一种新颖的两阶段方法，称为噪声自适应网络（NANet），用于摩尔斯电码图像分类。我们的方法涉及对原始图像进行专门训练，同时通过提取不受噪声影响的关键信息来适应嘈杂的图像。在初始阶段，我们引入了一个 U 形网络结构，旨在学习代表性特征并对图像进行去噪。随后，第二阶段采用深度卷积神经网络进行分类。通过利用第一阶段的去噪模块，我们的方法在后续分类阶段实现了更高的准确性和稳健性。我们在多样化的数据集上对我们的方法进行了评估，包括高斯、黑白和均匀噪声变化。结果令人信服地证明了我们的方法优于现有方法。数据集可在 https://github.com/apple1986/MorseCodeImageClassify 上找到]]></description>
      <guid>https://arxiv.org/abs/2410.19180</guid>
      <pubDate>Mon, 28 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于小波的无监督纹理分割综述、自适应小波的优势</title>
      <link>https://arxiv.org/abs/2410.19191</link>
      <description><![CDATA[arXiv:2410.19191v1 公告类型：新
摘要：基于小波的分割方法因其能够表征不同的纹理而广泛用于纹理分割目的。在本文中，我们评估了所选小波的影响，并建议使用最近引入的经验小波。我们表明，经验小波的适应性可以比经典小波获得更好的结果。为了只关注纹理信息，我们还建议在应用分割算法之前执行卡通+纹理分解步骤。基于几个流行的纹理图像，在六个经典基准上对所提出的方法进行了测试。]]></description>
      <guid>https://arxiv.org/abs/2410.19191</guid>
      <pubDate>Mon, 28 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用自行车街道图像对自行车基础设施进行分类</title>
      <link>https://arxiv.org/abs/2410.19194</link>
      <description><![CDATA[arXiv:2410.19194v1 公告类型：新
摘要：虽然骑自行车为可持续交通提供了一种有吸引力的选择，但由于缺乏合适和安全的基础设施，许多潜在的骑自行车者不愿意骑自行车。有效地绘制整个城市的自行车基础设施地图对于增进我们对如何提供高质量基础设施连接网络的理解是必要的。因此，我们提出了一个能够根据自行车智能手机摄像头数据对可用的自行车基础设施进行分类的系统。该系统接收图像序列作为输入，对序列进行时间分析以解释标牌的稀疏性。该模型输出由分层分类系统定义的自行车基础设施类别标签。数据是通过覆盖大墨尔本地区 7,006 公里的参与骑自行车者收集的，并通过 GPS 和 OpenStreetMap 数据库匹配算法自动标记。提出的模型实现了 95.38% 的准确率，与非时间模型相比，性能提高了 7.55%。该模型表现出对图像特征极度缺失的稳健性，在 90% 的图像被空白图像替换后，模型的准确率仅下降了 6.6%。这是首次仅使用从自行车安装的手机摄像头收集的街道级图像对自行车基础设施进行分类，同时通过长时间序列分析表现出对特征稀疏性的稳健性。]]></description>
      <guid>https://arxiv.org/abs/2410.19194</guid>
      <pubDate>Mon, 28 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于动态细粒度类别发现的原型哈希编码</title>
      <link>https://arxiv.org/abs/2410.19213</link>
      <description><![CDATA[arXiv:2410.19213v1 公告类型：新
摘要：本文研究了一项实用而又具有挑战性的任务，即动态类别发现 (OCD)，旨在通过仅利用标记数据中包含的已知类别知识，在线发现属于已知和未知类别的新流数据。以前的 OCD 方法采用基于哈希的技术，通过哈希码表示旧/新类别，以进行实例推理。然而，将特征直接映射到低维哈希空间不仅不可避免地损害了区分类别的能力，而且还会导致“高敏感性”问题，尤其是对于细粒度类别，从而导致性能下降。为了解决这些问题，我们提出了一种新颖的原型哈希编码 (PHE) 框架，该框架由类别感知原型生成 (CPG) 和判别类别编码 (DCE) 组成，以减轻哈希码的敏感性，同时以两阶段投影方式保留高维特征空间中包含的丰富判别信息。 CPG 通过使用多个原型表示每个类别，使模型能够充分捕捉类别内多样性。DCE 在生成的类别原型的指导下以及最小分离距离的约束下增强了哈希码的判别能力。通过联合优化 CPG 和 DCE，我们证明这两个组件对有效的 OCD 是互惠互利的。大量实验表明我们的 PHE 相对于以前的方法具有显著的优势，例如，在所有数据集上平均的 ALL ACC 提高了 +5.3%。此外，由于可解释原型的性质，我们直观地分析了 PHE 如何帮助将某些样本分组到已知或未知类别中的底层机制。代码可在 https://github.com/HaiyangZheng/PHE 获得。]]></description>
      <guid>https://arxiv.org/abs/2410.19213</guid>
      <pubDate>Mon, 28 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>提示持续人员搜索</title>
      <link>https://arxiv.org/abs/2410.19239</link>
      <description><![CDATA[arXiv:2410.19239v1 公告类型：新
摘要：近年来，行人搜索技术因其优越的实用性和具有挑战性的目标而得到了极大的推动。尽管现有的行人搜索模型取得了重大进展，但它们仍然缺乏从不断增加的真实数据中持续学习和自适应处理来自不同领域的输入的能力。为此，这项工作引入了持续行人搜索任务，该任务在多个领域上依次学习，然后在所有可见领域上执行行人搜索。这需要平衡模型的稳定性和可塑性，以不断学习新知识而不会发生灾难性遗忘。为此，我们在本文中提出了一种基于提示的持续行人搜索（PoPS）模型。首先，我们设计了一个组合行人搜索转换器，以构建一个有效的预训练转换器，而无需在大规模行人搜索数据上从头开始进行详尽的预训练。这是基于提示的持续学习的基础。最重要的是，我们设计了一个具有多样化属性匹配模块的领域增量提示池。对于每个领域，我们独立学习一组提示来编码面向领域的知识。同时，我们联合学习一组不同的属性投影和原型嵌入来捕获判别性领域属性。通过将输入图像与跨域学习到的属性进行匹配，可以正确选择学习到的提示进行模型推理。进行了广泛的实验来验证所提出的持续人员搜索方法。源代码可在 https://github.com/PatrickZad/PoPS 上找到。]]></description>
      <guid>https://arxiv.org/abs/2410.19239</guid>
      <pubDate>Mon, 28 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>