<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CV 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Wed, 16 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>使用基于评分的 3D 残留扩散模型在 ARDS 猪模型中进行高保真 3D 肺 CT 合成</title>
      <link>https://arxiv.org/abs/2410.10826</link>
      <description><![CDATA[arXiv:2410.10826v1 公告类型：新
摘要：急性呼吸窘迫综合征 (ARDS) 是一种以肺部炎症和呼吸衰竭为特征的严重疾病，死亡率高达约 40%。传统的成像方法，例如胸部 X 光片，仅提供二维视图，限制了它们在全面评估肺部病理方面的有效性。三维 (3D) 计算机断层扫描 (CT) 提供了更全面的可视化，能够详细分析肺通气、肺不张和治疗干预的效果。然而，在 ARDS 管理中常规使用 CT 受到将危重患者运送到远程扫描仪的实际挑战和风险的限制。在本研究中，我们使用基于分数的 3D 残余扩散模型从 ​​2D 生成的 X 射线图像与相关生理参数合成高保真 3D 肺 CT。我们的初步结果表明，这种方法可以生成经过地面实况验证的高质量 3D CT 图像，为增强 ARDS 管理提供了一种有希望的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2410.10826</guid>
      <pubDate>Wed, 16 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>关注重要的事情：基于视觉的强化学习泛化的分离模型</title>
      <link>https://arxiv.org/abs/2410.10834</link>
      <description><![CDATA[arXiv:2410.10834v1 公告类型：新
摘要：基于视觉的强化学习 (RL) 面临的主要挑战是在看不见的环境中有效地进行泛化。尽管先前的研究已经探索了不同的辅助任务来增强泛化，但很少有研究采用图像重建，因为担心在训练过程中加剧对与任务无关的特征的过度拟合。认识到图像重建在表示学习中的卓越地位，我们提出了 SMG（用于泛化的分离模型），这是一种利用图像重建进行泛化的新方法。SMG 引入了两个模型分支，通过协作重建分别从视觉观察中提取与任务相关和与任务无关的表示。在此架构的基础上，我们进一步强调了与任务相关的特征对于泛化的重要性。具体而言，SMG 结合了两个额外的一致性损失，以引导代理在不同场景中的注意力转向与任务相关的区域，从而实现避免过度拟合。 DMC 中的大量实验证明了 SMG 在泛化方面的 SOTA 性能，尤其是在视频背景设置中表现出色。对机器人操作任务的评估进一步证实了 SMG 在实际应用中的稳健性。]]></description>
      <guid>https://arxiv.org/abs/2410.10834</guid>
      <pubDate>Wed, 16 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Lotus：基于学习的边缘设备上两阶段检测器的在线热和延迟变化管理</title>
      <link>https://arxiv.org/abs/2410.10847</link>
      <description><![CDATA[arXiv:2410.10847v1 公告类型：新
摘要：两阶段物体检测器表现出高精度和精确定位，尤其适用于识别有利于各种边缘应用的小物体。然而，与两阶段检测方法相关的高计算成本导致边缘设备上更严重的热问题，导致动态运行时频率变化，从而导致较大的推理延迟变化。此外，不同帧中提案的动态数量会导致随时间推移的各种计算，从而导致进一步的延迟变化。边缘设备上检测器的显着延迟变化会损害用户体验并浪费硬件资源。为了避免热节流并提供稳定的推理速度，我们提出了 Lotus，这是一种针对两阶段检测器量身定制的新型框架，可基于深度强化学习 (DRL) 在线动态扩展 CPU 和 GPU 频率。为了证明 Lotus 的有效性，我们在 NVIDIA Jetson Orin Nano 和 Mi 11 Lite 移动平台上实现了它。结果表明，Lotus 可以在各种设置下持续显着地减少延迟变化，实现更快的推理，并保持较低的 CPU 和 GPU 温度。]]></description>
      <guid>https://arxiv.org/abs/2410.10847</guid>
      <pubDate>Wed, 16 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用扩散网络进行文化遗产三维重建</title>
      <link>https://arxiv.org/abs/2410.10927</link>
      <description><![CDATA[arXiv:2410.10927v1 公告类型：新
摘要：本文探讨了使用最新的生成式 AI 算法修复文化遗产对象，利用旨在有效重建 3D 点云的条件扩散模型。我们的研究评估了该模型在一般和特定文化遗产环境中的性能。结果表明，考虑到对象的可变性，扩散模型可以准确地再现文化遗产的几何形状。尽管遇到了数据多样性和异常值敏感性等挑战，但该模型在文物修复研究中仍显示出巨大的潜力。这项工作为使用 AI 技术推进古代文物的修复方法奠定了基础。]]></description>
      <guid>https://arxiv.org/abs/2410.10927</guid>
      <pubDate>Wed, 16 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>矩阵群上用于可变形图像配准的平稳速度场</title>
      <link>https://arxiv.org/abs/2410.10997</link>
      <description><![CDATA[arXiv:2410.10997v1 公告类型：新
摘要：平稳速度场 (SVF) 方法允许构建可逆变形场的参数化，这通常是图像配准中理想的特性。当用作机器学习启发式网络的块时，其表现力特别有吸引力。然而，它可能难以处理较大的变形。我们将 SVF 方法扩展到矩阵组，特别是 $\SE(3)$。这将欧几里得变换移到低频部分，网络架构通常自然偏向于低频部分，以便可以更轻松地恢复较大的运动。这需要扩展流动方程，为此我们提供了存在的充分条件。我们进一步证明了一个分解条件，使我们能够应用缩放和平方方法对流动方程进行有效的数值积分。我们在人类大脑 3D MRI 图像的患者间配准上对该方法进行了数值验证。]]></description>
      <guid>https://arxiv.org/abs/2410.10997</guid>
      <pubDate>Wed, 16 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ET-Former：高效三平面可变形注意力机制，用于单目相机完成 3D 语义场景</title>
      <link>https://arxiv.org/abs/2410.11019</link>
      <description><![CDATA[arXiv:2410.11019v1 公告类型：新
摘要：我们介绍了 ET-Former，这是一种使用单个单目相机进行语义场景完成的新型端到端算法。我们的方法从单个 RGB 观察生成语义占用图，同时为语义预测提供不确定性估计。通过设计基于三平面的可变形注意机制，我们的方法比其他 SOTA 方法提高了对场景的几何理解，并降低了语义预测中的噪声。此外，通过使用条件变分自动编码器 (CVAE)，我们估计了这些预测的不确定性。生成的语义和不确定性图将有助于制定导航策略，从而促进未来安全和允许的决策。在 Semantic-KITTI 数据集上进行评估，ET-Former 实现了最高的 IoU 和 mIoU，在 IoU 上超越其他方法 15.16%，在 mIoU 上超越其他方法 24.24%，同时将现有方法的 GPU 内存使用量降低了 25%-50.5%。]]></description>
      <guid>https://arxiv.org/abs/2410.11019</guid>
      <pubDate>Wed, 16 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>超越固定拓扑：3D 说话头像的未注册训练和综合评估指标</title>
      <link>https://arxiv.org/abs/2410.11041</link>
      <description><![CDATA[arXiv:2410.11041v1 公告类型：新
摘要：生成语音驱动的 3D 说话头像面临许多挑战；其中之一就是处理不同的网格拓扑。现有方法需要一个注册设置，其中所有网格共享一个共同的拓扑：模型可以动画的所有网格之间的逐点对应。虽然简化了问题，但它限制了适用性，因为看不见的网格必须遵守训练拓扑。这项工作提出了一个框架，能够以任意拓扑（包括真实扫描数据）为 3D 人脸制作动画。我们的方法依赖于利用网格上的热扩散来克服固定拓扑约束的模型。我们探索了两种训练设置：一种是监督设置，其中训练序列在序列内共享固定拓扑，但任何网格都可以在测试时动画化；另一种是无监督设置，它允许使用不同的网格结构进行有效训练。此外，我们强调了当前评估指标的局限性，并提出了新的指标，以更好地评估语音和面部动作之间的口型同步。我们经过广泛的评估，发现我们的方法与固定拓扑技术相比表现更佳，通过为 3D 说话头部生成提供多功能、高保真的解决方案树立了新的标杆。]]></description>
      <guid>https://arxiv.org/abs/2410.11041</guid>
      <pubDate>Wed, 16 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于字符的上下文感知视听字幕</title>
      <link>https://arxiv.org/abs/2410.11068</link>
      <description><![CDATA[arXiv:2410.11068v1 公告类型：新
摘要：本文介绍了一种改进的电视节目中人物感知视听字幕框架。我们的方法集成了语音识别、说话人分类和人物识别，同时利用了音频和视觉提示。这种整体解决方案解决了所说的内容、所说的时间和说话人的问题，为电视节目提供了更全面、更准确的人物感知字幕。我们的方法在两个方面带来了改进：首先，我们展示了视听同步可用于在视频片段中挑选出正在说话的面孔，并为相应的语音片段分配身份。与当前方法相比，这种视听方法提高了识别准确性和产量。其次，我们展示了可以通过使用场景中对话的时间上下文来确定短片段的说话人。我们提出了一种使用音频的本地语音嵌入和文本转录上的大型语言模型推理的方法。这克服了现有方法无法准确将说话者分配到短时间段的局限性。我们在包含 12 个电视节目的数据集上验证了该方法，与现有方法相比，该方法在说话者分类和字符识别准确度方面表现出色。项目页面：https://www.robots.ox.ac.uk/~vgg/research/llr-context/]]></description>
      <guid>https://arxiv.org/abs/2410.11068</guid>
      <pubDate>Wed, 16 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用深度感知 3D 高斯分层进行小样本新视图合成</title>
      <link>https://arxiv.org/abs/2410.11080</link>
      <description><![CDATA[arXiv:2410.11080v1 公告类型：新
摘要：3D 高斯溅射通过实现更低的计算成本和实时高质量渲染，在新型视图合成中超越了神经辐射场方法。虽然它使用大量输入视图产生高质量渲染，但当只有少数视图可用时，其性能会显着下降。在这项工作中，我们通过提出一种深度感知高斯溅射方法来解决这个问题，用于少量镜头新型视图合成。我们使用单目深度预测作为先验，以及尺度不变的深度损失，以在仅几个输入视图下约束 3D 形状。我们还使用低阶球面谐波对颜色进行建模以避免过度拟合。此外，我们观察到，定期移除不透明度较低的溅射（如在原始工作中执行的那样）会导致非常稀疏的点云，因此渲染质量较低。为了缓解这种情况，我们保留了所有 splat，从而可以在一些视图设置中实现更好的重建。实验结果表明，我们的方法优于传统的 3D 高斯 splatting 方法，峰值信噪比提高了 10.5%，结构相似度指数提高了 6%，感知相似度提高了 14.1%，从而验证了我们方法的有效性。代码将在以下网址提供：https://github.com/raja-kumar/depth-aware-3DGS]]></description>
      <guid>https://arxiv.org/abs/2410.11080</guid>
      <pubDate>Wed, 16 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>局部对齐改进视觉语言模型</title>
      <link>https://arxiv.org/abs/2410.11087</link>
      <description><![CDATA[arXiv:2410.11087v1 公告类型：新
摘要：近年来，视觉语言模型 (VLM) 的采用率不断提高，但许多模型仍在努力解决基本的空间推理错误问题。我们假设这是由于 VLM 采用了预先训练的视觉主干，特别是经过图像级监督和最小归纳偏差训练的视觉变换器 (ViT)。此类模型可能无法对图像中每个位置的类内容进行编码，我们的目标是通过确保视觉主干有效地捕获局部和全局图像语义来解决这个问题。我们的主要见解是，我们不需要新的监督来学习这种能力——预先训练的模型包含大量局部语义知识，我们可以提取这些知识并将其用于可扩展的自我监督。我们为 ViT 提出了一种新的高效后训练阶段，称为局部对齐，以及一种名为 MaskEmbed 的新型微调程序，它使用掩蔽重建损失来学习每个图像块的语义贡献。我们首先使用仅视觉基准来评估局部对齐，发现它可以提高模型在块级语义分割任务中的表现，尤其是对于使用图像标题对训练的强大主干（例如 CLIP 和 SigLIP）。然后，我们训练了一系列具有和不具有局部对齐的 VLM，并表明局部对齐的主干可以提高一系列基准的性能，特别是涉及空间理解的基准（例如 RefCOCO、OCID-Ref、TallyQA、VSR、AI2D）。总体而言，我们证明我们可以通过局部对齐阶段有效地学习局部语义提取，并且此过程补充了使用现成视觉主干的现有 VLM 训练方法。]]></description>
      <guid>https://arxiv.org/abs/2410.11087</guid>
      <pubDate>Wed, 16 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>EchoApex：超声心动图通用视觉基础模型</title>
      <link>https://arxiv.org/abs/2410.11092</link>
      <description><![CDATA[arXiv:2410.11092v1 公告类型：新
摘要：定量评估超声心动图对于精确评估心脏状况、监测疾病进展和指导治疗决策至关重要。回声图像的多样性，包括探头类型、制造商和病理的变化，对开发可以在不同临床实践中推广的人工智能模型提出了挑战。我们推出了 EchoApex，这是第一个通用视觉基础模型超声心动图，可应用于各种临床实践。利用自我监督学习，EchoApex 在来自 11 个临床中心的 2000 多万张回声图像上进行了预训练。通过结合特定于任务的解码器和适配器模块，我们展示了 EchoApex 在 4 种不同类型的临床应用上的有效性，包括 28 个子任务，包括视图分类、交互式结构分割、左心室肥大检测和从视图序列自动估计射血分数。与最先进的任务专用模型相比，EchoApex 凭借统一的图像编码架构实现了更高的性能，展示了使用域内数据进行大规模模型预训练的优势。此外，EchoApex 还展示了开发专门针对超声心动图的通用视觉基础模型的潜力，该模型能够高效、高效地解决各种临床应用。]]></description>
      <guid>https://arxiv.org/abs/2410.11092</guid>
      <pubDate>Wed, 16 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用多输入架构和 CNN 模型对健康和有缺陷的水果进行分类</title>
      <link>https://arxiv.org/abs/2410.11108</link>
      <description><![CDATA[arXiv:2410.11108v1 公告类型：新
摘要：本研究介绍了利用多输入架构将水果（苹果和芒果）分类为健康和有缺陷状态的研究，其中采用了 RGB 和轮廓图像。主要目的是提高 CNN 模型的准确性。该方法包括图像采集、数据集预处理、训练和评估两个 CNN 模型：MobileNetV2 和 VGG16。结果表明，与仅使用 RGB 图像进行水果分类（无论是健康的还是有缺陷的）相比，在多输入架构中加入轮廓图像可产生性能更优越的模型。具体而言，使用 MobileNetV2 模型可获得最佳结果，准确率达到 100%。这一发现表明这种组合方法在提高健康或有缺陷水果的精确分类方面的有效性，这可能对与水果外部质量检查相关的应用具有重要意义。]]></description>
      <guid>https://arxiv.org/abs/2410.11108</guid>
      <pubDate>Wed, 16 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MoonMetaSync：月球图像配准分析</title>
      <link>https://arxiv.org/abs/2410.11118</link>
      <description><![CDATA[arXiv:2410.11118v1 公告类型：新
摘要：本文比较了尺度不变 (SIFT) 和尺度变化 (ORB) 特征检测方法，以及我们专门应用于月球图像的新型特征检测器 IntFeat。我们使用低分辨率 (128x128) 和高分辨率 (1024x1024) 月球图像块评估这些方法，深入了解它们在具有挑战性的外星环境中跨尺度的性能。IntFeat 将来自 SIFT 的高级特征和来自 ORB 的低级特征组合到单个向量空间中，以实现稳健的月球图像配准。我们引入了 SyncVision，这是一个 Python 包，它使用各种配准方法（包括 SIFT、ORB 和 IntFeat）比较月球图像。我们的分析包括使用双线性和双三次插值对低分辨率月球图像进行升级，为跨尺度配准效果和月球景观中的特征检测器提供了独特的视角。这项研究通过比较月球图像的特征检测方法并引入一种用于月球图像配准和评估的多功能工具，为计算机视觉和行星科学做出了贡献，对太空探索应用中的多分辨率图像分析具有重要意义。]]></description>
      <guid>https://arxiv.org/abs/2410.11118</guid>
      <pubDate>Wed, 16 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用无人机影像对棕榈树进行实时定位和双峰点模式分析</title>
      <link>https://arxiv.org/abs/2410.11124</link>
      <description><![CDATA[arXiv:2410.11124v1 公告类型：新
摘要：了解热带森林中棕榈树的空间分布对于有效的生态监测、保护战略以及将天然林产品可持续地整合到当地和全球供应链中至关重要。然而，在这些环境中分析遥感数据面临着重大挑战，例如棕榈树和树冠重叠、树冠表面阴影不均匀以及森林景观的异质性，这些挑战通常会影响棕榈树检测和分割算法的性能。为了克服这些问题，我们引入了 PalmDSNet，这是一个用于实时检测、分割和计数树冠棕榈树的深度学习框架。此外，我们采用了一种模拟棕榈树空间传播的双峰再现算法，以进一步利用 PalmDSNet 的结果增强对这些点模式的理解。我们利用无人机拍摄的图像，从厄瓜多尔西部热带森林的 21 个地点创建了正射影像图，覆盖了从哥伦比亚附近常湿的乔科森林到厄瓜多尔西南部较干燥的森林的梯度。专家注释被用来创建一个综合数据集，包括图像块上的 7,356 个边界框和五个正射影像图中的 7,603 个棕榈树中心，总面积为 449 公顷。通过将 PalmDSNet 与双峰再现算法相结合，该算法优化了局部和全局空间变异性的参数，我们有效地模拟了棕榈树在多样化和密集的热带环境中的空间分布，验证了其在热带森林监测和遥感分析中的高级应用的实用性。]]></description>
      <guid>https://arxiv.org/abs/2410.11124</guid>
      <pubDate>Wed, 16 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>UAV3D：无人机大规模3D感知基准</title>
      <link>https://arxiv.org/abs/2410.11125</link>
      <description><![CDATA[arXiv:2410.11125v1 公告类型：新
摘要：配备摄像头的无人机 (UAV) 被用于航空摄影、监视和农业等众多应用。在这些应用中，强大的物体检测和跟踪对于无人机的有效部署至关重要。然而，现有的无人机应用基准主要针对传统的 2D 感知任务而设计，限制了需要对环境进行 3D 理解的现实世界应用的开发。此外，尽管单无人机感知方面取得了最新进展，但单个无人机平台的有限视野严重限制了其在长距离或遮挡区域的感知能力。为了应对这些挑战，我们推出了 UAV3D，这是一个旨在推进无人机 3D 和协作 3D 感知任务研究的基准。UAV3D 包含 1,000 个场景，每个场景有 20 帧，其中包含车辆上完全注释的 3D 边界框。我们为四项 3D 感知任务提供了基准：单无人机 3D 物体检测、单无人机物体跟踪、协作无人机 3D 物体检测和协作无人机物体跟踪。我们的数据集和代码可在 https://huiyegit.github.io/UAV3D_Benchmark/ 上找到。]]></description>
      <guid>https://arxiv.org/abs/2410.11125</guid>
      <pubDate>Wed, 16 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>