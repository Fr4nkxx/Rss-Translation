<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CV 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Mon, 14 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>利用颜色模型信息编码位平面提高脉冲神经网络准确率</title>
      <link>https://arxiv.org/abs/2410.08229</link>
      <description><![CDATA[arXiv:2410.08229v1 公告类型：新
摘要：脉冲神经网络 (SNN) 已成为计算神经科学和人工智能领域一个有前途的范例，具有能耗低、内存占用小等优势。然而，它们的实际应用受到几个挑战的限制，其中最突出的是性能优化。在本研究中，我们提出了一种新方法，通过一种新的编码方法来提高 SNN 的性能，该方法利用从输入图像数据的各种颜色模型中得到的位平面进行脉冲编码。我们提出的技术旨在提高 SNN 的计算精度，与传统方法相比，而不增加模型大小。通过广泛的实验验证，我们证明了我们的编码策略在实现多个计算机视觉任务的性能提升方面的有效性。据我们所知，这是首次在 SNN 环境中应用颜色空间的研究。通过利用颜色空间的独特特性，我们希望释放SNN性能的新潜力，为未来研究和应用中更高效、更有效的SNN模型铺平道路。]]></description>
      <guid>https://arxiv.org/abs/2410.08229</guid>
      <pubDate>Mon, 14 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>对 YOLOv9 进行微调以进行车辆检测：孟加拉国达卡智能交通系统的深度学习</title>
      <link>https://arxiv.org/abs/2410.08230</link>
      <description><![CDATA[arXiv:2410.08230v1 公告类型：新
摘要：达卡等世界各地特大城市的快速城市化带来了许多需要解决的交通挑战。深度学习和人工智能等新兴技术可以帮助我们解决这些问题，从而向城市智能交通系统 (ITS) 迈进。孟加拉国政府认识到，整合 ITS 以确保智能出行是实现“智能孟加拉国愿景 2041”发展计划的重要一步，但在理解 ITS、其影响和实施方向方面面临挑战。车辆检测系统可以为了解交通拥堵、发现出行模式和确保交通监控铺平道路。因此，本文提出了一种经过微调的物体检测器，即 YOLOv9 模型，用于检测基于孟加拉国数据集训练的本地车辆。结果表明，经过微调的 YOLOv9 模型在 IoU 阈值为 0.5 时实现了平均精度 (mAP) 0.934，与过去基于孟加拉国的数据集的研究相比，取得了最佳性能，这通过比较可以看出。后来，通过建议将该模型部署在道路上的闭路电视 (CCTV) 上，提出了一种概念技术，以图形结构处理车辆检测模型输出数据，从而在城市中创建车辆检测系统。最后，讨论了这种车辆检测系统的应用，展示了它如何解决进一步的 ITS 研究问题的框架，为政策制定者在城市中实施拟议的车辆检测系统提供了理论依据。]]></description>
      <guid>https://arxiv.org/abs/2410.08230</guid>
      <pubDate>Mon, 14 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于内在动力学视觉基础的神经材料适配器</title>
      <link>https://arxiv.org/abs/2410.08257</link>
      <description><![CDATA[arXiv:2410.08257v1 公告类型：新
摘要：虽然人类可以毫不费力地辨别内在动态并适应新场景，但现代人工智能系统往往举步维艰。当前用于动态视觉接地的方法要么使用纯基于神经网络的模拟器（黑盒），这可能会违反物理定律，要么使用传统的物理模拟器（白盒），这依赖于专家定义的方程，可能无法完全捕捉实际动态。我们提出了神经材料适配器 (NeuMA)，它将现有的物理定律与学习到的校正相结合，促进对实际动态的准确学习，同时保持物理先验的普遍性和可解释性。此外，我们提出了粒子驱动的 3D 高斯溅射变体 Particle-GS，它连接模拟和观察到的图像，允许反向传播图像梯度以优化模拟器。在接地粒子精度、动态渲染质量和泛化能力方面对各种动态的综合实验表明，NeuMA 可以准确捕捉内在动态。]]></description>
      <guid>https://arxiv.org/abs/2410.08257</guid>
      <pubDate>Mon, 14 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>寻找被遗忘的领域泛化</title>
      <link>https://arxiv.org/abs/2410.08258</link>
      <description><![CDATA[arXiv:2410.08258v1 公告类型：新
摘要：域外 (OOD) 泛化是指在一个或多个域上训练的模型能够推广到看不见的域的能力。在计算机视觉的 ImageNet 时代，用于衡量模型 OOD 性能的评估集被设计为在风格方面严格符合 OOD。然而，基础模型和广泛的网络规模数据集的出现混淆了这一评估过程，因为数据集涵盖了广泛的领域并存在测试域污染的风险。为了寻找被遗忘的领域泛化，我们从 LAION（LAION-Natural 和 LAION-Rendition）中创建了大规模数据集，这些数据集在风格方面严格符合相应的 ImageNet 和 DomainNet 测试集。在这些数据集上训练 CLIP 模型表明，它们性能的很大一部分是由域内示例解释的。这表明 ImageNet 时代的 OOD 泛化挑战仍然存在，而对网络规模数据的训练仅仅创造了 OOD 泛化的假象。此外，通过系统地探索以不同比例组合自然数据集和再现数据集，我们确定了在这些领域中进行模型泛化的最佳混合比例。我们的数据集和结果重新实现了对大规模 OOD 稳健性的有意义的评估——这是提高模型稳健性的关键先决条件。]]></description>
      <guid>https://arxiv.org/abs/2410.08258</guid>
      <pubDate>Mon, 14 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Koala-36M：提高细粒度条件与视频内容一致性的大规模视频数据集</title>
      <link>https://arxiv.org/abs/2410.08260</link>
      <description><![CDATA[arXiv:2410.08260v1 公告类型：新
摘要：随着视觉生成技术的不断发展，视频数据集的规模迅速扩大，这些数据集的质量对视频生成模型的性能至关重要。我们认为时间分割、详细字幕和视频质量过滤是决定数据集质量的三个关键因素。然而，现有的数据集在这些方面表现出各种局限性。为了应对这些挑战，我们引入了 Koala-36M，这是一个大规模、高质量的视频数据集，具有准确的时间分割、详细的字幕和卓越的视频质量。我们方法的核心在于提高细粒度条件和视频内容之间的一致性。具体来说，我们在概率分布上使用线性分类器来提高过渡检测的准确性，确保更好的时间一致性。然后，我们为分割后的视频提供结构化字幕，平均长度为 200 个字，以改善文本-视频对齐。此外，我们开发了视频训练适用性评分 (VTSS)，该评分集成了多个子指标，使我们能够从原始语料库中筛选出高质量的视频。最后，我们将多个指标纳入生成模型的训练过程，进一步细化细粒度条件。我们的实验证明了我们数据处理流程的有效性以及所提出的 Koala-36M 数据集的质量。我们的数据集和代码将在 https://koala36m.github.io/ 上发布。]]></description>
      <guid>https://arxiv.org/abs/2410.08260</guid>
      <pubDate>Mon, 14 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Meissonic：重振蒙版生成变压器，实现高效的高分辨率文本到图像合成</title>
      <link>https://arxiv.org/abs/2410.08261</link>
      <description><![CDATA[arXiv:2410.08261v1 公告类型：新
摘要：扩散模型（例如稳定扩散）在视觉生成方面取得了重大进展，但它们的范式与自回归语言模型仍然有根本区别，这使得统一语言视觉模型的开发变得复杂。最近的努力（例如 LlamaGen）尝试使用离散 VQVAE 标记进行自回归图像生成，但涉及的大量标记使得这种方法效率低下且速度缓慢。在这项工作中，我们提出了 Meissonic，它将非自回归掩蔽图像建模 (MIM) 文本到图像提升到与 SDXL 等最先进的扩散模型相当的水平。通过整合一套全面的架构创新、先进的位置编码策略和优化的采样条件，Meissonic 大大提高了 MIM 的性能和效率。此外，我们利用高质量的训练数据，整合由人类偏好分数决定的微条件，并使用特征压缩层来进一步增强图像保真度和分辨率。我们的模型在生成高质量、高分辨率图像方面不仅与 SDXL 等现有模型相当，而且往往超越了它们的性能。大量实验验证了 Meissonic 的功能，展示了其作为文本到图像合成新标准的潜力。我们发布了一个能够生成 $1024 \times 1024$ 分辨率图像的模型检查点。]]></description>
      <guid>https://arxiv.org/abs/2410.08261</guid>
      <pubDate>Mon, 14 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>NPU-CIM 异构 AR/VR 设备混合模型的神经架构搜索</title>
      <link>https://arxiv.org/abs/2410.08326</link>
      <description><![CDATA[arXiv:2410.08326v1 公告类型：新
摘要：低延迟和低功耗边缘 AI 对于虚拟现实和增强现实应用至关重要。最近的进展表明，结合卷积层 (CNN) 和变压器 (ViT) 的混合模型通常可以在各种计算机视觉和机器学习 (ML) 任务中实现出色的准确度/性能权衡。然而，由于混合 ML 模型在数据流和内存访问模式方面的多样性，它们可能会对延迟和能效带来系统挑战。在这项工作中，我们利用神经处理单元 (NPU) 和内存计算 (CIM) 的架构异构性，并执行不同的执行模式以有效执行这些混合模型。我们还引入了 H4H-NAS，这是一个神经架构搜索框架，用于为具有 NPU 和 CIM 的异构边缘系统设计高效的混合 CNN/ViT 模型。我们的 H4H-NAS 方法由一个性能评估器提供支持，该评估器基于在真实硅片上测量的 NPU 性能结果和基于行业 IP 的 CIM 性能构建而成。H4H-NAS 以细粒度搜索混合 CNN/ViT 模型，并在 ImageNet 数据集上实现了显著（高达 1.34%）的 top-1 准确率提升。此外，通过引入这种异构计算，我们的 Algo/HW 联合设计结果显示，与基线解决方案相比，总体延迟降低了 56.08%，能耗降低了 41.72%。该框架指导了 NPU+CIM 异构系统的混合网络架构和系统架构的设计。]]></description>
      <guid>https://arxiv.org/abs/2410.08326</guid>
      <pubDate>Mon, 14 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>人工智能产生的情绪与人类评估之间的一致程度：一种方法论建议</title>
      <link>https://arxiv.org/abs/2410.08332</link>
      <description><![CDATA[arXiv:2410.08332v1 公告类型：新
摘要：图像能够传达情感，但情感体验非常主观。人工智能的进步使得基于情感描述的图像生成成为可能。然而，生成图像与人类情感反应之间的一致性水平尚未得到评估。为了解决这个问题，使用 StyleGAN2-ADA 生成了 20 幅艺术风景画。为每幅图像创建了四种唤起积极情绪（满足、娱乐）和消极情绪（恐惧、悲伤）的变体，共得到 80 张图片。利用这些材料设计了一份在线问卷，其中 61 名观察者对生成的图像进行分类。对收集到的数据进行统计分析，以确定参与者之间、观察者的反应与人工智能生成的情绪之间的一致性水平。结果发现一致性水平普遍较好，消极情绪的结果更好。然而，这项研究证实了情感评估固有的主观性。]]></description>
      <guid>https://arxiv.org/abs/2410.08332</guid>
      <pubDate>Mon, 14 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AgroGPT：经过专家调优的高效农业视觉语言模型</title>
      <link>https://arxiv.org/abs/2410.08405</link>
      <description><![CDATA[arXiv:2410.08405v1 公告类型：新
摘要：利用在线提供的大量图像文本数据，在推进大型多模态对话模型 (LMM) 方面取得了重大进展。尽管取得了这些进展，但这些模型经常遇到巨大的领域差距，阻碍了它们在新的领域进行复杂对话的能力。最近的努力旨在缓解这个问题，尽管依靠特定领域的图像文本数据来整理指令调整数据。然而，许多领域，如农业，缺乏这样的视觉语言数据。在这项工作中，我们提出了一种构建指令调整数据的方法，该方法利用农业领域的视觉数据。我们利用跨多个领域的多样化农业数据集，整理特定于类的信息，并使用大型语言模型 (LLM) 来构建专家调整集，从而得到一个名为 AgroInstruct 的 70k 专家调整数据集。随后，我们经过专家调优，创建了 AgroGPT，这是一种高效的 LMM，可以进行复杂的农业相关对话并提供有用的见解。我们还开发了 AgroEvals 进行评估，并将 {AgroGPT} 的性能与大型开源和闭源模型进行比较。{AgroGPT} 擅长识别细粒度的农业概念，可以充当农业专家，并为多模态农业问题提供有用的信息。代码、数据集和模型可在 https://github.com/awaisrauf/agroGPT 上找到。]]></description>
      <guid>https://arxiv.org/abs/2410.08405</guid>
      <pubDate>Mon, 14 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>优化 YOLO 架构以实现最佳道路损坏检测和分类：YOLOv7 与 YOLOv10 的比较研究</title>
      <link>https://arxiv.org/abs/2410.08409</link>
      <description><![CDATA[arXiv:2410.08409v1 公告类型：新
摘要：维护道路基础设施对于确保安全、高效和可持续的交通系统至关重要。然而，手动收集数据来检测道路损坏既费时又费力，而且存在安全风险。人工智能（尤其是深度学习）的最新进展为使用道路图像自动化这一过程提供了一种有希望的解决方案。本文介绍了一种使用深度学习模型进行道路损坏检测的综合工作流程，重点是优化推理速度，同时保持检测精度。具体来说，为了适应硬件限制，裁剪大图像并使用轻量级模型。此外，还结合了外部坑洼数据集来增强对这种代表性不足的损坏类别的检测。所提出的方法采用了多种模型架构，包括具有坐标注意层的自定义 YOLOv7 模型和 Tiny YOLOv7 模型，这些模型经过训练和组合以最大限度地提高检测性能。这些模型进一步重新参数化以优化推理效率。实验结果表明，自定义 YOLOv7 模型（包含三个 Coordinate Attention 层）与默认 Tiny YOLOv7 模型的集成可实现 0.7027 的 F1 得分，推理速度为每张图像 0.0547 秒。完整的流程（包括数据预处理、模型训练和推理脚本）已在项目的 GitHub 存储库中公开，从而实现了可重复性并促进了进一步的研究。]]></description>
      <guid>https://arxiv.org/abs/2410.08409</guid>
      <pubDate>Mon, 14 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>人类石器制作动作语法 (HSTAG)：细粒度运动行为识别的具有挑战性的基准</title>
      <link>https://arxiv.org/abs/2410.08410</link>
      <description><![CDATA[arXiv:2410.08410v1 公告类型：新 
摘要：在过去十年中，动作识别见证了越来越多新算法和数据集的发展。然而，大多数公共基准都是围绕日常生活活动构建的，并且注释得相当粗粒度，这在特定领域的数据集中缺乏多样性，尤其是对于很少见的领域。在本文中，我们介绍了人类石器制作动作语法 (HSTAG)，这是一个经过精心注释的视频数据集，展示了以前未记录的石器制作行为，可用于研究先进的人工智能技术在理解两个手持物体之间快速连续的复杂交互中的应用。HSTAG 由 18,739 个视频片段组成，记录了专家在石器制作中的 4.5 小时活动。其独特功能包括 (i) 动作持续时间短、转换频繁，反映了许多运动行为固有的快速变化； (ii) 多个视角和多种工具之间的切换，增加了类内变异性；(iii) 类分布不均衡，不同动作序列之间的相似性高，增加了捕捉每个动作的不同模式的难度。使用几种主流动作识别模型进行实验分析，展示了 HSTAG 的挑战和独特性 https://nyu.databrary.org/volume/1697。]]></description>
      <guid>https://arxiv.org/abs/2410.08410</guid>
      <pubDate>Mon, 14 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>HorGait：利用 LiDAR 点云中的高效高阶空间交互来推进步态识别</title>
      <link>https://arxiv.org/abs/2410.08454</link>
      <description><![CDATA[arXiv:2410.08454v1 Announce Type: new 
摘要：步态识别是一种远程生物识别技术，利用人体运动的动态特征，即使在各种极端光照条件下也能识别个体。由于二维步态表征在空间感知能力上的局限性，LiDAR可以直接捕捉三维步态特征并将其表示为点云，在减少环境和光照对识别的干扰的同时，大大提高了隐私保护的效率。对于复杂的三维表征，浅层网络无法实现精准识别，视觉Transformers成为最流行的方法。然而，dumb patch的盛行限制了Transformer架构在步态识别中的广泛应用。本文提出了一种HorGait方法，利用Transformer架构的混合模型在LiDAR三维点云的平面投影上进行步态识别。具体来说，它采用了一种称为LHM Block的混合模型结构来实现Transformer架构的输入自适应、长距离和高阶空间交互。此外，它使用大卷积核 CNN 来分割输入表征，替换注意力窗口以减少哑块。我们进行了大量的实验，结果表明 HorGait 在 SUSTech1K 数据集上取得了 Transformer 架构方法中的最佳性能，验证了混合模型可以完成完整的 Transformer 过程，并且在点云平面投影中表现更好。HorGait 的出色表现为 Transformer 架构在步态识别中的未来应用提供了新的见解。]]></description>
      <guid>https://arxiv.org/abs/2410.08454</guid>
      <pubDate>Mon, 14 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于领域通用行人重新识别的统一深度语义扩展框架</title>
      <link>https://arxiv.org/abs/2410.08456</link>
      <description><![CDATA[arXiv:2410.08456v1 公告类型：新
摘要：监督行人重新识别（Person ReID）方法在一个摄像机网络内进行训练和测试时取得了出色的性能。然而，当应用于不同的摄像机系统时，它们通常会遭受相当大的性能下降。近年来，已经提出了许多领域自适应行人重新识别方法，在不需要目标域的标记数据的情况下实现了令人印象深刻的性能。然而，这些方法在训练过程中仍然需要目标域的未标记数据，这使得它们在许多现实场景中不切实际。我们的工作重点是更实用的领域广义行人重新识别（DG-ReID）问题。给定一个或多个源域，它旨在学习一个可以应用于看不见的目标域的广义模型。DG-ReID 中一个有前途的研究方向是使用隐式深度语义特征扩展，我们之前的方法域嵌入扩展（DEX）就是在 DG-ReID 中取得强大结果的一个例子。然而，在这项研究中，我们表明，由于 DEX 和其他类似的隐式深度语义特征扩展方法所提出的损失函数存在局限性，它们往往过早饱和，因此无法在大型评估基准上充分发挥其潜力。基于这一分析，我们提出了统一深度语义扩展，这是我们的新颖框架，它将隐式和显式语义特征扩展技术统一在一个框架中，以缓解这种早期过度拟合，并在所有 DG-ReID 基准中实现新的最先进 (SOTA)。此外，我们将我们的方法应用于更通用的图像检索任务，并在所有这些基准中都远远超过了当前的 SOTA。]]></description>
      <guid>https://arxiv.org/abs/2410.08456</guid>
      <pubDate>Mon, 14 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>面向全领域广义行人重新识别的多样化深度特征集成学习</title>
      <link>https://arxiv.org/abs/2410.08460</link>
      <description><![CDATA[arXiv:2410.08460v1 公告类型：新
摘要：行人重新识别 (Person ReID) 已经发展到单域监督行人重新识别性能饱和的水平。然而，这种方法在不同数据集上进行训练和测试时，性能会显著下降，从而推动了领域泛化技术的发展。然而，我们的研究表明，领域泛化方法在单个数据集基准上的表现明显不如单域监督方法。理想的行人重新识别方法应该无论涉及的域数有多少都是有效的，并且当测试域数据可用于训练时，它的表现应该与最先进的 (SOTA) 完全监督方法一样好。这是一个我们称之为全域泛化行人重新识别 (ODG-ReID) 的范例。我们提出了一种通过使用自集成创建深度特征多样性来实现 ODG-ReID 的方法。我们的方法，多样化深度特征集成学习 (D2FEL)，部署了独特的实例规范化模式，可生成多个不同的视图并将这些视图重新组合成紧凑的编码。据我们所知，我们的工作是少数考虑 Person ReID 中的全域泛化的工作之一，并且我们推进了在 Person ReID 中应用特征集成的研究。D2FEL 显著提高并匹配了主要领域泛化和单领域监督基准的 SOTA 性能。]]></description>
      <guid>https://arxiv.org/abs/2410.08460</guid>
      <pubDate>Mon, 14 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>对齐发散路径以实现全领域广义行人重新识别</title>
      <link>https://arxiv.org/abs/2410.08466</link>
      <description><![CDATA[arXiv:2410.08466v1 公告类型：新
摘要：行人重新识别 (Person ReID) 在完全监督和领域通用的行人重新识别方面取得了重大进展。然而，为一个任务领域开发的方法很难转移到另一个任务领域。理想的行人重新识别方法应该有效，无论训练或测试涉及的领域数量如何。此外，给定来自目标域的训练数据，它的性能至少应该与最先进的 (SOTA) 完全监督的行人重新识别方法一样好。我们将这种范式称为全域通用行人重新识别 (Omni-Domain Generalization Person ReID)，简称为 ODG-ReID，并提出了一种通过将兼容的主干架构扩展为多个不同路径来实现这一目标的方法。我们的方法，对齐发散路径 (ADP)，首先通过复制原始主干的尾部将基础架构转换为多分支结构。我们设计了动态最大偏差自适应实例规范化 (DyMAIN) 模块，鼓励学习对全域方向具有鲁棒性的广义特征，并将 DyMAIN 应用于 ADP 的分支。我们提出的分阶段余弦混合 (PMoC) 协调了分支之间稳定和动荡的学习率计划的混合，以实现进一步的多样化学习。最后，我们使用我们提出的维度一致性度量损失 (DCML) 重新调整分支之间的特征空间。ADP 在同一域内的多源域泛化和监督 ReID 方面的表现优于最先进的 (SOTA) 结果。此外，我们的方法在广泛的单源域泛化基准上表现出色，实现了人员 ReID 任务的全域泛化。]]></description>
      <guid>https://arxiv.org/abs/2410.08466</guid>
      <pubDate>Mon, 14 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>