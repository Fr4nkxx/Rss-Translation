<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CV 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Thu, 23 Jan 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>ImageRef-VL：在视觉语言模型中实现上下文图像引用</title>
      <link>https://arxiv.org/abs/2501.12418</link>
      <description><![CDATA[arXiv:2501.12418v1 公告类型：新
摘要：视觉语言模型 (VLM) 在理解多模态输入方面表现出了卓越的能力，并已广泛应用于基于检索增强生成 (RAG) 的对话系统。虽然目前由 VLM 驱动的聊天机器人可以在响应中提供文本源引用，但它们在对话过程中引用上下文相关图像方面表现出很大的局限性。在本文中，我们介绍了上下文图像引用——根据对话上下文适当地引用检索文档中的相关图像的能力——并系统地研究了 VLM 在这方面的能力。我们对上下文图像引用进行了首次评估，包括专用的测试数据集和评估指标。此外，我们提出了 ImageRef-VL，这种方法通过对大规模、手动策划的多模态对话数据集进行指令微调，显著增强了开源 VLM 的图像引用能力。实验结果表明，ImageRef-VL 不仅优于专有模型，而且在上下文图像引用任务中比最先进的开源 VLM 性能提高了 88%。我们的代码可在 https://github.com/bytedance/ImageRef-VL 上找到。]]></description>
      <guid>https://arxiv.org/abs/2501.12418</guid>
      <pubDate>Thu, 23 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>猫头鹰很聪明，狐狸不忠诚：揭示视觉语言模型中的动物刻板印象</title>
      <link>https://arxiv.org/abs/2501.12433</link>
      <description><![CDATA[arXiv:2501.12433v1 公告类型：新
摘要：动物刻板印象深深植根于人类文化和语言中。它们常常塑造我们对各种物种的看法和期望。我们的研究调查了动物刻板印象在图像生成任务中如何在视觉语言模型中体现。通过有针对性的提示，我们探索 DALL-E 是否会延续对动物的刻板印象，例如“猫头鹰是聪明的”、“狐狸是不忠诚的”等。我们的研究结果揭示了模型持续生成与文化偏见相符的图像的显著刻板印象实例。当前的研究是首次系统地研究视觉语言模型中的动物刻板印象，并强调人工智能生成的视觉内容中一个关键但尚未充分探索的偏见维度。]]></description>
      <guid>https://arxiv.org/abs/2501.12433</guid>
      <pubDate>Thu, 23 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>TOFFE——基于事件的临时对象流，用于高速、节能的对象检测和跟踪</title>
      <link>https://arxiv.org/abs/2501.12482</link>
      <description><![CDATA[arXiv:2501.12482v1 公告类型：新
摘要：物体检测和跟踪是实现机器人系统完全自主导航的重要感知任务。边缘机器人系统（例如小型无人机）需要在有限的资源下高速执行复杂的动作，这对底层算法和硬件提出了严格的限制。传统上，基于帧的相机由于其丰富的空间信息和简化的同步感知能力而用于基于视觉的感知。但是，跨帧获取详细信息会导致高能耗，甚至可能不需要。此外，它们的低时间分辨率使它们在高速运动场景中无效。基于事件的相机通过以极高的时间分辨率和低功耗仅捕获强度水平的变化，提供了一种受生物启发的解决方案，使其成为高速运动场景的理想选择。但是，它们的异步和稀疏输出并不适用于传统的深度学习方法。在这项工作中，我们提出了 TOFFE，这是一个用于执行基于事件的物体运动估计（包括姿势、方向和速度估计）的轻量级混合框架，称为 Object Flow。 TOFFE 集成了生物启发式脉冲神经网络 (SNN) 和传统模拟神经网络 (ANN)，能够高效处理高时间分辨率的事件，同时易于训练。此外，我们还提出了一种基于事件的新型合成数据集，该数据集涉及高速物体运动，用于训练 TOFFE。我们的实验结果表明，与之前基于事件的物体检测基线相比，TOFFE 在边缘 GPU（Jetson TX2）/混合硬件（Loihi-2 和 Jetson TX2）上实现了能耗降低 5.7 倍/8.3 倍、延迟降低 4.6 倍/5.8 倍。]]></description>
      <guid>https://arxiv.org/abs/2501.12482</guid>
      <pubDate>Thu, 23 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>fabSAM：基于 Segment Anything 模型的农田边界划定方法</title>
      <link>https://arxiv.org/abs/2501.12487</link>
      <description><![CDATA[arXiv:2501.12487v1 公告类型：新
摘要：划定农田边界对于农作物监测和农业普查等农业管理至关重要。使用遥感图像的传统方法虽然有效，但通用性有限。以令人印象深刻的零样本性能而闻名的 Segment Anything 模型 (SAM) 已通过快速学习和微调适应遥感任务。在这里，我们提出了一个基于 SAM 的农田边界划定框架“fabSAM”，它结合了基于 Deeplabv3+ 的 Prompter 和 SAM。此外，还引入了一种微调策略，使 SAMs 解码器能够改进对提示信息的使用。在 AI4Boundaries 和 AI4SmallFarms 数据集上的实验结果表明，fabSAM 在农田区域识别和边界划定方面有显著的改善。与零样本 SAM 相比，fabSAM 在 AI4Boundaries 和 AI4SmallFarms 数据集上的 mIOU 分别比零样本 SAM 高出 23.5% 和 15.1%。对于 Deeplabv3+，fabSAM 在 mIOU 上分别比零样本 SAM 高出 4.9% 和 12.5%。这些结果凸显了 fabSAM 的有效性，这也意味着我们可以更轻松地从 Sentinel2 等开源卫星图像数据集中获取全球农田区域和边界图。]]></description>
      <guid>https://arxiv.org/abs/2501.12487</guid>
      <pubDate>Thu, 23 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大图像物体检测，用于中世纪板画中穿孔图案的细粒度识别</title>
      <link>https://arxiv.org/abs/2501.12489</link>
      <description><![CDATA[arXiv:2501.12489v1 公告类型：新
摘要：艺术品作者的归属通常是一个费力的手动过程，通常依赖于专家的主观评价。然而，在某些情况下，艺术品的定量特征可以支持这些评估。这些特征的提取有时可以自动化，例如，使用机器学习 (ML) 技术。这些特征的一个例子是重复的、机械压印的图案，称为冲孔，主要出现在 13 世纪和 14 世纪的托斯卡纳板画中。艺术史的先前研究展示了冲孔形状与特定艺术家或工作室之间的紧密联系，这表明可以使用这些定量线索来支持归属。在目前的研究中，我们首先收集这些板画的大规模图像数据集。然后，使用最近流行的对象检测模型 YOLOv10，我们训练 ML 管道对图像中包含的冲孔执行对象检测。由于图像尺寸较大，检测过程采用重叠的滑动窗口方法，分为多个帧，然后使用自定义非最大抑制程序将整个图像的预测组合起来。我们的结果表明，在该领域工作的艺术史学家可以可靠地使用我们的方法来识别和提取打孔痕迹。]]></description>
      <guid>https://arxiv.org/abs/2501.12489</guid>
      <pubDate>Thu, 23 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ViDDAR：基于视觉语言模型的增强现实任务有害内容检测</title>
      <link>https://arxiv.org/abs/2501.12553</link>
      <description><![CDATA[arXiv:2501.12553v1 公告类型：新
摘要：在增强现实 (AR) 中，虚拟内容通过提供附加信息来增强用户体验。但是，位置或设计不当的虚拟内容可能会损害任务性能，因为它会削弱用户准确解释现实世界信息的能力。在本文中，我们研究了两种类型的任务有害虚拟内容：阻碍攻击，其中虚拟内容阻止用户看到现实世界的物体，以及信息操纵攻击，其中虚拟内容干扰用户准确解释现实世界信息的能力。我们提供了一个数学框架来描述这些攻击并创建了一个自定义开源数据集以进行攻击评估。为了应对这些攻击，我们推出了 ViDDAR（基于视觉语言模型的增强现实任务有害内容检测器），这是一个全面的全参考系统，利用视觉语言模型 (VLM) 和先进的深度学习技术来监控和评估 AR 环境中的虚拟内容，采用用户边缘云架构来平衡性能和低延迟。据我们所知，ViDDAR 是第一个在 AR 设置中使用 VLM 检测任务有害内容的系统。我们的评估结果表明，ViDDAR 可以有效理解复杂场景并检测任务有害内容，实现高达 92.15% 的障碍物检测准确率，检测延迟为 533 毫秒，实现 82.46% 的信息操纵内容检测准确率，延迟为 9.62 秒。]]></description>
      <guid>https://arxiv.org/abs/2501.12553</guid>
      <pubDate>Thu, 23 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>调整 OpenAI 的 CLIP 模型以用于制造质量控制中的小样本图像检测：具有多个应用示例的说明性案例研究</title>
      <link>https://arxiv.org/abs/2501.12596</link>
      <description><![CDATA[arXiv:2501.12596v1 公告类型：新
摘要：这篇说明性论文介绍了一种简化的基于图像的制造业质量检测方法，该方法使用 OpenAI 的 CLIP（对比语言-图像预训练）模型进行少量学习。虽然 CLIP 在一般计算机视觉任务中表现出令人印象深刻的能力，但由于其训练数据和工业应用之间的领域差距，将其直接应用于制造检测带来了挑战。我们通过五个案例研究评估了 CLIP 的有效性：金属盘表面检查、3D 打印挤压轮廓分析、随机纹理表面评估、汽车装配检查和微观结构图像分类。我们的结果表明，对于单组分和基于纹理的应用，CLIP 可以在相对较小的学习集（每个类 50-100 个示例）下实现较高的分类精度。然而，在复杂的多组分场景中，性能会下降。我们提供了一个实用的实施框架，使质量工程师能够在寻求更复杂的解决方案之前快速评估 CLIP 是否适合他们的特定应用。这项工作确立了基于 CLIP 的少样本学习作为一种有效的基线方法，它平衡了实施的简单性与稳健的性能，并在多个制造质量控制应用中得到了证明。]]></description>
      <guid>https://arxiv.org/abs/2501.12596</guid>
      <pubDate>Thu, 23 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>TeD-Loc：用于弱监督对象定位的文本蒸馏</title>
      <link>https://arxiv.org/abs/2501.12632</link>
      <description><![CDATA[arXiv:2501.12632v1 公告类型：新
摘要：使用仅使用图像类标签训练的分类模型进行弱监督对象定位 (WSOL) 仍然是计算机视觉中的一个重要挑战。鉴于对分类目标的依赖，传统的 WSOL 方法（如类激活映射）专注于最具辨别力的对象部分，通常会忽略整个空间范围。相比之下，最近基于视觉语言模型（如 CLIP）的 WSOL 方法需要地面实况类或外部分类器来生成定位图，从而限制了它们在下游任务中的部署。此外，像 GenPromp 这样的方法试图解决这些问题，但由于它们依赖于条件去噪过程和复杂的提示学习，因此引入了相当大的复杂性。本文介绍了用于定位的文本蒸馏 (TeD-Loc)，这种方法将 CLIP 文本嵌入中的知识直接提炼到模型主干中并产生补丁级定位。这些图像补丁的多实例学习允许使用一个模型进行准确的定位和分类，而无需外部分类器。这种文本和视觉模态的集成解决了同时实现准确定位和分类的长期挑战，因为文献中的 WSOL 方法通常在不同的时期收敛。大量实验表明，利用文本嵌入和定位线索可以提供经济高效的 WSOL 模型。TeD-Loc 在 CUB 和 ILSVRC 数据集上将 Top-1 LOC 准确率提高到领先模型的约 5%，同时与 GenPromp 相比显著降低了计算复杂度。]]></description>
      <guid>https://arxiv.org/abs/2501.12632</guid>
      <pubDate>Thu, 23 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多键多查询：基于提示的持续学习的精准提示匹配范式</title>
      <link>https://arxiv.org/abs/2501.12635</link>
      <description><![CDATA[arXiv:2501.12635v1 公告类型：新
摘要：持续学习要求机器学习模型在动态环境中不断获取新知识，同时避免遗忘先前的知识。基于提示的持续学习方法通​​过提示扩展和选择有效地解决了灾难性遗忘的问题。然而，现有的方法在提示选择方面往往存在准确率低的问题，这可能导致模型接收有偏差的知识并做出有偏差的预测。为了解决这个问题，我们提出了多键多查询 (MQMK) 提示匹配范式来实现精确的提示选择。MQMK 的目标是选择训练数据分布与测试样本分布最接近的提示。具体而言，多查询通过引入任务特定知识实现精确的广度搜索，而多键通过在细粒度级别表示训练样本的特征分布来执行深度搜索。实验表明，MQMK 在具有挑战性的场景中将即时匹配率提高了 30% 以上，并在三个广泛采用的持续学习基准上实现了最佳性能。一旦这篇论文被接受，我们将发布代码。]]></description>
      <guid>https://arxiv.org/abs/2501.12635</guid>
      <pubDate>Thu, 23 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DWTNeRF：通过离散小波变换增强小样本神经辐射场</title>
      <link>https://arxiv.org/abs/2501.12637</link>
      <description><![CDATA[arXiv:2501.12637v1 公告类型：新
摘要：神经辐射场 (NeRF) 在新型视图合成和 3D 场景表示方面取得了卓越的表现，但其实际应用受到收敛速度慢和对密集训练视图的依赖的阻碍。为此，我们提出了 DWTNeRF，这是一个基于 Instant-NGP 快速训练哈希编码的统一框架。它与为少样本 NeRF 设计的正则化项相结合，后者在稀疏训练视图上运行。我们的 DWTNeRF 包含一种新颖的离散小波损失，允许直接在训练目标中明确优先考虑低频，从而减少早期训练阶段少样本 NeRF 对高频的过度拟合。我们还介绍了一种基于多头注意力的基于模型的方法，该方法与对架构变化敏感的基于 INGP 的模型兼容。在 3 次 LLFF 基准测试中，DWTNeRF 在 PSNR 方面比 Vanilla NeRF 高出 15.07%，在 SSIM 方面高出 24.45%，在 LPIPS 方面高出 36.30%。我们的方法鼓励我们重新思考当前基于 INGP 模型的少样本方法。]]></description>
      <guid>https://arxiv.org/abs/2501.12637</guid>
      <pubDate>Thu, 23 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>掩盖背景和物体是否可以减少零样本动作识别的静态偏差？</title>
      <link>https://arxiv.org/abs/2501.12681</link>
      <description><![CDATA[arXiv:2501.12681v1 公告类型：新
摘要：在本文中，我们解决了零样本动作识别中的静态偏差问题。动作识别模型需要表示动作本身，而不是外观。然而，一些全监督工作表明，模型通常依赖于静态外观，例如背景和物体，而不是人类动作。这个被称为静态偏差的问题尚未在零样本中得到研究。虽然基于 CLIP 的零样本模型现在很常见，但它们是否充分关注人类动作仍不清楚，因为 CLIP 主要捕捉与语言相关的外观特征。在本文中，我们研究了静态偏差对基于 CLIP 的模型的零样本动作识别的影响。我们的方法包括在训练和验证期间以不同的方式掩盖背景、物体和人物。使用掩盖背景的实验表明，随着 Kinetics400 的性能下降，模型依赖于背景偏差。然而，对于具有弱背景偏差的 Mimetics，即使在验证期间掩盖背景，掩盖背景也会提高性能。此外，使用不同颜色遮盖背景和物体可提高 SSv2 的性能，因为 SSv2 具有很强的物体偏差。这些结果表明，在训练期间遮盖背景或物体可防止模型过度依赖静态偏差，并使它们更专注于人类行为。]]></description>
      <guid>https://arxiv.org/abs/2501.12681</guid>
      <pubDate>Thu, 23 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>结合知识图谱和 LLM 来增强零样本视觉问答</title>
      <link>https://arxiv.org/abs/2501.12697</link>
      <description><![CDATA[arXiv:2501.12697v1 公告类型：新
摘要：零样本视觉问答 (ZS-VQA) 是一个新兴的关键研究领域，旨在回答视觉问题而无需提供训练样本。ZS-VQA 中的现有研究提出分别利用知识图谱或大型语言模型 (LLM) 作为外部信息源，帮助 VQA 模型理解图像和问题。然而，LLM 往往难以准确解释特定的问题含义。同时，尽管知识图谱具有丰富的实体关系，但要有效地将实体连接到单个图像内容以提供视觉问题的答案却具有挑战性。在本文中，我们提出了一种新颖的设计，将知识图谱和 LLM 结合起来进行零样本视觉问答。我们的方法利用 LLM 强大的理解能力，通过战略性的问题搜索机制准确地解释图像内容。同时，知识图谱用于扩展和连接用户的查询到图像内容，以实现更好的视觉问答。进一步使用优化算法来确定来自不同信息源的损失函数的最佳权重，以得到一组全局最优的候选答案。在两个基准数据集上的实验结果表明，我们的模型达到了最先进的 (SOTA) 性能。源代码和基准数据都将发布供公众访问。]]></description>
      <guid>https://arxiv.org/abs/2501.12697</guid>
      <pubDate>Thu, 23 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>全模态人员重新识别的模态统一攻击</title>
      <link>https://arxiv.org/abs/2501.12761</link>
      <description><![CDATA[arXiv:2501.12761v1 公告类型：新
摘要：基于深度学习的人员重新识别 (re-id) 模型已广泛应用于监控系统。最近的研究表明，黑盒单模态和跨模态重新识别模型容易受到对抗性示例 (AE) 的攻击，而多模态重新识别模型的鲁棒性尚未得到探索。由于缺乏有关目标黑盒监控系统中部署的具体模型类型的知识，我们旨在为全模态 (单模态、跨模态和多模态) 重新识别模型生成模态统一 AE。具体而言，我们提出了一种新颖的模态统一攻击方法来训练特定于模态的对抗生成器以生成有效攻击不同全模态模型的 AE。采用多模态模型作为替代模型，其中融合之前每个模态的特征都受到度量破坏损失的干扰。为了破坏全模态模型的共同特征，引入了跨模态模拟破坏方法，通过故意将图像馈送到代理模型的非对应模态特定子网络来模拟跨模态特征嵌入。此外，设计了多模态协作破坏策略，以方便攻击者利用多模态特征协作度量破坏损失来全面破坏人物图像的信息内容。大量实验表明，我们的 MUA 方法可以有效攻击全模态重新识别模型，平均 mAP 丢失率分别达到 55.9%、24.4%、49.0% 和 62.7%。]]></description>
      <guid>https://arxiv.org/abs/2501.12761</guid>
      <pubDate>Thu, 23 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多阶人类视觉运动处理的机器学习建模</title>
      <link>https://arxiv.org/abs/2501.12810</link>
      <description><![CDATA[arXiv:2501.12810v1 公告类型：新
摘要：我们的研究旨在开发像人类一样学习感知视觉运动的机器。虽然计算机视觉 (CV) 的最新进展使基于 DNN 的模型能够准确估计自然图像中的光流，但 CV 模型与生物视觉系统在架构和行为方面仍然存在显着差异。这种差异包括人类感知高阶图像特征（二阶运动）运动的能力，许多 CV 模型由于依赖强度守恒定律而无法捕捉到这种运动。我们的模型架构模仿皮质 V1-MT 运动处理通路，利用可训练的运动能量传感器组和递归图网络。使用各种自然视频的监督学习使模型能够复制关于一阶（基于亮度）运动感知的心理物理和生理发现。对于二阶运动，受神经科学发现的启发，该模型包括一条额外的感知通路，在运动能量感知之前进行非线性预处理，使用简单的多层 3D CNN 块实现。在探索大脑如何获得在自然环境中感知二阶运动的能力时（在自然环境中，纯二阶信号很少见），我们假设二阶机制在估计光学波动中的稳健物体运动（例如光滑表面上的高光）时至关重要。我们在具有不同移动物体材料属性的新运动数据集上训练了我们的双通路模型。我们发现，训练以估计来自非朗伯材料的物体运动自然赋予了模型感知二阶运动的能力，就像人类一样。由此产生的模型有效地与生物系统保持一致，同时推广到自然场景中的一阶和二阶运动现象。]]></description>
      <guid>https://arxiv.org/abs/2501.12810</guid>
      <pubDate>Thu, 23 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用多源辅助任务增强单目深度估计</title>
      <link>https://arxiv.org/abs/2501.12824</link>
      <description><![CDATA[arXiv:2501.12824v1 公告类型：新
摘要：单目深度估计 (MDE) 是计算机视觉中的一项具有挑战性的任务，通常受到高质量标记数据集的成本和稀缺性的阻碍。我们使用来自相关视觉任务的辅助数据集来应对这一挑战，采用交替训练方案，在预先训练的视觉基础模型之上构建共享解码器，同时赋予 MDE 更高的权重。通过大量实验，我们证明了结合各种域内辅助数据集和任务的好处，平均可将 MDE 质量提高约 11%。我们的实验分析表明，辅助任务具有不同的影响，证实了任务选择的重要性，强调仅通过添加数据无法实现质量提升。值得注意的是，我们的研究表明，使用语义分割数据集作为多标签密集分类 (MLDC) 通常会带来额外的质量提升。最后，我们的方法显着提高了所考虑的 MDE 数据集的数据效率，提高了质量，同时将其大小减少了至少 80%。尽管高质量标记数据有限，但这为使用相关任务的辅助数据来提高 MDE 质量铺平了道路。代码可在 https://jugit.fz-juelich.de/ias-8/mdeaux 上找到。]]></description>
      <guid>https://arxiv.org/abs/2501.12824</guid>
      <pubDate>Thu, 23 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>