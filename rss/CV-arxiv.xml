<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CV 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Thu, 06 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>MIND：利用生成混合神经表征进行微结构逆向设计</title>
      <link>https://arxiv.org/abs/2502.02607</link>
      <description><![CDATA[arXiv:2502.02607v1 公告类型：新
摘要：微结构的逆向设计在优化具有特定、有针对性的物理特性的超材料方面起着关键作用。虽然传统的正向设计方法受到无法探索广阔的组合设计空间的限制，但逆向设计通过直接生成满足预定义性能标准的结构提供了一种引人注目的替代方案。然而，由于它们错综复杂的相互依赖性，实现对几何和材料特性的精确控制仍然是一项重大挑战。现有的方法通常依赖于体素或参数表示，通常会限制设计的灵活性和结构多样性。在这项工作中，我们提出了一种新颖的生成模型，该模型将潜在扩散与 Holoplane 相结合，Holoplane 是一种先进的混合神经表示，可同时编码几何和物理特性。这种组合确保了几何和属性之间的卓越一致性。我们的方法适用于多种微结构类别，能够生成多样化、可平铺的微结构，显着提高属性精度并增强对几何有效性的控制，超越现有方法的性能。我们引入了一个多类数据集，该数据集涵盖了各种几何形态，包括桁架、壳、管和板结构，以训练和验证我们的模型。实验结果表明，该模型能够生成满足目标属性的微结构，保持几何有效性，并无缝集成到复杂的组件中。此外，我们通过生成新的微结构、跨类插值和异质微结构的填充来探索我们框架的潜力。数据集和源代码将在发布后开源。]]></description>
      <guid>https://arxiv.org/abs/2502.02607</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于深度学习的老年人面部表情识别：系统评价</title>
      <link>https://arxiv.org/abs/2502.02618</link>
      <description><![CDATA[arXiv:2502.02618v1 公告类型：新
摘要：全球人口的快速老龄化凸显了对支持老年人的技术的需求，特别是在医疗保健和情绪健康方面。面部表情识别 (FER) 系统提供了一种监测情绪状态的非侵入性方法，可应用于辅助生活、心理健康支持和个性化护理。本研究对基于深度学习的 FER 系统进行了系统回顾，重点关注其在老年人群体中的应用。按照严格的方法，我们分析了过去十年发表的 31 项研究，解决了老年人专用数据集的稀缺、类别不平衡以及与年龄相关的面部表情差异的影响等挑战。我们的研究结果表明，卷积神经网络在 FER 中仍然占主导地位，尤其是针对资源受限环境的轻量级版本。然而，现有的数据集通常缺乏年龄表示的多样性，现实世界的部署仍然有限。此外，隐私问题和对可解释的人工智能的需求成为采用的主要障碍。本评论强调了开发涵盖年龄的数据集、集成多模态解决方案以及采用 XAI 技术来提高系统可用性、可靠性和可信度的重要性。最后，我们为未来的研究提供了建议，以弥合老年护理领域的学术进步与实际实施之间的差距。]]></description>
      <guid>https://arxiv.org/abs/2502.02618</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用形态膨胀去除盲可见水印</title>
      <link>https://arxiv.org/abs/2502.02676</link>
      <description><![CDATA[arXiv:2502.02676v1 公告类型：新
摘要：可见水印对图像恢复技术提出了重大挑战，尤其是在目标背景未知的情况下。为此，我们提出了 MorphoMod，这是一种自动可见水印去除的新方法，可在盲目设置下运行 - 无需目标图像。与现有方法不同，MorphoMod 可以有效去除不透明和透明的水印，同时保留语义内容，使其非常适合实际应用。对基准数据集（包括彩色大规模水印数据集 (CLWD)、LOGO 系列和新推出的 Alpha1 数据集）的评估表明，与最先进的方法相比，MorphoMod 的水印去除效果提高了 50.8%。消融研究强调了用于修复的提示、预移除填充策略和修复模型性能对水印去除的影响。此外，一项关于隐写术迷失方向的案例研究揭示了水印去除在破坏高级隐藏信息方面的更广泛应用。MorphoMod 提供了一种强大、适应性强的水印去除解决方案，并为图像恢复和对抗性操纵的进一步发展开辟了道路。]]></description>
      <guid>https://arxiv.org/abs/2502.02676</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>可控视频生成与可证明解缠</title>
      <link>https://arxiv.org/abs/2502.02690</link>
      <description><![CDATA[arXiv:2502.02690v1 公告类型：新 
摘要：尽管在生成高质量和一致的视频方面取得了进展，但可控视频生成仍然是一项重大挑战。现有的大多数控制视频生成的方法都将视频视为一个整体，忽略了复杂的细粒度时空关系，这限制了控制精度和效率。在本文中，我们提出了可控视频生成对抗网络 (CoVoGAN) 来解开视频概念，从而促进对单个概念的有效和独立控制。具体而言，遵循最小变化原则，我们首先解开静态和动态潜在变量。然后，我们利用足够的变化属性来实现动态潜在变量的组件可识别性，从而实现对运动和身份的独立控制。为了建立理论基础，我们提供了严格的分析来证明我们的方法的可识别性。基于这些理论见解，我们设计了一个时间转换模块来解开潜在动态。为了执行最小变化原则和充分变化属性，我们最小化了潜在动态变量的维数并施加了时间条件独立性。为了验证我们的方法，我们将此模块集成为 GAN 的插件。对各种视频生成基准进行的大量定性和定量实验表明，我们的方法显著提高了各种现实场景中的生成质量和可控性。]]></description>
      <guid>https://arxiv.org/abs/2502.02690</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过由粗到精的自我提炼实现多示例学习</title>
      <link>https://arxiv.org/abs/2502.02707</link>
      <description><![CDATA[arXiv:2502.02707v1 公告类型：新
摘要：计算病理学中全幻灯片图像 (WSI) 分析的多实例学习 (MIL) 经常忽略实例级学习，因为监督通常仅在包级别提供。在这项工作中，我们提出了 PathMIL，这是一个旨在通过两个角度改进 MIL 的框架：(1) 采用实例级监督和 (2) 在包级别学习实例间上下文信息。首先，我们提出了一种新颖的从粗到细的自蒸馏 (CFSD) 范式，以探测和蒸馏使用包级信息训练的分类器以获得实例级标签，从而可以更精细地有效地为同一分类器提供监督。其次，为了捕获 WSI 中的实例间上下文信息，我们提出了二维位置编码 (2DPE)，它对包内实例的空间外观进行编码。我们还从理论和经验上证明了 CFSD 的实例级可学习性。PathMIL 在多个基准测试任务上进行了评估，包括亚型分类（TCGA-NSCLC）、肿瘤分类（CAMELYON16）和乳腺癌受体状态分类的内部基准。我们的方法实现了最先进的性能，雌激素和孕激素受体状态分类的 AUC 得分分别为 0.9152 和 0.8524，亚型分类的 AUC 为 0.9618，肿瘤分类的 AUC 为 0.8634，超越了现有方法。]]></description>
      <guid>https://arxiv.org/abs/2502.02707</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RFMedSAM 2：使用 SAM 2 自动快速细化以增强体积医学图像分割</title>
      <link>https://arxiv.org/abs/2502.02741</link>
      <description><![CDATA[arXiv:2502.02741v1 公告类型：新
摘要：Segment Anything Model 2 (SAM 2) 是一种将 SAM 扩展到图像和视频领域的提示驱动的基础模型，与其前身相比，它表现出了卓越的零样本性能。基于 SAM 在医学图像分割方面的成功，SAM 2 具有进一步发展的巨大潜力。然而，与 SAM 类似，SAM 2 受到二进制掩码输出、无法推断语义标签以及对目标对象区域的精确提示的依赖的限制。此外，将 SAM 和 SAM 2 直接应用于医学图像分割任务会产生次优结果。在本文中，我们使用自定义微调适配器探索了 SAM 2 的上限性能，在 BTCV 数据集上实现了 92.30% 的 Dice 相似系数 (DSC)，比最先进的 nnUNet 高出 12%。在此之后，我们通过研究各种提示生成器来解决提示依赖性问题。我们引入了 UNet 来自主生成预测的掩码和边界框，作为 SAM 2 的输入。SAM 2 随后进行的双阶段细化进一步提高了性能。大量实验表明，我们的方法在 AMOS2022 数据集上取得了最佳结果，与 nnUNet 相比，Dice 改进了 2.9%，在 BTCV 数据集上的表现比 nnUNet 高出 6.4%。]]></description>
      <guid>https://arxiv.org/abs/2502.02741</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>重新思考以对象为中心的基础模型的视觉转换器</title>
      <link>https://arxiv.org/abs/2502.02763</link>
      <description><![CDATA[arXiv:2502.02763v1 公告类型：新
摘要：最近最先进的对象分割机制，例如 Segment Anything Model (SAM) 和 FastSAM，首先在多个层上对整个图像进行编码，然后专注于为一个特定对象或区域生成掩码。我们提出了一种离网 Fovea-Like 输入修补 (FLIP) 方法，该方法选择图像输入并以对象为中心的方式从头开始对其进行编码。在这样做的同时，它将位置编码与以对象为中心的感知代码分开。FLIP 的数据效率更高，并且在高分辨率视觉场景中掩蔽相对较小的物体时可提高分割性能。在 Hypersim、KITTI-360 和 OpenImages 等标准基准测试中，FLIP 实现了交并比 (IoU) 分数，该分数接近 SAM 的性能，但计算工作量要少得多。它在所有 IoU 测量中都超过了 FastSAM。我们还引入了一个额外的半自然但高度直观的数据集，其中 FLIP 总体上优于 SAM 和 FastSAM，尤其是在相对较小的物体上。鉴于 FLIP 是一种端到端的以对象为中心的分割方法，它具有很高的潜力，特别是对于那些受益于计算效率高、空间选择性高的对象跟踪的应用程序。]]></description>
      <guid>https://arxiv.org/abs/2502.02763</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于头部计算机断层扫描中通用疾病检测的 3D 基础 AI 模型</title>
      <link>https://arxiv.org/abs/2502.02779</link>
      <description><![CDATA[arXiv:2502.02779v1 公告类型：新
摘要：头部计算机断层扫描 (CT) 成像是一种广泛使用的成像方式，具有多种医学指征，特别是在评估大脑、颅骨和脑血管系统的病理方面。由于其图像采集速度快、安全性高、成本低且普遍性强，它通常是神经系统急诊的一线成像。深度学习模型可能有助于检测多种疾病。然而，高质量标签和注释的稀缺，特别是在较不常见的疾病中，严重阻碍了强大模型的开发。为了应对这一挑战，我们引入了 FM-CT：一种用于可推广疾病检测的头部 CT 基础模型，使用自监督学习进行训练。我们的方法在 361,663 个非造影 3D 头部 CT 扫描的大型多样化数据集上预先训练深度学习模型，无需手动注释，使模型能够学习稳健、可推广的特征。为了研究自监督学习在头部 CT 中的潜力，我们采用了自提炼和蒙版图像建模的鉴别方法，并在 3D 而不是切片级别 (2D) 构建模型，以更全面、更有效地利用头部 CT 扫描的结构。使用内部和三个外部数据集评估模型的下游分类性能，涵盖分布内 (ID) 和分布外 (OOD) 数据。我们的结果表明，与从头开始训练的模型和之前在稀缺注释数据集上训练的 3D CT 基础模型相比，自监督基础模型显著提高了下游诊断任务的性能。这项工作突出了自监督学习在医学成像中的有效性，并为 3D 头部 CT 图像分析树立了新的标杆，使人工智能更广泛地用于基于头部 CT 的诊断。]]></description>
      <guid>https://arxiv.org/abs/2502.02779</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于AIoT的智能交通管理系统</title>
      <link>https://arxiv.org/abs/2502.02821</link>
      <description><![CDATA[arXiv:2502.02821v1 公告类型：新
摘要：本文介绍了一种基于人工智能的新型智能交通管理系统，旨在优化交通流量并减少城市环境中的拥堵。通过分析现有闭路电视摄像机的实时录像，这种方法无需额外的硬件，从而最大限度地降低了部署成本和持续维护费用。人工智能模型处理实时视频源以准确计算车辆数量并评估交通密度，从而实现自适应信号控制，优先考虑交通量较大的方向。这种实时适应性可确保交通流量更顺畅，减少拥堵，并最大限度地减少驾驶员的等待时间。此外，使用 PyGame 模拟所提出的系统以评估其在各种交通条件下的性能。模拟结果表明，基于人工智能的系统比传统的静态交通信号灯系统高出 34%，从而显著提高交通流效率。使用人工智能优化交通信号可以在解决城市交通挑战中发挥关键作用，为现代城市提供经济高效、可扩展且高效的解决方案。这一创新系统代表了智能城市基础设施和智能交通系统领域的重大进步。]]></description>
      <guid>https://arxiv.org/abs/2502.02821</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>遥感变化检测的样本高效深度学习综述：任务、策略和挑战</title>
      <link>https://arxiv.org/abs/2502.02835</link>
      <description><![CDATA[arXiv:2502.02835v1 公告类型：新
摘要：在过去十年中，深度学习 (DL) 的快速发展使得对大量遥感图像 (RSI) 执行自动、准确和稳健的变化检测 (CD) 成为可能。然而，尽管 CD 方法取得了进展，但由于输入数据和应用环境的多样性，它们在现实世界中的实际应用仍然有限。例如，收集的 RSI 可以是时间序列观测值，需要更具信息量的结果来指示变化的时间或具体的变化类别。此外，训练深度神经网络 (DNN) 需要大量的训练样本，而在许多情况下这些样本很难收集。为了应对这些挑战，已经开发了各种特定的 CD 方法，考虑了不同的应用场景和训练资源。此外，图像生成、自我监督和视觉基础模型 (VFM) 方面的最新进展开辟了解决基于 DL 的 CD 的“数据饥渴”问题的新方法。这些方法在更广泛的应用场景中的开发需要进一步的研究和讨论。因此，本文总结了不同 CD 任务的文献方法以及在样本有限场景中训练和部署基于 DL 的 CD 方法的可用策略和技术。我们希望这篇综述可以为该领域的研究人员提供新的见解和灵感，以开发更有效的 CD 方法，并应用于更广泛的场景。]]></description>
      <guid>https://arxiv.org/abs/2502.02835</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RS-YOLOX：用于卫星遥感图像中物体检测的高精度检测器</title>
      <link>https://arxiv.org/abs/2502.02850</link>
      <description><![CDATA[arXiv:2502.02850v1 公告类型：新
摘要：卫星遥感图像的自动目标检测对于资源勘探和自然灾害评估具有重要意义。针对遥感图像检测中存在的问题，本文提出了一种改进的YOLOX卫星遥感图像自动检测模型，该模型被命名为RS-YOLOX。为了增强网络的特征学习能力，我们在YOLOX的主干网络中使用了高效通道注意（ECA），并将自适应空间特征融合（ASFF）与YOLOX的颈部网络相结合。为了平衡训练中的正负样本数量，我们使用了Varifocal Loss函数。最后，为了获得高性能的遥感目标检测器，我们将训练好的模型与一个叫做切片辅助超推理（SAHI）的开源框架相结合。这项工作在三个航空遥感数据集（DOTA-v1.5，TGRS-HRRSD和RSOD）上对模型进行了评估。我们的对比实验表明，我们的模型在遥感图像数据集中检测物体方面具有最高的准确率。]]></description>
      <guid>https://arxiv.org/abs/2502.02850</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过视觉观察进行跨域模仿学习的域不变每帧特征提取</title>
      <link>https://arxiv.org/abs/2502.02867</link>
      <description><![CDATA[arXiv:2502.02867v1 公告类型：新
摘要：模仿学习 (IL) 使代理能够在没有奖励信号的情况下模仿专家行为，但在高维、嘈杂和不完整的视觉观察的跨域场景中面临挑战。为了解决这个问题，我们提出了用于模仿学习的域不变每帧特征提取 (DIFF-IL)，这是一种新颖的 IL 方法，它从各个帧中提取域不变特征并将其调整为序列以隔离和复制专家行为。我们还引入了一种逐帧时间标记技术，按时间步长细分专家行为并分配与时间上下文一致的奖励，从而提高任务性能。在不同视觉环境中进行的实验证明了 DIFF-IL 在解决复杂视觉任务方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2502.02867</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于视频文本检索的专业字幕自动增强</title>
      <link>https://arxiv.org/abs/2502.02885</link>
      <description><![CDATA[arXiv:2502.02885v1 公告类型：新
摘要：随着深度学习的出现，视频文本检索这一新兴领域取得了重大进展。然而，由于视频的文本描述不足，匹配文本和视频的挑战仍然存在。两种模态之间的巨大信息差距阻碍了对视频的全面理解，导致检索结果不明确。虽然已经提出了基于大型语言模型的重写方法来拓宽文本表达，但精心设计的提示对于确保重写文本的合理性和完整性至关重要。本文提出了一种自动字幕增强方法，通过自学习来提高表达质量并减轻增强字幕中的经验主义。此外，设计并引入了一种专业的字幕选择机制，可以为每个视频定制增强字幕，从而促进视频文本匹配。我们的方法完全由数据驱动，不仅省去了繁重的数据收集和计算工作量，而且通过规避词典依赖性和引入个性化匹配提高了自适应性。我们方法的优越性已通过各种基准测试中的最新结果得到验证，具体来说，在 MSR-VTT 上实现了 68.5% 的 Top-1 召回准确率，在 MSVD 上实现了 68.1% 的 Top-1 召回准确率，在 DiDeMo 上实现了 62.0% 的 Top-1 召回准确率。]]></description>
      <guid>https://arxiv.org/abs/2502.02885</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用外观和置信度特征增强基于量子 QUBO 的物体检测抑制</title>
      <link>https://arxiv.org/abs/2502.02895</link>
      <description><![CDATA[arXiv:2502.02895v1 公告类型：新
摘要：众所周知，基于二次无约束二元优化 (QUBO) 的物体检测抑制优于传统的非最大抑制 (NMS)，尤其是在拥挤的场景中，NMS 可能会抑制具有低置信度分数的（部分）遮挡真阳性。虽然现有的 QUBO 公式比 NMS 更不容易错过遮挡的物体，但仍有改进的空间，因为现有的 QUBO 公式天真地考虑了基于预测之间空间重叠的置信度分数和成对分数。本研究提出了新的 QUBO 公式，旨在区分预测之间的重叠是由于物体的遮挡还是由于预测中的冗余，即对单个物体的多个预测。所提出的 QUBO 公式将两个特征集成到现有 QUBO 公式的成对得分中：i) 通过图像相似性度量计算的外观特征和 ii) 置信度得分的乘积。这些特征分别源自以下假设：冗余预测具有相似的外观特征，而（部分）遮挡的物体具有较低的置信度得分。所提出的方法比最先进的基于 QUBO 的抑制方法有显著的进步，且运行时间没有显著增加，mAP 提高了 4.54 个百分点，mAR 提高了 9.89 个百分点。]]></description>
      <guid>https://arxiv.org/abs/2502.02895</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>PoleStack：通过轮廓堆叠对不规则物体进行稳健极点估计</title>
      <link>https://arxiv.org/abs/2502.02907</link>
      <description><![CDATA[arXiv:2502.02907v1 公告类型：新
摘要：我们提出了一种算法，使用从多个相机姿势收集的轮廓图像来估计主轴旋转器的旋转极点。首先，将一组图像堆叠以形成单个轮廓堆栈图像，其中物体的旋转引入了关于成像极点方向的反射对称性。我们通过识别轮廓堆栈中的最大对称性来估计这个投影极点方向。为了处理未知的质心图像位置，我们应用离散傅里叶变换来生成轮廓堆栈振幅谱，实现平移不变性和增强的抗噪性。其次，通过组合从不同相机方向收集的两个或多个投影极点测量值来估计 3D 极点方向。我们使用低分辨率图像展示了度级极点估计精度，显示出对严重表面阴影和基于质心的图像配准误差的鲁棒性。所提出的方法可以适用于在接近目标物体的阶段和悬停期间的极点估计。]]></description>
      <guid>https://arxiv.org/abs/2502.02907</guid>
      <pubDate>Thu, 06 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>