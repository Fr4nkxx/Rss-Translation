<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>CS.CV更新arxiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.cv更新arxiv.org e-print存档。</description>
    <lastBuildDate>Mon, 17 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>GraphCompnet：一个用于预测和补偿形状偏差的位置感知模型</title>
      <link>https://arxiv.org/abs/2502.09652</link>
      <description><![CDATA[ARXIV：2502.09652V1公告类型：新 
摘要：本文介绍了一种数据驱动的算法，用于建模和补偿添加剂制造中的形状偏差（AM），以应对几何精度和批处理生产的挑战。虽然传统方法（例如分析模型和计量学）为几何精确度奠定了基础，但它们通常对于大规模生产而言是不切实际的。机器学习（ML）的最新进展提高了补偿精度，但是问题仍然是跨越复杂的几何形状并适应依赖位置的变化的问题。我们使用GraphCompnet提出了一种用于粉末床融合（PBF）过程的新方法，该方法是将基于图形的神经网络与生成性对抗网络（GAN）启发的训练过程相结合的计算框架。通过利用点云数据和动态图卷积神经网络（DGCNN），GraphCompnet模型复杂形状并结合了特定位置的热和机械因素。两阶段的对抗训练程序迭代地通过补偿器预言架构进行了补偿设计，从而提供了实时反馈和优化。跨不同形状和位置的实验验证显示，框架在整个打印空间中显着提高了补偿准确性（35％至65％），可适应依赖位置的变化。这项工作为AM的数字双技术开发，实现了可扩展，实时监控和补偿，并解决了AM过程控制中的关键差距。所提出的方法支持高精度，自动化的工业规模设计和制造系统。]]></description>
      <guid>https://arxiv.org/abs/2502.09652</guid>
      <pubDate>Mon, 17 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>双向扩散桥模型</title>
      <link>https://arxiv.org/abs/2502.09655</link>
      <description><![CDATA[ARXIV：2502.09655V1公告类型：新 
摘要：扩散桥在成对的图像到图像（I2i）翻译任务中显示了潜力。但是，现有方法受其单向性质的限制，需要单独的向前和反向翻译模型。这不仅使计算成本翻了一番，而且限制了它们的实用性。在这项工作中，我们介绍了双向扩散桥模型（BDBM），这是一种可扩展的方法，可促进使用单个网络之间的两个耦合分布之间的双向翻译。 BDBM利用Chapman-Kolmogorov方程用于桥梁，使其能够通过在此框架内利用初始时间和目标时间段的互换性来建模跨时间段的数据分布在跨时间段变化。值得注意的是，当给定端点的边际分布是高斯时，BDBM的过渡内核在两个方向上都具有分析形式，从而可以通过单个网络进行有效的学习。我们演示了BDBM与现有的桥梁方法之间的联系，例如DOOB的H-转换和变异方法，并突出显示其优势。高分辨率I2I翻译任务的广泛实验表明，BDBM不仅可以实现双向翻译，而且额外成本最低，而且表现优于最先进的桥梁模型。我们的源代码可从[https://github.com/kvmduc/bdbm|| shttps://github.com/kvmduc/bdbm]获得。]]></description>
      <guid>https://arxiv.org/abs/2502.09655</guid>
      <pubDate>Mon, 17 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>将时空视觉变压器整合到数字双胞胎中，以在校园环境中进行高分辨率热应力预测</title>
      <link>https://arxiv.org/abs/2502.09657</link>
      <description><![CDATA[ARXIV：2502.09657V1公告类型：新 
摘要：气候变化加剧了极端热量事件，对城市的弹性和计划构成了重大挑战。这项研究介绍了气候响应的数字双框架，该框架整合了时空视觉变压器（ST-VIT）模型，以增强热应力预测和决策。使用德克萨斯州校园作为测试台，我们与空间和气象数据合成了高分辨率物理模型模拟，以开发精细的人类热预测。由ST-Vit Digital Twin为计划者，政策制定者和校园利益相关者提供了有效的，数据驱动的见解，支持有针对性的降温策略并推进气候适应性的城市设计。]]></description>
      <guid>https://arxiv.org/abs/2502.09657</guid>
      <pubDate>Mon, 17 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在图像和视频中进行细粒度的互动细分</title>
      <link>https://arxiv.org/abs/2502.09660</link>
      <description><![CDATA[ARXIV：2502.09660V1公告类型：新 
摘要：最近的任何模型（SAM）已成为一般交互式分割的基础视觉模型。尽管表现出强大的概括能力，但在需要准确面具的情况下，它们仍然会遭受性能降解。现有的高精度互动分割方法面临着感知复杂的本地细节和保持稳定的提示能力之间的权衡，这阻碍了基础细分模型的适用性和有效性。为此，我们提出了建立在SAM2骨干上的SAM2Refiner框架。该体系结构允许SAM2在保留其固有优势的同时，为图像和视频生成细粒细分面罩。具体而言，我们设计了一个本地化增强模块，该模块结合了局部上下文提示，以通过跨注意机制增强全局特征，从而利用潜在的详细模式并维护语义信息。此外，为了增强增强物体嵌入的促进能力，我们引入了一个及时的重新定位模块，以使用空间对齐的及时功能更新嵌入。此外，为了获得准确的高分辨率分割掩码，通过使用多尺度的级联结构来融合带有编码器的层次表示的屏蔽结构来设计蒙版改进模块。广泛的实验证明了我们方法的有效性，表明所提出的方法可以为图像和视频产生高度精确的掩模，从而超过最新方法。]]></description>
      <guid>https://arxiv.org/abs/2502.09660</guid>
      <pubDate>Mon, 17 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DIFFEX：解释具有扩散模型的分类器以识别微观细胞变化</title>
      <link>https://arxiv.org/abs/2502.09663</link>
      <description><![CDATA[ARXIV：2502.09663V1公告类型：新 
摘要：近年来，深度学习模型已广泛应用于各种方式的生物学数据。歧视性的深度学习模型在将图像分为类别（例如，健康与患病，治疗与未经治疗）方面表现出色。但是，由于这些模型的复杂性和缺乏可解释性，这些模型通常被视为黑匣子，从而限制了它们在现实世界的生物学环境中的应用。在生物学研究中，解释性至关重要：了解分类器的决策并确定条件之间的细微差异对于阐明治疗，疾病进展和生物过程的影响至关重要。为了应对这一挑战，我们提出了DIFFEX，这是一种生成可视上解释属性的方法，以解释分类器并确定不同条件之间的微观细胞变化。我们证明了DIFFEX在解释接受自然图像和生物学图像训练的分类器方面的有效性。此外，我们使用DIFFEX来发现显微镜数据集中的表型差异。通过通过分类器解释提供对细胞变异的见解，Diffex有可能通过识别新型生物标志物来提高对疾病的理解和帮助发现药物的发现。]]></description>
      <guid>https://arxiv.org/abs/2502.09663</guid>
      <pubDate>Mon, 17 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>图像超分辨率，并通过共形生成模型保证</title>
      <link>https://arxiv.org/abs/2502.09664</link>
      <description><![CDATA[ARXIV：2502.09664V1公告类型：新 
摘要：对于图像超分辨率的生成ML基础模型的使用日益增加，要求鲁棒和可解释的不确定性量化方法。我们通过提出一种基于共形预测技术的新方法来解决这种需求，以创建一个“信心面具”，能够可靠，直觉地传达可以信任生成的图像的地方。我们的方法适用于任何黑盒生成模型，包括锁定不透明API的模型，仅需要易于达到的校准数据，并且可以通过选择本地图像相似性度量来高度自定义。我们证明了跨越保真度误差控制的方法（根据我们的本地图像相似度度量），重建质量以及面对数据泄漏时的鲁棒性。最后，我们通过经验评估这些结果并确定方法的扎实性能。]]></description>
      <guid>https://arxiv.org/abs/2502.09664</guid>
      <pubDate>Mon, 17 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用潜在扩散模型揭示小显微镜数据集中的微妙表型</title>
      <link>https://arxiv.org/abs/2502.09665</link>
      <description><![CDATA[ARXIV：2502.09665V1公告类型：新 
摘要：识别细胞图像中细微的表型变化对于推进生物学研究和加速药物发现至关重要。这些变化通常被固有的细胞异质性掩盖，从而使区分实验条件之间的差异具有挑战性。深层生成模型的最新进展表明，通过图像翻译，开放细胞和分子生物学的新边界以及新型生物标志物的鉴定，可以揭示这些细微的表型的重要潜力。在这些生成模型中，扩散模型在产生高质量，逼真的图像的能力方面脱颖而出。但是，培训扩散模型通常需要大量的数据集和大量的计算资源，这两者在生物学研究中都可能受到限制。在这项工作中，我们提出了一种新型方法，该方法利用预先训练的潜扩散模型来揭示微妙的表型变化。我们在微观图像的几个小数据集上对我们的方法进行定性和定量验证。我们的发现表明，我们的方法可以有效地检测表型变化，从而捕获视觉上明显和不可察觉的差异。最终，我们的结果突出了这种方法对表型检测的有希望的潜力，尤其是在受到有限的数据和计算能力约束的上下文中。]]></description>
      <guid>https://arxiv.org/abs/2502.09665</guid>
      <pubDate>Mon, 17 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>meta-inr：通过元学习隐式神经表示对体积数据的有效编码</title>
      <link>https://arxiv.org/abs/2502.09669</link>
      <description><![CDATA[ARXIV：2502.09669V1公告类型：新 
摘要：隐式神经表示（INR）已成为编码体积数据，提供连续表示和与体积渲染管道的无缝兼容性的有前途的解决方案。但是，从随机初始化的参数中优化每个新卷的INR网络在计算上效率低下，尤其是对于大规模的时变或集合体积数据集，其中体积具有相似的结构模式，但需要独立的培训。为了缩小这一差距，我们提出了Meta-Inr，这是一种预处理的策略，该策略是从元学习算法中改编的，从部分观察体积数据集从部分观察到初始INR参数。与从头开始的训练INR相比，学习的初始参数提供了强大的先验，从而增强了INR的概括性，在适应新的体积和更好的解释性时，可以在分析适应性INRS的参数时，仅需几个梯度更新，从而可以更快地收敛。我们证明，元I-Inr可以有效提取高质量的可推广功能，这些功能有助于编码各种数据集中看不见的相似音量数据。此外，我们在诸如仿真参数分析和代表性时间段选择之类的任务中强调了它的效用。该代码可在https://github.com/spacefarers/metainr上找到。]]></description>
      <guid>https://arxiv.org/abs/2502.09669</guid>
      <pubDate>Mon, 17 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>IMM-MOT：具有相互作用多个模型过滤器的新型3D多对象跟踪框架</title>
      <link>https://arxiv.org/abs/2502.09672</link>
      <description><![CDATA[ARXIV：2502.09672V1公告类型：新 
摘要：3D多对象跟踪（MOT）提供了周围物体的轨迹，协助机器人或车辆进行更智能的路径计划和避免障碍物。现有的3D MOT方法基于逐个检测框架通常使用单个运动模型在整个跟踪过程中跟踪对象。但是，由于周围环境中的变化，对象可能会改变其运动模式。在本文中，我们在IMM-MOT中介绍了相互作用的多个模型过滤器，该滤波器准确地符合单个对象的复杂运动模式，从而克服了现有方法中单模型跟踪的限制。此外，我们将阻尼窗口机理纳入轨迹生命周期管理中，利用轨迹的连续关联状态来控制其创造和终止，从而减少了被忽视的低信心真实目标的发生。此外，我们提出了基于距离的分数增强模块，该模块通过调整检测分数来增强误报和真实阳性之间的差异，从而提高了得分滤波器的有效性。在Nuscenes Val数据集上，IMM-MOT使用3D点云优于大多数其他单模式模型，达到73.8％的AMOTA。我们的项目可在https://github.com/ap01lo/imm-mot上找到。]]></description>
      <guid>https://arxiv.org/abs/2502.09672</guid>
      <pubDate>Mon, 17 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>以对象为中心的潜在动作学习</title>
      <link>https://arxiv.org/abs/2502.09680</link>
      <description><![CDATA[ARXIV：2502.09680V1公告类型：新 
摘要：目前，由于缺乏动作注释和与动作相关的干扰因素的存在，利用大量的Internet视频数据用于体现AI。我们提出了一种基于视频龙和拉波的新颖中心的潜在潜在动作学习方法，该方法将场景的自我监督分解为对象表示，并使用代理行动标签注释视频数据。该方法有效地将因果因素 - 对象相互作用从无关的背景噪声中解散，并降低了由干扰因素引起的潜在动作学习方法的性能下降。我们使用分散注意力控制套件进行的初步实验表明，基于对象分解的潜在动作预处理提高了X2.7推断潜在动作的质量，并通过一系列标记的动作来提高下游微调的效率，从平均的。]]></description>
      <guid>https://arxiv.org/abs/2502.09680</guid>
      <pubDate>Mon, 17 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过有条件生成建模进行放射学AI的虚拟临床试验</title>
      <link>https://arxiv.org/abs/2502.09688</link>
      <description><![CDATA[ARXIV：2502.09688V1公告类型：新 
摘要：人工智能（AI）有望通过数据驱动的见解来实现个性化和有效的护理来改变医疗保健。尽管放射学是AI采用的最前沿，但实际上，AI模型的潜力通常被严重失败概括而掩盖：当从受控的测试环境转变为放射科医生的临床使用时，AI模型可以使高达20％的性能降解。这种不匹配引起了人们的担忧，即放射科医生会因实践中的AI预测和/或成长为不信任的AI而被误导，从而使这些有前途的技术实际上是无效的。因此，在遇到各种数据样本时，对AI模型的详尽临床试验对于预测AI模型降解至关重要。但是，由于收集各种数据样本和相应的注释的高成本，实现这些目标是具有挑战性的。为了克服这些局限性，我们引入了一种针对放射学AI虚拟临床试验（VCT）设计的新型有条件生成的AI模型，该模型能够实际合成具有指定属性的患者的全身CT图像。通过学习图像和解剖结构的联合分布，我们的模型可以在此规模上以前所未有的细节来精确复制现实世界中的患者人群。我们通过我们的合成CT研究人群提供动力的VCT来证明对放射学AI模型的有意义评估，揭示了模型降级并促进算法审核，以诱导偏见的数据属性。我们对VCTS的生成AI方法是一种有希望的途径，可扩展解决方案，以评估模型的稳健性，减轻偏见和保护患者护理，从而在任何所需的多种患者人群中对AI模型进行更简单的测试和评估。]]></description>
      <guid>https://arxiv.org/abs/2502.09688</guid>
      <pubDate>Mon, 17 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Zerobench：当代大型多模型的不可能的视觉基准</title>
      <link>https://arxiv.org/abs/2502.09696</link>
      <description><![CDATA[ARXIV：2502.09696V1公告类型：新 
摘要：大型多模型模型（LMM）在解释图像时表现出严重的缺口，并且通过某些措施，空间认知的差异比小儿童或动物较差。尽管如此，他们还是在许多流行的视觉基准上获得了很高的分数，并且由于持续的模型进度激增而迅速侵蚀了净空。为了解决这个问题，迫切需要困难的基准测试，这些基准仍然相关。我们通过引入Zerobench-轻巧的视觉推理基准将这个想法达到极限，这对于当代边境LMM是完全不可能的。我们的基准包括100个手动策划的问题和334个难度较少的子问题。我们在Zerobench上评估了20个LMM，所有这些LMM的得分为0.0％，并严格分析错误。为了鼓励视觉理解的进步，我们公开发布了Zerobench。]]></description>
      <guid>https://arxiv.org/abs/2502.09696</guid>
      <pubDate>Mon, 17 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CNN的自动检测和分类脑肿瘤的方法</title>
      <link>https://arxiv.org/abs/2502.09731</link>
      <description><![CDATA[ARXIV：2502.09731V1公告类型：新 
摘要：脑肿瘤需要评估以确保及时诊断和有效的患者治疗。形态学因素，例如大小，位置，纹理和可变外观，包括检查肿瘤检查。医学成像提出了挑战，包括噪声和不完整的图像。本研究文章介绍了一种处理磁共振成像（MRI）数据的方法，包括用于图像分类和降解的技术。 MRI图像的有效使用使医疗专业人员可以检测到包括肿瘤在内的脑部疾病。这项研究旨在通过分析提供的MRI数据来分类健康的脑组织和脑肿瘤。与诸如计算机断层扫描（CT）之类的替代方法不同，MRI技术提供了内部解剖组件的更详细表示，它是研究与脑肿瘤有关的数据的合适选择。 MRI图片首先使用各向异性扩散滤波器进行脱氧技术。用于创建模型的数据集是公共可访问且经过验证的脑肿瘤分类（MRI）数据库，其中包括3,264次大脑MRI扫描。 SMOTE用于数据扩展和数据集平衡。卷积神经网络（CNN），例如RESNET152V2，VGG，VIT和EDIDENET进行分类程序。有效网络的精度为98％，是记录最高的。]]></description>
      <guid>https://arxiv.org/abs/2502.09731</guid>
      <pubDate>Mon, 17 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>有条件扩散模型的噪声控制的CT超分辨率</title>
      <link>https://arxiv.org/abs/2502.09793</link>
      <description><![CDATA[ARXIV：2502.09793V1公告类型：新 
摘要：改善CT图像的空间分辨率是一项有意义但具有挑战性的任务，通常伴随着噪声扩增的问题。本文介绍了利用条件扩散模型的噪声控制CT超分辨率的创新框架。该模型是在混合数据集上训练的，将噪声匹配的仿真数据与实际数据分割的细节相结合。实际CT图像的实验结果验证了我们提出的框架的有效性，显示了其在CT成像中实际应用的潜力。]]></description>
      <guid>https://arxiv.org/abs/2502.09793</guid>
      <pubDate>Mon, 17 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在挑战性的照明条件下，基于视觉的地理位置重新定位</title>
      <link>https://arxiv.org/abs/2502.09795</link>
      <description><![CDATA[ARXIV：2502.09795V1公告类型：新 
摘要：使用空中资产的行星探索有可能在火星上进行前所未有的科学发现。尽管NASA的火星直升机创造力证明在火星气氛中可以飞行，但未来的火星旋转船将需要远程飞行的高级导航能力。这样的关键功能之一是基于地图的本地化（MBL），该定位在飞行过程中将板上图像注册到参考图，以减轻视觉探测器的累积漂移。但是，旋律观测和参考图之间的显着照明差异证明了传统MBL系统的挑战，从而限制了车辆的操作窗口。在这项工作中，我们研究了一个新的MBL系统，并提出了Geo-loftr，这是一种用于图像注册的几何深度学习模型，在较大的照明差异下比以前的模型更健壮。该系统由一个自定义仿真框架支持，该框架使用真实的轨道图生成了火星地形的大量逼真的图像。全面的评估表明，在显着的照明和规模变化下，我们提出的系统在本地化精度方面优于先前的MBL努力。此外，我们在模拟的火星日展示了方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2502.09795</guid>
      <pubDate>Mon, 17 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>