<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>CS.CV更新arxiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.cv更新arxiv.org e-print存档。</description>
    <lastBuildDate>Thu, 20 Mar 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>神经气体网络对身体运动数据的合成数据生成情绪识别</title>
      <link>https://arxiv.org/abs/2503.14513</link>
      <description><![CDATA[arxiv：2503.14513v1公告类型：新 
摘要：在使用身体运动的情感识别领域中，主要挑战在于稀缺和可推广的数据集的稀缺性。自动情绪识别使用机器学习和人工智能技术来识别一个人的情绪状态，例如文本，图像，声音和身体运动。身体运动带来了独特的挑战，因为年龄，性别，种族，个性和疾病等许多因素都会影响其外观，从而导致缺乏专门用于情感识别的多样化和强大的数据集。为了解决这个问题，采用合成数据生成（SDG）方法，例如生成对抗网络（GAN）和变分自动编码器（VAE），提供了潜在的解决方案，尽管这些方法通常很复杂。这项研究介绍了神经天然气网络（NGN）算法的新应用，用于合成身体运动数据并优化多样性和发电速度。通过学习骨骼结构拓扑，NGN适合身体关节上的神经元或气体颗粒。稍后形成骨骼结构的产生的气体颗粒将用于合成新的身体姿势。通过将身体姿势连接到框架上，出现了最终的合成体运动。我们使用基准指标（例如fr \&#39;Echet Inpection距离（FID），多样性等，将生成的数据集与GAN，VAE和另一种基准算法产生的其他数据集进行了比较。此外，我们继续使用分类指标进行评估，例如准确性，精度，召回和其他一些。提取了与联合相关的特征或运动学参数，并针对看不见的数据评估了模型性能。我们的发现表明，NGN算法会产生更现实和情感上不同的身体运动数据，并且比现有方法更合成速度。]]></description>
      <guid>https://arxiv.org/abs/2503.14513</guid>
      <pubDate>Thu, 20 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>咖啡厅：通过多模式粗粒和细粒度控制生成3D说话的面部动画</title>
      <link>https://arxiv.org/abs/2503.14517</link>
      <description><![CDATA[ARXIV：2503.14517V1公告类型：新 
摘要：语音驱动的3D说话面部方法应提供准确的唇部同步和可控表达式。以前的方法仅采用离散的情绪标签来整个序列中全球控制表达式，同时限制了时空域内的柔性细粒面部控制。我们提出了一个基于扩散 - 转化器的3D谈话面部生成模型Cafe-Talk，该模型同时结合了粗粒和细粒的多模式控制条件。然而，多种条件的纠缠挑战达到令人满意的表现。为了解开语音音频和细粒度的条件，我们采用了两阶段的培训管道。具体而言，Cafe-Talk最初仅使用语音音频和粗粒条件进行训练。然后，提出的细粒控制适配器逐渐添加了由动作单元（AUS）表示的细粒指令，从而阻止了不利的语音流-LIP同步。为了消除粗糙和细粒度的条件，我们设计了一种交换标签的训练机制，从而使细粒条件的优势占据主导地位。我们还设计了一种基于掩模的CFG技术来调节细粒对照的发生和强度。此外，引入了基于文本的检测器，并带有文本AU对齐，以实现自然语言用户输入并进一步支持多模式控制。广泛的实验结果证明，咖啡厅达到了最先进的唇部同步和表达性能，并在用户研究中获得了细粒度控制的广泛接受。项目页面：https：//harryxd2018.github.io/cafe-talk/]]></description>
      <guid>https://arxiv.org/abs/2503.14517</guid>
      <pubDate>Thu, 20 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>动态场景图生成的明显时间编码</title>
      <link>https://arxiv.org/abs/2503.14524</link>
      <description><![CDATA[ARXIV：2503.14524V1公告类型：新 
摘要：使用结构化的时空场景图代表动态场景是一项新颖，特别具有挑战性的任务。要解决这项任务，除了它们的空间关系外，要学习对象之间的时间相互作用至关重要。由于缺乏当前基准数据集中明确注释的时间关系，因此大多数现有的时空场景图生成方法在跨帧的所有对象之间建立了密集和抽象的时间连接。但是，并非所有时间连接都在编码有意义的时间动态。我们提出了一种新颖的时空场景图生成方法，该方法仅在与时间相关的对象对之间有选择地构建时间连接，并将时间关系表示为场景图中的显式边缘。最终的稀疏和显式的时间表示使我们可以在场景图检测中提高强大场景图生成基线的$ 4.4 \％$。此外，我们表明我们的方法可以利用以改善下游视觉任务。特别是，采用我们的行动识别方法，与最先进]]></description>
      <guid>https://arxiv.org/abs/2503.14524</guid>
      <pubDate>Thu, 20 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Rebot：使用真实到现实的机器人视频综合来缩放机器人学习</title>
      <link>https://arxiv.org/abs/2503.14526</link>
      <description><![CDATA[ARXIV：2503.14526V1公告类型：新 
摘要：视觉语言动作（VLA）模型通过直接在开放式X-Embodiment（例如开放式机器人）数据集上进行培训策略提出了有希望的范式。但是，实际数据收集的高成本阻碍了进一步的数据扩展，从而限制了VLA的普遍性。在本文中，我们介绍了Rebot，Rebot是一种新颖的真实到现实方法，用于扩展真实的机器人数据集并将VLA模型调整为目标域，这是机器人操作中最后一英里的部署挑战。具体而言，Rebot在模拟中重播了现实世界的机器人轨迹，以使操纵对象（实际到SIM）多样化，并将模拟运动与成分的现实世界背景集成在一起，以合成物理上现实且具有时间一致的机器人视频（SIM-to-peal）。我们的方法具有多种优势：1）它享有实际数据的好处，以最大程度地减少SIM卡之间的差距； 2）它利用模拟的可伸缩性； 3）它可以将经过验证的VLA推广到具有全自动数据管道的目标域。在模拟和现实世界环境中进行的广泛实验表明，重建会显着提高VLA的性能和鲁棒性。例如，在使用寡妇机器人的SimpleReenV中，Rebot将OCTO的内域性能提高了7.2％，OpenVLA的表现分别提高了21.8％，并且分类范围的概括分别提高了19.9％和9.4％。对于使用Franka机器人进行的真实评估，Rebot将OCTO的成功率提高了17％，OpenVLA提高了20％。更多信息可以在以下网址找到：https：//yuffish.github.io/rebot/]]></description>
      <guid>https://arxiv.org/abs/2503.14526</guid>
      <pubDate>Thu, 20 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>调味料：具有稀疏自动编码器的视觉语言模型中的选择性概念</title>
      <link>https://arxiv.org/abs/2503.14530</link>
      <description><![CDATA[ARXIV：2503.14530V1公告类型：新 
摘要：视觉模型（VLMS）的学习方法主要是来自大语言模型（LLM）的改编技术，依赖于需要大量注释的忘记集的重量更新。此外，这些方法在粗糙的粒度上进行了学习，通常会导致过度遗忘和减少模型效用。为了解决这个问题，我们介绍了一种新颖的方法，该方法利用稀疏的自动编码器（SAE）在VLMS中进行细粒度和选择性的概念。简而言之，酱汁首先要火车SAE捕获高维，语义上丰富的稀疏特征。然后，它标识了与目标概念最相关的功能。在推断期间，它有选择地修改这些功能以抑制特定概念，同时保留无关的信息。我们在两种类型的任务上评估了两种不同的VLM上的酱汁，即Llava-V1.5-7B和Llama-3.2-11b-Vision-Instruction：混凝土概念（对象和体育场景）以及抽象的概念（对象和体育场景），以及抽象的概念（情感，颜色，颜色和材料），包括60个概念。广泛的实验表明，在保持可比较的模型实用程序的同时，酱汁的表现优于最先进的方法，在未学习的质量方面优于18.04％。此外，我们研究了酱汁对广泛使用的对抗性攻击的鲁棒性，其跨模型的可传递性以及其在处理多个同时学习请求时的可扩展性。我们的发现将调味料建立为在VLM中进行选择性概念的有效且可扩展的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2503.14530</guid>
      <pubDate>Thu, 20 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>现实世界中的低光场景的无监督的无监督的联合降解和增强</title>
      <link>https://arxiv.org/abs/2503.14535</link>
      <description><![CDATA[ARXIV：2503.14535V1公告类型：新 
摘要：现实世界中的低光图像通常会遭受复杂的降解，例如局部过度暴露，亮度低，噪音和不均匀的照明。监督的方法倾向于过度适合特定方案，而无监督的方法虽然在概括方面更好，但由于缺乏参考图像而难以模拟这些降解。为了解决这个问题，我们提出了一个可解释的，零引用的联合denoising和低光增强框架，该框架是针对现实世界而定制的。我们的方法基于与物理成像原理和Itinex理论基于不同照明和噪声水平的配对子图像的训练策略。此外，我们利用离散的余弦变换（DCT）在SRGB空间中执行频域分解，并引入隐式引导的混合表示策略，该策略有效地分离了复杂的复合降解。在骨干网络设计中，我们开发了由隐式降解表示机制引导的视网膜分解网络。广泛的实验证明了我们方法的优越性。代码将在https://github.com/huaqlili/unsupervise-light-enhance-iclr2025上找到。]]></description>
      <guid>https://arxiv.org/abs/2503.14535</guid>
      <pubDate>Thu, 20 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于学习的3D重建自主驾驶：一项全面调查</title>
      <link>https://arxiv.org/abs/2503.14537</link>
      <description><![CDATA[ARXIV：2503.14537V1公告类型：新 
摘要：基于学习的3D重建已成为自动驾驶中的一种变革性技术，通过先进的神经表示可以精确地建模动态和静态环境。尽管增强了人们的看法，但3D重建仍激发了对自主驾驶领域至关重要的任务的开创性解决方案，例如场景理解和闭环模拟。从检查输入方式开始研究，我们研究了3D重建的细节，并对最近进步进行了多方面的，深入的分析。具体而言，我们首先提供了预赛的系统介绍，包括基于学习的3D重建的数据格式，基准和技术初步，并促进基于硬件配置和传感器套件的合适方法即时识别。然后，我们系统地回顾了自动驾驶中基于学习的3D重建方法，通过子任务对方法进行分类并进行多维分析和摘要以建立全面的技术参考。在自动驾驶中基于学习的3D重建的背景下，总结了发展趋势和现有挑战。我们希望我们的审查能够激发未来的研究。]]></description>
      <guid>https://arxiv.org/abs/2503.14537</guid>
      <pubDate>Thu, 20 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>匹配基于骨架的活动表示与HAR的异构信号</title>
      <link>https://arxiv.org/abs/2503.14547</link>
      <description><![CDATA[ARXIV：2503.14547V1公告类型：新 
摘要：在人类活动识别（HAR）中，活动标签通常以一hot格式进行编码，该格式最近朝着使用文本表示来提供上下文知识的转变。在这里，我们认为HAR应该锚定在身体运动数据上，因为运动构成了活动的基础并在跨传感系统中有效地适用，而文本本质上是有限的。我们提出了Skelar，这是一种新颖的HAR框架，可以从骨骼数据中预先介绍活动表示，并与异质HAR信号相匹配。我们的方法解决了两个主要挑战：（1）捕获核心运动知识而没有特定于上下文的细节。我们通过自我监督的粗角度重建任务实现这一目标，该任务恢复了用户和部署不变的关节旋转角度； （2）将表示形式调整到以不同方式和重点的下游任务中。为了解决这个问题，我们介绍了一个自我发挥的匹配模块，该模块以数据驱动的方式动态优先考虑相关的身体部位。鉴于现有骨架数据中缺乏相应的标签，我们建立了MASD，这是一个带有IMU，WiFi和Skeleton的新HAR数据集，该数据集从20个受试者中收集了27个活动。这是第一个广泛适用的HAR数据集，具有三种模式的时间同步数据。实验表明，Skelar在完整镜头和少量设置中都达到了最先进的性能。我们还证明，Skelar可以有效利用合成骨架数据来扩展其在没有骨架收集的情况下的情况。]]></description>
      <guid>https://arxiv.org/abs/2503.14547</guid>
      <pubDate>Thu, 20 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>20年内的火灾和烟数据集：深入评论</title>
      <link>https://arxiv.org/abs/2503.14552</link>
      <description><![CDATA[ARXIV：2503.14552V1公告类型：新 
摘要：火与烟雾现象对自然环境，生态系统和全球经济以及人类的生命和野生动植物构成了重大威胁。在这种特殊情况下，需要更复杂，更先进的技术来实施有效的策略，以提早检测，实时监测以及最大程度地减少火灾对生态平衡和公共安全的总体影响。最近，人工智能（AI）和计算机视觉（CV）框架的快速发展已经彻底改变了开发有效的火灾管理系统的动力。但是，这些系统广泛依赖于足够和高质量的火灾和烟数据的可用性来为各种任务（例如检测和监视）创建熟练的机器学习（ML）方法。尽管火灾和烟雾数据集在训练，评估和测试高级深度学习（DL）模型中起着至关重要的作用，但是对现有数据集的全面审查仍未开发。为此，我们提供了深入的审查，以系统地分析和评估过去20年收集的火灾和烟雾数据集。我们研究了每个数据集的特征，包括类型，大小，格式，收集方法和地理多样性。我们还审查并突出了每个数据集的独特功能，例如成像方式（RGB，热，红外）及其对不同火灾管理任务（分类，分割，检测）的适用性。此外，我们总结了每个数据集的优势和劣势，并讨论了它们在消防管理中推进研究和技术的潜力。最终，我们使用多种最先进的算法（例如Resnet-50，DeepLab-V3和Yolov8）对不同数据集进行了广泛的实验分析。]]></description>
      <guid>https://arxiv.org/abs/2503.14552</guid>
      <pubDate>Thu, 20 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>重新定义用于计算机视觉任务的联合学习中的非IID数据：从标签到嵌入到特定任务的数据分布</title>
      <link>https://arxiv.org/abs/2503.14553</link>
      <description><![CDATA[ARXIV：2503.14553V1公告类型：新 
摘要：联合学习（FL）代表分布式机器学习（ML）的范式转移，使客户能够协作培训模型，同时保持其原始数据私密。这种范式从传统的集中式ML转变引入了挑战，这是由于跨客户的非IID（非独立和相同分布的）性质，从而极大地影响了FL的性能。现有文献，主要通过跨客户施加标签分布偏见来对数据异质性进行建模。在本文中，我们表明标签分布偏斜未能完全捕获客户视觉任务任务中客户端之间的现实数据异质性。随后，我们证明了当前的方法通过依靠标签/班级分配偏斜，暴露了文献中被忽视的差距，从而高估了FL的性能。通过利用预先训练的深神经网络来提取特定于任务的数据嵌入，我们通过每个视觉任务的镜头定义了特定于任务的数据异质性，并引入了一种新的数据异质性，称为基于嵌入的数据异质性。我们的方法涉及基于嵌入的聚类数据点，并使用Dirichlet分布将它们分配到客户端。通过广泛的实验，我们评估了对数据异质性概念的不同FL方法的性能，并将新的基准性能指标引入了文献。我们进一步推出了一系列可以追求的开放研究方向。]]></description>
      <guid>https://arxiv.org/abs/2503.14553</guid>
      <pubDate>Thu, 20 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SUPERPC：一个用于点云完成，Upsmpling，DeNoing和着色的单个扩散模型</title>
      <link>https://arxiv.org/abs/2503.14558</link>
      <description><![CDATA[ARXIV：2503.14558V1公告类型：新 
摘要：Point Cloud（PC）处理任务，例如完成，UPS采样，DeNoing和Colorization-在自动驾驶和3D重建等应用中至关重要。尽管有很大的进步，但先验方法通常独立解决这些任务，而单独的模型则集中在个人问题上。但是，这种孤立的方法未能说明一个事实，即不完整，低分辨率，噪声和颜色不足之类的缺陷经常共存，每个缺陷都会影响并与其他缺陷相关。仅仅依次应用这些模型就可以导致每个模型的错误积累，并增加计算成本。为了应对这些挑战，我们介绍了SuperPC，这是第一个能够同时处理所有四个任务的统一扩散模型。我们的方法采用了一个三级条件的扩散框架，通过一种新型的空间混合融合策略增强了，以利用这四个缺陷之间的相关性来同时进行，有效的处理。我们表明，SuperPC优于最先进的专业模型以及它们在所有四个任务上的组合。]]></description>
      <guid>https://arxiv.org/abs/2503.14558</guid>
      <pubDate>Thu, 20 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>长期测试时间适应的轻松主动标签</title>
      <link>https://arxiv.org/abs/2503.14564</link>
      <description><![CDATA[ARXIV：2503.14564V1公告类型：新 
摘要：长期测试时间适应（TTA）是由于误差积累而具有挑战性的任务。最近的方法通过在每批中积极标记一小部分样本来解决这个问题，但是随着批次数量的增加，注释负担迅速增加。在本文中，我们研究了如何实现轻松的主动标签，以便在每批中选择最多一个样本进行注释。首先，我们根据TTA上下文中的单步优化观点来注释每个批次中最有价值的样本。在这种情况下，在源和目标域数据分布之间接壤的样本被认为是模型在一次迭代中学习的最可行的样本。然后，我们引入了一种有效的策略，以使用特征扰动来识别这些样本。其次，我们发现由注释和未注释的样品产生的梯度大小具有显着变化。因此，我们建议使用两个动态权重平衡它们对模型优化的影响。关于流行的Imagenet-C，-R，-K，-A和PACS数据库的广泛实验表明，我们的方法始终优于较低的注释成本的最先进方法。]]></description>
      <guid>https://arxiv.org/abs/2503.14564</guid>
      <pubDate>Thu, 20 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多模式LLM时代的图像字幕评估：挑战和未来观点</title>
      <link>https://arxiv.org/abs/2503.14604</link>
      <description><![CDATA[ARXIV：2503.14604V1公告类型：新 
摘要：机器生成的图像标题的评估是一个复杂而不断发展的挑战。随着多模式大语言模型（MLLM）的出现，图像字幕已成为一项核心任务，增加了对可靠和可靠的评估指标的需求。这项调查提供了图像字幕评估的进步，分析现有指标的演变，优势和局限性的全面概述。我们在多个维度上评估这些指标，包括与人类判断，排名准确性和对幻觉的敏感性的相关性。此外，我们探讨了MLLM产生的更长，更详细的字幕所带来的挑战，并检查当前指标对这些风格变化的适应性。我们的分析强调了标准评估方法的一些局限性，并提出了图像字幕评估的未来研究的有希望的方向。]]></description>
      <guid>https://arxiv.org/abs/2503.14604</guid>
      <pubDate>Thu, 20 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型视觉语言模型可以像人类一样阅读地图吗？</title>
      <link>https://arxiv.org/abs/2503.14607</link>
      <description><![CDATA[ARXIV：2503.14607V1公告类型：新 
摘要：在本文中，我们介绍了Mapbench-第一个数据集专为基于人类可读的，基于像素的地图的室外导航而设计，并从复杂的路径查找方案策划。 Mapbench包括超过1600个像素空间图路径，从100个不同地图中查找问题。在Mapbench中，LVLMS生成基于语言的导航指令，并给定映射图像和具有开始和端标的查询。对于每个地图，Mapbench提供地图空间场景图（MSSG）作为索引数据结构，以在自然语言之间转换并评估LVLM生成的结果。我们证明，Mapbench挑战了最先进的LVLMS零射击提示和一项经营链（COT）的增强推理框架，将MAP导航分解为顺序认知过程。我们对开源和封闭源LVLM的评估强调了Mapbench造成的实质困难，揭示了其空间推理和结构化决策能力的关键局限性。我们在https://github.com/taco-group/mapbench中发布所有代码和数据集。]]></description>
      <guid>https://arxiv.org/abs/2503.14607</guid>
      <pubDate>Thu, 20 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>动态积累的注意力图，用于解释视觉变压器决策的演变</title>
      <link>https://arxiv.org/abs/2503.14640</link>
      <description><![CDATA[ARXIV：2503.14640V1公告类型：新 
摘要：各种视觉变压器（VIT）模型已被广泛用于图像识别任务。但是，现有的视觉解释方法无法显示隐藏在VIT模型内部结构内的注意流，这解释了最终注意区域是如何在VIT内部形成的。在本文中，提出了一种新颖的视觉解释方法，即动态积累的注意图（DAAM），以提供一种可以使注意力从顶部到底部通过VIT网络的引起流动的工具。为此，提出了一个新颖的分解模块，以通过解锁每个VIT块的自我发项模块产生的[类]令牌来构建和存储空间特征信息。该模块还可以通过分解监督VIT模型的分类评分来获得通道重要性系数。由于自我监督的VIT模型缺乏分类评分，因此我们提出了尺寸的重要性权重以计算通道重要性系数。这样的空间特征与相应的通道重要性系数线性结合，从而形成每个块的注意力图。动态注意力流可以通过嵌入每个注意图来揭示。这项工作的贡献着重于可视化VIT模型内部任何中间块的决策注意力的演变动态，并提出新型的分解模块和尺寸的重要性权重。定量和定性分析始终如一地验证了所提出的DAAM的有效性和卓越能力，这不仅是用完全连接的层将VIT模型解释为分类器，而且还可以自我保护的VIT模型。该代码可在https://github.com/ly9802/dynamicaccumulationatemap上获得。]]></description>
      <guid>https://arxiv.org/abs/2503.14640</guid>
      <pubDate>Thu, 20 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>