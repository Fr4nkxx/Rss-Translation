<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CV 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Tue, 23 Jul 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>CrowdMAC：蒙版人群密度补全，实现稳健的人群密度预测</title>
      <link>https://arxiv.org/abs/2407.14725</link>
      <description><![CDATA[arXiv:2407.14725v1 公告类型：新
摘要：人群密度预测任务旨在根据观察到的过去人群密度图预测未来人群密度图将如何变化。然而，由于行人的误检，过去的人群密度图往往不完整，开发一个针对误检的鲁棒人群密度预测模型至关重要。本文提出了一种用于人群密度预测的 MAsked 人群密度完成框架 (CrowdMAC)，该框架在重建被掩盖的观察图（即，输入有误检的过去地图）的同时，还经过训练可以从部分掩盖的过去人群密度图中预测未来人群密度图（即，从有误检的过去地图预测地图）。此外，我们提出了时间密度感知掩盖 (TDM)，它考虑到人群密度图的稀疏性和后续帧对预测任务的信息性，对观察到的人群密度图中的标记进行非均匀掩盖。此外，我们引入了多任务掩蔽来提高训练效率。在实验中，CrowdMAC 在七个大型数据集上实现了最佳性能，包括 SDD、ETH-UCY、inD、JRDB、VSCrowd、FDST 和 croHD。我们还证明了所提出的方法对合成和实际误检的稳健性。]]></description>
      <guid>https://arxiv.org/abs/2407.14725</guid>
      <pubDate>Wed, 24 Jul 2024 03:14:24 GMT</pubDate>
    </item>
    <item>
      <title>MetaAug：用于训练后量化的元数据增强</title>
      <link>https://arxiv.org/abs/2407.14726</link>
      <description><![CDATA[arXiv:2407.14726v1 公告类型：新
摘要：训练后量化 (PTQ) 受到了广泛关注，因为它只需要一小组校准数据即可量化全精度模型，这在无法完全访问大型训练集的实际应用中更为实用。然而，它往往会导致在小型校准数据集上过度拟合。已经提出了几种方法来解决这个问题，但它们仍然只依赖校准集进行量化，并且由于缺乏验证集，它们不会验证量化模型。在这项工作中，我们提出了一种基于元学习的新型方法来提高训练后量化的性能。具体来说，为了缓解过度拟合问题，我们的方法使用两组不同的图像来训练和验证量化模型，而不是像以前的 PTQ 工作那样在学习过程中仅使用原始校准集训练量化模型而不进行任何验证。具体来说，我们提出了一种基于元学习的方法，通过双层优化联合优化转换网络和量化模型。转换网络修改原始校准数据，修改后的数据将用作训练集来学习量化模型，目的是使量化模型在原始校准数据上取得良好的性能。在广泛使用的 ImageNet 数据集上使用不同神经网络架构进行的大量实验表明，我们的方法优于最先进的 PTQ 方法。]]></description>
      <guid>https://arxiv.org/abs/2407.14726</guid>
      <pubDate>Wed, 24 Jul 2024 03:14:24 GMT</pubDate>
    </item>
    <item>
      <title>通过低分辨率图像训练的卷积神经网络实现咖啡叶锈病的早期检测</title>
      <link>https://arxiv.org/abs/2407.14737</link>
      <description><![CDATA[arXiv:2407.14737v1 公告类型：新
摘要：咖啡叶锈病是一种由真菌 Hemileia vastatrix 引起的叶面疾病，对咖啡生产构成重大威胁，尤其是在中美洲。气候变化进一步加剧了这一问题，因为它缩短了叶锈病等疾病从初次感染到出现可见症状之间的潜伏期。潜伏期缩短会导致更严重的植物流行病和疾病更快的传播。因此，迫切需要有效的疾病管理策略。为了应对这些挑战，我们探索了深度学习模型在增强早期疾病检测方面的潜力。然而，深度学习模型需要广泛的处理能力和大量数据来进行模型训练，而这些资源通常很稀缺。为了克服这些障碍，我们提出了一种预处理技术，该技术涉及将训练图像与高通滤波器卷积以增强病变叶片对比度，从而显着提高资源有限环境中的模型功效。该方法和我们的模型表现出色，在所有评估指标（包括准确率、召回率、F1 分数和 Dice 系数）中均达到 90% 以上。我们的实验表明，该方法优于其他方法，包括两种不同的图像预处理技术和使用未改变的全彩色图像。]]></description>
      <guid>https://arxiv.org/abs/2407.14737</guid>
      <pubDate>Wed, 24 Jul 2024 03:14:24 GMT</pubDate>
    </item>
    <item>
      <title>小样本动作识别的综合回顾</title>
      <link>https://arxiv.org/abs/2407.14744</link>
      <description><![CDATA[arXiv:2407.14744v1 公告类型：新
摘要：少样本动作识别旨在解决动作识别中手动标记复杂多变的视频数据的高成本和不切实际的问题。它需要使用每个类别中少量标记的示例对视频中的人类动作进行准确分类。与图像场景中的少样本学习相比，由于视频数据的内在复杂性，少样本动作识别更具挑战性。识别动作涉及对复杂的时间序列进行建模并提取丰富的语义信息，这超出了每帧中单纯的人和物体识别。此外，类内方差问题在有限的视频样本中变得尤为明显，这使得学习新动作类别的代表性特征变得复杂。为了克服这些挑战，许多方法推动了少样本动作识别的重大进步，这凸显了进行全面调查的必要性。与早期专注于少样本图像或文本分类的调查不同，我们深入考虑了少样本动作识别的独特挑战。在这次调查中，我们回顾了各种最近的方法并总结了一般框架。此外，本调查还介绍了常用的基准，并讨论了相关的高级主题和有前景的未来方向。我们希望本调查可以成为研究人员的宝贵资源，为新手提供必要的指导，并以新见解激励经验丰富的研究人员。]]></description>
      <guid>https://arxiv.org/abs/2407.14744</guid>
      <pubDate>Wed, 24 Jul 2024 03:14:24 GMT</pubDate>
    </item>
    <item>
      <title>一种新的轻量级混合图卷积神经网络——使用物体检测推理进行场景分类的 CNN 方案</title>
      <link>https://arxiv.org/abs/2407.14658</link>
      <description><![CDATA[arXiv:2407.14658v1 公告类型：新
摘要：场景理解在自动驾驶汽车、智能视频监控或机器人等多种高级计算机视觉应用中发挥着重要作用。然而，针对室内/室外场景分类提出的解决方案太少，无法确保计算机视觉框架的场景环境适应性。我们提出了第一个轻量级混合图卷积神经网络 (LH-GCNN)-CNN 框架作为对象检测模型的附加组件。所提出的方法使用 CNN 对象检测模型的输出通过生成表示观察到的场景的语义和几何内容的连贯 GCNN 来预测观察到的场景类型。这种应用于自然场景的新方法在包含大量不同场景的 COCO 衍生数据集中实现了超过 90% 的场景分类效率，同时需要的参数比传统的 CNN 方法更少。为了造福科学界，我们将公开源代码：https://github.com/Aymanbegh/Hybrid-GCNN-CNN。]]></description>
      <guid>https://arxiv.org/abs/2407.14658</guid>
      <pubDate>Wed, 24 Jul 2024 03:14:23 GMT</pubDate>
    </item>
    <item>
      <title>从合成数据中学习判别特征以实现自监督细粒度视觉识别</title>
      <link>https://arxiv.org/abs/2407.14676</link>
      <description><![CDATA[arXiv:2407.14676v1 公告类型：新
摘要：自监督学习 (SSL) 已成为在各种任务中获取视觉表征的主要方法，但它在细粒度视觉识别 (FGVR) 中的应用面临着区分类别之间细微差别的复杂任务的挑战。为了克服这个问题，我们引入了一种新策略，可以增强 SSL 提取对 FGVR 至关重要的关键判别特征的能力。这种方法创建了合成数据对，以引导模型在 SSL 期间关注对 FGVR 至关重要的判别特征。我们首先使用两个主要标准来识别非判别特征：无法有效分离数据的低方差特征和由 SSL 损失引起的 Grad-CAM 认为不太重要的特征。然后，我们在保留判别特征的同时对这些非判别特征进行扰动。使用解码器从扰动和原始特征向量重建图像以创建数据对。编码器在生成的这些数据对上进行训练，使其对非判别性维度的变化具有不变性，同时专注于判别性特征，从而提高模型在 FGVR 任务中的性能。我们通过对各种数据集进行广泛的评估，证明了所提出的方法具有良好的 FGVR 性能。]]></description>
      <guid>https://arxiv.org/abs/2407.14676</guid>
      <pubDate>Wed, 24 Jul 2024 03:14:23 GMT</pubDate>
    </item>
    <item>
      <title>$\infty$-Brush：具有无限维扩散模型的可控大图像合成</title>
      <link>https://arxiv.org/abs/2407.14709</link>
      <description><![CDATA[arXiv:2407.14709v1 公告类型：新
摘要：从复杂的特定领域信息中合成高分辨率图像仍然是生成建模中的一项重大挑战，特别是对于数字组织病理学和遥感等大图像领域的应用。现有方法面临关键限制：像素或潜在空间中的条件扩散模型不能在不损失保真度的情况下超过训练时的分辨率，并且对于较大的图像尺寸，计算需求会显着增加。基于块的方法提供了计算效率，但由于过度依赖局部信息而无法捕获长距离空间关系。在本文中，我们介绍了一种新的无限维条件扩散模型$ \ infty $-Brush，用于可控的大图像合成。我们提出了一个交叉注意神经算子来实现函数空间中的条件调节。我们的模型克服了传统有限维扩散模型和基于块的方法的限制，提供了可扩展性和在保留全局图像结构的同时保持精细细节的卓越能力。据我们所知，$\infty$-Brush 是函数空间中第一个条件扩散模型，可以可控地合成分辨率高达 $4096\times4096$ 像素的图像。代码可在 https://github.com/cvlab-stonybrook/infinity-brush 上找到。]]></description>
      <guid>https://arxiv.org/abs/2407.14709</guid>
      <pubDate>Wed, 24 Jul 2024 03:14:23 GMT</pubDate>
    </item>
    <item>
      <title>多摄像机环境下群体重新识别的研究</title>
      <link>https://arxiv.org/abs/2407.14620</link>
      <description><![CDATA[arXiv:2407.14620v1 公告类型：新
摘要：物体重新识别在视觉监控中越来越重要。大多数现有工作都集中在从多个摄像机重新识别个体，而很少讨论群体重新识别（Re-ID）的应用。我们将群体重新识别重新定义为一个包括行人检测、特征提取、图形模型构建和图形匹配的过程。群体重新识别非常具有挑战性，因为它不仅受到传统重新识别任务中视点和人体姿势变化的干扰，而且还受到群体布局变化和群体成员变化的挑战。为了应对上述挑战，本文介绍了一种新方法，该方法利用群体内部的多粒度信息来促进群体重新识别。我们首先介绍了一种多粒度 Re-ID 流程，该流程为组中的多粒度对象（人/人子组）获取特征，并在组 Re-ID 期间迭代评估其重要性，以处理由于视角变化和组动态而导致的组内错位。我们进一步介绍了一种多阶匹配方案。它自适应地选择每个组中的代表性人/人子组，并整合来自这些人/人子组的多粒度信息以获得组内匹配，从而实现组间更可靠的匹配分数。在各种数据集上的实验结果证明了我们方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2407.14620</guid>
      <pubDate>Wed, 24 Jul 2024 03:14:22 GMT</pubDate>
    </item>
    <item>
      <title>利用自监督神经网络推进黑色素瘤诊断：评估不同技术的有效性</title>
      <link>https://arxiv.org/abs/2407.14628</link>
      <description><![CDATA[arXiv:2407.14628v1 公告类型：新
摘要：我们研究了自我监督在提高经过训练的深度学习模型对黑色素瘤斑块进行分类的准确性方面的潜力。实施了各种自我监督技术，例如旋转预测、缺失斑块预测和损坏消除，并评估了它们对卷积神经网络性能的影响。初步结果表明，自我监督方法对模型的准确性有积极影响。该研究特别证明了损坏消除方法在提高模型性能方面的有效性。尽管有明显的改进，但我们得出结论，自我监督模型具有相当大的进一步增强潜力，可以通过更多时期的训练或扩展数据集来实现。我们建议在未来的研究中探索其他自我监督方法，如 Bootstrap Your Own Latent (BYOL) 和对比学习，强调由于其资源密集型性质而产生的成本效益权衡。这些发现强调了自我监督在增强深度学习模型的黑色素瘤检测能力方面的前景。]]></description>
      <guid>https://arxiv.org/abs/2407.14628</guid>
      <pubDate>Wed, 24 Jul 2024 03:14:22 GMT</pubDate>
    </item>
    <item>
      <title>收集手套箱环境下的协同装配人机协作数据集</title>
      <link>https://arxiv.org/abs/2407.14649</link>
      <description><![CDATA[arXiv:2407.14649v1 公告类型：新
摘要：工业 4.0 引入了 AI 作为现代化制造流程的变革性解决方案。它的继任者工业 5.0 将人类视为指导这些 AI 驱动的制造解决方案的合作者和专家。开发这些技术需要能够在协作装配过程中安全、实时识别场景中人体位置（尤其是手部）的算法。尽管已经付出了大量努力来整理用于手部分割的数据集，但大多数数据集都集中在住宅或商业领域。现有的针对工业环境的数据集主要依赖于合成数据，我们证明这些数据无法有效地转移到现实世界的操作中。此外，这些数据集缺乏对安全协作至关重要的不确定性估计。为了解决这些差距，我们提出了 HAGS：手和手套分割数据集。该数据集提供了 1200 个具有挑战性的示例，用于在工业人机协作场景中构建手部和手套分割应用，以及评估通过绿屏增强构建的分布外图像，以确定 ML 分类器的稳健性。我们研究最先进的实时分割模型来评估现有方法。我们的数据集和基线是公开的：https://dataverse.tdl.org/dataset.xhtml?persistentId=doi:10.18738/T8/85R7KQ 和 https://github.com/UTNuclearRoboticsPublic/assembly_glovebox_dataset。]]></description>
      <guid>https://arxiv.org/abs/2407.14649</guid>
      <pubDate>Wed, 24 Jul 2024 03:14:22 GMT</pubDate>
    </item>
    <item>
      <title>LORTSAR：基于骨架的动作识别低秩变换器</title>
      <link>https://arxiv.org/abs/2407.14655</link>
      <description><![CDATA[arXiv:2407.14655v1 公告类型：新
摘要：用于基于骨架的动作识别的最先进的基于 Transformer 的模型的复杂性在计算效率和资源利用率方面带来了重大挑战。在本文中，我们探索了奇异值分解 (SVD) 的应用，以有效地减少这些预训练模型的模型大小，旨在最大限度地减少它们的资源消耗，同时保持准确性。我们的方法 LORTSAR (基于骨架的动作识别的低秩 Transformer) 还包括一个微调步骤，以补偿模型压缩导致的任何潜在准确性下降，并应用于两个领先的基于 Transformer 的模型“Hyperformer”和“STEP-CATFormer”。在“NTU RGB+D”和“NTU RGB+D 120”数据集上的实验结果表明，我们的方法可以显着减少模型参数的数量，而识别准确率几乎不会下降甚至性能提高。这证实了 SVD 结合压缩后微调可以提高模型效率，为更可持续、轻量级和高性能的人体动作识别技术铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2407.14655</guid>
      <pubDate>Wed, 24 Jul 2024 03:14:22 GMT</pubDate>
    </item>
    <item>
      <title>从生成视觉和语言模型中学习视觉基础</title>
      <link>https://arxiv.org/abs/2407.14563</link>
      <description><![CDATA[arXiv:2407.14563v1 公告类型：新
摘要：视觉基础任务旨在根据自然语言参考定位图像区域。在这项工作中，我们探索是否可以利用主要在图像文本数据上训练的生成式 VLM 来扩大视觉基础数据的文本注释。我们发现基础知识已经存在于生成式 VLM 中，可以通过适当的提示来引出。因此，我们通过从现有对象检测数据集中输入对象区域来提示 VLM 生成对象级描述。我们进一步提出了属性建模来明确捕获重要的对象属性，以及空间关系建模来捕获对象间关系，这两者都是指称表达中的常见语言模式。我们构建的数据集（500K 图像、1M 对象、16M 指称表达）是迄今为止最大的基础数据集之一，也是第一个具有纯模型生成的查询和人工注释对象的基础数据集。为了验证这些数据的质量，我们对流行的 RefCOCO 基准进行了零样本迁移实验，以完成指称表达理解 (REC) 和分割 (RES) 任务。在这两项任务中，我们的模型的表现都显著优于最先进的方法，而无需使用人工注释的视觉基础数据。我们的结果证明了生成式 VLM 在现实世界中扩大视觉基础的前景。代码和模型即将发布。]]></description>
      <guid>https://arxiv.org/abs/2407.14563</guid>
      <pubDate>Wed, 24 Jul 2024 03:14:21 GMT</pubDate>
    </item>
    <item>
      <title>手工制作的过滤器是否有助于归因人工智能生成的图像？</title>
      <link>https://arxiv.org/abs/2407.14570</link>
      <description><![CDATA[arXiv:2407.14570v2 公告类型：新
摘要：最近，大量的图像生成模型被提出，这引发了人们对滥用这些人工智能 (AI) 技术生成假图像的担忧。为了归因人工智能生成的图像，现有方案通常设计和训练深度神经网络 (DNN) 来学习模型指纹，这通常需要大量数据才能有效学习。在本文中，我们旨在回答以下两个关于人工智能生成的图像归因的问题：1) 是否有可能设计有用的手工制作的过滤器来促进指纹学习？2) 在我们加入手工制作的过滤器后，我们如何减少训练数据量？我们首先提出一组多方向​​高通滤波器 (MHF)，它们能够从各个方向提取细微的指纹。然后，我们提出了一个方向增强特征学习网络 (DEFL)，将 MHF 和随机初始化的过滤器都考虑在内。 DEFL 的输出与语义特征融合以生成紧凑指纹。为了使紧凑指纹在不同模型之间具有区分性，我们提出了双边缘对比 (DMC) 损失来调整我们的 DEFL。最后，我们提出了一种基于参考的图像归因指纹分类方案。实验结果表明，使用我们的 MHF 来归因 AI 生成的图像确实很有帮助。我们提出的方法的性能明显优于闭集和开集图像归因的最新技术，其中只需要少量图像进行训练。]]></description>
      <guid>https://arxiv.org/abs/2407.14570</guid>
      <pubDate>Wed, 24 Jul 2024 03:14:21 GMT</pubDate>
    </item>
    <item>
      <title>使用 CNN 和改进的 VGG16 模型进行情绪识别迁移学习的比较研究</title>
      <link>https://arxiv.org/abs/2407.14576</link>
      <description><![CDATA[arXiv:2407.14576v1 公告类型：新
摘要：情绪识别是人类互动的一个重要方面。这个话题在人工智能领域引起了极大的关注。在本研究中，我们研究了卷积神经网络 (CNN) 和 Modified VGG16 模型在两个数据集（FER2013 和 AffectNet）中情绪识别任务的性能。我们的目标是衡量这些模型在识别情绪方面的有效性以及它们推广到不同和更广泛的数据集的能力。我们的研究结果表明，这两种模型在 FER2013 数据集上都取得了合理的性能，而 Modified VGG16 模型的准确度略有提高。在 Affect-Net 数据集上进行评估时，两种模型的性能都会下降，而 Modified VGG16 模型的表现继续优于 CNN。我们的研究强调了数据集多样性在情绪识别中的重要性，并讨论了未解决的问题和未来的研究方向，包括探索多模态方法和开发更全面的数据集。]]></description>
      <guid>https://arxiv.org/abs/2407.14576</guid>
      <pubDate>Wed, 24 Jul 2024 03:14:21 GMT</pubDate>
    </item>
    <item>
      <title>ESCAPE：基于能量的选择性自适应校正，用于分布外 3D 人体姿势估计</title>
      <link>https://arxiv.org/abs/2407.14605</link>
      <description><![CDATA[arXiv:2407.14605v1 公告类型：新
摘要：尽管人体姿势估计 (HPE) 取得了最新进展，但对分布外 (OOD) 数据的泛化能力较差仍然是一个难题。虽然之前的研究已经提出了测试时间自适应 (TTA) 来通过在推理时细化网络参数来弥补训练测试域差距，但缺乏地面实况注释使其极具挑战性，现有方法通常会将推理时间增加一个或多个数量级。我们观察到 1) 并非每个测试时间样本都是 OOD，2) 远端关键点（手腕、脚踝）的 HPE 误差明显较大。为此，我们提出了 ESCAPE：一种轻量级校正和选择性自适应框架，它对大多数数据应用快速前向校正，同时为 OOD 数据保留昂贵的 TTA。引入自由能函数将 OOD 样本与传入数据分离，并训练校正网络以估计预训练主干 HPE 预测对远端关键点的误差。对于 OOD 样本，我们提出了一种新颖的自洽适应损失，通过第二个“反向”网络利用远端关键点和近端关键点（肩部、臀部）之间的约束关系来更新校正网络。ESCAPE 在未见数据上将五种流行 HPE 模型的远端 MPJPE 提高了高达 7%，在两个流行的 HPE 基准上取得了最先进的结果，并且比现有的适应方法快得多。]]></description>
      <guid>https://arxiv.org/abs/2407.14605</guid>
      <pubDate>Wed, 24 Jul 2024 03:14:21 GMT</pubDate>
    </item>
    </channel>
</rss>