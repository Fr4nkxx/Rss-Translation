<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>CS.CV更新arxiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.cv更新arxiv.org e-print存档。</description>
    <lastBuildDate>Thu, 13 Mar 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>各向异性颗粒的方向跟踪方法</title>
      <link>https://arxiv.org/abs/2503.08694</link>
      <description><![CDATA[ARXIV：2503.08694V1公告类型：新 
摘要：针对各向异性颗粒的粒子方向跟踪方法是开发和演示的。利用（高速）多摄像机的各向异性颗粒的多相机记录从不同的角度使用，我们使用已知的形状重建了这些粒子的3D位置和方向。本文介绍了一种算法，该算法随着时间的推移跟踪多个各向异性颗粒的位置和方向，从而详细研究了位置，方向和旋转统计。量化了此方法的鲁棒性和误差，我们通过将算法应用于合成图像来探索噪声，图像大小，使用相机数量以及相机布置的影响。我们在几个实验（在静态流体和湍流中）中展示了该方法的几个用例，证明了所描述的跟踪方法的有效性和广泛的适用性。所提出的方法显示可用于广泛不同的粒子形状，同时成功跟踪多个粒子，并且该方法可以区分不同类型的粒子。]]></description>
      <guid>https://arxiv.org/abs/2503.08694</guid>
      <pubDate>Thu, 13 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>自主驾驶中的分布分段：问题和最新状态</title>
      <link>https://arxiv.org/abs/2503.08695</link>
      <description><![CDATA[ARXIV：2503.08695V1公告类型：新 
摘要：在本文中，我们回顾了分布外（OOD）细分的最新技术，重点是自动驾驶中的道路障碍物检测作为现实世界的应用。我们分析了两种广泛使用的基准测试的现有方法的性能，分割了障碍物轨道和失落的障碍物，突出了它们的优势，局限性和现实世界的适用性。此外，我们讨论了主要的挑战，并概述了推进该领域的潜在研究方向。我们的目标是为研究人员和从业人员提供有关当前OOD细分景观的全面视角，并促进进一步的进步，朝着更安全，更可靠的自动驾驶系统方面发展。]]></description>
      <guid>https://arxiv.org/abs/2503.08695</guid>
      <pubDate>Thu, 13 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用嵌入式U-NET对空中图像进行实时语义分割：CPU，GPU和FPGA工作流程的比较</title>
      <link>https://arxiv.org/abs/2503.08700</link>
      <description><![CDATA[ARXIV：2503.08700V1公告类型：新 
摘要：这项研究介绍了一种优化的轻巧的U-NET模型，以实时的空中图像的实时语义分割，以有效利用商业现成（COTS）嵌入式计算平台。 We maintain the accuracy of the U-Net on a real-world dataset while significantly reducing the model&#39;s parameters and Multiply-Accumulate (MAC) operations by a factor of 16. Our comprehensive analysis covers three hardware platforms (CPU, GPU, and FPGA) and five different toolchains (TVM, FINN, Vitis AI, TensorFlow GPU, and cuDNN), assessing each on metrics such as延迟，功耗，内存足迹，能源效率和FPGA资源使用情况。结果突出了这些平台和工具链之间的权衡，特别关注现实世界应用中的实际部署挑战。我们的发现表明，尽管FPGA具有Vitis AI的FPGA作为其性能，能效和成熟度的出色选择，但它需要专业的硬件知识，强调需要平衡的方法来选择嵌入式计算解决方案，以进行语义段任务]]></description>
      <guid>https://arxiv.org/abs/2503.08700</guid>
      <pubDate>Thu, 13 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>全身动画的多功能多模式控件</title>
      <link>https://arxiv.org/abs/2503.08714</link>
      <description><![CDATA[ARXIV：2503.08714V1公告类型：新 
摘要：来自单个参考图像的人类动画应灵活，以使爆头或全身肖像合成全身运动，其中动作很容易通过音频信号和文本提示来控制。对于大多数现有方法而言，这很难，因为它们仅支持产生预先指定的头部或半身运动与音频输入对齐的头部运动。在本文中，我们提出了一种多功能的人类动画方法，即Versaanimator，该方法从任意肖像图像中生成了全身说话的人类，不仅是由音频信号驱动的，而且还受文本提示的灵活控制。具体而言，我们设计了一个文本控制的，音频驱动的运动发生器，该动作生成器在3D中与音频输入同步的3D同时产生全身运动表示形式，同时遵循文本运动描述。为了促进自然的平滑运动，我们提出了一个代码姿势翻译模块，将VAE代码簿与从模板视频中提取的2D DWPOSE联系起来。此外，我们介绍了一个多模式视频扩散，该视频扩散会根据音频输入和全身运动表示从参考图像中生成逼真的人类动画。广泛的实验表明，Versaimator在视觉质量，身份保存和音频同步方面的表现优于现有方法。]]></description>
      <guid>https://arxiv.org/abs/2503.08714</guid>
      <pubDate>Thu, 13 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>改善遥感VLM零射击概括的秘诀</title>
      <link>https://arxiv.org/abs/2503.08722</link>
      <description><![CDATA[ARXIV：2503.08722V1公告类型：新 
摘要：基础模型对各种AI应用产生了重大影响，从而实现了以前不可能的用例。在许多任务中，尤其是对比性视觉语言模型（VLMS）在许多任务中的其他技术都优于其他技术。但是，由于遥感视觉语言数据集的稀缺性，它们在遥感（RS）中的普遍性仍然有限。在这项工作中，我们介绍了两个新型的图像捕获数据集，用于培训遥感基础模型。第一个数据集将天线和卫星图像与双子座生成的标题配对，并使用从Google Maps中提取的地标生成。第二个数据集利用公共网络图像及其相应的Alt-Text，用于遥感域，从而产生了多样化的数据集，图像样式和主题都具有更大的广度。这些数据集用于预先培训the mammut〜 \ citep {kuo2023mammutsimplearchitecture关键} vlm架构，从而在零摄像的交叉模式检索中在众所周知的公共基准下进行最新的通用性能。最后，我们介绍了正在进行的研究，以提炼在VLM对比度训练程序中获得的图像级知识，以增强模型的本地化能力。具体而言，我们根据模型的注意图迭代生成图像区域的伪标记，并使用这些标签进行进一步训练。为了减轻嘈杂的注意图并创建可靠的分割面罩，我们引入了一种新型的注意力吸收机制，称为“平滑注意”操作。]]></description>
      <guid>https://arxiv.org/abs/2503.08722</guid>
      <pubDate>Thu, 13 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过扩散模型保留大规模图像的产品保真度</title>
      <link>https://arxiv.org/abs/2503.08729</link>
      <description><![CDATA[ARXIV：2503.08729V1公告类型：新 
摘要：我们提出了一个使用文本对图扩散模型和新型数据增强管道的高保真产品图像再上下文化的框架。该管道利用图像到视频扩散，在/支出和负面方面来创建合成训练数据，以解决此任务的现实世界数据收集的局限性。我们的方法通过解开产品表示并增强模型对产品特性的理解来提高生成图像的质量和多样性。使用自动指标和人类评估对ABO数据集和私人产品数据集进行评估，证明了我们框架在产生现实和引人入胜的产品可视化方面的有效性，对电子商务和虚拟产品展示等应用的影响。]]></description>
      <guid>https://arxiv.org/abs/2503.08729</guid>
      <pubDate>Thu, 13 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Fairdeface：评估面部混淆方法的公平和对抗性鲁棒性</title>
      <link>https://arxiv.org/abs/2503.08731</link>
      <description><![CDATA[ARXIV：2503.08731V1公告类型：新 
摘要：缺乏用于评估面部混淆方法的常见平台和基准数据集是一个挑战，使用任意实验，数据集和指标对每种方法进行测试。虽然先前的工作表明，面部识别系统对某些人口统计群体表现出偏见，但我们对面部混淆方法的公平性的理解存在很大的差距。提供公平的面貌混淆方法可以确保各种人口组的公平保护，尤其是因为它们可以用来保留弱势群体的隐私。为了解决这些差距，本文介绍了一个名为Fairdeface的综合框架，旨在评估面部混淆方法的对抗性鲁棒性和公平性。该框架引入了一组模块，其中包含数据基准，面部检测和识别算法，对抗模型，公用事业检测模型和公平度量指标。 Fairdeface是一个多功能平台，可以集成任何面部混淆方法，从而可以与其他最先进的方法进行严格的测试和比较。 Fairdeface在目前的实施中包含了6次攻击，以及一些隐私，公用事业和公平指标。使用Fairdeface，并通过进行500多个实验，我们评估并比较了七种面部混淆方法的对抗性鲁棒性。这种广泛的分析导致了许多有趣的发现，包括现有方法的鲁棒性及其对某些性别或种族群体的偏见。 Fairdeface还使用重点区域的可视化来进行混淆和验证攻击，不仅显示了某些人口统计学的混淆过程中主要改变了哪些区域，而且还显示了为什么它们通过对混淆和验证的重点区域比较而失败的原因。]]></description>
      <guid>https://arxiv.org/abs/2503.08731</guid>
      <pubDate>Thu, 13 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用64个潜在矢量代表3D扩散模型的3D形状</title>
      <link>https://arxiv.org/abs/2503.08737</link>
      <description><![CDATA[ARXIV：2503.08737V1公告类型：新 
摘要：通过变量自动编码器（VAE）构建压缩潜在空间是有效的3D扩散模型的关键。本文介绍了COD-VAE，该VAE是一种编码3D形状的VAE，不牺牲质量，将3D形状编码为紧凑的1D潜在媒介。 COD-VAE引入了两阶段的自动编码器方案，以提高压缩和解码效率。首先，我们的编码器块通过中间点贴片逐渐压缩为紧凑的潜在向量。其次，我们基于三烷基的解码器重建了潜在载体的密集三分球，而不是直接解码神经场，从而大大降低了神经场解码的计算开销。最后，我们提出了不确定性引导的代币修剪，该修剪通过跳过更简单区域的计算并提高解码器效率来自适应地分配资源。实验结果表明，与基线相比，COD-VAE在保持质量的同时，达到了16倍的压缩。这使20.8倍的加速能力发表，强调了大量潜在向量不是高质量重建和生成的先决条件。]]></description>
      <guid>https://arxiv.org/abs/2503.08737</guid>
      <pubDate>Thu, 13 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>绿洲：多模式指令数据综合所需的一张图像</title>
      <link>https://arxiv.org/abs/2503.08741</link>
      <description><![CDATA[ARXIV：2503.08741V1公告类型：新 
摘要：多模式大语言模型（MLLM）的成功主要归因于大型培训数据。但是，由于隐私问题，许多MLLM的培训数据无法使用。收集多模式数据的昂贵且劳动密集型的过程进一步加剧了问题。是否可以自动合成多模式训练数据，而不会损害多样性和质量？在本文中，我们提出了一种新方法，即仅使用图像合成高质量的多模式数据。 OASIS通过仅向MLLM提示图像来破坏传统方法，从而将数据多样性扩展到很大的边距。我们的方法具有一种精致的质量控制方法，可确保数据质量。我们收集了超过500k的数据，并在LLAVA-NEXT上进行了增量实验。广泛的实验表明，我们的方法可以显着提高MLLM的性能。基于图像的合成还使我们能够专注于MLLM的特定域能力。代码和数据将公开可用。]]></description>
      <guid>https://arxiv.org/abs/2503.08741</guid>
      <pubDate>Thu, 13 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>解开世界模型：学习从分散注意力的视频中转移语义知识以进行强化学习</title>
      <link>https://arxiv.org/abs/2503.08751</link>
      <description><![CDATA[ARXIV：2503.08751V1公告类型：新 
摘要：在实际情况下，培训视觉增强学习（RL）提出了一个重大挑战，$ \ textit {i。尽管各种方法试图通过分离表示的学习来减轻这个问题，但这些方法通常在没有事先了解世界的情况下从头开始学习。相比之下，本文试图通过离线到Online的潜在蒸馏和灵活的分离限制来学习和理解分散视频的潜在语义变化。为了启用有效的跨域语义知识转移，我们引入了一个可解释的基于模型的RL框架，称为Disentangled World Models（DISWM）。具体来说，我们将无动作的视频预测模型脱机预定，并通过分离正规化来从分散视频中提取语义知识。然后通过潜在蒸馏将验证模型的分离能力转移到世界模型中。对于在线环境中的填充，我们利用验证的模型利用知识，并对世界模型引入了分离的限制。在适应阶段，在线环境相互作用中纳入动作和奖励会丰富数据的多样性，这反过来又增强了分离的表示形式学习。实验结果验证了我们方法在各种基准测试上的优越性。]]></description>
      <guid>https://arxiv.org/abs/2503.08751</guid>
      <pubDate>Thu, 13 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>像您测试一样过滤：用于剪辑预处理的数据驱动数据过滤</title>
      <link>https://arxiv.org/abs/2503.08805</link>
      <description><![CDATA[ARXIV：2503.08805V1公告类型：新 
摘要：我们介绍了像您的测试（Flyt）一样介绍过滤器，这是一种策划大规模视觉语言数据集的方法，该数据集将每个数据点作为一个预处理的示例学习。弗莱特（Flyt）训练一个评分模型，该模型学会使用下游任务训练集中的梯度信号来称量每个示例。使用相同的训练方法，我们开发了混合粉末（M-Flyt），该方法采用不同评分方法产生的每个示例分数，并学会将它们统一成单个分数。我们的培训方法自然会在培训示例上产生分布，我们通过软上限采样（SCS）利用这些分布，这是一种从每个示例概率中获得过滤的预处理数据集的策略，这些数据集示例示例示例，同时通过重复惩罚预防过度代表。使用所有三种方法，我们在Datacomp Medium Scale滤波基准上实现了40.1％的Imagenet零射击精度，比以前所有结果的绝对准确性提高了1.9％，并且比我们（例如我们）仅使用公共资源的结果增加了5.5％。]]></description>
      <guid>https://arxiv.org/abs/2503.08805</guid>
      <pubDate>Thu, 13 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在户外农业环境中，关键点语义集成以改进功能匹配</title>
      <link>https://arxiv.org/abs/2503.08843</link>
      <description><![CDATA[ARXIV：2503.08843V1公告类型：新 
摘要：在室外环境中，健壮的机器人导航需要能够处理视觉挑战的准确感知系统，例如重复结构和不断变化的外观。视觉功能匹配对于基于视觉的管道至关重要，但由于知觉混乱，在自然户外环境中尤其具有挑战性。我们在葡萄园中解决了这个问题，在葡萄园中，重复的葡萄树干和其他自然元素会产生模棱两可的描述符，从而阻碍可靠的特征匹配。我们假设与关键点位置相关的语义信息可以通过增强关键点描述符的独特性来减轻知觉混乱。为此，我们介绍了一种按键点语义集成技术，该技术可以改善图像中语义上有意义的区域中的描述符，即使在视觉上相似的本地特征中，也可以更准确地差异化。我们在两个葡萄园感知任务中验证了这种方法：（i）相对姿势估计和（ii）视觉定位。在所有经过测试的关键点类型和描述符中，我们的方法将匹配的准确性提高了12.6％，在挑战性的葡萄园条件下表明了其在多个月内的有效性。]]></description>
      <guid>https://arxiv.org/abs/2503.08843</guid>
      <pubDate>Thu, 13 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>查看不存在的内容：多模式LLM中的虚假相关性</title>
      <link>https://arxiv.org/abs/2503.08884</link>
      <description><![CDATA[ARXIV：2503.08884V1公告类型：新 
摘要：已知单峰视觉模型依赖于虚假的相关性，但是尽管语言监督了语言，但尚不清楚多模式大语言模型（MLLM）在多大程度上表现出相似的偏见。在本文中，我们调查了MLLM中的杂散偏见，并引入Spurlens，这是一种利用GPT-4和开放式对象检测器的管道，以自动识别无人监督的虚假视觉提示。我们的发现表明，伪造的相关性在MLLM中引起了两种主要的故障模式：（1）过度依赖对物体识别的虚假提示，其中消除这些线索会降低准确性，以及（2）物体幻觉，在其中伪造的提示将幻觉扩大了10倍以上。我们在各种MLLM和数据集中验证我们的发现。除了诊断这些故障外，我们还探索了潜在的缓解策略，例如迅速结合和基于推理的提示，并进行消融研究以检查MLLM中伪造偏见的根本原因。通过揭示虚假相关性的持续性，我们的研究要求采用更严格的评估方法和缓解策略来提高MLLM的可靠性。]]></description>
      <guid>https://arxiv.org/abs/2503.08884</guid>
      <pubDate>Thu, 13 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>及时：视觉模型适应知识保存的最佳传输正规化范式</title>
      <link>https://arxiv.org/abs/2503.08906</link>
      <description><![CDATA[ARXIV：2503.08906V1公告类型：新 
摘要：视觉模型（VLM）（例如剪辑）表现出强烈的性能，但在适应下游任务时挣扎。迅速学习已成为一种适应VLM的有效策略，同时保留其预培训的知识。但是，现有方法仍会导致过度拟合和降解零弹性概括。为了应对这一挑战，我们提出了一个最佳的运输（OT）指导的及时学习框架，该框架通过在预训练和微调模型之间保留特征分布的结构一致性来减轻忘记。与传统的点约束不同，OT自然会捕获跨境关系，并扩展可行的参数空间以迅速调整，从而可以在适应和概括之间进行更好的权衡。我们的方法对视觉和文本表示都有共同的限制，从而确保了整体特征对齐。在基准数据集上进行的广泛实验表明，我们简单而有效的方法可以在基本到新颖的概括，跨数据库评估和域概括的情况下胜过现有的迅速学习策略，而无需其他增强或集成技术。该代码可从https://github.com/chongqingnosubway/prompt-ot获得]]></description>
      <guid>https://arxiv.org/abs/2503.08906</guid>
      <pubDate>Thu, 13 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>提示：灵活的迅速小组活动识别</title>
      <link>https://arxiv.org/abs/2503.08933</link>
      <description><![CDATA[ARXIV：2503.08933V1公告类型：新 
摘要：我们提出了提示，这是一个新颖的框架，该框架通过利用多模式提示来实现输入灵活性和高识别准确性来解决当前小组活动识别方法（GAR）方法的局限性。现有的方法由于依赖完全及时的注释，缺乏长期演员一致性以及多组场景的探索而遭受现实世界中的适用性有限。为了弥合差距，我们提出了提示，这是第一个在不需要重新训练的情况下提供提示，框架和实例的输入灵活性的GAR模型。具体而言，我们将边界框，骨骼关键点和区域统一为点提示，并采用识别解码器来进行跨升级类和提示令牌。为了确保扩展活动持续时间的长期一致性，我们还引入了一种直接编码实例ID的相对实例注意机制。最后，提示加尔加探讨了区域提示的使用，以在包含多个并发组的视频中选择性识别特定组活动。全面的评估表明，促使Gargar在完整的提示和各种提示输入上取得了竞争性表演，从而确立了其对现实应用程序的输入灵活性和概括能力的有效性。]]></description>
      <guid>https://arxiv.org/abs/2503.08933</guid>
      <pubDate>Thu, 13 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>