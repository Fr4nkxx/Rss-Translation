<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CV 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Wed, 24 Jul 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>Fr\'echet 视频运动距离：评估视频运动一致性的指标</title>
      <link>https://arxiv.org/abs/2407.16124</link>
      <description><![CDATA[arXiv:2407.16124v1 公告类型：新
摘要：最近，视频生成模型取得了重大进展。与图像生成不同，视频生成带来了更大的挑战，不仅需要生成高质量的帧，还需要确保这些帧之间的时间一致性。尽管取得了令人瞩目的进展，但对评估生成视频质量的指标的研究，尤其是关于时间和运动一致性的指标，仍然没有得到充分探索。为了弥补这一研究空白，我们提出了 Fr\&#39;echet 视频运动距离 (FVMD) 指标，该指标专注于评估视频生成中的运动一致性。具体来说，我们基于关键点跟踪设计显式运动特征，然后通过 Fr\&#39;echet 距离测量这些特征之间的相似性。我们通过向真实视频中注入噪声来进行敏感性分析，以验证 FVMD 的有效性。此外，我们进行了一项大规模的人体研究，证明我们的指标可以有效地检测时间噪声，并且比现有指标更符合人类对生成视频质量的感知。此外，我们的运动特征可以持续提高视频质量评估 (VQA) 模型的性能，这表明我们的方法也适用于一元视频质量评估。代码可在 https://github.com/ljh0v0/FMD-frechet-motion-distance 上找到。]]></description>
      <guid>https://arxiv.org/abs/2407.16124</guid>
      <pubDate>Thu, 25 Jul 2024 03:13:56 GMT</pubDate>
    </item>
    <item>
      <title>基于扩散先验的噪声逆问题摊销变分推断</title>
      <link>https://arxiv.org/abs/2407.16125</link>
      <description><![CDATA[arXiv:2407.16125v1 公告类型：新
摘要：最近对逆问题的研究提出了后验采样器，利用预训练的扩散模型作为强大的先验。这些尝试为在广泛的逆问题中使用扩散模型铺平了道路。然而，现有的方法需要计算要求高的迭代采样程序，并为每个测量优化单独的解决方案，这导致可扩展性有限，并且缺乏对未见样本的泛化能力。为了解决这些限制，我们提出了一种新方法，即基于扩散先验的摊销变分推理 (DAVI)，它从摊销变分推理的角度解决具有扩散先验的逆问题。具体而言，我们的摊销推理不是单独的测量优化，而是学习一个函数，该函数直接将测量映射到相应干净数据的隐式后验分布，即使对于未见测量也可以实现单步后验采样。使用两个基准数据集对图像恢复任务（例如高斯去模糊、4$\times$ 超分辨率和框修复）进行了大量实验，证明了我们的方法比强基线具有更出色的性能。代码可在 https://github.com/mlvlab/DAVI 上找到。]]></description>
      <guid>https://arxiv.org/abs/2407.16125</guid>
      <pubDate>Thu, 25 Jul 2024 03:13:56 GMT</pubDate>
    </item>
    <item>
      <title>MxT：用于图像修复的 Mamba x Transformer</title>
      <link>https://arxiv.org/abs/2407.16126</link>
      <description><![CDATA[arXiv:2407.16126v1 公告类型：新
摘要：图像修复或图像完成是计算机视觉中的一项关键任务，旨在使用语义连贯的内容恢复图像中缺失或损坏的区域。该技术需要在局部纹理复制和全局上下文理解之间取得精确平衡，以确保恢复的图像与周围环境无缝集成。使用卷积神经网络 (CNN) 的传统方法可以有效捕捉局部模式，但由于接受域有限，往往难以处理更广泛的上下文关系。最近的进展已经结合了 transformers，利用它们理解全局交互的能力。然而，这些方法面临计算效率低下的问题，难以保持细粒度的细节。为了克服这些挑战，我们引入了由拟议的混合模块 (HM) 组成的 MxT，它将 Mamba 与 transformer 以协同的方式结合在一起。Mamba 擅长以线性计算成本高效处理长序列，使其成为 transformer 处理长尺度数据交互的理想补充。我们的 HM 促进了像素和块级的双层交互学习，大大增强了模型重建高质量和上下文准确性的图像的能力。我们在广泛使用的 CelebA-HQ 和 Places2 标准数据集上评估了 MxT，结果发现它的表现始终优于现有的最先进方法。]]></description>
      <guid>https://arxiv.org/abs/2407.16126</guid>
      <pubDate>Thu, 25 Jul 2024 03:13:56 GMT</pubDate>
    </item>
    <item>
      <title>通过循序渐进的自主学习逐步推进脑成像分析</title>
      <link>https://arxiv.org/abs/2407.16128</link>
      <description><![CDATA[arXiv:2407.16128v1 公告类型：新
摘要：深度学习的最新进展改变了脑成像分析的发展。然而，仍然存在一些挑战，例如异质性、个体差异以及脑成像数据集的高维性和小尺寸之间的矛盾。这些问题使学习过程复杂化，阻止模型捕捉内在的、有意义的模式，并可能由于偏差和过度拟合导致性能不佳。课程学习 (CL) 通过将训练示例从简单到复杂组织起来，模仿人类的学习过程，并可能促进更稳健、更准确的模型的发展，提供了一种有前途的解决方案。尽管它有潜力，但初始训练数据集较小所带来的固有局限性带来了重大挑战，包括过度拟合和泛化能力差。在本文中，我们介绍了渐进式自定进度蒸馏 (PSPD) 框架，采用自适应和渐进式节奏和蒸馏机制。这允许根据过去和现在模型的状态进行动态课程调整。过去的模型充当老师，用逐渐完善的课程知识指导当前模型，并帮助防止丢失以前获得的知识。我们使用阿尔茨海默病神经成像计划 (ADNI) 数据集验证了 PSPD 在各种卷积神经网络中的有效性和适应性，强调了其在增强模型性能和泛化能力方面的优势。此方法的源代码将在 https://github.com/Hrychen7/PSPD 发布。]]></description>
      <guid>https://arxiv.org/abs/2407.16128</guid>
      <pubDate>Thu, 25 Jul 2024 03:13:56 GMT</pubDate>
    </item>
    <item>
      <title>EfficientCD：一种基于双时间层交换的变化检测新策略</title>
      <link>https://arxiv.org/abs/2407.15999</link>
      <description><![CDATA[arXiv:2407.15999v1 公告类型：新
摘要：随着遥感技术在环境监测中的广泛应用，对自然环境高效准确的遥感图像变化检测（CD）的需求日益增长。我们提出了一种专门用于遥感图像变化检测的新型深度学习框架EfficientCD。该框架采用EfficientNet作为其特征提取的主干网络。为了增强双时态图像特征图之间的信息交换，我们设计了一个针对遥感变化检测的新型特征金字塔网络模块，名为ChangeFPN。此外，为了在解码阶段充分利用多级特征图，我们开发了一个结合欧氏距离的逐层特征上采样模块，以改进解码阶段的特征融合和重构。EfficientCD已在四个遥感数据集上进行了实验验证：LEVIR-CD，SYSU-CD，CLCD和WHUCD。实验结果表明，EfficientCD在变化检测精度方面表现出色。代码和预训练模型将在https://github.com/dyzy41/mmrscd 发布。]]></description>
      <guid>https://arxiv.org/abs/2407.15999</guid>
      <pubDate>Thu, 25 Jul 2024 03:13:55 GMT</pubDate>
    </item>
    <item>
      <title>基于卷积神经网络的路面疲劳裂缝检测及严重程度分类</title>
      <link>https://arxiv.org/abs/2407.16021</link>
      <description><![CDATA[arXiv:2407.16021v1 公告类型：新 
摘要：由于路面裂缝强度各异、拓扑结构复杂、纹理背景噪声大，沥青路面裂缝图像分类已成为一项具有挑战性的问题。疲劳开裂，也称为鳄鱼开裂，是沥青路面常见的病害之一。因此，检测和监测道路路面鳄鱼开裂的状况非常重要。该领域的大多数研究通常集中于使用有限的数据集对裂缝进行像素级检测。提出了一种可以实现两个目标的新型深度卷积神经网络。所提出的神经网络的第一个目标是根据路面图像对疲劳开裂的存在进行分类。第二个目标是根据病害识别手册 (DIM) 标准对疲劳开裂严重程度进行分类。本文建立了一个包含4484幅高分辨率路面图像的数据库，图像均在美国弗吉尼亚州布莱克斯堡镇当地拍摄。在数据预准备中，人工将4000多幅图像按照DIM标准分为4类。然后，构建了四层卷积神经网络模型，实现对图像按路面裂缝严重程度进行分类的目标。训练好的模型达到了现有方法中准确率最高的，仅经过30轮训练，模型的裂缝存在分类准确率达到96.23%，严重程度等级分类准确率达到96.74%。经过20轮训练，模型的路面标线存在分类准确率达到97.64%。]]></description>
      <guid>https://arxiv.org/abs/2407.16021</guid>
      <pubDate>Thu, 25 Jul 2024 03:13:55 GMT</pubDate>
    </item>
    <item>
      <title>PLayerTV：先进的球员跟踪和识别技术，可自动播放足球精彩片段</title>
      <link>https://arxiv.org/abs/2407.16076</link>
      <description><![CDATA[arXiv:2407.16076v1 公告类型：新
摘要：在快速发展的体育分析领域，有针对性的视频处理的自动化是一项关键的进步。我们提出了 PlayerTV，这是一个创新的框架，它利用最先进的人工智能技术自动跟踪和识别足球视频中的球员。通过集成对象检测和跟踪、光学字符识别 (OCR) 和颜色分析，PlayerTV 可以从大量比赛镜头中生成特定于球员的精彩片段，从而大大减少了传统上与此类任务相关的体力劳动。对我们的核心管道进行评估的初步结果表明，在挪威 Eliteserien 联赛的数据集上进行测试，PlayerTV 可以准确有效地识别球队和球员，我们的交互式图形用户界面 (GUI) 是一个用户友好的应用程序，它包装了此功能以实现简化的使用。]]></description>
      <guid>https://arxiv.org/abs/2407.16076</guid>
      <pubDate>Thu, 25 Jul 2024 03:13:55 GMT</pubDate>
    </item>
    <item>
      <title>增强效率：通过混合视觉减少内存占用并加速 3D 语义分割的推理</title>
      <link>https://arxiv.org/abs/2407.16102</link>
      <description><![CDATA[arXiv:2407.16102v1 公告类型：新
摘要：语义分割已成为计算机视觉研究的关键领域，对场景理解和提升各个领域的人机交互具有深远的意义。虽然 2D 语义分割在轻量级、高精度模型方面取得了重大进展，但过渡到 3D 语义分割仍面临明显的挑战。我们的研究重点是实现 3D 语义分割模型的效率和轻量级设计，类似于 2D 模型的效率和轻量级设计。这种设计会影响 3D 语义分割的应用，其中内存和延迟是值得关注的。本文介绍了一种新的 3D 语义分割方法，其特点是结合了 2D 和 3D 计算机视觉技术的混合，从而实现了简化、高效的过程。
我们对链接到 3D 点云的 RGB 图像进行 2D 语义分割，并使用挤压技术将结果扩展到 3D，以减少点云子空间。我们以 DeepViewAgg 模型为基础，在完整的点云上进行严格的评估，测量交并比 (IoU) 准确度、推理时间延迟和内存消耗。此模型是 KITTI-360 数据集上目前最先进的 3D 语义分割模型。我们可以实现更高的准确度结果，在 15 个类别中有 6 个类别的准确度超过基线，同时将其余类别标签的偏差保持在基线以下 1% 的边际水平。与基线相比，我们的分割方法实现了 1.347 倍的速度提升和约 43% 的内存使用量减少。]]></description>
      <guid>https://arxiv.org/abs/2407.16102</guid>
      <pubDate>Thu, 25 Jul 2024 03:13:55 GMT</pubDate>
    </item>
    <item>
      <title>Craft：跨模态对齐特征提升快速调优的稳健性</title>
      <link>https://arxiv.org/abs/2407.15894</link>
      <description><![CDATA[arXiv:2407.15894v1 公告类型：新
摘要：即时调整已成为一种重要的研究范式，用于将视觉语言模型适应各种下游任务。然而，最近的研究表明，即时调整方法往往由于训练样本有限而导致过度拟合。在本文中，我们提出了一种 \textbf{Cr}oss-modal \textbf{a}ligned \textbf{f}eature \textbf{t}uning (\textbf{Craft}) 方法来解决这个问题。跨模态对齐是通过首先从替代域中选择锚点并为所选锚点导出嵌入的相对表示来进行的。针对锚点对齐的文本和图像模态的特征对齐损失进行优化可以创建更统一的文本图像公共空间。即时调整中的过度拟合也会降低模型在分布外样本上的性能。为了进一步提高提示模型的鲁棒性，我们建议最小化锚对齐特征空间上的最大均值差异 (MMD)，以减轻域偏移。对四种不同的提示调整结构的实验一致表明我们的方法有所改进，在 Base-to-Novel 泛化任务中增幅高达 $6.1\%$，在组鲁棒性任务中增幅高达 $5.8\%$，在分布外任务中增幅高达 $2.7\%$。代码将在 \href{https://github.com/Jingchensun/Craft} 上提供]]></description>
      <guid>https://arxiv.org/abs/2407.15894</guid>
      <pubDate>Thu, 25 Jul 2024 03:13:54 GMT</pubDate>
    </item>
    <item>
      <title>通过置信度最大化实现视觉语言模型零样本泛化的测试时低秩自适应</title>
      <link>https://arxiv.org/abs/2407.15913</link>
      <description><![CDATA[arXiv:2407.15913v1 公告类型：新摘要：在测试时调整预训练的视觉语言模型 (VLM) 的传统做法是调整可学习的提示，即测试时提示调整。本文介绍了测试时低秩自适应 (TTL) 作为大规模 VLM 零样本泛化的提示调整的替代方案。从最近在有效微调大型语言模型方面的进展中汲取灵感，TTL 提供了一种测试时参数高效的自适应方法，通过最大化预测置信度来更新 Transformer 编码器的注意权重。自监督置信度最大化目标是使用加权熵损失来指定的，该损失强制增强样本的预测之间的一致性。TTL 仅为模型空间中的低秩适配器引入少量可训练参数，同时保持提示和主干冻结。在各种自然分布和跨域任务上进行的大量实验表明，TTL 在严格的零样本设置下，在 VLM 的测试时间优化方面可以胜过其他技术。具体来说，TTL 的表现优于测试时间即时调整基线，平均而言有显著的改进。我们的代码可在 https://github.com/Razaimam45/TTL-Test-Time-Low-Rank-Adaptation 上找到。]]></description>
      <guid>https://arxiv.org/abs/2407.15913</guid>
      <pubDate>Thu, 25 Jul 2024 03:13:54 GMT</pubDate>
    </item>
    <item>
      <title>FDWST：使用小波风格转换对指纹照片进行去模糊处理</title>
      <link>https://arxiv.org/abs/2407.15964</link>
      <description><![CDATA[arXiv:2407.15964v1 公告类型：新
摘要：去除手指照片模糊，或者从给定的模糊照片生成清晰的手指照片，是计算机视觉领域的一个重要问题。为了解决这个问题，我们提出了一种手指照片去模糊架构，称为使用小波风格转移的手指照片去模糊 (FDWST)，旨在利用风格转移技术的信息传输来去除手指照片模糊。此外，我们结合了离散小波变换 (DWT)，因为它能够将图像分成不同的频带。通过结合这两种技术，我们可以在广泛的小波频带上执行风格转移，从而提高从清晰图像到模糊图像传输的清晰度信息的质量和多样性。使用这种技术，我们的模型能够显著提高生成的手指照片与原始照片的质量，并且在将去模糊的手指照片与清晰的手指照片进行匹配时实现 0.9907 的峰值匹配准确率，优于其他多种最先进的去模糊和风格转换技术。]]></description>
      <guid>https://arxiv.org/abs/2407.15964</guid>
      <pubDate>Thu, 25 Jul 2024 03:13:54 GMT</pubDate>
    </item>
    <item>
      <title>医学图像分析基础模型可信度调查</title>
      <link>https://arxiv.org/abs/2407.15851</link>
      <description><![CDATA[arXiv:2407.15851v1 公告类型：新
摘要：基础模型在医学成像中的快速发展代表着在提高诊断准确性和个性化治疗方面取得了重大飞跃。然而，在医疗保健领域部署基础模型需要严格检查其可信度，包括隐私、稳健性、可靠性、可解释性和公平性。目前关于医学成像基础模型的调查文献揭示了相当大的差距，特别是在可信度方面。此外，现有的关于基础模型可信度的调查未能解决它们在医学成像领域的具体变化和应用。这篇调查论文回顾了目前在主要医学成像应用中对基础模型的研究，重点关注分割、医学报告生成、医学问答 (Q&amp;A) 和疾病诊断，其中包括其手稿中的可信度讨论。我们探讨了使医学图像分析的基础模型可信的复杂挑战，与每个应用相关，并总结了当前关注的问题和提高可信度的策略。此外，我们还探讨了这些模型在彻底改变患者护理方面的未来前景。我们的分析强调了在医学图像分析中向值得信赖的人工智能迈进的必要性，提倡一种平衡的方法，既能促进创新，又能确保提供合乎道德和公平的医疗服务。]]></description>
      <guid>https://arxiv.org/abs/2407.15851</guid>
      <pubDate>Thu, 25 Jul 2024 03:13:53 GMT</pubDate>
    </item>
    <item>
      <title>BSH 用于点云模型中的碰撞检测</title>
      <link>https://arxiv.org/abs/2407.15852</link>
      <description><![CDATA[arXiv:2407.15852v1 公告类型：新
摘要：点云模型是一种常见的形状表示，原因有几个。三维扫描设备如今被广泛使用，点是渲染复杂几何图形的有吸引力的图元。然而，关于点云模型碰撞检测的文献并不多。本文提出了一种使用体素、八叉树和边界球层次结构 (BSH) 的大型点云模型的新型碰撞检测算法。场景图按体素划分。每个体素的对象被组织成一个八叉树。由于场景中的点数很多，八叉树的每个非空单元都基于类似 R 树层次结构的边界球层次结构进行组织。BSH 层次结构用于对相邻点进行分组，并非常快速地过滤掉不与其他模型交互的对象部分。从激光扫描数据中得出的点通常不进行分割，并且可以具有任意空间分辨率，从而引入计算和建模问题。我们解决了这些问题，结果表明，所提出的碰撞检测算法能够有效地找到点云模型之间的交点，因为它能够减少边界体积检查和更新的次数。]]></description>
      <guid>https://arxiv.org/abs/2407.15852</guid>
      <pubDate>Thu, 25 Jul 2024 03:13:53 GMT</pubDate>
    </item>
    <item>
      <title>一种提高多视角捕捉中表面覆盖质量的新方法</title>
      <link>https://arxiv.org/abs/2407.15883</link>
      <description><![CDATA[arXiv:2407.15883v1 公告类型：新
摘要：相机的景深是限制需要在较短的拍摄对象到相机距离处拍摄图像或使用较大焦距的应用（例如全身摄影、考古学和其他近距离摄影测量应用）的因素。此外，在多视图捕获中，目标大于相机的视野，因此优化高质量捕获的表面覆盖的有效方法仍然是一个挑战。给定目标对象的 3D 网格和相机姿势，我们提出了一种新方法来推导每个相机的焦距，从而优化覆盖表面积的质量。我们首先设计一个期望最小化 (EM) 算法，将网格上的点唯一地分配给相机，然后根据相关点集求解每个相机的焦距。我们通过提出一种 $k$ 视图算法进一步提高了质量表面覆盖率，该算法通过同时考虑多个视图来解决点分配和焦距。我们在各种全身摄影模拟中证明了所提方法的有效性。EM 和 $k$ 视图算法分别将基线单视图方法的相对成本降低了至少 $24$% 和 $28$%，这相当于将对焦表面积增加了大约 $1550$ cm$^2$ 和 $1780$ cm$^2$。我们相信这些算法可用于许多需要摄影测量细节但受景深限制的视觉应用。]]></description>
      <guid>https://arxiv.org/abs/2407.15883</guid>
      <pubDate>Thu, 25 Jul 2024 03:13:53 GMT</pubDate>
    </item>
    <item>
      <title>CatVTON：使用扩散模型进行虚拟试穿只需要串联</title>
      <link>https://arxiv.org/abs/2407.15886</link>
      <description><![CDATA[arXiv:2407.15886v1 Announce Type: new 
摘要：基于扩散模型的虚拟试穿方法虽然可以实现逼真的试穿效果，但往往需要将主干网络复制为 ReferenceNet，或者使用额外的图像编码器来处理条件输入，导致训练和推理成本过高。本文重新思考了 ReferenceNet 和图像编码器的必要性，提出了一种简单高效的虚拟试穿扩散模型 CatVTON，创新了服装与人的交互方式。CatVTON 只需将任意类别的店内或穿着服装在空间维度上连接起来作为输入，即可将其无缝转移到目标人群。模型的高效性体现在三个方面：（1）轻量级网络：只使用原有的扩散模块，无需额外的网络模块。删除了主干网络中用于文本注入的文本编码器和交叉注意，减少了 167.02M 的参数。 （2）参数高效训练：通过实验确定试穿相关模块，仅训练 49.57M 参数，约占骨干网络参数的 5.51%，就获得了高质量的试穿效果。（3）简化推理：CatVTON 消除了所有不必要的条件和预处理步骤，包括姿势估计、人体解析和文本输入，只需要服装参考、目标人物图像和面具即可进行虚拟试穿。大量实验表明，与基线方法相比，CatVTON 以更少的先决条件和可训练参数获得了更好的定性和定量结果。此外，尽管使用只有 73K 样本的开源数据集，CatVTON 在自然场景中表现出良好的泛化能力。]]></description>
      <guid>https://arxiv.org/abs/2407.15886</guid>
      <pubDate>Thu, 25 Jul 2024 03:13:53 GMT</pubDate>
    </item>
    </channel>
</rss>