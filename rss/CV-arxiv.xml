<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CV 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Mon, 26 Aug 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>开放集 Deepfake 检测：一种混合伪造风格的参数高效自适应方法</title>
      <link>https://arxiv.org/abs/2408.12791</link>
      <description><![CDATA[arXiv:2408.12791v1 公告类型：新
摘要：开放集人脸伪造检测构成重大安全威胁，并对现有检测模型提出了重大挑战。这些检测器主要有两个限制：它们无法在未知的伪造域中推广，并且无法有效地适应新数据。为了解决这些问题，我们引入了一种通用且参数高效的人脸伪造检测方法。它建立在不同的伪造源域表现出不同风格统计数据的假设之上。以前的方法通常需要完全微调预训练网络，这会消耗大量时间和计算资源。反过来，我们设计了一种伪造风格混合配方，可以增强伪造源域的多样性，从而增强模型在看不见的域中的通用性。借鉴视觉变换器 (ViT) 在人脸伪造检测方面的最新进展，我们开发了一种基于 ViT 的参数高效的检测模型，其中包括轻量级伪造特征提取模块，并使模型能够同时提取全局和局部伪造线索。我们仅在训练期间优化插入的轻量级模块，保持原始 ViT 结构及其预训练的 ImageNet 权重。这种训练策略有效地保留了信息丰富的预训练知识，同时灵活地将模型调整为 Deepfake 检测任务。大量实验结果表明，设计的模型实现了最先进的通用性，可训练参数显著减少，代表了朝着开放集 Deepfake 检测迈出的重要一步。]]></description>
      <guid>https://arxiv.org/abs/2408.12791</guid>
      <pubDate>Mon, 26 Aug 2024 06:18:34 GMT</pubDate>
    </item>
    <item>
      <title>对称掩蔽策略增强了掩蔽图像建模的性能</title>
      <link>https://arxiv.org/abs/2408.12772</link>
      <description><![CDATA[arXiv:2408.12772v1 公告类型：新
摘要：蒙版图像建模 (MIM) 是一种自监督学习技术，其重点是通过估计随机蒙版部分中的缺失像素来从未标记图像中获取详细的视觉表示。事实证明，它是视觉变换器 (ViT) 初步训练的强大工具，在各种任务中取得了令人印象深刻的结果。尽管如此，大多数 MIM 方法严重依赖随机掩蔽策略来制定借口任务。该策略需要进行大量试验才能确定最佳丢弃率，这可能会耗费大量资源，需要对模型进行 800 到 1600 个时期的预训练。此外，这种方法可能不适用于所有数据集。在这项工作中，我们提出了一种新的掩蔽策略，可以有效地帮助模型捕获全局和局部特征。基于这种掩蔽策略 SymMIM，我们介绍了针对 MIM 提出的训练流程。 SymMIM 使用 ViT-Large 在 ImageNet 上实现了 85.9% 的新 SOTA 准确率，并在图像分类、语义分割、对象检测、实例分割任务等下游任务中超越了之前的 SOTA。]]></description>
      <guid>https://arxiv.org/abs/2408.12772</guid>
      <pubDate>Mon, 26 Aug 2024 06:18:33 GMT</pubDate>
    </item>
    <item>
      <title>视频数据中对象的上下文感知时间嵌入</title>
      <link>https://arxiv.org/abs/2408.12789</link>
      <description><![CDATA[arXiv:2408.12789v1 公告类型：新
摘要：在视频分析中，理解时间上下文对于识别对象交互、事件模式和随时间变化的上下文至关重要。所提出的模型利用相邻视频帧中对象之间的邻接性和语义相似性来构建上下文感知的时间对象嵌入。与仅依赖视觉外观的传统方法不同，我们的时间嵌入模型考虑了对象之间的上下文关系，从而创建了一个有意义的嵌入空间，其中时间连接的对象的向量位于邻近位置。实证研究表明，我们的上下文感知时间嵌入可以与传统的视觉嵌入结合使用，以增强下游应用的有效性。此外，嵌入可用于使用大型语言模型 (LLM) 讲述视频。本文描述了所提出的目标函数的复杂细节，用于为视频数据生成上下文感知的时间对象嵌入，并展示了生成的嵌入在视频分析和对象分类任务中的潜在应用。]]></description>
      <guid>https://arxiv.org/abs/2408.12789</guid>
      <pubDate>Mon, 26 Aug 2024 06:18:33 GMT</pubDate>
    </item>
    <item>
      <title>硬盘设计中颗粒表征的任意分段模型</title>
      <link>https://arxiv.org/abs/2408.12732</link>
      <description><![CDATA[arXiv:2408.12732v1 公告类型：新
摘要：硬盘设计中新材料的开发需要通过晶粒分割来表征纳米级材料。高通量快速变化的研究环境使零样本泛化成为一种非常理想的特性。为此，我们探索了 Meta 的 Segment Anything Model (SAM) 在这一问题上的应用。我们首先分析 SAM 的开箱即用。然后，我们在标记数据可用性最小的假设下讨论改进的机会和策略。开箱即用的 SAM 在属性分布提取方面表现出良好的准确性。我们能够确定四个潜在的改进领域，并在四个领域中的两个领域中显示出初步进展。]]></description>
      <guid>https://arxiv.org/abs/2408.12732</guid>
      <pubDate>Mon, 26 Aug 2024 06:18:32 GMT</pubDate>
    </item>
    <item>
      <title>CatFree3D：使用扩散进行类别无关的 3D 物体检测</title>
      <link>https://arxiv.org/abs/2408.12747</link>
      <description><![CDATA[arXiv:2408.12747v1 公告类型：新
摘要：基于图像的 3D 物体检测广泛应用于自动驾驶汽车和机器人等应用，但由于问题设置复杂且训练数据有限，当前系统难以实现泛化。我们引入了一种新颖的管道，将 3D 检测与 2D 检测和深度预测分离，使用基于扩散的方法来提高准确性并支持与类别无关的检测。此外，我们引入了标准化匈牙利距离 (NHD) 指标来准确评估 3D 检测结果，解决了传统 IoU 和 GIoU 指标的局限性。实验结果表明，我们的方法在各种物体类别和数据集中实现了最先进的准确性和强大的泛化能力。]]></description>
      <guid>https://arxiv.org/abs/2408.12747</guid>
      <pubDate>Mon, 26 Aug 2024 06:18:32 GMT</pubDate>
    </item>
    <item>
      <title>通过联邦学习和自动标记增强车辆环境意识</title>
      <link>https://arxiv.org/abs/2408.12769</link>
      <description><![CDATA[arXiv:2408.12769v1 公告类型：新
摘要：车辆环境意识是提高道路安全的关键问题。通过各种传感器和车对车通信，车辆可以收集大量数据。然而，为了使这些数据有用，必须有效地整合传感器数据。本文重点研究图像数据和车对车通信数据的整合。更具体地说，我们的目标是识别在图像中发送消息的车辆的位置，这一挑战称为车辆识别问题。在本文中，我们采用监督学习模型来解决车辆识别问题。然而，我们面临两个实际问题：首先，司机通常不愿意分享隐私敏感的图像数据，其次，司机通常不参与数据标记。为了应对这些挑战，本文介绍了一种全面的车辆识别问题解决方案，该解决方案利用联邦学习和自动标记技术与上述监督学习模型相结合。我们通过实验验证了我们提出的方法的可行性。]]></description>
      <guid>https://arxiv.org/abs/2408.12769</guid>
      <pubDate>Mon, 26 Aug 2024 06:18:32 GMT</pubDate>
    </item>
    <item>
      <title>重新审视基于 LiDAR 的 3D 物体检测的跨域问题</title>
      <link>https://arxiv.org/abs/2408.12708</link>
      <description><![CDATA[arXiv:2408.12708v1 公告类型：新
摘要：卷积神经网络和 Transformer 等深度学习模型已被广泛应用于解决自动驾驶领域的 3D 物体检测问题。虽然现有模型在大多数公开基准上都取得了出色的表现，但这些深度网络的泛化能力仍然存在疑问。为了使模型适应其他领域，包括不同的城市、国家和天气，目前需要使用目标域数据进行重新训练，这阻碍了自动驾驶的广泛应用。在本文中，我们深入分析了最先进模型的跨域性能。我们观察到大多数模型都会过拟合训练域，直接将它们适配到其他领域具有挑战性。现有的 3D 物体检测问题的领域自适应方法实际上是在转移模型的知识领域，而不是提高其泛化能力。然后，我们提出了额外的评估指标——侧视和前视 AP——以更好地分析方法准确率大幅下降的核心问题。通过使用提出的指标并进一步评估每个维度的跨域性能，我们得出结论，过度拟合问题在正面视图表面和宽度维度上更为明显，这些维度通常面向传感器并且周围有更多 3D 点。同时，我们的实验表明，点云数据的密度也显著影响模型的跨域性能。]]></description>
      <guid>https://arxiv.org/abs/2408.12708</guid>
      <pubDate>Mon, 26 Aug 2024 06:18:31 GMT</pubDate>
    </item>
    <item>
      <title>BankTweak：通过操纵特征库对多目标跟踪器进行对抗性攻击</title>
      <link>https://arxiv.org/abs/2408.12727</link>
      <description><![CDATA[arXiv:2408.12727v1 公告类型：新
摘要：多目标跟踪 (MOT) 旨在为目标构建移动轨迹，现代多目标跟踪器主要采用检测跟踪方法。最初的 MOT 攻击方法主要旨在降低受攻击帧的检测质量，从而仅降低特定帧的准确性，这凸显了 \textit{效率} 的不足。为了提高效率，最近的进展操纵目标位置以在关联阶段引起持续的身份 (ID) 切换，即使在攻击在几帧内结束后也是如此。然而，这些位置操纵攻击具有固有的局限性，因为它们可以通过在关联阶段调整与距离相关的参数轻松抵消，从而表明缺乏 \textit{鲁棒性}。在本文中，我们提出了 \textsf{BankTweak}，这是一种专为 MOT 跟踪器设计的新型对抗性攻击，具有效率和鲁棒性。 \textsf{BankTweak} 专注于关联阶段的特征提取器，并揭示了基于特征的 MOT 系统使用的匈牙利匹配方法中的漏洞。利用此漏洞，\textsf{BankTweak} 即使在攻击结束后也会诱导持续的 ID 切换（解决 \textit{效率}），方法是策略性地将改变的特征注入特征库而不修改对象位置（解决 \textit{鲁棒性}）。为了证明适用性，我们将 \textsf{BankTweak} 应用于三个多对象跟踪器（DeepSORT、StrongSORT 和 MOTDT），这些跟踪器具有单阶段、双阶段、无锚和变压器检测器。在 MOT17 和 MOT20 数据集上进行的大量实验表明，我们的方法大大超越了现有的攻击，暴露了跟踪检测框架对 \textsf{BankTweak} 的脆弱性。]]></description>
      <guid>https://arxiv.org/abs/2408.12727</guid>
      <pubDate>Mon, 26 Aug 2024 06:18:31 GMT</pubDate>
    </item>
    <item>
      <title>构建和更好地理解视觉语言模型：见解和未来方向</title>
      <link>https://arxiv.org/abs/2408.12637</link>
      <description><![CDATA[arXiv:2408.12637v1 公告类型：新
摘要：视觉语言模型 (VLM) 领域以图像和文本作为输入和输出文本，该领域正在迅速发展，但尚未就开发流程的几个关键方面达成共识，包括数据、架构和训练方法。本文可以看作是构建 VLM 的教程。我们首先全面概述当前最先进的方法，强调每种方法的优缺点，解决该领域的主要挑战，并为未充分探索的领域提出有希望的研究方向。然后，我们将介绍构建 Idefics3-8B 的实际步骤，这是一个功能强大的 VLM，其性能明显优于其前身 Idefics2-8B，同时可以高效地、专门在开放数据集上进行训练并使用简单的流程。这些步骤包括创建 Docmatix，这是一个用于提高文档理解能力的数据集，其大小是以前可用的数据集的 240 倍。我们将发布该模型以及为其训练创建的数据集。]]></description>
      <guid>https://arxiv.org/abs/2408.12637</guid>
      <pubDate>Mon, 26 Aug 2024 06:18:30 GMT</pubDate>
    </item>
    <item>
      <title>GSFusion：高斯溅射与 TSDF 融合的在线 RGB-D 映射</title>
      <link>https://arxiv.org/abs/2408.12677</link>
      <description><![CDATA[arXiv:2408.12677v1 公告类型：新
摘要：传统的体积融合算法保留了 3D 场景的空间结构，这对计算机视觉和机器人技术中的许多任务有益。然而，它们在可视化方面往往缺乏真实感。新兴的 3D 高斯 splatting 弥补了这一差距，但现有的基于高斯的重建方法经常受到伪影和与底层 3D 结构不一致的影响，并且难以进行实时优化，无法为用户提供高质量的即时反馈。瓶颈之一来自于优化过程中需要更新的大量高斯参数。我们没有使用 3D 高斯作为独立的地图表示，而是将其合并到体积映射系统中以利用几何信息，并建议在图像上使用四叉树数据结构来大幅减少初始化的 splats 数量。通过这种方式，我们可以同时生成一个紧凑的 3D 高斯图，其中伪影更少，并且动态生成体积图。我们的方法 GSFusion 显著提高了计算效率，同时又不牺牲渲染质量，这一点在合成数据集和真实数据集上都得到了证明。代码将在 https://github.com/goldoak/GSFusion 上提供。]]></description>
      <guid>https://arxiv.org/abs/2408.12677</guid>
      <pubDate>Mon, 26 Aug 2024 06:18:30 GMT</pubDate>
    </item>
    <item>
      <title>GPT-4 模型可以检测误导性可视化效果吗？</title>
      <link>https://arxiv.org/abs/2408.12617</link>
      <description><![CDATA[arXiv:2408.12617v1 公告类型：新
摘要：网络上误导性可视化的泛滥，特别是在公共卫生危机和选举等关键事件期间，构成了重大风险。本研究调查了 GPT-4 模型（4V、4o 和 4o mini）检测误导性可视化的能力。利用包含各种视觉误导的推文可视化对数据集，我们在四种实验条件下以不同程度的指导测试了这些模型。我们表明，GPT-4 模型可以在没有事先训练的情况下以中等准确度检测误导性可视化（天真的零样本），并且在提供误导性定义（引导零样本）时性能显着提高。然而，单一的提示工程技术并不能为所有误导类型产生最佳结果。具体而言，为模型提供误导性定义和示例（引导少量样本）被证明对于推理误导更有效，而引导零样本对于设计误导更佳。这项研究强调了使用大型视觉语言模型检测视觉错误信息的可行性以及及时工程对于优化检测准确性的重要性。]]></description>
      <guid>https://arxiv.org/abs/2408.12617</guid>
      <pubDate>Mon, 26 Aug 2024 06:18:29 GMT</pubDate>
    </item>
    <item>
      <title>通过合成特征采样实现无数据类增量手势识别</title>
      <link>https://arxiv.org/abs/2408.12629</link>
      <description><![CDATA[arXiv:2408.12629v1 公告类型：新
摘要：无数据类增量学习 (DFCIL) 旨在使模型能够不断学习新类，同时重新训练旧类的知识，即使在旧类的训练数据不可用的情况下也是如此。尽管研究人员主要使用图像数据集进行探索，但本研究重点研究基于骨架的手势分类的 DFCIL，因为它具有重大的现实意义，特别是考虑到 VR/AR 耳机的日益普及，其中手势是控制和交互的主要手段。在这项工作中，我们做出了一个有趣的观察：使用基类（即使非常有限）训练的骨架模型无需额外训练即可展示出对看不见的类的强大泛化能力。基于这一见解，我们开发了合成特征重放 (SFR)，它可以从类原型中采样合成特征以重放旧类并增强新类（在少数镜头设置下）。我们提出的方法展示了比最先进技术更显著的进步，所有步骤的平均准确率提高了 15%，并且大大缓解了基类和新类之间的准确率不平衡。]]></description>
      <guid>https://arxiv.org/abs/2408.12629</guid>
      <pubDate>Mon, 26 Aug 2024 06:18:29 GMT</pubDate>
    </item>
    <item>
      <title>图像特征弱到强一致性：半监督学习的增强范式</title>
      <link>https://arxiv.org/abs/2408.12614</link>
      <description><![CDATA[arXiv:2408.12614v1 公告类型：新
摘要：图像级弱到强一致性由于其简单性和令人印象深刻的性能而成为半监督学习（SSL）中的主要范例。尽管如此，这种方法将所有扰动限制在图像级别，并且受到过多幼稚样本的影响，因此需要进一步改进。在本文中，我们引入了不同强度和形式的特征级扰动来扩展增强空间，建立了图像特征弱到强一致性范式。此外，我们的范式开发了一个三分支结构，促进了同一分支内两种类型的扰动之间的相互作用，以增强它们的协同作用。此外，我们提出了一种基于置信度的识别策略来区分幼稚样本和挑战性样本，从而为幼稚样本引入了额外的挑战。值得注意的是，我们的范式可以与现有的 SSL 方法无缝集成。我们将提出的范式应用于几个代表性算法，并在多个基准上进行了实验，包括标记样本的平衡分布和不平衡分布。结果表明，现有 SSL 算法的性能得到了显著提升。]]></description>
      <guid>https://arxiv.org/abs/2408.12614</guid>
      <pubDate>Mon, 26 Aug 2024 06:18:28 GMT</pubDate>
    </item>
    <item>
      <title>基于大型语言模型的水下图像语义通信</title>
      <link>https://arxiv.org/abs/2408.12616</link>
      <description><![CDATA[arXiv:2408.12616v1 公告类型：新
摘要：水下通信对于环境监测、海洋生物研究和水下探索至关重要。传统的水下通信面临着低带宽、高延迟和易受噪声影响等限制，而语义通信 (SC) 通过专注于语义而不是符号或比特的交换提供了一种有前途的解决方案。然而，SC 在水下环境中遇到了挑战，包括信息丢失以及难以准确识别和传输符合水下应用多样化要求的关键信息。为了应对这些挑战，我们提出了一种基于大型语言模型 (LLM) 的新型语义通信 (SC) 框架。我们的框架利用视觉 LLM 根据用户的查询对水下图像数据执行语义压缩和优先级排序。通过识别和编码图像中的关键语义元素，系统有选择地传输高优先级信息，同时对不太重要的区域应用更高的压缩率。在接收端，基于 LLM 的恢复机制以及 Global Vision ControlNet 和 Key Region ControlNet 网络有助于重建图像，从而提高通信效率和鲁棒性。我们的框架将整体数据大小减少到原始数据的 0.8\%。实验结果表明，我们的方法明显优于现有方法，可确保高质量、语义准确的图像重建。]]></description>
      <guid>https://arxiv.org/abs/2408.12616</guid>
      <pubDate>Mon, 26 Aug 2024 06:18:28 GMT</pubDate>
    </item>
    <item>
      <title>通过大型混合模式专家模型实现多参数 MRI 对乳腺癌患者的非侵入性和个性化管理</title>
      <link>https://arxiv.org/abs/2408.12606</link>
      <description><![CDATA[arXiv:2408.12606v1 公告类型：新
摘要：乳腺磁共振成像 (MRI) 是检测乳腺癌灵敏度最高的成像技术，常用于高危女性。尽管乳腺 MRI 具有全面的多参数方案，但现有的基于人工智能的研究主要依赖单个序列，并且验证有限。在这里，我们报告了一个大型混合模态专家模型 (MOME)，该模型将多参数 MRI 信息集成在一个统一的结构中，为个性化乳腺癌管理提供了一种非侵入性方法。我们整理了最大的多参数乳腺 MRI 数据集，涉及来自中国北部、东南部和西南部的三家医院的 5,205 名患者，用于开发和广泛评估我们的模型。MOME 证明了对乳腺癌的准确和稳健的识别。它在恶性肿瘤识别方面的表现与四名高级放射科医生相当，且明显优于初级放射科医生，其 AUROC 为 0.913、AUPRC 为 0.948、F1 得分为 0.905 和 MCC 为 0.723。我们的研究结果表明，MOME 可将 BI-RADS 4 患者的活检需求减少 7.3%，以 0.709 的 AUROC 对三阴性乳腺癌进行分类，并以 0.694 的 AUROC 预测新辅助化疗的病理完全缓解。该模型进一步支持可扩展和可解释的推理，适应缺失的模态并通过突出显示病变和测量模态贡献来提供决策解释。MOME 体现了一种有判别力、稳健、可扩展且可解释的多模态模型，为基于多参数乳腺成像数据对乳腺癌患者进行无创个性化管理铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2408.12606</guid>
      <pubDate>Mon, 26 Aug 2024 06:18:27 GMT</pubDate>
    </item>
    </channel>
</rss>