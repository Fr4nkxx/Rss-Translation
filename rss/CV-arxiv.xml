<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CV 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Thu, 29 Aug 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>基于 FPGA 平台的铁路故障检测边缘 AI 系统</title>
      <link>https://arxiv.org/abs/2408.15245</link>
      <description><![CDATA[arXiv:2408.15245v1 公告类型：新
摘要：随着铁路运输安全需求的增加，传统的轨道检查方法已不再满足现代铁路系统的需求。为了解决轨道故障检测的自动化和效率问题，本研究介绍了一种基于现场可编程门阵列 (FPGA) 的铁路检测系统。该边缘 AI 系统通过摄像头采集轨道图像，并使用卷积神经网络 (CNN) 对轨道缺陷进行实时检测并自动报告故障信息。该系统的创新之处在于其自动化程度高、检测效率高。该系统采用的神经网络方法实现了 88.9% 的检测准确率，大大提高了检测的可靠性和效率。实验结果表明，该基于 FPGA 的系统在能效上分别比 GPU 和 CPU 平台上的同类实现高 1.39* 和 4.67*。]]></description>
      <guid>https://arxiv.org/abs/2408.15245</guid>
      <pubDate>Thu, 29 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 STG3Net 进行多层空间转录组学数据整合分析</title>
      <link>https://arxiv.org/abs/2408.15246</link>
      <description><![CDATA[arXiv:2408.15246v1 公告类型：新 
摘要：随着最新的空间分辨转录组学 (SRT) 技术的快速发展，该技术可以绘制组织切片内的基因表达图，对多个 SRT 数据的综合分析变得越来越重要。然而，多个切片之间的批次效应对分析 SRT 数据提出了重大挑战。为了应对这些挑战，我们开发了一种即插即用的批次校正方法，称为全局最近邻 (G2N) 锚对选择。G2N 通过跨切片选择代表性锚对来有效地减轻批次效应。在 G2N 的基础上，我们提出了 STG3Net，它巧妙地结合了掩蔽图卷积自动编码器作为主干模块。这些自动编码器与生成对抗学习相结合，使 STG3Net 能够实现强大的多切片空间域识别和批次校正。我们综合评估了 STG3Net 在来自不同平台的三个多 SRT 数据集上的可行性，考虑了准确性、一致性和 F1LISI 指标（批次效应校正效率的衡量标准）。与现有方法相比，STG3Net 在保留生物变异性和切片间连通性的同时实现了最佳整体性能。本文使用的源代码和所有公开数据集可在 https://github.com/wenwenmin/STG3Net 和 https://zenodo.org/records/12737170 上找到。]]></description>
      <guid>https://arxiv.org/abs/2408.15246</guid>
      <pubDate>Thu, 29 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用基于 Transformer 的行为聚类和数据驱动的可达性分析进行行人运动预测</title>
      <link>https://arxiv.org/abs/2408.15250</link>
      <description><![CDATA[arXiv:2408.15250v1 公告类型：新
摘要：在这项工作中，我们提出了一个基于变换器的框架，用于根据聚类的历史轨迹数据预测未来的行人状态。在之前的研究中，研究人员提出使用手工制作的标签对行人行为和意图进行分类，以增强行人轨迹预测。然而，这些方法通常只能捕捉有限范围的行人行为，并在预测中引入人为偏见。为了减轻对手工制作标签的依赖，我们利用变换器编码器结合基于密度的分层聚类来自动识别不同的行为模式，并在数据驱动的可达性分析中使用这些聚类。通过使用基于变换器的方法，我们寻求增强行人轨迹的表示，并发现随后用于将轨迹分组为不同“行为”聚类的特征或特性。我们表明，这些行为聚类可以与数据驱动的可达性分析一起使用，从而产生一种端到端的数据驱动方法来预测行人的未来运动。我们在真实的行人数据集上训练和评估我们的方法，展示了其在预测行人运动方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2408.15250</guid>
      <pubDate>Thu, 29 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>TrajFM：用于区域和任务可转移性的车辆轨迹基础模型</title>
      <link>https://arxiv.org/abs/2408.15251</link>
      <description><![CDATA[arXiv:2408.15251v1 公告类型：新
摘要：车辆轨迹提供了有价值的运动信息，可支持各种下游任务并为实际应用提供支持。理想的轨迹学习模型应该能够在无需重新训练的情况下在不同区域和任务之间转移，从而在有限的训练数据下提高计算效率和有效性。然而，模型跨区域转移的能力受到每个区域独特的空间特征和 POI 排列的限制，这些特征和 POI 排列与车辆运动模式密切相关且难以推广。此外，由于各种任务所需的生成方案不同，实现任务可转移性具有挑战性。现有的可转移性努力主要涉及学习轨迹的嵌入向量，这些向量在区域转移方面表现不佳，并且仍然需要重新训练任务转移的预测模块。
为了应对这些挑战，我们提出了 TrajFM，这是一种在区域和任务可转移性方面都表现出色的车辆轨迹基础模型。对于区域可转移性，我们引入了 STRFormer 作为 TrajFM 中的主要可学习模型。它集成了轨迹的空间、时间和 POI 模态，以有效管理不同区域 POI 排列的变化，并包含一个可学习的时空旋转位置嵌入模块，用于处理空间特征。为了实现任务可转移性，我们提出了一种轨迹掩蔽和恢复方案。该方案将各种任务的生成过程统一到模态和子轨迹的掩蔽和恢复中，允许 TrajFM 进行一次预训练并转移到不同的任务而无需重新训练。在不同设置下对两个真实车辆轨迹数据集进行的实验证明了 TrajFM 的有效性。代码可在 https://anonymous.4open.science/r/TrajFM-30E4 获得。]]></description>
      <guid>https://arxiv.org/abs/2408.15251</guid>
      <pubDate>Thu, 29 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>vFusedSeg3D：2024 年 Waymo 开放数据集挑战赛语义分割第三名解决方案</title>
      <link>https://arxiv.org/abs/2408.15254</link>
      <description><![CDATA[arXiv:2408.15254v1 公告类型：新
摘要：在这项技术研究中，我们介绍了 VFusedSeg3D，这是 VisionRD 团队创建的一种创新的多模态融合系统，它结合了摄像头和 LiDAR 数据，显著提高了 3D 感知的准确性。VFusedSeg3D 使用摄像头图片的丰富语义内容和 LiDAR 的精确深度感知来生成强大而全面的环境理解，解决了每种模态固有的限制。通过精心设计的网络架构在不同阶段对齐和合并这些信息，我们的新颖特征融合技术将 LiDAR 点云的几何特征与摄像头图像的语义特征相结合。通过使用多模态技术，性能得到了显着改善，在验证集上获得了最先进的 mIoU 72.46%，而之前的 mIoU 为 70.51%。VFusedSeg3D 为 3D 分割准确性树立了新的标杆。使其成为需要精确环境感知的应用的理想解决方案。]]></description>
      <guid>https://arxiv.org/abs/2408.15254</guid>
      <pubDate>Thu, 29 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于 Transformer 的神经动画器，用于定性模拟软体运动</title>
      <link>https://arxiv.org/abs/2408.15258</link>
      <description><![CDATA[arXiv:2408.15258v1 公告类型：新
摘要：人类思维可以毫不费力地模拟受物理定律支配的物体的运动，例如飘扬的旗帜或在风力作用下飘扬的旗帜，而无需了解其背后的物理原理。这表明，人类认知可以使用直观的预测过程来预测物理事件的展开。这个过程可能是记忆回忆的结果，产生一个定性可信的心理图像，尽管它可能并不完全符合现实世界的物理。本文从人类无需明确参与数学计算就能定性地可视化和描述过去经验中的动态事件这一有趣的能力中汲取灵感，研究了最近的 Transformer 架构作为神经动画模型的应用。视觉 Transformer 模型经过训练，可以在给定 \emph{t-n} $\cdots$ \emph{t} 个时间步骤中的先前运动信息的情况下，预测 \emph{t+1} 时间步骤中的旗帜运动。结果表明，基于视觉变换器的架构成功学习了旗帜运动的时间嵌入，并对不同风力下的旗帜飘扬产生了合理质量的模拟。]]></description>
      <guid>https://arxiv.org/abs/2408.15258</guid>
      <pubDate>Thu, 29 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>S4DL：用于高光谱图像无监督域自适应的移位敏感空间光谱解缠学习</title>
      <link>https://arxiv.org/abs/2408.15263</link>
      <description><![CDATA[arXiv:2408.15263v1 公告类型：新
摘要：无监督域自适应技术在高光谱图像 (HSI) 分类中得到了广泛的研究，旨在使用标记的源域数据和未标记的目标域数据来学习跨场景分类的域不变特征。与自然图像相比，HSI 的众多光谱带提供了丰富的语义信息，但它们也显著增加了域偏移。在大多数现有方法中，显式对齐和隐式对齐都只是对齐特征分布，忽略了光谱中的域信息。我们注意到，当源域和目标域之间的光谱通道明显区分时，这些方法的传输性能往往会下降。此外，由于不同数据集之间的域偏移不同，它们的性能波动很大。为了解决这些问题，提出了一种新的偏移敏感的空间光谱解缠学习 (S4DL) 方法。在 S4DL 中，梯度引导的空间谱分解旨在通过在域分类的梯度引导下生成定制的掩码来分离特定域和域不变表示。定义了一个移位敏感的自适应监视器，以根据域移位的幅度调整解缠强度。此外，构建了一个可逆神经网络来保留域信息，这些信息不仅存在于语义中，还存在于浅层详细信息中。在多个跨场景 HSI 数据集上进行的大量实验结果一致证明 S4DL 优于最先进的 UDA 方法。我们的源代码将在 https://github.com/xdu-jjgs/S4DL 上提供。]]></description>
      <guid>https://arxiv.org/abs/2408.15263</guid>
      <pubDate>Thu, 29 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SkillMimic：通过演示学习可重复使用的篮球技巧</title>
      <link>https://arxiv.org/abs/2408.15270</link>
      <description><![CDATA[arXiv:2408.15270v1 公告类型：新
摘要：掌握篮球技能（例如各种上篮和运球）涉及与球的复杂互动，需要实时调整。传统的互动技能强化学习方法依赖于劳动密集型、手动设计的奖励，这些奖励不能很好地推广到不同的技能中。受人类从演示中学习的启发，我们提出了 SkillMimic，这是一种数据驱动的方法，可以模仿人类和球的运动来学习各种各样的篮球技能。SkillMimic 采用统一的配置从人球运动数据集中学习各种技能，随着数据集的增长，技能多样性和泛化能力不断提高。这种方法允许训练单一策略来学习多种技能，即使这些切换不存在于参考数据集中，也可以实现平滑的技能切换。SkillMimic 获得的技能可以被高级控制器轻松重用来完成复杂的篮球任务。为了评估我们的方法，我们引入了两个篮球数据集：一个是通过单目 RGB 视频估计的，另一个是使用先进的动作捕捉设备估计的，总共包含约 35 分钟的各种篮球技巧。实验表明，我们的方法可以有效地学习数据集中包含的各种篮球技巧，并采用统一的配置，包括各种运球、上篮和投篮风格。此外，通过训练高级控制器来重复使用所获得的技能，我们可以实现复杂的篮球任务，例如上篮得分，其中包括向篮筐运球、把握运球和上篮得分的时机、抢篮板并重复该过程。项目页面和视频演示可在 https://ingrid789.github.io/SkillMimic/ 上找到]]></description>
      <guid>https://arxiv.org/abs/2408.15270</guid>
      <pubDate>Thu, 29 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>群体层面情绪识别的深度学习综述</title>
      <link>https://arxiv.org/abs/2408.15276</link>
      <description><![CDATA[arXiv:2408.15276v1 公告类型：新
摘要：随着人工智能 (AI) 技术的进步，群体层面的情绪识别 (GER) 已成为分析人类行为的重要领域。早期的 GER 方法主要依赖于手工制作的特征。然而，随着深度学习 (DL) 技术的普及及其在不同任务中取得的显著成功，神经网络对 GER 的兴趣日益浓厚。与个人情绪不同，群体情绪表现出多样性和动态性。目前，已经提出了几种 DL 方法来有效利用群体级图像中固有的丰富信息并显着提高 GER 性能。在这篇调查中，我们对应用于 GER 的 DL 技术进行了全面回顾，提出了一种新的分类法，涵盖了基于 DL 的 GER 的所有方面。该调查概述了数据集、深度 GER 管道以及过去十年来最先进方法的性能比较。此外，它总结并讨论了每个方面的基本方法和高级发展。此外，我们指出了尚未解决的挑战，并提出了设计稳健 GER 系统的潜在途径。据我们所知，这项调查是对深度 GER 方法的首次全面回顾，可为未来的 GER 研究工作提供重要参考。]]></description>
      <guid>https://arxiv.org/abs/2408.15276</guid>
      <pubDate>Thu, 29 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用条件扩散模型实现 3D 光子计数 CT 图像超分辨率</title>
      <link>https://arxiv.org/abs/2408.15283</link>
      <description><![CDATA[arXiv:2408.15283v1 公告类型：新
摘要：本研究旨在使用去噪扩散概率模型 (DDPM) 提高光子计数 CT (PCCT) 图像分辨率。尽管 DDPM 在应用于各种计算机视觉任务时表现出色，但它们的有效性尚未转化为高维 CT 超分辨率。为了以条件采样的方式训练 DDPM，我们首先利用 CatSim 模拟来自高分辨率 CT 扫描的真实低分辨率 PCCT 图像。由于最大化 DDPM 性能对于推理和训练都很耗时，尤其是在高维 PCCT 数据上，我们探索了条件 DDPM 的 2D 和 3D 网络并应用方法来加速训练。具体来说，我们将 3D 任务分解为高效的 2D DDPM，并在反向扩散过程中设计联合 2D 推理，协同所有三个维度的 2D 结果以做出最终的 3D 预测。实验结果表明，我们的 DDPM 在恢复高频结构方面比基线参考模型取得了更好的效果，这表明基于真实模拟和 DDPM 的框架有望提高 PCCT 分辨率。]]></description>
      <guid>https://arxiv.org/abs/2408.15283</guid>
      <pubDate>Thu, 29 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>处理外科 RGB 和高光谱图像语义分割中的几何域偏移</title>
      <link>https://arxiv.org/abs/2408.15373</link>
      <description><![CDATA[arXiv:2408.15373v1 公告类型：新
摘要：术中图像数据的稳健语义分割有望实现自动手术场景理解和自主机器人手术。虽然模型开发和验证主要在理想场景中进行，但几何域偏移（例如位置遮挡）在现实世界的开放手术中很常见。为了弥补这一差距，我们 (1) 首次分析了面对几何分布不均 (OOD) 数据的最先进的 (SOA) 语义分割模型，(2) 提出了一种称为“器官移植”的增强技术，以增强通用性。我们对六个不同的 OOD 数据集进行了全面验证，包括来自 33 头猪的 600 个 RGB 和高光谱成像 (HSI) 立方体，每个立方体都标注了 19 个类别，结果显示 SOA 器官分割模型在几何 OOD 数据上的性能大幅下降。这种性能下降不仅出现在传统的 RGB 数据中（骰子相似系数 (DSC) 下降了 46%），也出现在 HSI 数据中（DSC 下降了 45%），尽管光谱信息内容更丰富。性能下降会随着输入数据的空间粒度而增加。我们的增强技术可将 RGB 数据的 SOA 模型性能提高 67%，将 HSI 数据的 SOA 模型性能提高 90%，在真实 OOD 测试数据上达到分布内性能水平。鉴于我们的增强方法的简单性和有效性，无论底层模型如何，它都是解决手术场景分割中几何域偏移的有力工具。我们的代码和预训练模型可在 https://github.com/IMSY-DKFZ/htc 公开获取。]]></description>
      <guid>https://arxiv.org/abs/2408.15373</guid>
      <pubDate>Thu, 29 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有更好循环的 CycleGAN</title>
      <link>https://arxiv.org/abs/2408.15374</link>
      <description><![CDATA[arXiv:2408.15374v1 公告类型：新
摘要：CycleGAN 提供了一个使用循环一致性损失训练图像到图像转换的框架，该框架使用非配对数据集 [4]。虽然在许多应用中结果都很好，但像素级循环一致性可能会出现问题，并在某些情况下导致图像不切实际。在这个项目中，我们提出了对循环一致性的三个简单修改，并表明这种方法可以以更少的伪影实现更好的结果。]]></description>
      <guid>https://arxiv.org/abs/2408.15374</guid>
      <pubDate>Thu, 29 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>扩散模型中的多特征聚合用于增强人脸超分辨率</title>
      <link>https://arxiv.org/abs/2408.15386</link>
      <description><![CDATA[arXiv:2408.15386v1 公告类型：新
摘要：超分辨率算法通常难以处理来自监控环境的图像，因为诸如未知退化、姿势变化、不规则照明和遮挡等不利条件。但是，使用监控摄像机可以获取多张图像，即使是低质量的图像。在这项工作中，我们开发了一种基于扩散模型的算法，该算法利用低分辨率图像与从多张低质量图像中提取的特征相结合来生成超分辨率图像，同时最大限度地减少个人身份的扭曲。与其他算法不同，我们的方法无需明确提供属性信息，也无需在重建过程中计算函数的梯度即可恢复面部特征。据我们所知，这是第一次将多特征与低分辨率图像相结合用作调节器，使用随机微分方程生成更可靠的超分辨率图像。使用 FFHQ 数据集进行训练，在 CelebA 和 Quis-Campi 数据集上进行评估时，在面部识别和验证指标方面取得了最先进的表现。我们的代码可在 https://github.com/marcelowds/fasr 上公开获取]]></description>
      <guid>https://arxiv.org/abs/2408.15386</guid>
      <pubDate>Thu, 29 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>HEAD：一种针对异构网联和自动驾驶汽车的带宽高效协同感知方法</title>
      <link>https://arxiv.org/abs/2408.15428</link>
      <description><![CDATA[arXiv:2408.15428v1 公告类型：新
摘要：在合作感知研究中，通信带宽和感知性能之间通常存在权衡。虽然当前的特征融合解决方案以其出色的物体检测性能而闻名，但传输整个中间特征图集需要大量带宽。此外，这些融合方法通常仅限于使用相同检测模型的车辆。我们的目标是开发一种支持配备不同传感器模式的车辆之间的合作感知的解决方案。与后期融合技术相比，该方法旨在提供更好的感知性能，同时实现与最先进的中间融合相似的精度，但所需的带宽要少一个数量级。我们提出了 HEAD，一种融合 3D 物体检测网络中分类和回归头的特征的方法。我们的方法与异构检测网络兼容，例如 LiDAR PointPillars、SECOND、VoxelNet 和相机鸟瞰图 (BEV) 编码器。鉴于检测头中的特征尺寸自然较小，我们设计了一种自注意力机制来融合分类头，并设计了一个互补特征融合层来融合回归头。我们在 V2V4Real 和 OPV2V 数据集上进行的实验综合评估表明，HEAD 是一种有效平衡通信带宽和感知性能的融合方法。]]></description>
      <guid>https://arxiv.org/abs/2408.15428</guid>
      <pubDate>Thu, 29 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有序数嵌入的细粒度长度可控视频字幕</title>
      <link>https://arxiv.org/abs/2408.15447</link>
      <description><![CDATA[arXiv:2408.15447v1 公告类型：新
摘要：本文提出了一种用于视频字幕生成的方法，可以控制生成的字幕的长度。以前关于长度控制的工作通常只有几个表示长度的层次。在本研究中，我们提出了两种长度嵌入方法，用于细粒度的长度控制。传统的嵌入方法是线性的，使用独热向量和嵌入矩阵。在本研究中，我们提出了在多热向量中表示长度的方法。一种是以位表示形式表示长度的位嵌入，另一种是使用序数回归中常用的二进制表示的序数嵌入。这些多热向量的长度表示通过非线性 MLP 转换为长度嵌入。该方法不仅可以控制字幕句子的长度，还可以控制阅读字幕的时间。使用 ActivityNet Captions 和 Spoken Moments in Time 进行的实验表明，所提出的方法可以有效地控制生成的字幕的长度。使用 ICA 对嵌入向量的分析表明，长度和语义是分别学习的，证明了所提出的嵌入方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2408.15447</guid>
      <pubDate>Thu, 29 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>