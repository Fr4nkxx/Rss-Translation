<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CV 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Mon, 16 Dec 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>评估代理：高效、快捷的视觉生成模型评估框架</title>
      <link>https://arxiv.org/abs/2412.09645</link>
      <description><![CDATA[arXiv:2412.09645v1 公告类型：新
摘要：视觉生成模型的最新进展使得高质量图像和视频生成成为可能，从而开启了各种应用。然而，评估这些模型通常需要对数百或数千张图像或视频进行采样，这使得该过程在计算上非常昂贵，尤其是对于采样速度本来就很慢的基于扩散的模型而言。此外，现有的评估方法依赖于僵化的流程，这些流程忽略了特定的用户需求，并且提供了数值结果而没有明确的解释。相比之下，人类只需观察几个样本就可以快速形成对模型能力的印象。为了模仿这一点，我们提出了评估代理框架，该框架采用类似人类的策略进行高效、动态、多轮评估，每轮仅使用几个样本，同时提供详细的、用户定制的分析。它具有四个主要优势：1）效率，2）针对不同用户需求的即时评估，3）超越单一数值分数的可解释性，4）跨各种模型和工具的可扩展性。实验表明，评估代理在提供可比结果的同时，将评估时间缩短至传统方法的 10%。评估代理框架完全开源，旨在推动视觉生成模型及其高效评估的研究。]]></description>
      <guid>https://arxiv.org/abs/2412.09645</guid>
      <pubDate>Mon, 16 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于矢量地图的杆式车辆定位：摄像头-激光雷达对比研究</title>
      <link>https://arxiv.org/abs/2412.09649</link>
      <description><![CDATA[arXiv:2412.09649v1 公告类型：新
摘要：对于自主导航，需要根据地图进行精确定位。在城市环境中，建筑物或桥梁等基础设施给全球导航卫星系统 (GNSS) 带来了重大困难，尽管惯性导航取得了进展，但仍需要使用其他外部感知信息源来支持它们。在道路环境中，许多常见的家具，如交通标志、交通信号灯和路灯，都采用杆的形式。通过在矢量地图中对这些特征进行地理配准，它们可以在包含检测管道和数据关联方法的定位过滤器中使用。可以使用 LiDAR 传感器从 3D 几何信息中提取具有判别性垂直结构的杆。或者，可以使用深度神经网络从单目相机中检测它们。缺乏深度信息给将相机检测与地图特征关联带来了挑战。然而，多相机集成提供了一种经济高效的解决方案。本文定量评估了这些方法在定位方面的有效性。本文介绍了一种基于摄像头的杆检测实时方法，该方法使用在自动注释图像上训练的轻量级神经网络。使用矢量地图对具有挑战性的序列评估了所提出方法的效率。结果突出了基于视觉的方法在开放道路条件下的高精度。]]></description>
      <guid>https://arxiv.org/abs/2412.09649</guid>
      <pubDate>Mon, 16 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从噪声到细微差别：深度生成图像模型的进展</title>
      <link>https://arxiv.org/abs/2412.09656</link>
      <description><![CDATA[arXiv:2412.09656v1 公告类型：新
摘要：自 2021 年以来，基于深度学习的图像生成经历了范式转变，其特点是基础架构突破和计算创新。通过回顾架构创新和实证结果，本文分析了从传统生成方法到高级架构的转变，重点关注计算效率高的扩散模型和视觉变换器架构。我们研究了稳定扩散、DALL-E 和一致性模型的最新发展如何重新定义图像合成的能力和性能边界，同时解决效率和质量方面的持续挑战。我们的分析侧重于潜在空间表示、交叉注意机制和参数高效的训练方法的演变，这些方法可以在资源受限的情况下加速推理。虽然更高效的训练方法可以实现更快的推理，但 ControlNet 和区域注意系统等高级控制机制同时提高了生成精度和内容定制。我们研究了增强的多模态理解和零样本生成能力如何重塑跨行业的实际应用。我们的分析表明，尽管生成质量和计算效率取得了显著进步，但在开发资源意识架构和可解释的工业应用生成系统方面仍然存在重大挑战。本文最后概述了有前景的研究方向，包括神经架构优化和可解释的生成框架。]]></description>
      <guid>https://arxiv.org/abs/2412.09656</guid>
      <pubDate>Mon, 16 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SEGT：用于基于 nuScenes 激光雷达的物体检测任务的通用空间扩展组变换器</title>
      <link>https://arxiv.org/abs/2412.09658</link>
      <description><![CDATA[arXiv:2412.09658v1 公告类型：新
摘要：在技术报告中，我们提出了一种基于 n​​uScenes 激光雷达的物体检测任务的新型基于 Transformer 的框架，称为空间扩展组 Transformer (SEGT)。为了有效地处理点云的不规则和稀疏性质，我们建议使用一般的空间扩展策略将体素迁移到不同的专门有序场中，并采用组注意机制来提取每个场内的独有特征图。随后，我们通过交替应用不同的扩展策略来整合不同有序场中的特征表示，从而增强模型捕获全面空间信息的能力。该方法在基于 nuScenes 激光雷达的物体检测测试数据集上进行了评估，在没有测试时间增强 (TTA) 的情况下获得了 73.5 的 NDS 分数，在有 TTA 的情况下获得了 74.2 的 NDS 分数，证明了所提方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2412.09658</guid>
      <pubDate>Mon, 16 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>视觉语言模型认为，深色皮肤的黑人个体比浅色皮肤的黑人个体更加同质化</title>
      <link>https://arxiv.org/abs/2412.09668</link>
      <description><![CDATA[arXiv:2412.09668v1 公告类型：新
摘要：视觉语言模型 (VLM) 将大型语言模型 (LLM) 功能与图像处理相结合，支持图像字幕和文本到图像生成等任务。然而，人们仍然担心它们可能会放大类似人类的偏见，包括肤色偏见。肤色偏见，即肤色较深的人比肤色较浅的人面临更多的负面刻板印象，在社会科学中已有充分记录，但在人工智能 (AI) 中仍未得到充分探索，尤其是在 VLM 中。虽然在社会科学中已有充分记录，但这种偏见在人工智能中仍未得到充分探索，尤其是在 VLM 中。使用 GAN 人脸数据库，我们对计算机生成的美国黑人男性和女性图像进行了采样，控制肤色变化，同时保持其他特征不变。然后，我们要求 VLM 撰写有关这些面孔的故事，并比较生成的故事的同质性。在四个模型中的三个模型中，VLM 生成的关于深色皮肤黑人的故事比关于浅色皮肤的故事更同质，而且在所有模型中，黑人女性的代表性始终比黑人男性更同质。相互作用效应表明，在两个 VLM 中，肤色对女性的影响更大，而另外两个 VLM 的结果不显著，反映了已知的刻板印象模式。这些发现强调了偏见从单模态 AI 系统传播到多模态模型，并强调需要进一步研究以解决 AI 中的交叉偏见。]]></description>
      <guid>https://arxiv.org/abs/2412.09668</guid>
      <pubDate>Mon, 16 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>PBR-NeRF：基于物理的神经场的逆向渲染</title>
      <link>https://arxiv.org/abs/2412.09680</link>
      <description><![CDATA[arXiv:2412.09680v1 公告类型：新 
摘要：我们使用基于物理的渲染 (PBR) 理论的神经辐射场 (NeRF) 方法（称为 PBR-NeRF）解决了 3D 重建中的不适定逆渲染问题。我们的方法解决了大多数 NeRF 和 3D Gaussian Splatting 方法中的一个关键限制：它们估计与视图相关的外观而无需对场景材料和照明进行建模。为了解决这一限制，我们提出了一种能够联合估计场景几何、材料和照明的逆渲染 (IR) 模型。我们的模型建立在最近基于 NeRF 的 IR 方法的基础上，但至关重要的是引入了两个新的基于物理的先验，可以更好地约束 IR 估计。我们的先验被严格地表述为直观的损失项，并实现了最先进的材料估计，而不会影响新颖的视图合成质量。我们的方法很容易适应需要材料估计的其他逆渲染和 3D 重建框架。我们展示了扩展当前神经渲染方法的重要性，以全面模拟几何和视图相关外观以外的场景属性。代码可在 https://github.com/s3anwu/pbrnerf 上公开获取]]></description>
      <guid>https://arxiv.org/abs/2412.09680</guid>
      <pubDate>Mon, 16 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>TOAP：实现通用可转移反面部检索的更好稳健性</title>
      <link>https://arxiv.org/abs/2412.09692</link>
      <description><![CDATA[arXiv:2412.09692v1 公告类型：new 
摘要：基于深度哈希的检索技术被广泛应用于人脸检索系统，以提高人脸匹配的效率。然而，它也带来了隐私泄露的风险。深度哈希模型很容易受到对抗样本的影响，可以利用对抗样本来防止私人图像的恶意检索。现有的针对深度哈希模型的对抗样本方法侧重于普适性和可迁移性，缺乏对其在在线社交网络（OSN）中的鲁棒性研究，导致其在后处理后的反检索中失败。因此，我们首次深入讨论了通用可迁移反人脸检索中的鲁棒性对抗扰动，并提出了三合一对抗扰动（TOAP）。具体而言，我们首先分析了深度哈希模型在后处理后的性能，并构建了一个局部和全局压缩生成器（CG）来模拟复杂的后处理场景。然后探究图像后处理下模型目标的变化规律，提出鲁棒的优化目标、聚类中心和数据空间中心，并利用元学习对其进行优化。最后，通过交替生成对抗样本和微调对抗网络来迭代优化扰动，平衡扰动的性能同时增强对抗网络缓解扰动的能力。大量实验表明，TOAP 除了在普适性和可迁移性上的优势外，在多个鲁棒性指标上均显著优于目前最先进的方法，将普适性和可迁移性进一步提升5%~28%，并在多个模拟后处理场景和主流OSN 中实现了高达约33%的显着提升，表明 TOAP 可以有效地在实际场景中保护隐私图像免遭恶意检索。]]></description>
      <guid>https://arxiv.org/abs/2412.09692</guid>
      <pubDate>Mon, 16 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Omni-ID：为生成任务设计的整体身份表征</title>
      <link>https://arxiv.org/abs/2412.09694</link>
      <description><![CDATA[arXiv:2412.09694v1 公告类型：新
摘要：我们介绍了 Omni-ID，一种专为生成任务设计的新型面部表征。Omni-ID 在一个固定大小的表征中编码了关于个人在各种表情和姿势下外貌的整体信息。它将来自不同数量的非结构化输入图像的信息整合成一个结构化表征，其中每个条目代表某些全局或局部身份特征。我们的方法使用少对多身份重建训练范式，其中使用一组有限的输入图像来重建同一个人在各种姿势和表情下的多个目标图像。进一步采用多解码器框架来利用不同解码器在训​​练过程中的互补优势。与通​​常通过判别或对比目标学习的传统表征（例如 CLIP 和 ArcFace）不同，Omni-ID 通过生成目标进行了优化，从而为生成任务提供了更全面、更细致的身份捕获。 Omni-ID 在我们的 MFHQ 数据集（多视图面部图像集合）上进行训练，在各种生成任务中比传统表示表现出显着的改进。]]></description>
      <guid>https://arxiv.org/abs/2412.09694</guid>
      <pubDate>Mon, 16 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用无人机时间序列图像的二维轮廓图预测大豆成熟度</title>
      <link>https://arxiv.org/abs/2412.09696</link>
      <description><![CDATA[arXiv:2412.09696v1 公告类型：新
摘要：植物育种计划需要对成熟天数进行评估，以便准确选择和将条目放置在适当的测试中。在育种流程的早期阶段，大豆育种计划为实验品种分配相对成熟度等级，以表明其合适的成熟度区域。传统上，育种品种成熟度值的估计需要育种者手动检查田地并目视评估成熟度值。这种方法严重依赖于评估者的判断，因此主观且耗时。本研究旨在开发一种使用基于无人机的时间序列图像评估大豆成熟度的机器学习模型。图像以三天为间隔拍摄，从最早的品种开始成熟开始，一直持续到最后的品种完全成熟。本次实验收集的数据包括三年（2021 年至 2023 年）收集的 22,043 个地块，代表相对成熟度组 1.6 - 3.9。我们利用从时间序列 UAV RGB 图像中提取的等高线图图像作为神经网络模型的输入。这种等高线图方法将每个图内的时间和空间变化编码为单个图像。我们训练了一个深度学习模型来利用这种等高线图来预测成熟度等级。该模型显著提高了准确度和稳健性，准确度高达 85%。我们还在减少时间点数量时评估了模型的准确性，量化了时间分辨率和成熟度预测之间的权衡。预测模型提供了一种可扩展、客观且有效的作物成熟度评估方法，使表型组学和 ML 方法能够减少对人工检查和主观评估的依赖。这种方法能够在育种计划中自动预测相对成熟度等级，从而节省时间和资源。]]></description>
      <guid>https://arxiv.org/abs/2412.09696</guid>
      <pubDate>Mon, 16 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过文本和图像增强实现扩散增强测试时间自适应</title>
      <link>https://arxiv.org/abs/2412.09706</link>
      <description><![CDATA[arXiv:2412.09706v1 公告类型：新
摘要：现有的测试时即时调整 (TPT) 方法侧重于单模态数据，主要增强图像并使用置信度评级来过滤不准确的图像。然而，虽然图像生成模型可以生成视觉上多样化的图像，但单模态数据增强技术仍然无法捕捉不同模态提供的全面知识。此外，我们注意到，当增强图像的数量有限时，基于 TPT 的方法的性能会显着下降，考虑到生成增强的计算成本，这并不罕见。为了解决这些问题，我们引入了 IT3A，这是一种新颖的测试时自适应方法，它利用预先训练的生成模型对来自未知新领域的每个测试样本进行多模态增强。通过结合来自预训练视觉和语言模型的增强数据，我们增强了模型适应未知新测试数据的能力。此外，为了确保在生成各种视觉和文本增强时准确保留关键语义，我们在增强图像和文本的逻辑与原始测试数据之间采用了余弦相似性过滤。此过程使我们能够过滤掉一些虚假增强和不充分的组合。为了利用生成模型在不同模态中提供的各种增强功能，我们用适配器替换了即时调整，以便在使用文本模板方面具有更大的灵活性。我们在具有分布偏移和域间隙的测试数据集上进行的实验表明，在零样本设置中，IT3A 的表现优于最先进的测试时间即时调整方法，准确率提高了 5.50%。]]></description>
      <guid>https://arxiv.org/abs/2412.09706</guid>
      <pubDate>Mon, 16 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>人类与人工智能：新基准以及对生成图像检测和提示影响的比较研究</title>
      <link>https://arxiv.org/abs/2412.09715</link>
      <description><![CDATA[arXiv:2412.09715v1 公告类型：新
摘要：随着基于 AI 的文本转图像系统的公开出现，创建逼真但完全合成的图像的过程已基本民主化。这可能通过简化虚假信息的传播对公众构成威胁。机器检测器和人类媒体专业知识可以帮助区分 AI 生成的（假）图像和真实图像并抵消这种危险。尽管 AI 生成模型高度依赖于提示，但提示对假检测性能的影响尚未得到研究。因此，这项工作研究了提示的细节级别对假图像可检测性的影响，包括使用 AI 检测器和用户研究。为此，我们创建了一个新数据集 COCOXGEN，它由来自 COCO 数据集的真实照片以及使用两种标准长度的提示使用 SDXL 和 Fooocus 生成的图像组成。我们针对 200 名参与者进行的用户研究表明，使用较长、更详细的提示生成的图像比使用较短提示生成的图像更容易被检测到。同样，基于 AI 的检测模型在使用较长提示生成的图像上取得了更好的效果。然而，正如我们在热图分析中所展示的那样，人类和 AI 模型似乎关注不同的细节。]]></description>
      <guid>https://arxiv.org/abs/2412.09715</guid>
      <pubDate>Mon, 16 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>BayesAdapter：增强 CLIP 小样本自适应中的不确定性估计</title>
      <link>https://arxiv.org/abs/2412.09718</link>
      <description><![CDATA[arXiv:2412.09718v1 公告类型：新
摘要：大型预训练视觉语言模型 (VLM) 的出现代表了机器学习的范式转变，在广泛的视觉识别任务中取得了前所未有的成果。CLIP 是最流行的 VLM 之一，在分类中表现出卓越的零样本和迁移学习能力。为了将 CLIP 转移到下游任务，适配器构成了一种参数高效的方法，避免了通过大型模型进行反向传播（与相关的即时学习方法不同）。然而，CLIP 适配器的开发目标是判别性能，而其不确定性估计的质量却被忽视了。在这项工作中，我们表明，最先进的 CLIP 适配器的判别性能并不总是与它们的不确定性估计能力相关，而不确定性估计能力对于在现实世界场景中安全部署至关重要。我们还证明，其中一个适配器是通过更通用的概率框架的 MAP 推理获得的。基于这一观察，我们引入了 BayesAdapter，它利用贝叶斯推理来估计完整的概率分布而不是单个点，从而更好地捕捉参数空间中固有的可变性。在全面的实证评估中，我们表明我们的方法在预测中获得了高质量的不确定性估计，在校准和选择性分类中脱颖而出。我们的代码公开发布在：https://github.com/pablomorales92/BayesAdapter。]]></description>
      <guid>https://arxiv.org/abs/2412.09718</guid>
      <pubDate>Mon, 16 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MAC-Ego3D：用于实时协作自我运动和逼真 3D 重建的多智能体高斯共识</title>
      <link>https://arxiv.org/abs/2412.09723</link>
      <description><![CDATA[arXiv:2412.09723v1 公告类型：新
摘要：实时多智能体协作进行自我运动估计和高保真 3D 重建对于可扩展空间智能至关重要。然而，传统方法会产生稀疏、低细节的地图，而最近的密集映射方法则面临高延迟的问题。为了克服这些挑战，我们提出了 MAC-Ego3D，这是一种通过多智能体高斯共识进行实时协作逼真 3D 重建的新型框架。MAC-Ego3D 使智能体能够使用统一的高斯图块表示独立构建、对齐和迭代细化局部地图。通过智能体内部高斯共识，它可以加强智能体内部相邻高斯图块之间的空间一致性。对于全局对齐，并行化的多智能体高斯共识通过正则化多智能体高斯图块异步对齐和优化局部地图，将它们无缝集成到高保真 3D 模型中。利用高斯基元，MAC-Ego3D 支持高效的 RGB-D 渲染，实现快速的跨智能体高斯关联和对齐。MAC-Ego3D 连接局部精度和全局一致性，提供更高的效率，大大减少定位误差，并提高映射保真度。它在合成和真实基准上建立了新的 SOTA，实现了推理速度提高 15 倍，部分情况下的自我运动估计误差降低了数量级，RGB PSNR 提高了 4 到 10 dB。我们的代码将在 https://github.com/Xiaohao-Xu/MAC-Ego3D 上公开发布。]]></description>
      <guid>https://arxiv.org/abs/2412.09723</guid>
      <pubDate>Mon, 16 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>推理能量的双指数增长：准确率竞赛的代价</title>
      <link>https://arxiv.org/abs/2412.09731</link>
      <description><![CDATA[arXiv:2412.09731v1 公告类型：新
摘要：计算机视觉中的深度学习模型取得了重大成功，但人们对能源消耗和可持续性的担忧日益增加。尽管存在这些担忧，但人们对它们在推理过程中的能源效率缺乏全面的了解。在这项研究中，我们对 1,200 个 ImageNet 分类模型的推理能耗进行了全面分析 - 这是迄今为止同类评估中规模最大的一次。我们的研究结果表明，相对于能源使用量的增加，准确度收益的收益急剧递减，凸显了在追求边际改进时对可持续性的担忧。我们确定了导致能源消耗的关键因素，并展示了提高能源效率的方法。为了促进更可持续的人工智能实践，我们引入了一个能源效率评分系统并开发了一个交互式网络应用程序，允许用户根据准确度和能耗比较模型。通过提供大量经验数据和实用工具，我们旨在促进明智的决策并鼓励合作开发节能的人工智能技术。]]></description>
      <guid>https://arxiv.org/abs/2412.09731</guid>
      <pubDate>Mon, 16 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 Vision Foundation 模型进行蔓越莓成熟度分析的农业科技框架</title>
      <link>https://arxiv.org/abs/2412.09739</link>
      <description><![CDATA[arXiv:2412.09739v1 公告类型：新
摘要：农业领域正在因支持定量视觉评估的人工智能和计算机视觉的最新进展而发生改变。利用时间序列上的空中和地面成像，我们开发了一个框架来表征蔓越莓作物的成熟过程，这是精准农业任务的关键组成部分，例如比较作物品种（高通量表型分析）和检测疾病。利用无人机成像，我们从多个沼泽的 20 个航点捕获图像，利用地面成像（手持相机），我们使用固定的基准标记对同一沼泽斑块进行成像。重复这两种成像方法以收集整个生长季节的多周时间序列。空中成像提供多个样本来计算反照率值的分布。地面成像能够跟踪单个浆果，以详细查看浆果外观的变化。使用视觉变换器 (ViT) 在分割后进行特征检测，我们提取了浆果外观的高维特征描述符。外观的可解释性对于植物生物学家和蔓越莓种植者来说至关重要，它可以支持作物育种决策（例如，比较育种计划中的浆果品种）。为了便于解释，我们通过对 ViT 特征进行 UMAP 降维，创建了蔓越莓外观的 2D 流形。此投影可以量化成熟路径和有用的成熟率指标。我们根据成熟度评估展示了四种蔓越莓品种的比较。这项工作是同类研究中的首例，对蔓越莓和其他作物（包括酿酒葡萄、橄榄、蓝莓和玉米）未来具有影响。空中和地面数据集已公开。]]></description>
      <guid>https://arxiv.org/abs/2412.09739</guid>
      <pubDate>Mon, 16 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>