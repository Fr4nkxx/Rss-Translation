<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CV 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Tue, 22 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>用于语义分割的深度域隔离和样本聚类联邦学习</title>
      <link>https://arxiv.org/abs/2410.14693</link>
      <description><![CDATA[arXiv:2410.14693v1 公告类型：新
摘要：实证研究表明，联邦学习在非独立同分布 (IID) 设置中表现出收敛问题。然而，这些研究仅关注标签分布变化或概念变化（例如模糊任务）。在本文中，我们首次探讨了参与者数据之间的协变量变化在 2D 分割任务中的影响，结果表明其影响远不如标签变化严重，但仍然存在收敛性。此外，当前的个性化 (PFL) 和集群 (CFL) 联邦学习方法本质上假设每个参与者的数据集的同质性及其与未来测试样本的一致性，方法是在客户端级别进行操作。我们引入了一个更通用、更现实的框架，其中每个参与者都拥有多个底层特征域分布的混合。为了诊断影响以联邦方式训练的模型的病理特征分布，我们开发了深度域隔离 (DDI) 来直接在模型的梯度空间中隔离图像域。联邦高斯混合模型适合每个类的样本梯度，同时将结果与服务器端的谱聚类相结合，以隔离分散的样本级域。我们通过样本聚类联邦学习 (SCFL) 框架利用这种聚类算法，对几个独立模型执行标准联邦学习，每个分散图像域一个。最后，我们训练一个分类器，能够在推理时将测试样本与其相应的域集群相关联，提供一组最终模型，这些模型与每个参与者的测试分布的任何假设无关。我们使用 EfficientVIT-B0 模型在玩具分割数据集以及 Cityscapes 和 GTA5 数据集组合的不同分区上验证了我们的方法，与其他方法相比，性能显着提升。我们的代码可以在 https://github.com/MatthisManthe/DDI_SCFL 上找到。]]></description>
      <guid>https://arxiv.org/abs/2410.14693</guid>
      <pubDate>Tue, 22 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>深度学习增强道路交通分析：使用 PlanetScope 影像进行可扩展车辆检测和速度估计</title>
      <link>https://arxiv.org/abs/2410.14698</link>
      <description><![CDATA[arXiv:2410.14698v1 公告类型：新
摘要：本文介绍了一种使用 PlanetScope SuperDove 卫星图像检测和估计车速的方法，为全球车辆交通监控提供了可扩展的解决方案。传统方法（例如固定传感器和无人机等移动系统）覆盖范围有限，并且受到高成本和法律限制的限制。基于卫星的方法提供了广泛的空间覆盖范围，但面临着挑战，包括成本高、帧速率低以及难以在高分辨率图像中检测小型车辆。我们提出了一个 Keypoint R-CNN 模型来跟踪 RGB 波段上的车辆轨迹，利用波段时间差异来估计速度。使用无人机镜头和覆盖德国和波兰高速公路的 GPS 数据进行验证。与 GPS 数据相比，我们的模型实现了 0.53 的平均精度和大约 3.4 m/s 的速度估计误差。无人机对比结果显示，卫星数据的平均速度为 112.85 公里/小时，而无人机镜头的平均速度为 131.83 公里/小时。虽然高速精度仍存在挑战，但这种方法展示了在广阔区域进行可扩展的日常交通监控的潜力，为全球交通动态提供了宝贵的见解。]]></description>
      <guid>https://arxiv.org/abs/2410.14698</guid>
      <pubDate>Tue, 22 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用深度关键点表征进行自监督关键点检测</title>
      <link>https://arxiv.org/abs/2410.14700</link>
      <description><![CDATA[arXiv:2410.14700v1 公告类型：新
摘要：现有的无监督关键点检测方法对图像施加人工变形，例如遮盖图像的很大一部分并使用原始图像的重建作为学习目标来检测关键点。然而，这种方法缺乏图像中的深度信息，并且经常检测到背景上的关键点。为了解决这个问题，我们提出了 Distill-DKP，这是一种新颖的跨模态知识蒸馏框架，它利用深度图和 RGB 图像在自监督环境中进行关键点检测。在训练期间，Distill-DKP 从基于深度的教师模型中提取嵌入级知识，以指导基于图像的学生模型，推理仅限于学生。实验表明，Distill-DKP 的表现显著优于之前的无监督方法，在 Human3.6M 上将平均 L2 误差降低了 47.15%，在 Taichi 上将平均误差降低了 5.67%，在 DeepFashion 数据集上将关键点准确率提高了 1.3%。详细的消融研究表明了知识蒸馏在网络不同层上的敏感性。项目页面：https://23wm13.github.io/distill-dkp/]]></description>
      <guid>https://arxiv.org/abs/2410.14700</guid>
      <pubDate>Tue, 22 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>优化停车位分类：将集成模型提炼为轻量级分类器</title>
      <link>https://arxiv.org/abs/2410.14705</link>
      <description><![CDATA[arXiv:2410.14705v1 公告类型：新
摘要：在为智能城市应用（例如基于图像的停车场监控）部署大规模机器学习模型时，通常必须将数据发送到中央服务器以执行分类任务。这对城市基础设施来说是一个挑战，因为基于图像的应用程序需要传输大量数据，需要复杂的网络和硬件基础设施来处理数据。为了解决基于图像的停车位分类中的这个问题，我们建议创建一个强大的分类器集合作为教师模型。这些教师模型被提炼成轻量级和专门的学生模型，可以直接部署在边缘设备上。知识通过教师模型生成的伪标记样本提炼到学生模型中，这些样本用于在目标场景上微调学生模型。我们的结果表明，学生模型的参数数量比教师模型少 26 倍，但在目标测试数据集上的平均准确率达到 96.6%，超过了教师模型的平均准确率 95.3%。]]></description>
      <guid>https://arxiv.org/abs/2410.14705</guid>
      <pubDate>Tue, 22 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>FACMIC：用于医学图像分类的联合自适应 CLIP 模型</title>
      <link>https://arxiv.org/abs/2410.14707</link>
      <description><![CDATA[arXiv:2410.14707v1 公告类型：新
摘要：联邦学习 (FL) 已成为一种有前途的医学图像分析方法，它允许使用分散数据进行深度模型训练，同时确保数据隐私。然而，在 FL 领域，通信成本在评估模型的性能方面起着至关重要的作用。因此，由于涉及大量资源成本，转移视觉基础模型可能特别具有挑战性。在本文中，我们介绍了一种专为分类任务设计的联邦自适应对比语言图像预训练 CLIP 模型。我们为 CLIP 采用了轻量级且高效的特征注意模块，为每个客户端的数据选择合适的特征。此外，我们提出了一种领域自适应技术来减少客户端之间数据分布的差异。在四个公开可用的数据集上的实验结果表明，FACMIC 在处理现实世界和多源医学成像数据方面具有卓越的性能。我们的代码可在 https://github.com/AIPMLab/FACMIC 获得。]]></description>
      <guid>https://arxiv.org/abs/2410.14707</guid>
      <pubDate>Tue, 22 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>G2D2：用于图像逆问题求解的梯度引导离散扩散</title>
      <link>https://arxiv.org/abs/2410.14710</link>
      <description><![CDATA[arXiv:2410.14710v1 公告类型：新
摘要：最近的文献有效地利用了在连续变量上训练的扩散模型作为先验来解决逆问题。值得注意的是，具有离散潜码的离散扩散模型表现出了强大的性能，特别是在适合离散压缩表示的模态中，例如图像和运动生成。然而，它们的离散和不可微分性质限制了它们在连续空间中形成的逆问题中的应用。本文提出了一种利用基于离散扩散的图像生成模型作为先验来解决线性逆问题的新方法。我们通过使用由分类分布和连续松弛技术构建的变分分布来近似真实后验分布来克服这些限制。此外，我们采用星形噪声过程来减轻具有吸收状态的传统离散扩散模型的缺点，证明我们的方法与连续扩散技术相当。据我们所知，这是第一种使用基于离散扩散模型的先验来解决图像逆问题的方法。]]></description>
      <guid>https://arxiv.org/abs/2410.14710</guid>
      <pubDate>Tue, 22 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>动画再现过去：通过视频重建三叶虫</title>
      <link>https://arxiv.org/abs/2410.14715</link>
      <description><![CDATA[arXiv:2410.14715v1 公告类型：新
摘要：古生物学是研究过去生命的学科，从根本上依赖化石来重建古代生态系统并了解进化动态。三叶虫是已灭绝的重要海洋节肢动物群，通过其保存完好的化石记录为古生代环境提供了宝贵的见解。从静态化石重建三叶虫的行为将为科学研究和教育中的动态重建树立新的标准。尽管具有潜力，但目前用于此目的的计算方法（如文本转视频 (T2V)）面临着重大挑战，例如保持视觉真实感和一致性，这阻碍了它们在科学环境中的应用。为了克服这些障碍，我们引入了一种自动 T2V 提示学习方法。在此框架内，微调视频生成模型的提示由大型语言模型生成，该模型使用量化生成视频的视觉真实感和流畅度的奖励进行训练。视频生成模型的微调以及奖励计算利用了收集的 9,088 张 Eoredlichia intermedia 化石图像数据集，该数据集提供了所有三叶虫类别的视觉细节的共同代表。定性和定量实验表明，与强大的基线相比，我们的方法可以生成具有更高视觉真实感的三叶虫视频，有望促进科学理解和公众参与。]]></description>
      <guid>https://arxiv.org/abs/2410.14715</guid>
      <pubDate>Tue, 22 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>按需提供代币：代币压缩作为无需训练的测试时间自适应</title>
      <link>https://arxiv.org/abs/2410.14729</link>
      <description><![CDATA[arXiv:2410.14729v1 公告类型：新
摘要：在这项工作中，我们引入了 Token Condensation as Adaptation (TCA)，这是一种无需训练的方法，旨在缓解视觉语言模型 (VLM) 在测试时推理过程中遇到的分布变化。TCA 通过压缩对 token 注意力较低的图像 token 来弥补补丁级别的分布差距。认识到 token 可能对应于通用概念，TCA 会识别并跟踪与历史数据流中的目标类别特别一致的最可靠 token。为了实现这一点，我们提出了一个上下文标记库 (CTR)，它将不确定性最低的标记保留为“锚点”，以指导推理过程中类相关标记的保存。这些锚点反过来充当标记级分类器，以纠正 VLM 预测并改善视觉文本对齐。利用从 CTR 采样的锚点，TCA 通过两个操作压缩标记：(1) 修剪在所有注意力头中始终排名较低的类不相关标记，以就其不相关性达成跨头共识，以及 (2) 使用核心集选择将剩余的类模糊标记合并到代表中心，保持线性计算复杂度。作为探索测试时自适应中标记效率的第一种方法，TCA 在跨数据集和分布外自适应任务中始终表现出卓越的性能，将 GFLOP 降低了 12.2% 至 48.9%，同时在不引入额外参数的情况下实现了相对于最强基线高达 21.4% 的准确率提升。]]></description>
      <guid>https://arxiv.org/abs/2410.14729</guid>
      <pubDate>Tue, 22 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过重新组装破碎部件来重建完整物体的计算解决方案综述</title>
      <link>https://arxiv.org/abs/2410.14770</link>
      <description><![CDATA[arXiv:2410.14770v1 公告类型：新
摘要：从物体的各个部分重建完整的物体是许多科学领域的基本问题。本文的目的是对这一主题进行系统的调查。重组问题需要了解各个部件的属性并建立不同部件之间的匹配。许多方法还对底层完整对象的先验进行建模。现有方法是形状分割、形状匹配和学习形状先验紧密相关的问题。我们在此背景下提供现有算法，并强调它们与通用方法的相似之处和不同之处。我们还调查了从早期的非深度学习方法到最近的深度学习方法的趋势。除了算法之外，本调查还将描述现有数据集、开源软件包和应用程序。据我们所知，这是计算机图形学中关于这一主题的第一次全面调查。]]></description>
      <guid>https://arxiv.org/abs/2410.14770</guid>
      <pubDate>Tue, 22 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SSL-NBV：一种基于自监督学习的次佳视图算法，用于机器人高效 3D 植物重建</title>
      <link>https://arxiv.org/abs/2410.14790</link>
      <description><![CDATA[arXiv:2410.14790v1 公告类型：新
摘要：植物的 3D 重建具有挑战性，因为它们的形状复杂，会造成许多遮挡。下一个最佳视图 (NBV) 方法通过迭代选择新视点来最大化信息增益 (IG) 来解决此问题。基于深度学习的 NBV (DL-NBV) 方法比基于体素的传统 NBV 方法具有更高的计算效率，但当前的方法需要使用地面实况植物模型进行大量训练，这使得它们不适用于现实世界的植物。此外，这些方法依赖于使用预先收集的数据进行离线训练，限制了在不断变化的农业环境中的适应性。本文提出了一种基于自监督学习的 NBV 方法 (SSL-NBV)，该方法使用深度神经网络来预测候选视点的 IG。该方法允许机器人在任务执行过程中通过将新的 3D 传感器数据与之前收集的数据进行比较，并采用弱监督学习和经验重放来实现高效的在线学习，从而收集自己的训练数据。使用交叉验证在模拟和现实环境中进行了综合评估。结果表明，SSL-NBV 所需的植物重建视图比非 NBV 方法更少，并且比基于体素的方法快 800 多倍。与基线 DL-NBV 相比，SSL-NBV 将训练注释减少了 90% 以上。此外，SSL-NBV 可以通过在线微调适应新场景。同样使用真实植物，结果表明，所提出的方法可以学习有效地规划 3D 植物重建的新视点。最重要的是，SSL-NBV 自动化了整个网络训练并使用持续的在线学习，使其能够在不断变化的农业环境中运行。]]></description>
      <guid>https://arxiv.org/abs/2410.14790</guid>
      <pubDate>Tue, 22 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于动态网格图的深度通用动态物体检测</title>
      <link>https://arxiv.org/abs/2410.14799</link>
      <description><![CDATA[arXiv:2410.14799v1 公告类型：新
摘要：本文介绍了一种用于自动驾驶的通用动态物体检测方法。首先，在线生成基于 LiDAR 的动态网格。其次，在动态网格上训练基于深度学习的检测器以推断任何类型的动态物体的存在，这是在任意极端情况下确保自动驾驶汽车安全的先决条件。旋转等变检测器 (ReDet) 最初设计用于航空图像上的定向物体检测，由于其高检测性能而被选中。实验基于真实传感器数据进行，并强调了与经典动态单元聚类策略相比的优势。所提出的方法大大降低了误报物体检测率。]]></description>
      <guid>https://arxiv.org/abs/2410.14799</guid>
      <pubDate>Tue, 22 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>GESH-Net：用于皮质表面配准的图形增强球面谐波卷积网络</title>
      <link>https://arxiv.org/abs/2410.14805</link>
      <description><![CDATA[arXiv:2410.14805v1 Announce Type: new 
摘要：目前基于经典方法的皮质表面配准技术已经得到了很好的发展。然而经典方法的一个关键问题是对于每对待配准图像，需要按照特定的优化算法在形变空间中寻找最优变换，直至相似性度量函数收敛，无法满足医学图像配准的实时性和高精度的要求。基于深度学习模型的研究皮质表面配准成为一个新的方向。但到目前为止，基于深度学习的皮质表面图像配准研究还很少。而且，虽然深度学习方法理论上具有更强的表征能力，但在配准精度和畸变控制方面超越最先进的经典方法仍然是一个挑战。因此，针对这一挑战，本文构建了深度学习模型来研究皮质表面图像配准技术。具体工作如下：（1）设计了一种基于多尺度级联结构的无监督皮层表面配准网络，引入基于球面谐波变换的卷积方法对皮层表面数据进行配准，解决了球面特征变换的尺度不灵活性问题，优化了多尺度配准流程。（2）通过融合注意机制，在配准网络中引入图增强模块，利用图注意模块帮助网络学习皮层表面数据的全局特征，增强网络的学习能力。结果表明，图注意模块有效增强了网络提取全局特征的能力，其配准结果相较于其他方法具有显著优势。]]></description>
      <guid>https://arxiv.org/abs/2410.14805</guid>
      <pubDate>Tue, 22 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>解决分布外内窥镜成像的领域泛化问题</title>
      <link>https://arxiv.org/abs/2410.14821</link>
      <description><![CDATA[arXiv:2410.14821v1 公告类型：新
摘要：虽然深度学习 (DL) 在手术场景分割方面的最新进展已经在单中心和单成像模态数据上取得了有希望的结果，但这些方法通常不能很好地推广到看不见的分布或模态。即使人类专家可以识别视觉外观，当数据样本不遵循相似的分布时，DL 方法往往无法做到这一点。当前解决模态变化领域差距的文献主要集中在自然场景数据上。然而，这些方法不能直接应用于内窥镜数据，因为与自然场景相比，此类数据中的视觉线索更为有限。在这项工作中，我们通过执行实例规范化和特征协方差映射技术来利用图像中的样式和内容信息，以保留稳健且可推广的特征表示。此外，为了避免删除与感兴趣对象相关的显着特征表示的风险，我们在特征学习 ResNet 主干中引入了一个恢复模块，以保留有用的任务相关特征。我们提出的方法比基线 DeepLabv3+ 提高了 13.7%，比 EndoUDA 息肉数据集的目标（不同模态）集的最新 (SOTA) 方法提高了近 8%。同样，我们的方法在 EndoUDA Barrett 食管 (BE) 数据集上比基线提高了 19%，比表现最佳的 SOTA 方法提高了 6%。]]></description>
      <guid>https://arxiv.org/abs/2410.14821</guid>
      <pubDate>Tue, 22 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>结合密集深度扩张可分离空间金字塔池化和 DeepLabV3+ 从卫星图像中自动提取道路</title>
      <link>https://arxiv.org/abs/2410.14836</link>
      <description><![CDATA[arXiv:2410.14836v1 公告类型：新
摘要：道路提取是遥感应用的一个子领域；它是一个广泛且持续研究的主题。由于道路的多尺度和多样化结构，从卫星图像中自动提取道路的过程面临重大挑战；需要改进这一领域。DeepLab 系列以其在解释多尺度对象特征方面的效率而闻名，它在语义分割方面非常出色，解决了由道路性质多变引起的一些挑战。本研究建议使用 DeepLab 系列的最新版本 DeepLabV3+，通过引入创新的密集深度扩张可分离空间金字塔池 (DenseDDSSPP) 模块并将其集成到传统的 Atrous 空间金字塔池 (ASPP) 模块中。这种修改增强了从卫星图像中提取复杂道路结构的能力。本研究假设，将 DenseDDSSPP 与适当选择的骨干网络和 Squeeze-and-Excitation 模块相结合，将通过关注相关特征来生成高效的密集特征图，从而从遥感图像中提取更精确的道路。结果部分将我们的模型的性能与最先进的模型进行了比较，展示了更好的结果，突出了所提出方法的有效性和成功性。]]></description>
      <guid>https://arxiv.org/abs/2410.14836</guid>
      <pubDate>Tue, 22 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>摘要：金属表面检测机器视觉的图像合成流程</title>
      <link>https://arxiv.org/abs/2410.14844</link>
      <description><![CDATA[arXiv:2410.14844v1 公告类型：新
摘要：使用机器学习 (ML) 方法开发稳健且灵活的视觉检测系统已显示出良好的前景。然而，它们的性能在很大程度上取决于训练数据的数量和多样性。这通常不仅由于成本而受到限制，而且还由于各种缺陷和产品表面以不同的频率出现而受到限制。因此，无法保证获取的数据集包含足够的缺陷和产品表面发生情况，而这些缺陷和产品表面发生情况是开发稳健模型所需的。使用参数合成数据集生成，可以避免这些问题。在这项工作中，我们介绍了一个完整的流程，详细描述了如何进行表面检查的图像合成 - 从第一次采集，到纹理和缺陷建模，数据生成，与真实数据的比较，最后使用合成数据来训练缺陷分割模型。针对铣削和喷砂铝表面详细评估了该流程。除了提供对每个步骤的深入了解、所选方法的讨论和 ML 结果的展示外，我们还提供了一个包含真实图像和合成图像的综合双重数据集。]]></description>
      <guid>https://arxiv.org/abs/2410.14844</guid>
      <pubDate>Tue, 22 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>