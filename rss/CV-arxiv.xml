<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CV 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Mon, 07 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>BoViLA：通过基于法学硕士的自我问答实现视频语言对齐</title>
      <link>https://arxiv.org/abs/2410.02768</link>
      <description><![CDATA[arXiv:2410.02768v1 公告类型：新
摘要：多模态模型的发展正在迅速推进，其中一些模型表现出非凡的能力。然而，对视频-文本对进行注释仍然昂贵且不足。以视频问答 (VideoQA) 任务为例，人工注释的问题和答案通常仅覆盖视频的一部分，并且相似的语义也可以通过不同的文本形式表达，导致视频利用不足。为了解决这个问题，我们提出了 BoViLA，这是一个自训练框架，它通过基于 LLM 的自问自答在训练期间扩充问题样本，这有助于模型更彻底地利用视频信息和 LLM 的内部知识来改进模态对齐。为了过滤不好的自生成问题，我们引入了证据深度学习 (EDL) 来估计不确定性并通过评估上下文中的模态对齐来评估自生成问题的质量。据我们所知，这项工作是第一个探索基于 LLM 的模态对齐自训练框架的工作。我们在五个强大的 VideoQA 基准上对 BoViLA 进行了评估，它的表现优于几种最先进的方法，并证明了其有效性和通用性。此外，我们还对自训练框架和基于 EDL 的不确定性过滤机制进行了广泛的分析。代码将在 https://github.com/dunknsabsw/BoViLA 上提供。]]></description>
      <guid>https://arxiv.org/abs/2410.02768</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>复值卷积神经网络对雷达图像中的手势进行分类</title>
      <link>https://arxiv.org/abs/2410.02771</link>
      <description><![CDATA[arXiv:2410.02771v1 公告类型：新
摘要：手势识别系统在过去十年中取得了许多令人兴奋的进步，并在 HCI（人机交互）中越来越受欢迎，其应用领域涵盖从安全和安保应用到汽车领域等多个领域。各种深度神经网络架构已经用于手势识别系统，包括多层感知器 (MLP)、卷积神经网络 (CNN)、循环神经网络 (RNN) 以及最后两种架构的级联（称为 CNN-RNN）。然而，仍然存在一个主要问题，即大多数现有的 ML 算法都是为实值 (RV) 设计和开发的构建块和技术。研究人员将各种 RV 技术应用于复值 (CV) 雷达图像，例如通过将复数分成实部和虚部，将 CV 优化问题转换为 RV 问题。然而，这种方法的主要缺点是生成的算法将使网络维度加倍。近期关于 RNN 的研究和其他基础理论分析表明 CV 数字具有更丰富的表示能力，但由于缺乏设计此类模型所需的构建块，CV 网络的性能被边缘化。在本报告中，我们提出了一个完整的 CV-CNN，包括复杂域中的所有构建块、前向和后向操作以及导数。我们在两组 CV 手势雷达图像上探索了我们提出的分类模型，并与等效 RV 模型进行了比较。在第五章中，我们提出了一个 CV-forward 残差网络，用于对两组 CV 手势雷达数据集进行二元分类，并将其性能与我们提出的 CV-CNN 和基线 CV-forward CNN 进行了比较。]]></description>
      <guid>https://arxiv.org/abs/2410.02771</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>注意人类分歧中的不确定性：评估 VQA 中模型预测与人类反应之间的差异</title>
      <link>https://arxiv.org/abs/2410.02773</link>
      <description><![CDATA[arXiv:2410.02773v1 公告类型：新
摘要：大型视觉语言模型经常难以准确预测多个人类注释者提供的响应，特别是当这些响应表现出人类的不确定性时。在这项研究中，我们专注于视觉问答 (VQA) 任务，并全面评估最先进的视觉语言模型与人类响应分布的相关性。为此，我们根据人类不确定性 (HUD) 的水平（低、中、高）对样本进行分类，并在 VQA 中不仅采用准确性，还采用三个新的与人类相关的指标来调查 HUD 的影响。为了更好地将模型与人类对齐，我们还验证了通用校准和人工校准的效果。我们的结果表明，即使是目前最适合这项任务的模型 BEiT3，也难以捕捉到不同人类反应中固有的多标签分布。此外，我们观察到，常用的以准确度为导向的校准技术对 BEiT3 捕获 HUD 的能力产生了不利影响，进一步扩大了模型预测与人类分布之间的差距。相比之下，我们展示了针对 VQA 的人类分布校准模型的好处，可以更好地将模型置信度与人类不确定性对齐。我们的研究结果强调，对于 VQA，人类反应与模型预测之间的一致性研究不足，应该成为未来研究的下一个关键目标。]]></description>
      <guid>https://arxiv.org/abs/2410.02773</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>猜猜我的想法：使用潜在扩散模型简化 EEG 到图像的生成</title>
      <link>https://arxiv.org/abs/2410.02780</link>
      <description><![CDATA[arXiv:2410.02780v1 公告类型：新
摘要：通过脑电波生成图像，它有可能通过了解脑信号如何编码视觉线索来推进脑机接口 (BCI) 系统，因此越来越受到关注。大多数文献都集中在 fMRI 到图像任务上，因为 fMRI 具有高空间分辨率的特点。然而，fMRI 是一种昂贵的神经成像方式，不允许实时 BCI。另一方面，脑电图 (EEG) 是一种低成本、非侵入性且便携的神经成像技术，使其成为未来实时应用的一个有吸引力的选择。然而，EEG 由于其低空间分辨率和易受噪声和伪影的影响而存在固有的挑战，这使得从 EEG 生成图像更加困难。在本文中，我们使用基于 ControlNet 适配器的精简框架来解决这些问题，该框架用于通过 EEG 信号调节潜在扩散模型 (LDM)。我们对流行的基准进行了实验和消融研究，以证明所提出的方法优于其他最先进的模型。与这些方法不同，这些方法通常需要大量的预处理、预训练、不同的损失和字幕模型，而我们的方法高效而直接，只需要最少的预处理和一些组件。代码将在发布后提供。]]></description>
      <guid>https://arxiv.org/abs/2410.02780</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过黎曼朗之万动力学进行稳健对称性检测</title>
      <link>https://arxiv.org/abs/2410.02786</link>
      <description><![CDATA[arXiv:2410.02786v1 公告类型：新
摘要：无论是自然界还是人造物，对称性在各种物体中都无处不在。虽然这些对称性对人眼来说似乎是直观的，但由于搜索空间巨大，用机器检测它们并非易事。经典的基于几何的方法通过聚合每个对称性的“投票”来工作，但难以应对噪音。相比之下，基于学习的方法可能对噪声更具鲁棒性，但由于注释数据的稀缺，通常会忽略部分对称性。在这项工作中，我们通过提出一种新颖的对称性检测方法来应对这一挑战，该方法将经典的对称性检测技术与生成建模的最新进展相结合。具体而言，我们将朗之万动力学应用于重新定义的对称空间，以增强对噪声的鲁棒性。我们对各种形状提供了实证结果，表明我们的方法不仅对噪声具有鲁棒性，而且还可以识别部分和全局对称性。此外，我们展示了所检测到的对称性在各种下游任务中的实用性，例如噪声形状的压缩和对称化。]]></description>
      <guid>https://arxiv.org/abs/2410.02786</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 VLM 框架导航：转到任何语言</title>
      <link>https://arxiv.org/abs/2410.02787</link>
      <description><![CDATA[arXiv:2410.02787v1 公告类型：新
摘要：导航到完全开放的语言目标并以类似于人类探索的方式探索开放场景一直是一个重大挑战。最近，视觉大型语言模型 (VLM) 已经展示了使用语言和视觉数据进行推理的卓越能力。虽然许多工作都专注于利用 VLM 在开放场景和开放词汇中进行导航，但这些努力往往未能充分利用 VLM 的潜力或需要大量的计算资源。我们引入了使用 VLM 进行导航 (NavVLM) 的框架，该框架利用设备级 VLM 使代理能够在开放场景中导航到任何特定或非特定的语言目标，模拟人类的探索行为而无需任何事先训练。代理利用 VLM 作为其认知核心，根据任何语言目标感知环境信息，并在导航过程中不断提供探索指导，直到到达目标位置或区域。我们的框架不仅在传统的特定目标设置中实现了成功率 (SR) 和路径长度加权成功率 (SPL) 方面的领先性能，而且还将导航功能扩展到任何开放集语言目标。我们在 Habitat 模拟器中的 Matterport 3D (MP3D)、Habitat Matterport 3D (HM3D) 和 Gibson 数据集中评估了 NavVLM 在丰富细节环境中的表现。借助 VLM 的强大功能，导航已进入一个新时代。]]></description>
      <guid>https://arxiv.org/abs/2410.02787</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RoMo：一种用于全身无标记光学运动捕捉的稳健解算器</title>
      <link>https://arxiv.org/abs/2410.02788</link>
      <description><![CDATA[arXiv:2410.02788v1 公告类型：新
摘要：光学运动捕捉 (MoCap) 是准确捕捉全身运动的“黄金标准”。为了利用原始 MoCap 点数据，系统会用相应的身体部位位置标记这些点并解决全身运动。然而，MoCap 数据通常包含错误标记、遮挡和位置错误，需要大量的手动校正。为了减轻这种负担，我们引入了 RoMo，这是一个基于学习的框架，用于稳健地标记和解决原始光学运动捕捉数据。在标记阶段，RoMo 采用分而治之的策略将复杂的全身标记挑战分解为可管理的子任务：对齐、全身分割和特定部位标记。为了利用标记的时间连续性，RoMo 使用基于 K-partite 图的聚类算法生成标记轨迹，其中标记作为节点，并根据位置和特征相似性形成边。对于运动解算，为了防止误差沿运动链累积，我们引入了一种混合逆运动解算器，该解算器利用关节位置作为中间表示并调整模板骨架以匹配估计的关节位置。我们证明了 RoMo 在多个指标和各种数据集上实现了高标记和解算精度。广泛的比较表明，我们的方法优于最先进的研究方法。在真实数据集上，RoMo 将手部标记的 F1 分数从 0.94 提高到 0.98，并将身体运动解算的关节位置误差降低了 25%。此外，RoMo 可应用于商业系统不足的场景。RoMo 的代码和数据可在 https://github.com/non-void/RoMo 获得。]]></description>
      <guid>https://arxiv.org/abs/2410.02788</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>无逻辑楼宇自动化：使用墙壁开关和天花板摄像头学习控制房间设施</title>
      <link>https://arxiv.org/abs/2410.02789</link>
      <description><![CDATA[arXiv:2410.02789v1 公告类型：新
摘要：人工智能通过学习用户对设施控制偏好的能力，实现了楼宇自动化的更智能控制。强化学习 (RL) 是实现这一目标的方法之一，但在实际实施中面临许多挑战。我们提出了一种无逻辑楼宇自动化 (LFBA) 的新架构，利用深度学习 (DL) 来控制房间设施，而无需预定义的逻辑。我们的方法与 RL 的不同之处在于它使用墙壁开关作为监督信号，并使用天花板摄像头来监控环境，从而允许 DL 模型直接从场景和开关状态中学习用户的首选控制。我们的测试平台在各种条件和用户活动中测试了该 LFBA 系统。结果证明了其有效性，使用 VGG 实现了 93%-98% 的控制精度，优于 Vision Transformer 和 ResNet 等其他 DL 模型。这表明 LFBA 可以通过从可观察的场景和用户交互中学习来实现更智能、更用户友好的控制。]]></description>
      <guid>https://arxiv.org/abs/2410.02789</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 3D 数据估算身体体积和身高</title>
      <link>https://arxiv.org/abs/2410.02800</link>
      <description><![CDATA[arXiv:2410.02800v1 公告类型：新
摘要：准确的体重估计对于急诊医学中基于体重的药物的正确剂量至关重要，但在紧急情况下直接测量往往是不切实际的。本文介绍了一种通过使用 3D 成像技术计算总体体积和身高来估计体重的非侵入性方法。使用 RealSense D415 摄像头捕捉患者的高分辨率深度图，并据此生成 3D 模型。然后应用凸包算法计算总体体积，通过将点云数据分割成多个部分并对其各自的体积求和，可以提高精度。身高是通过识别身体上关键点之间的距离从 3D 模型得出的。这种组合方法可以准确估计体重，从而提高无法获得精确体重数据的医疗干预的可靠性。所提出的方法显示出在紧急情况下提高患者安全性和治疗效果的巨大潜力。]]></description>
      <guid>https://arxiv.org/abs/2410.02800</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用检索增强方法实现缺失模态下的多模态情感识别</title>
      <link>https://arxiv.org/abs/2410.02804</link>
      <description><![CDATA[arXiv:2410.02804v1 Announce Type: new 
摘要：多模态情感识别利用完整的多模态信息和鲁棒的多模态联合表示来获得高性能。然而，全模态完整性的理想条件在现实中往往不适用，总是会出现一些模态缺失的情况。例如，由于传感器故障或网络带宽问题导致视频、音频或文本数据丢失，这对 MER 研究提出了巨大的挑战。传统方法从完整的模态中提取有用信息，并重建缺失的模态以学习鲁棒的多模态联合表示。这些方法为该领域的研究奠定了坚实的基础，并在一定程度上缓解了缺失模态下多模态情感识别的难度。然而，仅仅依靠内部重建和多模态联合学习有其局限性，尤其是当缺失信息对情感识别至关重要时。为了应对这一挑战，我们提出了一种新颖的缺失模态多模态情感识别 (RAMER) 检索增强框架，该框架引入了类似的多模态情感数据来增强缺失模态下的情感识别性能。通过利用包含相关多模态情感数据的数据库，我们可以检索类似的多模态情感信息来填补缺失模态留下的空白。各种实验结果表明，我们的框架在缺失模态 MER 任务中优于现有的最先进方法。我们的整个项目可在 https://github.com/WooyoohL/Retrieval_Augment_MER 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2410.02804</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>研究随机性对计算机视觉可重复性的影响：土木工程和医学应用研究</title>
      <link>https://arxiv.org/abs/2410.02806</link>
      <description><![CDATA[arXiv:2410.02806v1 公告类型：新
摘要：可重复性对于科学研究至关重要。然而，在计算机视觉领域，由于各种因素，获得一致的结果具有挑战性。一个有影响力但经常被忽视的因素是 CUDA 引起的随机性。尽管 CUDA 在加速 GPU 上的算法执行方面具有优势，但如果不加以控制，其在多次执行中的行为仍然是不确定的。虽然正在研究 ML 中的可重复性问题，但 CUDA 引起的随机性在应用中的影响尚待了解。我们的调查重点是隔离环境中一个标准基准数据集和两个真实数据集中的这种随机性。我们的结果表明，CUDA 引起的随机性可以解释高达 4.77% 的性能得分差异。我们发现，管理这种可重复性的可变性可能会导致运行时间增加或性能降低，但缺点并不像以前的研究报告的那样明显。]]></description>
      <guid>https://arxiv.org/abs/2410.02806</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于特定类目标移除器的任务解耦图像修复框架</title>
      <link>https://arxiv.org/abs/2410.02894</link>
      <description><![CDATA[arXiv:2410.02894v1 公告类型：新
摘要：对象移除是指在保留整体外观的同时从图像中擦除指定对象的过程。现有的关于对象移除的工作是使用图像修复网络擦除移除目标。然而，图像修复网络通常会产生不令人满意的移除结果。在这项工作中，我们发现当前的训练方法鼓励单个图像修复模型同时处理对象移除和恢复任务，这是导致这种不令人满意的结果的原因之一。基于这一发现，我们提出了一个任务解耦的图像修复框架，该框架生成两个独立的修复模型：用于对象恢复任务的对象恢复器和用于对象移除任务的对象移除器。我们使用部分覆盖移除目标的掩码来训练对象恢复器。然后，所提出的框架制作一个对象恢复器来生成训练对象移除器的指导。使用所提出的框架，我们获得了一个特定类的物体移除器，它专注于移除目标类的物体，旨在比一般的物体移除器更好地清除目标类的物体。我们还引入了一种数据管理方法，该方法包含用于为所提出的特定类物体移除器生成训练数据的图像选择和掩码生成方法。使用所提出的管理方法，我们可以模拟使用物体移除真实图像在数据上训练物体移除器的场景。在多个数据集上进行的实验表明，所提出的特定类的物体移除器比基于图像修复网络的物体移除器可以更好地移除目标类的物体。]]></description>
      <guid>https://arxiv.org/abs/2410.02894</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AirLetters：空中绘制字符的开放视频数据集</title>
      <link>https://arxiv.org/abs/2410.02921</link>
      <description><![CDATA[arXiv:2410.02921v1 公告类型：新
摘要：我们介绍了 AirLetters，这是一个新的视频数据集，由人类生成的、清晰的动作的真实世界视频组成。具体来说，我们的数据集需要一个视觉模型来预测人类在空中画出的字母。与现有的视频数据集不同，AirLetters 的准确分类预测主要依赖于辨别运动模式和随着时间的推移整合视频中的远程信息。对 AirLetters 上最先进的图像和视频理解模型的广泛评估表明，这些方法表现不佳，远远落后于人类基线。我们的工作表明，尽管最近在端到端视频理解方面取得了进展，但复杂清晰动作的准确表示（对人类来说是一项小菜一碟的任务）仍然是端到端学习的一个悬而未决的问题。]]></description>
      <guid>https://arxiv.org/abs/2410.02921</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RSA：通过语言描述解决单目深度估计器中的尺度模糊问题</title>
      <link>https://arxiv.org/abs/2410.02924</link>
      <description><![CDATA[arXiv:2410.02924v1 公告类型：新
摘要：我们提出了一种用于度量尺度单目深度估计的方法。由于在图像形成过程中透视投影的尺度损失，从单个图像推断深度是一个不适定问题。选择的任何尺度都是偏差，通常源于对数据集的训练；因此，现有工作选择使用相对（归一化、逆）深度。我们的目标是通过线性变换恢复度量尺度的深度图。我们方法的关键在于观察到某些物体（例如汽车、树木、路牌）通常会在某些类型的场景（例如户外）中找到或与之相关。我们探索是否可以使用语言描述将相对深度预测转换为度量尺度的预测。我们的方法 RSA 将描述图像中存在的对象的文本标题作为输入，并输出线性变换的参数，该参数可以全局应用于相对深度图以产生度量尺度的深度预测。我们在室内（NYUv2）和室外（KITTI）的最新通用单目深度模型上展示了我们的方法。在多个数据集上进行训练时，RSA 可以作为零样本设置中的通用对齐模块。我们的方法在相对于度量深度进行对齐方面比常见做法有所改进，并且得出的预测结果与通过线性变换将相对深度拟合到地面实况的上限相当。]]></description>
      <guid>https://arxiv.org/abs/2410.02924</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于多通道 IF 成像的全自动 CTC 检测、分割和分类</title>
      <link>https://arxiv.org/abs/2410.02988</link>
      <description><![CDATA[arXiv:2410.02988v1 公告类型：新
摘要：液体活检（例如抽血）为监测转移性乳腺癌（mBCa）的进展提供了一种侵入性较小且非局部的组织活检替代方法。免疫荧光（IF）显微镜是一种对患者样本中的数百万个血细胞进行成像和分析的工具。通过检测和基因测序血液中的循环肿瘤细胞（CTC），可以针对各种癌症亚型制定个性化治疗计划。然而，CTC 很罕见（约 2M 中 1 个），这使得手动 CTC 检测非常困难。此外，临床医生依靠定量细胞生物标志物来手动分类 CTC。这需要先完成细胞检测、分割和特征提取的任务。为了协助临床医生，我们开发了一条完全自动化的基于机器学习的生产级流程，以有效地检测、分割和分类多通道 IF 图像中的 CTC。我们对 15 名 mBCa 患者的 9,533 个细胞实现了超过 99% 的灵敏度和 97% 的特异性。我们的流程已成功部署到真正的 mBCa 患者身上，将患者平均检测到的 1400 万个细胞减少到仅 335 个 CTC 候选细胞以供人工审核。]]></description>
      <guid>https://arxiv.org/abs/2410.02988</guid>
      <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>