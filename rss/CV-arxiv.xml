<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CV 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Tue, 15 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>2024 感知测试挑战赛时间动作定位任务解决方案</title>
      <link>https://arxiv.org/abs/2410.09088</link>
      <description><![CDATA[arXiv:2410.09088v1 公告类型：新
摘要：本报告介绍了我们的时间动作定位 (TAL) 方法，该方法侧重于识别和分类整个视频序列中特定时间间隔内的动作。我们采用数据增强技术，通过使用 Something-SomethingV2 数据集中的重叠标签扩展训练数据集，增强模型在各种动作类别中推广的能力。对于特征提取，我们利用最先进的模型，包括用于视频特征的 UMT、VideoMAEv2 以及用于音频特征的 BEATs 和 CAV-MAE。我们的方法包括训练多模态（视频和音频）和单模态（仅视频）模型，然后使用加权框融合 (WBF) 方法结合它们的预测。这种融合策略可确保稳健的动作定位。我们的整体方法得分为 0.5498，在比赛中名列第一。]]></description>
      <guid>https://arxiv.org/abs/2410.09088</guid>
      <pubDate>Tue, 15 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>实现高级土地覆盖分析：使用动态世界数据集进行预测建模的集成数据提取管道</title>
      <link>https://arxiv.org/abs/2410.09135</link>
      <description><![CDATA[arXiv:2410.09135v1 公告类型：新
摘要：了解土地覆盖对无数实际应用具有巨大潜力，特别是随着数据可访问性从政府和商业实体专属转变为现在包括更广泛的研究界。尽管如此，尽管任何有兴趣探索的社区成员都可以访问数据，但存在着巨大的学习曲线，并且没有标准化的流程来访问、预处理和利用数据进行后续任务。在本研究中，我们通过提供灵活高效的端到端管道来处理动态世界数据集（一种尖端的近实时土地利用/土地覆盖 (LULC) 数据集），从而使这些数据民主化。这包括一个预处理和表示框架，该框架可解决噪声消除、大量数据的有效提取以及以适合多个下游任务的格式重新表示 LULC 数据的问题。为了展示我们管道的强大功能，我们使用它来提取城市化预测问题的数据并构建一套性能优异的机器学习模型。这项任务很容易推广到任何类型的土地覆盖的预测，并且我们的流程也与一系列其他下游任务兼容。]]></description>
      <guid>https://arxiv.org/abs/2410.09135</guid>
      <pubDate>Tue, 15 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RealEra：通过邻近概念挖掘进行语义级概念擦除</title>
      <link>https://arxiv.org/abs/2410.09140</link>
      <description><![CDATA[arXiv:2410.09140v1 公告类型：新
摘要：文本到图像生成模型的显著发展引发了显著的安全问题，例如侵犯肖像权和生成不当内容。概念擦除已被提出来删除模型关于受保护和不适当概念的知识。尽管许多方法试图平衡有效性（擦除目标概念）和特异性（保留不相关概念），但它们仍然可以在语义相关输入的引导下生成丰富的擦除概念。在本文中，我们提出了 RealEra 来解决这个“概念残留”问题。具体来说，我们首先引入邻居概念挖掘机制，通过在擦除概念的嵌入中添加随机扰动来挖掘出相关概念，从而扩大擦除范围并消除即使通过相关概念输入的生成。此外，为了减轻擦除范围扩大对不相关概念生成的负面影响，RealEra 通过超越概念的正则化保留了特异性。这使得不相关的概念保持其相应的空间位置，从而保持其正常的生成性能。我们还采用闭式解决方案来优化 U-Net 的交叉注意对齐权重以及与 LoRA 模块的预测噪声对齐。在多个基准上进行的大量实验表明，RealEra 在卓越的擦除功效、特异性和通用性方面优于以前的概念擦除方法。更多详细信息请访问我们的项目页面 https://realerasing.github.io/RealEra/ 。]]></description>
      <guid>https://arxiv.org/abs/2410.09140</guid>
      <pubDate>Tue, 15 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>面部小鸡性别鉴定：基于小鸡面部图像的自动小鸡性别鉴定系统</title>
      <link>https://arxiv.org/abs/2410.09155</link>
      <description><![CDATA[arXiv:2410.09155v1 公告类型：新
摘要：小鸡性别鉴定是确定雏鸡性别的过程，由于每个性别在生产中扮演着不同的角色，因此它是家禽业的一项关键任务。虽然有效的传统方法可以实现高精度，但颜色和翅膀羽毛的性别鉴定仅限于特定品种，而泄殖腔性别鉴定具有侵入性，需要训练有素的专家。为了应对这些挑战，我们提出了一种受人类面部性别分类技术启发的新方法：面部小鸡性别鉴定。这种新方法不需要专业知识，旨在通过最大限度地减少对小鸡的操作来减少训练时间，同时提高动物福利。我们开发了一个全面的训练和推理系统，包括数据收集、面部和关键点检测、面部对齐和分类。我们在两组图像上评估我们的模型：裁剪的全脸和裁剪的中脸，这两组图像都保留了小鸡的基本面部特征以供进一步分析。我们的实验证明了这种方法的良好可行性，最终准确率为 81.89%，可以使这种方法在未来的小鸡性别鉴定实践中具有更广泛的适用性。]]></description>
      <guid>https://arxiv.org/abs/2410.09155</guid>
      <pubDate>Tue, 15 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>跨领域小样本分类模型评估：自然图像与组织病理学图像</title>
      <link>https://arxiv.org/abs/2410.09176</link>
      <description><![CDATA[arXiv:2410.09176v1 公告类型：新
摘要：在本研究中，我们研究了不同领域（特别是自然图像和组织病理学图像）中少样本分类模型的性能。我们首先在自然图像上训练几个少样本分类模型，并评估它们在组织病理学图像上的表现。随后，我们在组织病理学图像上训练相同的模型并比较它们的性能。我们结合了四个组织病理学数据集和一个自然图像数据集，并使用一系列最先进的分类技术评估了 5 路 1 次、5 路 5 次和 5 路 10 次场景下的性能。我们的实验结果揭示了少样本分类模型在不同图像域之间的可转移性和泛化能力。我们分析了这些模型在适应新领域方面的优势和局限性，并提供了在跨领域场景中优化其性能的建议。这项研究有助于加深我们对跨不同领域图像分类背景下少样本学习的理解。]]></description>
      <guid>https://arxiv.org/abs/2410.09176</guid>
      <pubDate>Tue, 15 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>跨域分布对齐用于分割隐私未注释的 3D 医学图像</title>
      <link>https://arxiv.org/abs/2410.09210</link>
      <description><![CDATA[arXiv:2410.09210v1 公告类型：新
摘要：手动注释 3D 医学图像以进行分割任务非常繁琐且耗时。此外，数据隐私限制了众包在医学领域执行数据注释的适用性。因此，训练用于医学图像分割的深度神经网络可能具有挑战性。我们引入了一种新的无源无监督域自适应 (UDA) 方法来解决这个问题。我们的想法是基于通过基础模型估计相关源域的内部学习分布，然后生成伪标签，用于通过自我训练增强模型细化。我们证明我们的方法可以在现实世界的 3D 医学数据集上实现 SOTA 性能。]]></description>
      <guid>https://arxiv.org/abs/2410.09210</guid>
      <pubDate>Tue, 15 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过免训练适配器实现基础模型驱动的 3D 小样本类别增量学习</title>
      <link>https://arxiv.org/abs/2410.09237</link>
      <description><![CDATA[arXiv:2410.09237v1 公告类型：新
摘要：用于处理点云的深度学习的最新进展引起了人们对 3D 计算机视觉的少样本类增量学习 (FSCIL) 的关注。本文介绍了一种解决 3D 点云环境中少样本持续增量学习 (FSCIL) 问题的新方法。我们利用在点云数据上进行大量训练的基础 3D 模型。借鉴基础模型的最新改进（以其在不同任务中表现良好而闻名），我们提出了一种新颖的策略，该策略不需要额外的训练即可适应新任务。我们的方法使用双缓存系统：首先，它根据模型对预测的信心程度使用先前的测试样本以防止遗忘，其次，它包含少量新任务样本以防止过度拟合。这种动态适应可确保在不同学习任务中实现出色的性能，而无需进行大量微调。我们在 ModelNet、ShapeNet、ScanObjectNN 和 CO3D 等数据集上测试了我们的方法，结果表明它优于其他 FSCIL 方法，并证明了其有效性和多功能性。代码可在 \url{https://github.com/ahmadisahar/ACCV_FCIL3D} 上找到。]]></description>
      <guid>https://arxiv.org/abs/2410.09237</guid>
      <pubDate>Tue, 15 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>增强型卡尔曼自适应外观运动 SORT 用于地面通用多目标跟踪</title>
      <link>https://arxiv.org/abs/2410.09243</link>
      <description><![CDATA[arXiv:2410.09243v1 公告类型：新
摘要：尽管最近取得了进展，但多目标跟踪 (MOT) 仍然面临重大挑战，特别是它对先验知识和预定义类别的依赖，使跟踪不熟悉的对象变得复杂。通用多目标跟踪 (GMOT) 是一种有前途的解决方案，需要较少的先验信息。然而，现有的 GMOT 方法主要设计为 OneShot-GMOT，严重依赖初始边界框，并且经常难以应对视点、光照、遮挡和比例的变化。为了克服 MOT 和 GMOT 在跟踪具有特定通用属性的对象时固有的局限性，我们引入了 Grounded-GMOT，这是一种创新的跟踪范例，使用户能够通过自然语言描述符跟踪视频中的多个通用对象。
我们的贡献始于 G2MOT 数据集的介绍，其中包括一系列以各种通用对象为特色的视频，每个视频都附有其属性的详细文本描述。随后，我们提出了一种新颖的跟踪方法 KAM-SORT，它不仅有效地将视觉外观与运动线索相结合，还增强了卡尔曼滤波器。在 GMOT 场景中处理来自同一通用类别的高视觉相似性对象时，KAM-SORT 特别有优势。通过全面的实验，我们证明了 Grounded-GMOT 优于现有的 OneShot-GMOT 方法。此外，我们对各种跟踪器进行的广泛比较突出了 KAM-SORT 在 GMOT 中的有效性，进一步确立了其在该领域的重要性。项目页面：https://UARK-AICV.github.io/G2MOT。源代码和数据集将公开提供。]]></description>
      <guid>https://arxiv.org/abs/2410.09243</guid>
      <pubDate>Tue, 15 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过领域感知选择性自适应实现基于少量样本的通用医学图像分割</title>
      <link>https://arxiv.org/abs/2410.09254</link>
      <description><![CDATA[arXiv:2410.09254v1 公告类型：新
摘要：医学图像分割由于领域差距、数据模态变化以及对领域知识或专家的依赖而带来挑战，尤其是对于中低收入国家 (LMIC)。而对于人类来说，给定一些样本（带有相应的标签），即使没有大量特定领域的临床训练，我们也能够分割不同的医学图像。此外，当前基于 SAM 的医学分割模型在测试阶段使用细粒度的视觉提示，例如从手动注释的目标分割掩模生成的边界矩形，作为边界框 (bbox) 提示。然而，在实际的临床场景中，没有这种精确的先验知识。我们的实验结果还表明，当给出较粗的 bbox 提示时，以前的模型几乎无法预测。考虑到这些问题，在本文中，我们引入了一种领域感知选择性适应方法，将从使用自然图像训练的大型模型中学到的一般知识应用于相应的医学领域/模式，并且仅需访问少数（例如少于 5 个）样本。我们的方法缓解了上述限制，提供了一种高效且适合中低收入国家的解决方案。广泛的实验分析展示了我们方法的有效性，为中低收入国家的医疗诊断和临床应用提供了潜在的进步。]]></description>
      <guid>https://arxiv.org/abs/2410.09254</guid>
      <pubDate>Tue, 15 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SurgicalGS：动态 3D 高斯溅射，用于精确的机器人辅助手术场景重建</title>
      <link>https://arxiv.org/abs/2410.09292</link>
      <description><![CDATA[arXiv:2410.09292v1 公告类型：新
摘要：从内窥镜视频中精确地对动态手术场景进行 3D 重建对于机器人辅助手术至关重要。虽然最近的 3D 高斯 Splatting 方法在实现高质量重建和快速渲染方面表现出良好的前景，但它们使用逆深度损失函数会压缩深度变化。这可能会导致精细几何细节的丢失，限制它们捕捉精确 3D 几何图形的能力和在术中应用的有效性。为了应对这些挑战，我们提出了 SurgicalGS，这是一个动态 3D 高斯 Splatting 框架，专门为具有更高几何精度的手术场景重建而设计。我们的方法首先使用深度先验初始化高斯点云，采用二元运动掩码来识别具有显着深度变化的像素，并融合跨帧深度图中的点云进行初始化。我们使用灵活变形模型来表示动态场景，并引入归一化的深度正则化损失以及无监督的深度平滑度约束，以确保更准确的几何重建。在两个真实手术数据集上进行的大量实验表明，SurgicalGS 实现了最先进的重建质量，特别是在精确几何方面，提高了 3D Gaussian Splatting 在机器人辅助手术中的可用性。]]></description>
      <guid>https://arxiv.org/abs/2410.09292</guid>
      <pubDate>Tue, 15 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>神经影像中基于学习的配准的分层不确定性估计</title>
      <link>https://arxiv.org/abs/2410.09299</link>
      <description><![CDATA[arXiv:2410.09299v1 公告类型：新
摘要：近年来，基于深度学习的图像配准在许多领域都取得了令人印象深刻的准确性，包括医学成像，特别是使用磁共振成像 (MRI) 的人体神经成像。然而，与这些方法相关的不确定性估计在很大程度上仅限于通用技术（例如，蒙特卡洛 dropout）的应用，这些技术没有利用问题领域（特别是空间建模）的特殊性。在这里，我们提出了一种原则性的方法，将这些方法在空间位置级别估计的不确定性（认知或随机）传播到全局转换模型级别，并进一步传播到下游任务。具体来说，我们证明了选择高斯分布进行局部不确定性建模的合理性，然后提出了一个框架，其中不确定性根据转换模型的选择分布在层次结构中。在公开数据集上进行的实验表明，蒙特卡洛 dropout 与参考配准误差的相关性很差，而我们的不确定性估计相关性要好得多。 % 与参考配准误差。至关重要的是，结果还表明，不确定性感知的变换拟合提高了脑 MRI 扫描的配准精度。最后，我们说明了如何从变换的后验分布中抽样，以将不确定性传播到下游神经成像任务。代码可在以下位置获得：https://github.com/HuXiaoling/Regre4Regis。]]></description>
      <guid>https://arxiv.org/abs/2410.09299</guid>
      <pubDate>Tue, 15 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>TD-Paint：通过时间感知像素调节实现更快的扩散修复</title>
      <link>https://arxiv.org/abs/2410.09306</link>
      <description><![CDATA[arXiv:2410.09306v1 公告类型：新
摘要：扩散模型已成为一种高效的修复技术，然而，它们仍然受到缓慢采样率的限制。虽然最近的进展提高了生成质量，但也增加了采样时间，从而限制了实际应用中的可扩展性。我们研究了基于扩散的修复模型的生成采样过程，并观察到这些模型在初始采样步骤中对输入条件的使用最少。因此，采样轨迹偏离数据流形，需要复杂的同步机制来重新调整生成过程。为了解决这个问题，我们提出了时间感知扩散绘制 (TD-Paint)，这是一种通过在像素级建模可变噪声水平来调整扩散过程的新方法。这种技术允许模型从一开始就有效地使用已知的像素值，从而引导生成过程朝着目标流形发展。通过在扩散过程的早期嵌入这些信息，TD-Paint 显着加快了采样速度，而不会影响图像质量。与需要专用架构或昂贵生成循环的传统基于扩散的修复模型不同，TD-Paint 无需修改架构即可实现更快的采样时间。三个数据集的实验结果表明，TD-Paint 的表现优于最先进的扩散模型，同时保持了较低的复杂度。]]></description>
      <guid>https://arxiv.org/abs/2410.09306</guid>
      <pubDate>Tue, 15 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多模态动物姿势估计：深入分析</title>
      <link>https://arxiv.org/abs/2410.09312</link>
      <description><![CDATA[arXiv:2410.09312v1 公告类型：新
摘要：动物姿势估计 (APE) 旨在使用多种传感器和模态输入来定位动物身体部位，这对于神经科学、生物力学和兽医学的研究至关重要。通过评估自 2013 年以来的 178 篇论文，APE 方法按传感器和模态类型、学习范例、实验设置和应用领域进行分类，详细分析了单模态和多模态 APE 系统的当前趋势、挑战和未来方向。分析还强调了人类和动物姿势估计之间的转变。此外，还提供了基于不同传感器和模态的 2D 和 3D APE 数据集和评估指标。此处提供了定期更新的项目页面：https://github.com/ChennyDeng/MM-APE。]]></description>
      <guid>https://arxiv.org/abs/2410.09312</guid>
      <pubDate>Tue, 15 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用轻量级背景感知视觉转换器进行标记修剪</title>
      <link>https://arxiv.org/abs/2410.09324</link>
      <description><![CDATA[arXiv:2410.09324v1 公告类型：新 
摘要：高运行时内存和高延迟对 Vision Transformer 训练和推理造成了重大限制，尤其是在边缘设备上。令牌修剪根据每个令牌的重要性标准减少了输入 ViT 的令牌数量。我们提出了一个背景感知视觉变换器 (BAViT) 模型，这是一个对象检测模型（如 DETR/YOLOS）的预处理块，旨在通过使用一种新方法识别图像中的背景令牌来减少运行时内存并提高吞吐量。在输入到基于 ViT 的对象检测器之前，可以完全或部分修剪背景令牌。我们使用分割图和/或边界框注释提供的语义信息来训练几层 ViT，以将令牌分类为前景或背景。使用 2 层和 10 层 BAViT，可以在 VOC 数据集上以 75% 和 88% 的准确率分离背景和前景标记，在 COCO 数据集上以 71% 和 80% 的准确率分离背景和前景标记。我们展示了一个 2 层 BAViT-small 模型作为 YOLOS 的预处理器，可以在不进行任何稀疏微调的情况下将吞吐量提高 30% - 40%，而 mAP 下降 3%，在进行稀疏微调的情况下则下降 2%。我们的方法专门针对 Edge AI 用例。]]></description>
      <guid>https://arxiv.org/abs/2410.09324</guid>
      <pubDate>Tue, 15 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>自闭症领域的高级手势识别：集成 YOLOv7、视频增强和 VideoMAE 进行视频分析</title>
      <link>https://arxiv.org/abs/2410.09339</link>
      <description><![CDATA[arXiv:2410.09339v1 公告类型：新
摘要：深度学习和非接触式传感器的进步大大增强了我们理解医疗保健环境中复杂人类活动的能力。特别是，利用计算机视觉的深度学习模型已经开发出来，可以详细分析人类手势识别，尤其是自闭症儿童常见的重复性手势。这项研究工作旨在通过分析儿童在自然环境中从事日常活动时拍摄的视频来识别表明自闭症的重复性行为。重点是准确分类实时重复性手势，例如旋转、头部撞击和手臂拍打。为此，我们利用可公开访问的自我刺激行为数据集 (SSBD) 对这些刻板动作进行分类。所提出方法的一个关键组成部分是使用 \textbf{VideoMAE}，该模型旨在通过掩蔽和重建机制改进视频数据的空间和时间分析。该模型的表现明显优于传统方法，准确率达到 97.7%，比之前的最先进水平提高了 14.7%。]]></description>
      <guid>https://arxiv.org/abs/2410.09339</guid>
      <pubDate>Tue, 15 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>