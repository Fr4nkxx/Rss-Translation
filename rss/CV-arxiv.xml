<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CV 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Thu, 24 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>音频驱动的情感 3D 说话头部生成</title>
      <link>https://arxiv.org/abs/2410.17262</link>
      <description><![CDATA[arXiv:2410.17262v1 公告类型：新
摘要：音频驱动的视频肖像合成是虚拟人机交互和电影制作应用中一项重要且有用的技术。最近的进展主要集中在提高图像保真度和口型同步。然而，生成准确的情绪表达是生成逼真的说话头像的一个重要方面，这在以前的研究中仍未得到充分探索。本文提出了一种新颖的系统，用于合成具有准确情绪表达的高保真、音频驱动的视频肖像。具体来说，我们利用基于变分自动编码器 (VAE) 的音频到运动模块来生成面部标志。这些标志与情感嵌入连接在一起，通过我们的运动到情感模块产生情感标志。然后，这些情感标志被用于使用基于神经辐射场 (NeRF) 的情感到视频模块来渲染逼真的情感说话头像视频。此外，我们提出了一种姿势采样方法，该方法可以根据无声音频输入生成自然的空闲状态（非说话）视频。大量实验表明，我们的方法可以更准确地生成情绪，保真度更高。]]></description>
      <guid>https://arxiv.org/abs/2410.17262</guid>
      <pubDate>Thu, 24 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>联合脑肿瘤分割：广泛的基准</title>
      <link>https://arxiv.org/abs/2410.17265</link>
      <description><![CDATA[arXiv:2410.17265v1 公告类型：新
摘要：最近，联邦学习因其能够聚合具有隐私保护特性的多中心数据而引起了医学图像分析领域的越来越多的关注。已经发布了大量的联邦训练方案，我们将其分为全局（一个最终模型）、个性化（每个机构一个模型）或混合（每个机构集群一个模型）方法。然而，它们在最近发布的联邦脑肿瘤分割 2022 数据集上的适用性尚未被探索。我们提出了一个广泛的基准，对这个任务上所有三个类别的联邦学习算法进行基准测试。虽然标准 FedAvg 已经表现得非常好，但我们表明，每个类别中的一些方法可以带来轻微的性能改进，并可能限制最终模型对联邦主要数据分布的偏差。此外，我们通过在机构之间分发汇集的数据集的替代方法，即独立和相同的分布式（IID）设置和有限的数据设置，更深入地了解联邦学习在此任务上的行为。]]></description>
      <guid>https://arxiv.org/abs/2410.17265</guid>
      <pubDate>Thu, 24 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>连续环境下具有碰撞缓解功能的零样本视觉和语言导航</title>
      <link>https://arxiv.org/abs/2410.17267</link>
      <description><![CDATA[arXiv:2410.17267v1 公告类型：新
摘要：我们提出了零样本视觉和语言导航与碰撞缓解 (VLN-CM)，它考虑到了这些因素。VLN-CM 由四个模块组成，预测每一步下一步移动的方向和距离。我们为每个模块使用大型基础模型。为了选择方向，我们使用注意力点预测器 (ASP)、视图选择器 (VS) 和进度监视器 (PM)。ASP 采用大型语言模型 (例如 ChatGPT) 将导航指令拆分为注意力点，即移动到位置的对象或场景 (例如黄色门)。VS 使用 CLIP 相似性从以 30 度为间隔提供的全景图像中选择包含注意力点的图像。然后，我们选择所选图像的角度作为移动的方向。PM 使用基于规则的方法来决定在从指令中得出的多个点中下一个要关注的注意力点。如果当前关注点与视觉观察之间的相似性在每个步骤中连续下降，则 PM 确定代理已通过当前点并继续移动到下一个点。为了选择移动距离，我们使用了开放地图预测器 (OMP)。OMP 使用全景深度信息来预测占用掩码。然后，我们根据占用掩码在预测方向上选择无碰撞距离。我们使用 VLN-CE 的验证数据评估了我们的方法。我们的方法比几种基线方法表现出更好的性能，并且 OPM 可以有效地减轻代理的碰撞。]]></description>
      <guid>https://arxiv.org/abs/2410.17267</guid>
      <pubDate>Thu, 24 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用人工视觉实现金枪鱼罐头生产的自动化质量控制系统</title>
      <link>https://arxiv.org/abs/2410.17275</link>
      <description><![CDATA[arXiv:2410.17275v1 公告类型：新
摘要：这篇科学文章介绍了一种使用人工视觉检测和分类金枪鱼金属罐头缺陷的自动控制系统的实现。该系统利用传送带和摄像头进行光电传感器触发的视觉识别。机械臂根据金属罐的状况对其进行分类。通过使用 Mosquitto、Node-RED、InfluxDB 和 Grafana 的物联网系统实现工业 4.0 集成。YOLOv5 模型用于检测金属罐盖中的缺陷和易开环的定位。在 Google Colab 上使用 GPU 进行训练可以实现标签上的 OCR 文本检测。结果表明，可以高效实时地识别问题、优化资源并交付优质产品。同时，视觉系统有助于实现质量控制任务的自主性，使操作员可以自由地在公司内执行其他职能。]]></description>
      <guid>https://arxiv.org/abs/2410.17275</guid>
      <pubDate>Thu, 24 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于集合的文本到图像生成的离线评估</title>
      <link>https://arxiv.org/abs/2410.17331</link>
      <description><![CDATA[arXiv:2410.17331v1 公告类型：新
摘要：文本转图像 (TTI) 系统通常在创意过程中为人们提供支持，在创意过程的早期阶段，接触大量相关图像可以帮助探索设计空间。由于创意是 TTI 任务的一个重要子类，因此了解如何根据 TTI 系统对创意的支持程度对其进行定量评估对于促进这些用户的研究和开发至关重要。然而，现有的 TTI 评估指标仍然集中在分布相似性指标上，如 Fr\&#39;echet 初始距离 (FID)。我们采取了另一种方法，并基于排名评估的既定方法，开发了 TTI 评估指标，其中包含用户如何浏览和与空间排列的生成图像集交互的明确模型。我们为 TTI 提出的离线评估指标不仅可以捕捉生成的图像与用户创意需求的相关性，还可以考虑生成图像集的多样性和排列。我们利用人类研究对三种不同 TTI 系统生成的图像网格进行分析，这些系统基于广泛使用的基准的子集（例如 MS-COCO 字幕和本地化叙述以及自然环境中使用的提示），分析了我们提出的 TTI 指标系列。我们的结果表明，根据人们如何使用系统来制定指标是基准设计中一个重要且研究不足的领域。]]></description>
      <guid>https://arxiv.org/abs/2410.17331</guid>
      <pubDate>Thu, 24 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>对生成的医疗报告进行图像感知评估</title>
      <link>https://arxiv.org/abs/2410.17357</link>
      <description><![CDATA[arXiv:2410.17357v1 公告类型：新
摘要：本文提出了一种新的评估指标，用于从 X 射线图像自动生成医疗报告，VLScore。它旨在克服现有评估方法的局限性，这些方法要么只关注文本相似性，忽略临床方面，要么只关注单一临床方面，即病理学，而忽略所有其他因素。我们度量的关键思想是在考虑相应图像的同时测量放射学报告之间的相似性。我们通过对数据集的评估证明了我们度量的好处，其中放射科医生在报告中标记了错误，显示出与放射科医生的判断明显一致。此外，我们提供了一个用于评估指标的新数据集。该数据集包括精心设计的扰动，可区分重大修改（例如，删除诊断）和不重要的修改。它突出了当前评估指标的弱点，并提供了一个清晰的分析框架。]]></description>
      <guid>https://arxiv.org/abs/2410.17357</guid>
      <pubDate>Thu, 24 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Denoise-I2W：将图像映射到去噪词，实现准确的零样本合成图像检索</title>
      <link>https://arxiv.org/abs/2410.17393</link>
      <description><![CDATA[arXiv:2410.17393v1 公告类型：新
摘要：零样本合成图像检索 (ZS-CIR) 支持各种任务，具有广泛的视觉内容操作意图，可与域、场景、对象和属性相关。ZS-CIR 的一个关键挑战是准确地将图像表示映射到伪词标记，该伪词标记可捕获广义 CIR 的操作意图相关图像信息。然而，检索和预训练阶段之间的现有方法导致伪词标记中存在大量冗余。在本文中，我们提出了一种新颖的去噪图像到词映射方法，称为 Denoise-I2W，用于将图像映射到去噪伪词标记，这些标记没有与意图无关的视觉信息，可增强准确的 ZS-CIR。具体而言，伪三元组构造模块首先自动构造伪三元组（\textit{即}伪参考图像、伪操作文本和目标图像）以预训练去噪映射网络。然后，伪组合映射模块将伪参考图像映射到伪单词标记，并将其与具有操作意图的伪操作文本相结合。此组合与目标图像对齐，有助于去噪与意图无关的视觉信息以进行映射。我们提出的 Denoise-I2W 是一种与模型无关且无需注释的方法。它在四个基准数据集上的三个最先进的 ZS-CIR 模型中展示了强大的泛化能力。通过将 Denoise-I2W 与现有的最佳模型相结合，我们在不增加推理成本的情况下获得了与最佳方法相比从 1.45\% 到 4.17\% 的一致且显着的性能提升。并在 ZS-CIR 上取得了新的最先进的结果。我们的代码可以在 \url{https://github.com/Pter61/denoise-i2w-tmm} 找到。]]></description>
      <guid>https://arxiv.org/abs/2410.17393</guid>
      <pubDate>Thu, 24 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SigCLR：视觉表征的 S 形对比学习</title>
      <link>https://arxiv.org/abs/2410.17427</link>
      <description><![CDATA[arXiv:2410.17427v1 公告类型：新
摘要：我们提出了 SigCLR：视觉表征的 Sigmoid 对比学习。SigCLR 利用仅对成对进行操作的逻辑损失，而不需要像 SimCLR 中使用的交叉熵损失那样具有全局视图。我们表明，与其他已建立的 SSL 目标相比，逻辑损失在 CIFAR-10、CIFAR-100 和 Tiny-IN 上表现出了竞争力。我们的研究结果验证了可学习偏差的重要性，就像 SigLUP 的情况一样，但它需要像 SimCLR 中那样的固定温度才能出类拔萃。总体而言，SigCLR 是 SimCLR 的一个有前途的替代品，SimCLR 无处不在，并在各个领域取得了巨大的成功。]]></description>
      <guid>https://arxiv.org/abs/2410.17427</guid>
      <pubDate>Thu, 24 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LongVU：用于长视频语言理解的时空自适应压缩</title>
      <link>https://arxiv.org/abs/2410.17434</link>
      <description><![CDATA[arXiv:2410.17434v1 公告类型：新
摘要：多模态大型语言模型 (MLLM) 在理解和分析视频内容方面取得了令人鼓舞的进展。然而，由于 LLM 的上下文大小限制，处理长视频仍然是一项重大挑战。为了解决这一限制，我们提出了 LongVU，这是一种时空自适应压缩机制，可减少视频标记的数量，同时保留长视频的视觉细节。我们的想法是基于利用跨模态查询和帧间依赖性来自适应地减少视频中的时间和空间冗余。具体来说，我们利用 DINOv2 特征来删除表现出高相似性的冗余帧。然后，我们利用文本引导的跨模态查询来选择性地减少帧特征。此外，我们根据帧的时间依赖性跨帧执行空间标记减少。我们的自适应压缩策略有效地处理了大量的帧，在给定的上下文长度内几乎没有视觉信息丢失。我们的 LongVU 在各种视频理解基准上始终超越现有方法，尤其是在长达一小时的视频理解任务（如 VideoMME 和 MLVU）上。鉴于轻量级的 LLM，我们的 LongVU 还可以有效地扩展到更小的尺寸，并具有最先进的视频理解性能。]]></description>
      <guid>https://arxiv.org/abs/2410.17434</guid>
      <pubDate>Thu, 24 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>哪个客户端是可靠的？：基于可靠和个性化提示的医学图像问答联邦学习</title>
      <link>https://arxiv.org/abs/2410.17484</link>
      <description><![CDATA[arXiv:2410.17484v1 公告类型：新
摘要：传统的医学人工智能 (AI) 模型由于无法处理医疗数据的隐私敏感特性而面临临床应用障碍和伦理问题。我们提出了一种用于医学视觉问答 (VQA) 模型的新型个性化联邦学习 (pFL) 方法，解决了医学领域的隐私可靠性挑战。我们的方法将可学习的提示引入 Transformer 架构，以便在没有大量计算成本的情况下有效地在不同的医学数据集上对其进行训练。然后，我们引入了一个可靠的客户端 VQA 模型，该模型结合了 Dempster-Shafer 证据理论来量化预测中的不确定性，从而提高了模型的可靠性。此外，我们提出了一种新颖的客户端间通信机制，该机制使用最大似然估计来平衡准确性和不确定性，促进客户端之间见解的有效整合。]]></description>
      <guid>https://arxiv.org/abs/2410.17484</guid>
      <pubDate>Thu, 24 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过自组装和条件嵌入对齐实现动作识别的无监督领域自适应</title>
      <link>https://arxiv.org/abs/2410.17489</link>
      <description><![CDATA[arXiv:2410.17489v1 公告类型：新
摘要：基于深度学习的可穿戴人体动作识别 (wHAR) 的最新进展改进了复杂动作的捕获和分类，但由于缺乏专家注释和用户变化的领域差异，采用仍然有限。有限的注释阻碍了模型推广到分布外样本的能力。虽然数据增强可以提高普遍性，但必须谨慎应用无监督增强技术以避免引入噪音。无监督域自适应 (UDA) 通过将条件分布与标记的目标样本对齐来解决域差异，但普通伪标记会导致错误传播。为了应对这些挑战，我们提出了 $\mu$DAR，这是一种新颖的联合优化架构，由三个函数组成：(i) 增强样本之间的一致性正则化器以提高模型分类的普遍性，(ii) 用于稳健伪标签生成的时间集成和 (iii) 条件分布对齐以提高域普遍性。时间集成通过聚合过去时期的预测来平滑嘈杂的伪标签预测，然后在条件分布对齐模块中使用这些预测来最小化源和目标特征空间之间基于核的类条件最大均值差异 ($k$CMMD)，以学习域不变嵌入。一致性正则化的增强确保同一样本的多个增强共享相同的标签；这导致 (a) 使用有限的源域样本实现强大的泛化和 (b) 在目标样本中生成一致的伪标签。这三个模块在 $\mu$DAR 中的新颖集成导致在四个基准 wHAR 数据集中，与六种最先进的 UDA 方法相比，平均宏 F1 分数提高了 $\approx$ 4-12%]]></description>
      <guid>https://arxiv.org/abs/2410.17489</guid>
      <pubDate>Thu, 24 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>PLGS：基于 3D 高斯分层的稳健全景提升</title>
      <link>https://arxiv.org/abs/2410.17505</link>
      <description><![CDATA[arXiv:2410.17505v1 公告类型：新 
摘要：以前的方法利用神经辐射场 (NeRF) 进行全景提升，但其训练和渲染速度不令人满意。相比之下，3D 高斯分层 (3DGS) 因其快速的训练和渲染速度而成为一种突出的技术。然而，与 NeRF 不同，传统的 3DGS 可能不满足基本的平滑度假设，因为它不依赖于任何参数化结构来渲染（例如 MLP）。因此，传统的 3DGS 本质上更容易受到嘈杂的 2D 掩模监督的影响。在本文中，我们提出了一种称为 PLGS 的新方法，该方法使 3DGS 能够从嘈杂的 2D 分割掩模中生成一致的全景分割掩模，同时保持与基于 NeRF 的方法相比更高的效率。具体而言，我们构建了一个全景感知的结构化 3D 高斯模型来引入平滑度并设计有效的降噪策略。对于语义场，我们不是使用运动结构进行初始化，而是构建可靠的语义锚点来初始化 3D 高斯。然后，我们在训练期间使用这些锚点作为平滑正则化。此外，我们提出了一种自训练方法，使用通过将渲染的蒙版与噪声蒙版合并而生成的伪标签来增强 PLGS 的鲁棒性。对于实例场，我们将 2D 实例蒙版投影到 3D 空间中，并将它们与有向边界框匹配，以生成用于监督的跨视图一致实例蒙版。在各种基准上的实验表明，我们的方法在分割质量和速度方面都优于以前的最先进方法。]]></description>
      <guid>https://arxiv.org/abs/2410.17505</guid>
      <pubDate>Thu, 24 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>HCDN：使用特征融合和大型视觉模型的建筑内务管理变化检测网络</title>
      <link>https://arxiv.org/abs/2410.17513</link>
      <description><![CDATA[arXiv:2410.17513v1 公告类型：新
摘要：随着全球数百万工人遭受与工作相关的事故，工作场所安全受到越来越多的关注。尽管糟糕的管理是造成建筑事故的重要因素，但仍然缺乏专注于改善建筑工地管理实践的技术研究。识别和定位动态建筑工地中的糟糕管理是一项重要任务，可以通过计算机视觉方法进行改进。尽管人工智能和计算机视觉取得了进步，但现有的检测糟糕管理条件的方法面临许多挑战，包括有限的解释、缺乏糟糕的管理定位以及缺乏注释数据集。另一方面，变化检测旨在检测变化的环境条件（例如，从良好的管理变为糟糕的管理）和变化发生的“位置”（例如，导致糟糕管理的物体的位置），尚未被探索用于管理问题。为了应对这些挑战，我们提出了 Housekeeping 变化检测网络 (HCDN)，这是一种先进的变化检测神经网络，集成了特征融合模块和大型视觉模型，实现了最先进的性能。此外，我们还介绍了一种建立新型变化检测数据集（名为 Housekeeping-CCD）的方法，该数据集专注于建筑工地的内务管理，以及内务管理分割数据集。与现有方法相比，我们的贡献包括显着的性能改进，为增强建筑内务管理和安全性提供了有效的工具。为了促进进一步发展，我们与全球研究人员分享了我们的源代码和训练模型：https://github.com/NUS-DBE/Housekeeping-CD。]]></description>
      <guid>https://arxiv.org/abs/2410.17513</guid>
      <pubDate>Thu, 24 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>PathMoCo：一种改进组织病理学图像自监督对比学习中特征嵌入的新框架</title>
      <link>https://arxiv.org/abs/2410.17514</link>
      <description><![CDATA[arXiv:2410.17514v1 公告类型：新
摘要：自监督对比学习已成为各个领域的基石，尤其是组织病理学图像分析。图像增强在自监督对比学习中起着至关重要的作用，因为它会在图像样本中产生变化。然而，传统的图像增强技术往往忽视了组织病理学图像的独特特征。在本文中，我们提出了一种新的组织病理学专用图像增强方法，称为染色重建增强 (SRA)。我们将我们的 SRA 与自监督对比学习中的领先模型 MoCo v3 以及我们的附加对比损失项相结合，并将新模型称为 PathMoCo。我们证明我们的 PathMoCo 在各种下游任务中始终优于标准 MoCo v3，并且与在明显更大的组织病理学数据集上预训练的其他基础模型相比，其性能相当或更优越。]]></description>
      <guid>https://arxiv.org/abs/2410.17514</guid>
      <pubDate>Thu, 24 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>变分似然估计和图像去噪的扩散先验</title>
      <link>https://arxiv.org/abs/2410.17521</link>
      <description><![CDATA[arXiv:2410.17521v1 公告类型：新
摘要：现实世界的噪声消除在低级计算机视觉中至关重要。由于扩散模型具有出色的生成能力，最近的注意力转向利用扩散先验进行图像恢复任务。然而，现有的基于扩散先验的方法要么考虑简单的噪声类型，要么依赖于近似后验估计，限制了它们在处理现实世界图像中常见的结构化和信号相关噪声方面的有效性。在本文中，我们基于扩散先验，并在逆扩散过程中提出自适应似然估计和 MAP 推理来解决现实世界的噪声。我们引入一个独立的、非相同分布的似然与噪声精度（逆方差）先验相结合，并在生成过程中使用变分贝叶斯动态推断精度后验。同时，我们通过局部高斯卷积校正估计的噪声方差。通过传播平衡更新的似然和扩散先验的中间 MAP 解来获得最终的去噪图像。此外，我们探索了低分辨率扩散模型中固有的局部扩散先验，从而可以直接处理高分辨率噪声图像。对各种真实世界数据集的大量实验和分析证明了我们方法的有效性。代码可在 https://github.com/HUST-Tan/DiffusionVI 上找到。]]></description>
      <guid>https://arxiv.org/abs/2410.17521</guid>
      <pubDate>Thu, 24 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>