<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CV 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Mon, 18 Nov 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>面向视觉的神经基础模型：协调 EEG、MEG 和 fMRI 表征以进行解码、编码和模态转换</title>
      <link>https://arxiv.org/abs/2411.09723</link>
      <description><![CDATA[arXiv:2411.09723v1 公告类型：新
摘要：本文介绍了一种新方法，通过利用对比学习来创建基础模型，以在大脑活动的多模态表示中对齐神经数据和视觉刺激。我们使用了脑电图 (EEG)、脑磁图 (MEG) 和功能性磁共振成像 (fMRI) 数据。我们的框架功能通过三个关键实验得到展示：从神经数据中解码视觉信息、将图像编码为神经表征以及在神经模态之间进行转换。结果突出了该模型能够跨不同的大脑成像技术准确捕获语义信息的能力，说明了其在解码、编码和模态转换任务中的潜力。]]></description>
      <guid>https://arxiv.org/abs/2411.09723</guid>
      <pubDate>Mon, 18 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过元学习和对比特征对齐实现部分多视图聚类</title>
      <link>https://arxiv.org/abs/2411.09758</link>
      <description><![CDATA[arXiv:2411.09758v1 公告类型：新
摘要：部分多视图聚类 (PVC) 对实际应用中的数据分析提出了重大挑战，尤其是当数据的某些视图部分缺失时。现有的聚类方法难以有效处理不完整的视图，导致聚类性能不佳。在本文中，我们提出了一种基于对比学习的新型双重优化框架，旨在最大化不完整多视图数据中潜在特征的一致性，并通过深度学习模型提高聚类性能。通过结合微调的 Vision Transformer 和 k-最近邻 (KNN)，我们填充缺失的视图并使用自监督学习和元学习动态调整视图权重。实验结果表明，我们的框架在 BDGP 和 HW 数据集上的表现优于最先进的聚类模型，特别是在处理复杂和不完整的多视图数据时。]]></description>
      <guid>https://arxiv.org/abs/2411.09758</guid>
      <pubDate>Mon, 18 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>NACNet：一种用于预测三阴性乳腺癌新辅助化疗治疗反应的组织学上下文感知变换器图卷积网络</title>
      <link>https://arxiv.org/abs/2411.09766</link>
      <description><![CDATA[arXiv:2411.09766v1 公告类型：新
摘要：三阴性乳腺癌 (TNBC) 患者的新辅助化疗 (NAC) 反应预测在临床上是一项具有挑战性的任务，因为它需要了解肿瘤微环境 (TME) 内复杂的组织学相互作用。数字全幻灯片图像 (WSI) 捕获详细的组织信息，但它们的千兆像素大小需要基于多实例学习的计算方法，这些方法通常分析没有 TME 空间背景的小而孤立的图像块。为了解决这一限制并将 TME 空间组织学相互作用纳入预测 TNBC 患者的 NAC 反应，我们开发了一种组织学上下文感知变压器图卷积网络 (NACNet)。我们的深度学习方法从 WSI 中识别单个图像块上的组织病理学标签，构建空间 TME 图，并使用来自组织纹理和社交网络分析的特征表示每个节点。它使用增强了图同构网络层的变压器图卷积网络模型来预测 NAC 响应。我们利用一组 TNBC 患者（N=105）的 WSI 评估了我们的方法，并将其性能与多种最先进的机器学习和深度学习模型（包括图形和非图形方法）进行了比较。我们的 NACNet 通过八倍交叉验证实现了 90.0% 的准确度、96.0% 的灵敏度、88.0% 的特异性和 0.82 的 AUC，优于基线模型。这些全面的实验结果表明，NACNet 具有根据 NAC 反应对 TNBC 患者进行分层的强大潜力，从而有助于防止过度治疗、改善患者生活质量、降低治疗成本并改善临床结果，标志着个性化乳腺癌治疗的重要进步。]]></description>
      <guid>https://arxiv.org/abs/2411.09766</guid>
      <pubDate>Mon, 18 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>荧光引导手术中的视频去噪</title>
      <link>https://arxiv.org/abs/2411.09798</link>
      <description><![CDATA[arXiv:2411.09798v1 公告类型：新
摘要：荧光引导手术 (FGS) 是一种很有前途的手术技术，它为外科医生提供了独特的组织视图，通过描绘组织类型和患病区域来指导他们的实践。随着具有低荧光光子产量的新型荧光造影剂的开发，开发计算模型以允许 FGS 系统在实时环境中保持良好的视频质量变得越来越重要。为了进一步复杂化这项任务，FGS 有一个来自激光泄漏光 (LLL) 的困难偏置噪声项，它代表未过滤的激发光，其数量级可以与荧光信号相当。大多数传统的视频去噪方法侧重于零均值噪声和非因果处理，而这两者都在 FGS 中被违反。幸运的是，在 FGS 中，通常还会捕获一个共置参考视频，我们使用它来模拟 LLL 并协助去噪过程。在这项工作中，我们提出了一种包含 LLL 的精确噪声模拟流程，并提出了三种基于基线深度学习的 FGS 视频去噪算法。]]></description>
      <guid>https://arxiv.org/abs/2411.09798</guid>
      <pubDate>Mon, 18 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多模式中风风险预测的自监督模型</title>
      <link>https://arxiv.org/abs/2411.09822</link>
      <description><![CDATA[arXiv:2411.09822v1 公告类型：新
摘要：预测中风风险是一项复杂的挑战，可以通过整合各种临床可用的数据模式来增强。本研究引入了一个自监督的多模态框架，该框架结合了 3D 脑成像、临床数据和图像衍生特征，以改善发病前的中风风险预测。通过利用大量未注释的临床数据集，该框架可以捕获图像和表格数据模式之间的互补和协同信息。我们的方法基于对比学习框架，该框架将对比语言图像预训练与图像表格匹配模块结合在一起，以更好地在共享潜在空间中对齐多模态数据表示。该模型在英国生物库上进行训练，其中包括结构性脑 MRI 和临床数据。我们在不同的冻结和可训练模型设置下，使用表格、图像和图像表格组合将其性能与最先进的单模态和多模态方法进行基准测试。与自监督表格（图像）方法相比，所提出的模型在 ROC-AUC 方面表现优于 2.6%（2.6%），在平衡准确度方面表现优于 3.3%（5.6%）。此外，与最佳多模态监督模型相比，其平衡准确度提高了 7.6%。通过可解释的工具，我们的方法展示了表格和图像数据的更好集成，提供了更丰富、更一致的嵌入。梯度加权类激活映射热图进一步揭示了文献中通常与大脑老化、中风风险和临床结果相关的激活大脑区域。这种强大的自监督多模态框架超越了最先进的中风风险预测方法，并为未来整合多种数据模式以推进临床预测模型的研究奠定了坚实的基础。]]></description>
      <guid>https://arxiv.org/abs/2411.09822</guid>
      <pubDate>Mon, 18 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>建筑师：利用分层 2D 修复技术生成生动且可交互的 3D 场景</title>
      <link>https://arxiv.org/abs/2411.09823</link>
      <description><![CDATA[arXiv:2411.09823v1 公告类型：新
摘要：创建大规模交互式 3D 环境对于机器人和具身 AI 研究的发展至关重要。当前的方法包括手动设计、程序生成、基于扩散的场景生成和大型语言模型 (LLM) 引导的场景设计，受到过多人力、依赖预定义规则或训练数据集以及有限的 3D 空间推理能力等限制。由于预训练的 2D 图像生成模型比 LLM 更好地捕捉场景和对象配置，我们通过引入 Architect 来解决这些挑战，Architect 是一个生成框架，它利用基于扩散的 2D 图像修复创建复杂而逼真的 3D 具身环境。具体来说，我们利用基础视觉感知模型从图像中获取每个生成的对象，并利用预训练的深度估计模型将生成的 2D 图像提升到 3D 空间。我们的流程进一步扩展为分层和迭代修复过程，以不断生成大型家具和小物体的布局，从而丰富场景。这种迭代结构为我们的方法带来了灵活性，可以从各种起点（例如文本、平面图或预先安排的环境）生成或优化场景。]]></description>
      <guid>https://arxiv.org/abs/2411.09823</guid>
      <pubDate>Mon, 18 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过整合精心设计的测量来增强逆问题的扩散后验采样</title>
      <link>https://arxiv.org/abs/2411.09850</link>
      <description><![CDATA[arXiv:2411.09850v1 公告类型：新
摘要：扩散模型已成为视觉生成的强大基础模型。通过适当的采样过程，它可以有效地作为解决一般逆问题的生成先验。当前基于后验采样的方法将测量值（即退化的图像样本）带入后验采样以推断目标数据（即干净的图像样本）的分布。然而，通过这种方式，我们表明高频信息可以在早期阶段过早引入，这可能会在恢复采样期间引起更大的后验估计误差。为了解决这个问题，我们首先揭示了用噪声测量值（即来自扩散前向过程的样本）而不是干净的测量值形成对数后验梯度可以有利于逆过程。因此，我们提出了一种新颖的扩散后验采样方法 DPS-CM，该方法结合了 Crafted 测量（即通过逆向去噪过程生成的样本，而不是标准方法中的随机采样和噪声）来形成后验估计。这种整合旨在减轻累积后验估计误差导致的与扩散先验不一致。实验结果表明，与现有方法相比，我们的方法显著提高了解决一般和嘈杂逆问题的整体能力，例如高斯去模糊、超分辨率、修复、非线性去模糊和泊松噪声任务。]]></description>
      <guid>https://arxiv.org/abs/2411.09850</guid>
      <pubDate>Mon, 18 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>蒙版图像对比学习助力高效视觉概念预训练</title>
      <link>https://arxiv.org/abs/2411.09858</link>
      <description><![CDATA[arXiv:2411.09858v1 公告类型：新
摘要：本文提出了一种可扩展且直接的预训练范式，用于高效的视觉概念表示，称为掩蔽图像对比学习 (MiCL)。我们的 MiCL 方法很简单：我们随机掩蔽补丁以在图像中生成不同的视图，并在小批量图像之间进行对比。MiCL 背后的核心思想包括两种设计。首先，掩蔽标记有可能显著减少图像中固有的概念冗余，并在语义概念级别而不是实例级别创建具有大量细粒度差异的不同视图。其次，对比学习擅长在预训练期间提取高级语义概念特征，从而避免高频干扰和与图像重建相关的额外成本。重要的是，MiCL 可以有效地学习高度语义的概念表示，而无需依赖手工制作的数据增强或额外的辅助模块。从经验上看，MiCL 通过 Vision Transformers 展示了高度的可扩展性，因为 ViT-L/16 仅使用 4 个 A100 GPU 即可在 133 小时内完成预训练，并在下游微调任务中实现 85.8% 的准确率。]]></description>
      <guid>https://arxiv.org/abs/2411.09858</guid>
      <pubDate>Mon, 18 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>人脸去识别：最新方法与比较研究</title>
      <link>https://arxiv.org/abs/2411.09863</link>
      <description><![CDATA[arXiv:2411.09863v1 公告类型：新 
摘要：图像采集技术的广泛使用以及面部识别技术的进步引发了严重的隐私问题。人脸去识别通常是指隐藏或替换个人身份信息的过程，被认为是保护人脸图像隐私的有效手段。近年来，提出了大量人脸去识别方法。在这篇调查中，我们全面回顾了最先进的人脸去识别方法，分为三个层次：像素级、表示级和语义级技术。我们根据两个关键标准，即隐私保护的有效性和图像效用的保存，系统地评估这些方法，突出它们的优点和局限性。我们的分析包括对主要算法的定性和定量比较，表明基于深度学习的方法，特别是使用生成对抗网络 (GAN) 和扩散模型的方法，在平衡隐私和效用方面取得了重大进展。实验结果表明，虽然最近的方法表现出强大的隐私保护能力，但在视觉保真度和计算复杂度方面仍然存在权衡。本综述不仅总结了当前的情况，还确定了人脸去识别方面的关键挑战和未来的研究方向。]]></description>
      <guid>https://arxiv.org/abs/2411.09863</guid>
      <pubDate>Mon, 18 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>内容感知保留图像生成</title>
      <link>https://arxiv.org/abs/2411.09871</link>
      <description><![CDATA[arXiv:2411.09871v1 公告类型：新
摘要：随着生成模型的引入，图像生成取得了显著进展。然而，由于生成图像的基本训练目标，精确控制生成图像中的内容仍然是一项具有挑战性的任务。本文通过提出一种新颖的图像生成框架来解决这一挑战，该框架明确设计用于将所需内容合并到输出图像中。该框架采用先进的编码技术，集成了称为内容融合和频率编码模块的子网络。频率编码模块首先通过专注于选定的频率分量来捕获参考图像的特征和结构。随后，内容融合模块生成一个封装所需内容特征的内容引导向量。在图像生成过程中，来自真实图像的内容引导向量与投影噪声向量融合。这确保生成的图像不仅保持与引导图像一致的内容，而且还表现出多样的风格变化。为了验证所提出的框架在保留内容属性方面的有效性，在广泛使用的基准数据集上进行了大量实验，包括 Flickr-Faces-High Quality、Animal Faces High Quality 和 Large-scale Scene Understanding 数据集。]]></description>
      <guid>https://arxiv.org/abs/2411.09871</guid>
      <pubDate>Mon, 18 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于视觉导航的记忆代理地图</title>
      <link>https://arxiv.org/abs/2411.09893</link>
      <description><![CDATA[arXiv:2411.09893v1 公告类型：新
摘要：视觉导航的灵感来自人类，人类使用视觉在以前未见过的环境中导航，而无需详细的环境地图。受此启发，我们引入了一种新颖的无强化学习、无图形、无里程计的视觉导航方法，使用封建学习来构建三层代理。我们方法的关键是记忆代理图 (MPM)，这是高级管理代理以自我监督的方式学习的环境的中间表示，它充当简化的记忆，近似于代理所见的内容。我们证明，在这个学习到的潜在空间中记录观察结果是一种有效且高效的记忆代理，可以消除视觉导航任务中对图形和里程计的需求。对于中级管理代理，我们开发了一个航点网络 (WayNet)，它输出中间子目标或航点，模仿人类在本地导航过程中的航点选择。对于低级工作代理，我们在离散动作空间上学习分类器，以避开局部障碍物并将代理移向 WayNet 航点。由此产生的封建导航网络提供了一种新颖的方法，无需 RL、无需图形、无需里程计、无需度量地图；同时在图像目标导航任务上实现 SOTA 结果。]]></description>
      <guid>https://arxiv.org/abs/2411.09893</guid>
      <pubDate>Mon, 18 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>病理学基础模型中的免费午餐：通过概念引导的特征增强实现任务特定的模型自适应</title>
      <link>https://arxiv.org/abs/2411.09894</link>
      <description><![CDATA[arXiv:2411.09894v1 公告类型：新
摘要：全幻灯片图像 (WSI) 分析在医学成像领域越来越受到重视。病理基础模型的最新进展表明，从 WSI 中提取强大的特征表示可用于下游任务。然而，这些基础模型通常是为通用病理图像分析而设计的，可能不适合特定的下游任务或癌症类型。在这项工作中，我们提出了概念锚引导的任务特定特征增强 (CATE)，这是一种适应性范式，可以提高病理基础模型对特定下游任务的表现力和辨别力。基于一组从病理视觉语言模型中衍生的具有专家设计提示的任务特定概念，我们引入了两个相互连接的模块来动态校准基础模型为某些任务或癌症类型提取的通用图像特征。具体来说，我们设计了一个概念引导信息瓶颈模块，通过最大化图像特征和概念锚之间的互信息同时抑制多余信息来增强与任务相关的特征。此外，提出了一个概念特征干扰模块，利用校准特征和概念锚之间的相似性进一步生成有判别力的任务特定特征。在公共 WSI 数据集上进行的大量实验表明，CATE 显著提高了 MIL 模型的性能和通用性。此外，热图和 umap 可视化结果也揭示了 CATE 的有效性和可解释性。源代码可在 https://github.com/HKU-MedAI/CATE 获得。]]></description>
      <guid>https://arxiv.org/abs/2411.09894</guid>
      <pubDate>Mon, 18 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DiffFNO：扩散傅里叶神经算子</title>
      <link>https://arxiv.org/abs/2411.09911</link>
      <description><![CDATA[arXiv:2411.09911v1 公告类型：新
摘要：我们引入了 DiffFNO，这是一种用于任意尺度超分辨率的新型扩散框架，由加权傅立叶神经算子 (WFNO) 增强。WFNO 中的模式重新平衡可有效捕获关键频率分量，显著改善对超分辨率任务至关重要的高频图像细节的重建。门控融合机制 (GFM) 自适应地将 WFNO 的光谱特征与基于注意力的神经算子 (AttnNO) 的空间特征互补。这增强了网络捕获全局结构和局部细节的能力。自适应时间步长 (ATS) ODE 求解器是一种确定性采样策略，通过动态调整积分步长 ATS 来加速推理，而不会牺牲输出质量。大量实验表明，DiffFNO 取得了最先进的 (SOTA) 结果，在各种缩放因子中，PSNR 比现有方法高出 2 到 4 dB，包括训练分布之外的 PSNR。它还在较短的推理时间内实现了这一目标。我们的方法在超分辨率方面树立了新标准，提供了卓越的准确性和计算效率。]]></description>
      <guid>https://arxiv.org/abs/2411.09911</guid>
      <pubDate>Mon, 18 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于运动的视频推理：在像素级别理解和感知运动</title>
      <link>https://arxiv.org/abs/2411.09921</link>
      <description><![CDATA[arXiv:2411.09921v1 公告类型：新
摘要：在本文中，我们介绍了基于运动的视频推理，这是一项新的运动理解任务，需要根据输入问题生成视觉答案（视频分割掩码），因此需要隐式时空推理和基础。此任务通过问题实现隐式推理，将现有的专注于显式动作/运动基础的时空基础工作扩展到更通用的格式。为了促进新任务的开发，我们收集了一个名为 GROUNDMORE 的大型数据集，其中包含 1,715 个视频剪辑、249K 个对象掩码，这些掩码是专门为 4 种问题类型（因果、顺序、反事实和描述性）设计的，用于对深度和全面的运动推理能力进行基准测试。GROUNDMORE 独特地要求模型生成视觉答案，提供比纯文本更具体和更直观的响应。它评估了时空基础和推理方面的模型，以解决与运动相关的视频推理、时间感知和像素级理解中的复杂挑战。此外，我们引入了一种名为运动基础视频推理助手（MORA）的新型基线模型。MORA 结合了多模态 LLM 的多模态推理能力、接地模型（SAM）的像素级感知能力以及轻量级定位头的时间感知能力。MORA 在 GROUNDMORE 上取得了可观的表现，比现有的最佳视觉接地基线模型平均高出 21.5%。我们希望这项新颖而富有挑战性的任务将为未来通过视频推理分割实现稳健和通用的运动理解铺平道路]]></description>
      <guid>https://arxiv.org/abs/2411.09921</guid>
      <pubDate>Mon, 18 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于物理扩散原理的偏振图像去雾方法</title>
      <link>https://arxiv.org/abs/2411.09924</link>
      <description><![CDATA[arXiv:2411.09924v1 Announce Type: new 
摘要：计算机视觉在无人车、监控系统、遥感等领域的应用越来越广泛，然而在有雾的场景下，图像退化会导致目标细节的丢失，严重影响这些视觉任务的准确性和有效性。偏振光由于其电磁波沿特定方向振动，与非偏振光相比，能够更有效地抵抗复杂介质中的散射和折射作用，从而在复杂的传输介质中以及长距离成像条件下具有更强的保持偏振特性的能力，这一特性使得偏振成像特别适合于户外、水下等复杂场景，尤其是在有雾的环境中，可以获得更高质量的图像。基于这一优势，我们提出了一种创新的不依赖外部光源的半物理偏振去雾方法，该方法模拟了雾的扩散过程，并设计了一个与雾扩散引起的图像模糊相对应的扩散核。该方法通过时空傅里叶变换和反卷积操作，恢复扩散前雾滴的状态和物体的光反转分布，有效地实现了场景的去雾和细节增强。]]></description>
      <guid>https://arxiv.org/abs/2411.09924</guid>
      <pubDate>Mon, 18 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>