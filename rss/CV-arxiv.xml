<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>CS.CV更新arxiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.cv更新arxiv.org e-print存档。</description>
    <lastBuildDate>Wed, 02 Apr 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>通过动态照明和图像融合来增强基于视觉的触觉传感器</title>
      <link>https://arxiv.org/abs/2504.00017</link>
      <description><![CDATA[ARXIV：2504.00017V1公告类型：新 
摘要：基于视觉的触觉传感器使用结构化光来测量其弹性界面中的变形。到目前为止，基于视觉的触觉传感器（例如Digit和Gelsight）一直在使用一种调谐到传感器特定外形的结构光的单个静态图案。在这项工作中，我们研究了动态照明模式与图像融合技术的有效性，以提高基于视觉的触觉传感器的传感质量。具体而言，我们建议捕获多个测量值，每个测量都具有不同的照明模式，然后将它们融合在一起以获得单个高质量的测量。实验结果表明，这种动态照明在图像对比度，清晰度和背景差异方面取得了重大改善。这一发现打开了通过简单的软件更新和能够充分利用动态照明的新硬件设计，可以追溯地提高现有基于视觉的触觉传感器的传感质量的可能性。]]></description>
      <guid>https://arxiv.org/abs/2504.00017</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>一种用于图像分割质量评估的新型基于距离的度量</title>
      <link>https://arxiv.org/abs/2504.00023</link>
      <description><![CDATA[ARXIV：2504.00023V1公告类型：新 
摘要：分割质量的评估在开发，优化和比较中的分割方法中起着基本作用，这些方法用于广泛应用。除了少数例外，使用传统指标进行质量评估，这些指标基于计算错误像素的数量，但不会捕获错误的空间分布。建立的基于距离的指标，例如平均Hausdorff距离，对于不同的方法和数据集很难解释和比较。在本文中，我们介绍了表面一致性系数（SCC），这是一种基于距离的新型质量度量，该指标可根据误差的空间分布，该指标基于其靠近结构表面的空间分布。通过使用合成数据和实际分割结果进行严格的分析，我们证明了SCC在将表面附近的误差与更远的误差区分开的鲁棒性和有效性。同时，在不同的结构环境中，SCC易于解释和可比。]]></description>
      <guid>https://arxiv.org/abs/2504.00023</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>骨骼化质量评估：机器人技术中点云分析的几何指标</title>
      <link>https://arxiv.org/abs/2504.00032</link>
      <description><![CDATA[ARXIV：2504.00032V1公告类型：新 
摘要：骨骼化是形状分析的强大工具，它植根于理解对象形态的固有本能。它发现了包括机器人技术在内的各个领域的应用程序。尽管近年来已经研究了骨骼化算法，但很少通过详细的数值评估来量化它们的性能。这项工作着重于定义和量化几何特性，以系统地评分多个方面的点云形状的骨骼化结果，包括拓扑相似性，界限，中心度和平滑度。我们介绍了这些代表性的度量定义以及数值评分框架，以分析从对象操作到移动机器人导航的不同场景的点云数据的骨架结果。此外，我们还提供了一种开源工具，以使研究社区能够评估和完善其骨架模型。最后，我们评估了来自各种机器人应用的拟议几何评估方法的性能和敏感性。]]></description>
      <guid>https://arxiv.org/abs/2504.00032</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>vit-linearizer：将二次知识蒸馏成线性时间视觉模型</title>
      <link>https://arxiv.org/abs/2504.00037</link>
      <description><![CDATA[ARXIV：2504.00037V1公告类型：新 
摘要：视觉变形金刚（VIT）通过全球自我注意力取得了显着的进步，但是它们的二次复杂性对于高分辨率输入而言可能会变得过于敏锐。在这项工作中，我们提出了Vit-Linearizer，这是一种跨架构蒸馏框架，可将丰富的VIT表示转移到线性时间，经过循环式模型中。 Our approach leverages 1) activation matching, an intermediate constraint that encourages student to align its token-wise dependencies with those produced by the teacher, and 2) masked prediction, a contextual reconstruction objective that requires the student to predict the teacher&#39;s representations for unseen (masked) tokens, to effectively distill the quadratic self-attention knowledge into the student while maintaining efficient complexity.从经验上讲，我们的方法为高分辨率任务提供了显着的加速，可以显着解决推理中的硬件挑战。此外，它还提高了基于MAMBA的架构在标准视觉基准上的性能，并以基本尺寸的模型实现了Imagenet上有竞争力的84.3％Top-1精度。我们的结果强调了基于RNN的解决方案对于大规模视觉任务的良好潜力，从而弥合了理论效率和现实世界实践之间的差距。]]></description>
      <guid>https://arxiv.org/abs/2504.00037</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>章节：有效的章节在长达一个小时的视频中使用LLMS</title>
      <link>https://arxiv.org/abs/2504.00072</link>
      <description><![CDATA[ARXIV：2504.00072V1公告类型：新 
摘要：我们解决视频章节的任务，即将长视频时间表分为语义单元并生成相应的章节标题。虽然相对不流行，但自动分会有可能在长期视频中实现有效的导航和内容检索。在本文中，我们通过使用我们的“章节”框架有效解决文本域中的问题，在长时间的视频上实现了强大的章节表现。具体来说，我们利用具有大上下文窗口的经过验证的大语言模型（LLM），并作为输入（i）语音成绩单和（ii）描述视频帧的字幕以及各自的时间戳。考虑到所有框架的效率低下，我们提出了基于语音成绩单内容的轻巧的语音引导选择策略，并在实验上证明了显着的优势。我们训练LLM，以输出本章边界的时间戳以及自由形式的章节标题。这种简单而强大的方法可以在单个前传球中处理一小时长的视频。我们的结果表明，在最近的7M基准中，在最新的基准中，与最新的状态相比，相比，相比，45.3 vs 26.7 f1得分得到了重大改进。为了促进进一步的研究，我们在项目页面上发布了代码和模型。]]></description>
      <guid>https://arxiv.org/abs/2504.00072</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>超级发明：基于事件的关键点检测的跨模式学习</title>
      <link>https://arxiv.org/abs/2504.00139</link>
      <description><![CDATA[ARXIV：2504.00139V1公告类型：新 
摘要：基于事件的关键点检测和匹配具有巨大的潜力，从而使事件传感器在数十年的研究中将事件传感器集成到为框架摄像机开发的高度优化的视觉大满贯系统中。不幸的是，现有的方法与关键点的运动相关外观和事件流中普遍存在的复杂噪声遇到了困难，从而导致特征匹配的功能受到严格有限，并且在下游任务上的性能差。为了减轻此问题，我们提出了Superevent，这是一种数据驱动的方法，可以通过表达性描述符预测稳定的关键。由于缺乏带有地面真相关键点标签的事件数据集，我们利用现有的基于框架的键盘探测器在容易获得的事件一致的和同步的灰度框架上进行自学：我们在时间上生成了较稀疏的键盘点式伪点，考虑到现场外观和摄像机运动的产物。结合了我们的小说，信息丰富的事件表示，我们可以在事件流中有效地学习强大的关键点检测和描述。最后，我们通过将其集成到最初是为传统摄像机开发的现代稀疏关键和基于描述符的SLAM框架中，证明了Usevent的实用性，超过了基于事件的SLAM的最先进的框架。源代码和多媒体材料可在smartroboticslab.github.io/superevent上找到。]]></description>
      <guid>https://arxiv.org/abs/2504.00139</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>迈向精确的动作发现：解决具有动态标签分配的标签中的时间未对准</title>
      <link>https://arxiv.org/abs/2504.00149</link>
      <description><![CDATA[ARXIV：2504.00149V1公告类型：新 
摘要：由于其有希望的应用，精确的动作发现引起了很大的关注。尽管现有方法通过采用精心设计的模型体系结构来实现实质性性能，但它们忽略了一个重大挑战：地面真实标签固有的时间不一致。当标记为包含事件的框架与实际事件时间不准确时，通常是由于人类注释误差或精确识别相邻框架的事件边界的固有困难时，就会出现这种错位。为了解决这个问题，我们提出了一种新颖的动态标签分配策略，该策略允许预测在训练过程中具有地面操作时间的时间偏移，从而确保始终如一的事件发现。我们的方法将最小成本匹配的概念扩展到了空间域中用于对象检测的最小成本匹配的概念。通过基于预测的行动类别得分和时间偏移来计算匹配成本，我们的方法将标签动态分配给最可能的预测，即使这些预测的预测时间偏离了地面真实时代，从而减轻了标签中时间失差的负面影响。我们进行了广泛的实验，并证明我们的方法实现了最先进的性能，尤其是在视觉上与众不同且标签中时间错位的条件很常见的情况下。]]></description>
      <guid>https://arxiv.org/abs/2504.00149</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>几乎没有发电的脑肿瘤，可用于安全和公平的数据共享</title>
      <link>https://arxiv.org/abs/2504.00150</link>
      <description><![CDATA[ARXIV：2504.00150V1公告类型：新 
摘要：利用多中心数据进行医学分析提出了由于隐私问题和数据异质性而引起的挑战。尽管联合学习之类的分布式方法已引起关注，但它们仍然容易受到隐私漏洞的影响，尤其是在诸如医学成像之类的敏感领域。生成模型（例如扩散模型）通过综合现实数据来增强隐私。但是，它们很容易记忆，尤其是在小型数据集中接受培训时。这项研究提出了一个分散的少数发电模型（DFGM），以合成脑肿瘤图像，同时完全保留隐私。 DFGM将私人肿瘤数据与来自多个医疗中心的公开共享健康图像进行协调，从而通过将肿瘤前景融合具有健康背景的肿瘤前景来构建新数据集。这种方法可确保严格的隐私保护，并通过保留健康的背景和肿瘤前景来实现可控制的高质量综合。我们使用UNET评估DFGM在脑肿瘤分割方面的有效性，以提高数据增强的骰子得分为3.9％，而在单独的数据集中获得了4.6％的公平性。]]></description>
      <guid>https://arxiv.org/abs/2504.00150</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Sonarsplat：通过高斯分裂的成像声纳的新颖视图综合</title>
      <link>https://arxiv.org/abs/2504.00159</link>
      <description><![CDATA[ARXIV：2504.00159V1公告类型：新 
摘要：在本文中，我们介绍了Sonarsplat，这是一个新颖的高斯裂纹框架，用于成像声纳，展示了现实的新型观点合成和模型的声学条纹现象。我们的方法将场景表示为具有声学反射和饱和特性的3D高斯人。我们开发了一种新颖的方法，可以有效地栅格化学习的高斯人产生范围/方位角图像，该图像忠于成像声纳的声学图像形成模型。特别是，我们开发了一种新颖的方法来模拟在高斯分裂框架中的方位差。我们使用在受控的测试池中和实际河流环境中从水下机器人平台收集的声纳图像的现实世界数据集评估声音平台。与最先进的图像相比，Sonarsplat提供了改进的图像合成功能（+2.5 dB PSNR）。我们还证明，可以利用声音平台进行方位，并重建3D场景。]]></description>
      <guid>https://arxiv.org/abs/2504.00159</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>保存：学习denoise低SNR视频以提高下游性能</title>
      <link>https://arxiv.org/abs/2504.00161</link>
      <description><![CDATA[ARXIV：2504.00161V1公告类型：新 
摘要：基础模型在自然图像中的视觉任务上表现出色，但在低信噪比（SNR）视频中失败，例如水下声纳，超声和显微镜。我们在视频中介绍了时空的增强和DeNoing，以进行下游任务（保存），这是一种自我监管的方法，它可以降低低SNR传感器视频，并仅使用原始的噪声数据进行培训。通过利用前景和背景运动的差异，保存了使用带有时间瓶颈的编码器来增强对象可见性。我们的方法改善了分类，检测，跟踪和计数，优于资源要求较低的最先进的视频denoising方法。项目页面：https：//suzanne-stathatos.github.io/saved代码页：https：//github.com/suzanne-stathatos/saved]]></description>
      <guid>https://arxiv.org/abs/2504.00161</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用视觉批评家的自我发展的视觉概念库</title>
      <link>https://arxiv.org/abs/2504.00185</link>
      <description><![CDATA[ARXIV：2504.00185V1公告类型：新 
摘要：我们研究建立视觉概念库以进行视觉识别的问题。构建有效的视觉概念库是具有挑战性的，因为手动定义是劳动密集型的，而仅依靠LLM进行概念生成可能会导致缺乏歧视力或无法解释它们之间的复杂相互作用的概念。我们的方法埃舍尔（Escher）将图书馆的学习视角迭代地发现并改善了视觉概念。 Escher使用视觉模型（VLM）作为批评家迭代地完善概念库，包括考虑概念之间的相互作用以及它们如何影响下游分类器。通过利用LLM的文化学习能力和使用各种概念的绩效历史，Escher基于VLM评论家的反馈，动态改善了其概念生成策略。最后，Escher不需要任何人类注释，因此是自动插入式框架。我们从经验上证明了Escher学习一个概念库的能力，以进行零拍，很少的和微调的视觉分类任务。据我们所知，这项工作代表了概念库学习到现实世界视觉任务的首次应用。]]></description>
      <guid>https://arxiv.org/abs/2504.00185</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用扩散模型和图像基础模型，以改善冠状动脉造影的对应关系</title>
      <link>https://arxiv.org/abs/2504.00191</link>
      <description><![CDATA[ARXIV：2504.00191V1公告类型：新 
摘要：冠状动脉血管造影图像中准确的对应匹配对于重建3D冠状动脉结构至关重要，这对于冠状动脉疾病（CAD）的精确诊断和治疗计划至关重要。自然图像的传统匹配方法通常由于固有的差异（例如缺乏纹理，较低的对比度和重叠结构）而无法推广到X射线图像，因此训练数据不足。为了应对这些挑战，我们提出了一条新型的管道，该管道使用以3D重建网格的2D投影从冠状动脉计算的网状术（CCTA）的2D投影中生成逼真的配对冠状动脉造影图像，从而为训练提供了高质量的合成数据。此外，我们采用大型图像基础模型来指导特征聚合，通过关注语义相关区域和关键点来提高对应的匹配精度。我们的方法证明了合成数据集上的卓越匹配性能，并有效地将其推广到现实世界数据集，为此任务提供了实用的解决方案。此外，我们的工作还研究了不同基础模型在对应匹配中的功效，从而为利用先进的图像基础模型提供了医学成像应用的新见解。]]></description>
      <guid>https://arxiv.org/abs/2504.00191</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SmartScan：一个基于AI的交互式框架，用于从卫星图像中提取自动区域</title>
      <link>https://arxiv.org/abs/2504.00200</link>
      <description><![CDATA[ARXIV：2504.00200V1公告类型：新 
摘要：连续甲烷监测系统的部署需要确定固定传感器的最佳数量和放置。但是，计划是劳动密集型的，需要大量的现场设置和迭代才能满足客户限制。评估多个站点时，这一挑战会放大，从而限制可扩展性。为了解决这个问题，我们介绍了SmartScan，SmartScan是一个AI框架，可自动化数据提取以进行最佳传感器放置。 SmartScan使用交互式工具从卫星图像中标识了感兴趣的子空间，以有效地创建特定于设施的约束集。 SmartScan利用了任何模型（SAM）的细分，这是一种基于迅速的变压器，用于零拍分段，从而无需明确的培训即可提取子空间。它以两种模式运行：（1）数据策划模式，其中处理卫星图像以使用SAM的交互式提示系统提取高质量子空间，以及（2）自主模式，在此过程中，用户策划的提示提示训练深度学习网络以替换手动提示，以完全自动化的子空间提取子空间提取。交互式工具还用于质量控制，使用户可以完善AI生成的输出并根据需要生成其他约束集。 SmartScan凭借其AI驱动的促进机制，可提供高通量，高质量的子空间提取，并以最少的人为干预，提高可伸缩性和效率。值得注意的是，其适应性设计使其适合从各个领域的超高分辨率卫星图像中提取感兴趣的区域。]]></description>
      <guid>https://arxiv.org/abs/2504.00200</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RAILGOERL24：G \“ Orlitz Rail Test Center CV数据集2024</title>
      <link>https://arxiv.org/abs/2504.00204</link>
      <description><![CDATA[ARXIV：2504.00204V1公告类型：新 
摘要：无人驾驶火车运营，用于在城市指导运输和主线铁路上进行开放式轨道，除其他外，还需要在火车路径的危险区域自动检测实际和潜在的障碍，尤其是人类。事实证明，机器学习算法是针对此任务的强大最新工具。但是，这些算法需要大量的高质量注释数据，其中包含人类在铁路特异性环境中作为培训数据。不幸的是，公开可用的数据集尚不足够，并且与道路域中的数据集显着较低。因此，本文介绍了RailGoerl24，这是一个在T \“ UV S \”的铁路测试中心记录的12205帧的板载视觉灯全高清摄像机数据集，该型号的“ UV s \” UD轨道，在G \“ Orlitz”，德国Orlitz。其主要目的是为了支持无人驾驶运输的无人驾驶火车的开发。除了原始数据外，数据集还包含33556个盒子的注释“人”。]]></description>
      <guid>https://arxiv.org/abs/2504.00204</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LITA-GS：通过无参考的3D高斯分裂和物理先验的照明 - 不足的新颖观点综合</title>
      <link>https://arxiv.org/abs/2504.00219</link>
      <description><![CDATA[ARXIV：2504.00219V1公告类型：新 
摘要：直接在具有不良照明条件的图像上直接采用3D高斯裂（3DG），这在实现高质量的，正常暴露的表示方面表现出很大的困难，这是由于：（1）估计的（SFM）点有限的结构估计估计的不良照明场景无法捕获足够的场景详细信息； （2）没有地面真实参考，强度信息丢失，明显的噪声和颜色失真对3DGS产生高质量的结果构成了重大挑战； （3）将现有的曝光校正方法与3DG结合在一起，由于其单个增强过程而无法实现令人满意的性能，从而导致从不同角度来看，增强图像之间的照明不一致。为了解决这些问题，我们提出了Lita-GS，这是一种通过无参考的3DG和物理先验的新型照明 - 敏捷的小说综合方法。首先，我们引入了一个照明不变的物理提取管道。其次，基于提取的鲁棒空间结构的先验，我们开发了照明 - 静态结构渲染策略，从而促进了场景结构和物体外观的优化。此外，引入了渐进的denoising模块，以有效地减轻光不变表示内的噪声。我们采用无监督的策略来训练LITA-GS，广泛的实验表明，LITA-GS超过了最先进的（SOTA）基于NERF的方法，同时享受更快的推理速度和减少训练时间的成本。该代码在https://github.com/lowlevelai/lita-gs上发布。]]></description>
      <guid>https://arxiv.org/abs/2504.00219</guid>
      <pubDate>Wed, 02 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>