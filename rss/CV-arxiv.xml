<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>CS.CV更新arxiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.cv更新arxiv.org e-print存档。</description>
    <lastBuildDate>Thu, 06 Mar 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>边缘视觉变压器：对模型压缩和加速策略的全面调查</title>
      <link>https://arxiv.org/abs/2503.02891</link>
      <description><![CDATA[ARXIV：2503.02891V1公告类型：新 
摘要：近年来，视觉变形金刚（VIT）已成为计算机视觉任务（例如图像分类，对象检测和细分）的强大而有前途的技术。与依赖层次特征提取的卷积神经网络（CNN）不同，VIT将图像视为斑块的序列并利用自我注意机制。但是，它们的高计算复杂性和内存要求在资源受限的边缘设备上部署构成重大挑战。为了解决这些局限性，广泛的研究集中在模型压缩技术和硬件感知的加速策略上。但是，仍然缺乏一项全面的审查，该综述将这些技术及其在精确，效率和硬件适应性方面的权衡进行分类仍然缺乏。这项调查通过提供模型压缩技术的结构化分析，用于推断边缘的软件工具以及VIT的硬件加速策略来弥合这一差距。我们讨论了它们对准确性，效率和硬件适应性的影响，突出了关键挑战和新兴的研究方向，以推动Edge平台上的VIT部署，包括图形处理单元（GPU），张量处理单元（TPU）和现场程序可编程的栅极阵列（FPGAS）。目的是通过当代优化VIT的当代指南来激发进一步的研究，以在边缘设备上有效部署。]]></description>
      <guid>https://arxiv.org/abs/2503.02891</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>剪贴剂：利用视觉语言模型在物体检测中进行稳健标签质量评估</title>
      <link>https://arxiv.org/abs/2503.02897</link>
      <description><![CDATA[ARXIV：2503.02897V1公告类型：新 
摘要：高质量的注释对于对象检测模型至关重要，但是确保标签准确性 - 尤其是边界框 - 既具有挑战性又昂贵。本文介绍了剪贴画，这是一种新型的方法，它利用视觉模型自动评估边界框注释的准确性。通过调整剪辑（对比性语言图像的预训练）来评估类标签的正确性和边界框的空间精度，Clipgrader为对象检测标签提供了有效的解决方案。在带有人工干扰边界框的修改对象检测数据集上测试，夹板以1.8％的假阳性速率在可可的可可速度上达到91％的精度。此外，当仅10％的可可数据训练时，它保持87％的准确性，误报率为2.1％。剪贴剂还有效地扩展到较大的数据集，例如LVI，在1,203个类别中达到79％的准确性。我们的实验表明，夹具在现有的可可注释中识别错误的能力，突出了其数据集细化的潜力。当集成到半监督对象检测（SSOD）模型中时，夹板很容易改善伪标签质量，从而帮助在整个训练过程中实现更高的MAP（平均平均精度）。因此，夹具提供了可扩展的AI辅助工具，用于增强注释质量控制和验证大规模对象检测数据集中的注释。]]></description>
      <guid>https://arxiv.org/abs/2503.02897</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Langgas：使用新数据集中的半透明气体泄漏检测中的选择性零摄影背景减法引入语言</title>
      <link>https://arxiv.org/abs/2503.02910</link>
      <description><![CDATA[ARXIV：2503.02910V2公告类型：新 
摘要：气体泄漏构成了需要预防的重大危害。传统上，人类检查已被用于检测，这是一个缓慢而劳动密集的过程。最近的研究将机器学习技术应用于此问题，但仍缺乏高质量的公开数据集。本文介绍了一个合成数据集，具有不同的背景，干扰前景对象，不同的泄漏位置以及精确的分割地面真相。我们提出了一种结合背景减法，零击对象检测，过滤和分割以利用此数据集的零拍方法。实验结果表明，我们的方法仅基于背景减法和分割零射对象检测的基线方法明显胜过基线方法，总体上达到69 \％。我们还对各种及时的配置和阈值设置进行了分析，以提供对我们方法性能的更深入的见解。该代码和数据集将在发布后发布。]]></description>
      <guid>https://arxiv.org/abs/2503.02910</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在相机自我动机下的单眼定位</title>
      <link>https://arxiv.org/abs/2503.02916</link>
      <description><![CDATA[ARXIV：2503.02916V1公告类型：新 
摘要：从移动的单眼摄像机中定位一个人对于人类机器人相互作用（HRI）至关重要。为了从2D图像估算3D人体位置，现有方法要么取决于固定相机的几何假设，要么使用在包含少量摄像机自我运动的数据集上训练的位置回归模型。这些方法容易受到凶猛的相机自我运动的影响，导致人本地化不准确。我们将人定位视为姿势估计问题的一部分。通过用四点模型代表人类，我们的方法可以通过优化共同估计2D摄像头态度和该人的3D位置。对公共数据集和真实机器人实验的评估表明，我们的方法的本地化精度优于基准。我们的方法进一步实施到跟随人员的系统中，并在敏捷四倍的机器人上部署。]]></description>
      <guid>https://arxiv.org/abs/2503.02916</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过AI驱动的机器愿景彻底改变交通管理：朝着智能城市迈出的一步</title>
      <link>https://arxiv.org/abs/2503.02967</link>
      <description><![CDATA[ARXIV：2503.02967V1公告类型：新 
摘要：城市的快速城市化和越来越多的车辆充血对交通管理和安全提出了重大挑战。这项研究探讨了人工智能（AI）和机器视觉技术在革新交通系统中的变革潜力。通过利用先进的监视摄像机和深度学习算法，本研究提出了一种用于实时检测车辆，交通异常和驾驶员行为的系统。该系统集成了地理空间和天气数据，以动态适应环境条件，以确保在各种情况下的良好性能。使用Yolov8和Yolov11模型，该研究在车辆检测和异常识别方面具有很高的精度，优化了交通流量并提高道路安全性。这些发现有助于开发智能交通管理解决方案，并符合创建具有可持续和高效的城市基础设施的智能城市的愿景。]]></description>
      <guid>https://arxiv.org/abs/2503.02967</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从与对比度转换器的嘈杂标签中学习</title>
      <link>https://arxiv.org/abs/2503.03042</link>
      <description><![CDATA[ARXIV：2503.03042V1公告类型：新 
摘要：带有嘈杂标签的深度学习是弱监督学习的有趣挑战。尽管具有很高的学习能力，但CNN仍具有在带有嘈杂标签的样品的情况下过度合适的趋势。减轻此问题，众所周知的共同培训框架被用作我们工作的基本基础。在本文中，我们引入了一个对比的共同转化框架，该框架简单而快速，但与最先进的方法相比，它可以通过大幅度提高性能。我们认为在处理标签噪声时，变压器的鲁棒性。我们的对比共同转化方法能够利用数据集中的所有样本，无论它们是干净还是嘈杂的情况。变压器是通过对比损失和分类损失的组合来训练的。来自六个标准基准数据集（包括服装1M）的损坏数据的广泛实验结果表明，我们的对比共同转化器优于现有的最新方法。]]></description>
      <guid>https://arxiv.org/abs/2503.03042</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AHCPTQ：针对任何模型的细分</title>
      <link>https://arxiv.org/abs/2503.03088</link>
      <description><![CDATA[ARXIV：2503.03088V1公告类型：新 
摘要：任何模型（SAM）的细分市场已经证明了各种视觉任务的强烈多功能性。但是，其较大的存储要求和高计算成本对实际部署构成了挑战。培训后量化（PTQ）已成为有效部署的有效策略，但是我们确定了SAM中的两个关键挑战，这些挑战阻碍了现有PTQ方法的有效性：Gelu后激活的重尾和偏斜分布，以及线性投射激活中的大量信息间变异。为了应对这些挑战，我们提出了AHCPTQ，这是SAM的准确且硬件有效的PTQ方法。 AHCPTQ引入了与硬件兼容的混合对数均匀量子量化（HLUQ），以管理Gelu后激活，对log2量化对密集的小值和稀疏大值的均匀量化，以增强量化分辨率。此外，AHCPTQ通过逐步群集激活通道具有相似的分布，从而结合了通道感知分组（CAG），以减轻通道间的变化，从而使它们能够共享量化参数并提高硬件效率。 HLUQ和CAG的组合不仅提高了量化有效性，而且还确保了与有效的硬件执行的兼容性。例如，在SAM-L模型上的W4A4配置下，AHCPTQ通过Dino检测器实例分割实现了36.6％的映射，同时在FPGA实施中实现了7.89倍的加速和8.64x的浮点。]]></description>
      <guid>https://arxiv.org/abs/2503.03088</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RVAFM：重新参数化手写段落文本识别的垂直注意融合模块</title>
      <link>https://arxiv.org/abs/2503.03104</link>
      <description><![CDATA[ARXIV：2503.03104V1公告类型：新 
摘要：手写段落文本识别（HPTR）是计算机视觉中的一项具有挑战性的任务，需要将段落文本图像转换为文本文本，并将其富含手写文本进行编码序列。该任务最先进的模型之一是垂直注意网络（VAN），该网络利用垂直注意模块（VAM）隐式将文本图像分段段为文本行，从而减少了识别任务的难度。但是，从网络结构的角度来看，VAM是一个单分支模块，与多分支模块相比，它在学习方面的有效性较低。在本文中，我们提出了一个新的模块，称为重新参数化垂直注意融合模块（RVAFM），该模块结合了结构性重新参数化技术。 RVAFM在训练和推理阶段中分解了模块的结构。在培训期间，它使用多支分支结构来进行更有效的学习，在推断期间，它使用单分支结构进行更快的处理。多支分支结构学到的特征通过一种称为重新参数融合（RF）的特殊融合方法融合到单分支结构中，而不会丢失任何信息。结果，我们在IAM段落级测试集上获得了4.44％的字符错误率（CER），单词错误率（WER）为14.37％。此外，推理速度略高于货车。]]></description>
      <guid>https://arxiv.org/abs/2503.03104</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>改进的纯完全连接的神经网络，用于稻米分类</title>
      <link>https://arxiv.org/abs/2503.03111</link>
      <description><![CDATA[ARXIV：2503.03111V1公告类型：新 
摘要：米饭是世界上很大一部分人口的主食，提供必需的营养素，并在广泛的烹饪传统中充当多功能的内在物质。最近，深度学习的使用使大米的自动分类，提高了准确性和效率。但是，基于第一阶段训练的经典模型可能在区分具有相似外部特征的水稻品种时遇到困难，从而导致错误分类。考虑到模型的透明度和可行性，我们选择并逐渐改善了纯完全连接的神经网络来实现水稻颗粒的分类。我们使用的数据集分别包含从网站和实验室获得的全球和国内水稻图像。首先，训练模式从一阶段的训练更改为两阶段训练，这显着有助于区分两种类似类型的大米。其次，预处理方法从随机倾斜到水平或垂直位置COR截止。在这两个增强之后，我们的模型的准确性显着从97％提高到99％。总而言之，这项研究中提出的两种微妙的方法可以显着增强深度学习模型的分类能力。]]></description>
      <guid>https://arxiv.org/abs/2503.03111</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>NTR-GAUSSIAN：基于热力学的4D高斯脱落的夜间动态热重建</title>
      <link>https://arxiv.org/abs/2503.03115</link>
      <description><![CDATA[ARXIV：2503.03115V1公告类型：新 
摘要：热红外成像提供了全天候能力的优势，从而实现了对物体表面温度的不侵入测量。因此，使用热红外图像重建了准确反映场景温度分布的3D模型，从而有助于诸如建筑监视和能源管理等应用。但是，现有方法主要集中在一个时间段内的静态3D重建上，忽视了环境因素对热辐射的影响，并且未能随着时间的推移预测或分析温度变化。为了应对这些挑战，我们提出了NTR-Gaussian方法，该方法将温度视为热辐射的一种形式，并结合了对流传热和辐射热散热等元素。我们的方法利用神经网络来预测热力学参数，例如发射率，对流传热系数和热容量。通过整合这些预测，我们可以在整个夜间场景中的不同时间准确预测热温。此外，我们引入了一个专门用于夜间热图像的动态数据集。广泛的实验和评估表明，NTR-Gaussian在热重建中的比较方法显着优于比较方法，从而在1度摄氏度内达到了预测的温度误差。]]></description>
      <guid>https://arxiv.org/abs/2503.03115</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>弹性4D形状表示和分析的动态神经表面</title>
      <link>https://arxiv.org/abs/2503.03132</link>
      <description><![CDATA[ARXIV：2503.03132V1公告类型：新 
摘要：我们提出了一个新的框架，用于对零4D表面的统计分析，即随时间变形和演变的3D表面。由于这些表面的任意参数化及其变化速度，因此该问题尤其具有挑战性，因此需要有效的时空注册。传统上，在计算其时空登记，地球学和统计数据之前，在空间和时间上，4D表面被离散化。但是，这种方法可能导致次优的解决方案，正如我们在本文中所证明的那样，不是必需的。相反，我们将4D表面视为空间和时间上的连续功能。我们引入了动态球形神经表面（D-SNS），这是一种有效的平滑和连续的时空表示，用于属-0 4D表面。然后，我们演示了如何直接在没有预先离散和网格划分的情况下直接在这些连续表示上执行诸如时空注册，测量学计算和平均4D形状估计的核心4D形状分析任务。通过将神经表示与经典的Riemannian几何形状和统计形状分析技术相结合，我们提供了构成块，以实现完整的功能形状分析。我们证明了该框架对4D人类和面部数据集的效率。源代码和其他结果可在https://4d-dsns.github.io/dsns/上获得。]]></description>
      <guid>https://arxiv.org/abs/2503.03132</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>与熵正则化的时间分离，用于峰值神经网络中的知识蒸馏</title>
      <link>https://arxiv.org/abs/2503.03144</link>
      <description><![CDATA[ARXIV：2503.03144V1公告类型：新 
摘要：受人脑启发的尖峰神经网络（SNN）通过基于尖峰的信息传输提供了显着的计算效率。尽管它们有可能减少推理能源消耗，但SNN和人工神经网络（ANN）之间的性能差距仍然存在，这主要是由于当前的培训方法和固有的模型限制。尽管最近的研究旨在通过使用ANN教师网络的知识蒸馏（KD）来增强SNN学习，但传统的蒸馏技术通常忽略了SNNS的独特时空特性，因此未能充分利用其优势。为了克服这些挑战，我们提出了一种以时间分离和熵正则化为特征的新型逻辑蒸馏方法。这种方法通过在不同时间步骤上对逻辑进行蒸馏学习来改善现有的SNN蒸馏技术，而不仅仅是在汇总的输出功能上。此外，熵正则化的整合稳定模型优化并进一步提高了性能。广泛的实验结果表明，我们的方法超过了先前的SNN蒸馏策略，无论是基于逻辑蒸馏，特征蒸馏还是两者的组合。该代码将在GitHub上可用。]]></description>
      <guid>https://arxiv.org/abs/2503.03144</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>部分卷积会引起视觉关注</title>
      <link>https://arxiv.org/abs/2503.03148</link>
      <description><![CDATA[ARXIV：2503.03148V1公告类型：新 
摘要：设计有效有效的神经网络在计算机视觉研究中仍然是一个重要的主题。深度方向（DWCONV）被广泛用于有效的CNN或VIT中，但在推理过程中需要频繁的内存访问，这会导致吞吐量较低。 Fasternet试图引入部分卷积（PCONV）作为DWCONV的替代方案，但由于未充分利用的通道而损害了准确性。为了纠正这种缺点并考虑特征映射通道之间的冗余，我们引入了一种新型的部分视觉注意机制（PAT），该机制可以有效地将PCONV与视觉注意力相结合。我们的探索表明，部分注意机制可以完全替代全部注意机制并减少模型参数和失败。我们的PAT可以得出三种类型的块：部分通道 - 注意区块（PAT_CH），部分空间注意区（PAT_SP）和部分自我注意区块（PAT_SF）。首先，PAT_CH集成了增强的高斯通道注意机制，以将全球分布信息注入PCONV的未触及的通道中。其次，我们将空间关注引入MLP层，以进一步提高模型的准确性。最后，我们将在最后阶段替换PAT_CH，以扩展全球接受场的自我发项机制。在PAT的基础上，我们提出了一个名为Patnet的新型混合网络家族，该家族的TOP-1准确性和推理速度与Imagenet-1K分类的Fernet相比，在可可数据集上的检测和分段中都达到了fornetnet。特别是，我们的PATNET-T2比FOSTNET-T2高1.3％，而GPU吞吐量高25％，CPU潜伏期降低了24％。]]></description>
      <guid>https://arxiv.org/abs/2503.03148</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DSPNET：鲁棒3D问题回答的双视频场景感知</title>
      <link>https://arxiv.org/abs/2503.03190</link>
      <description><![CDATA[Arxiv：2503.03190V2公告类型：新 
摘要：3D问题回答（3D QA）要求该模型全面理解其本文所描述的位置的3D场景，然后是关于其周围环境的原因，并在这种情况下回答问题。但是，现有方法通常依赖于纯3D点云中的全局场景感知，并忽略了多视图图像中丰富的本地纹理细节的重要性。此外，由于相机姿势和复杂的阻塞中固有的噪声，在将3D点云与多视图图像对齐时存在显着的特征降解和降低功能鲁棒性问题。在本文中，我们提出了一个双视场景感知网络（DSPNET），以全面整合多视图和点云特征，以改善3D QA中的鲁棒性。我们的文本指导的多视图融合（TGMF）模块优先考虑与文本的语义内容匹配的图像视图。为了自适应融合的背面曲线图与点云功能，我们设计了自适应双视觉感知（ADVP）模块，增强了3D场景理解。此外，我们的多模式上下文引导的推理（MCGR）模块通过在视觉和语言模式中整合上下文信息来促进鲁棒推理。 SQA3D和SCANQA数据集的实验结果证明了我们的DSPNET的优势。代码将在https://github.com/lz-ch/dspnet上找到。]]></description>
      <guid>https://arxiv.org/abs/2503.03190</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Spiritsight Agent：高级GUI代理人</title>
      <link>https://arxiv.org/abs/2503.03196</link>
      <description><![CDATA[ARXIV：2503.03196V1公告类型：新 
摘要：图形用户界面（GUI）代理在协助人类计算机交互，自动化人机用户在数字设备上的导航具有惊人的能力。预计理想的GUI代理将在不同的GUI平台上获得高精度，低潜伏期和兼容性。最近基于视觉的方法通过利用高级视觉语言模型（VLM）表现出了希望。尽管它们通常符合兼容性和延迟较低的要求，但由于元素接地的局限性，这些基于视觉的GUI代理的精度往往较低。为了解决这个问题，我们建议$ \ textbf {siritsight} $，这是一种基于远见的端到端GUI代理，在各个GUI平台上擅长GUI导航任务。首先，我们使用可伸缩方法创建了一个多级，大规模的高质量GUI数据集，称为$ \ textbf {Gui-lasagne} $，并以强大的GUI理解和接地功能来增强Spiritsight。其次，我们介绍了$ \ textbf {Universal Block解析（UBP）} $方法，以解决视觉输入动态高分辨率中的模棱两可问题，从而进一步增强了Spiritsight的地面GUI对象的能力。通过这些努力，Spiritsight代理在不同的GUI基准方面优于其他高级方法，证明了其在GUI导航任务中的优势能力和兼容性。模型可在$ \ href {https://huggingface.co/sensellm/sensellm/sensellm/sentight-agent-8b} {this \ url} $中获得。]]></description>
      <guid>https://arxiv.org/abs/2503.03196</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>