<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CV 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Tue, 31 Dec 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>Vitron：用于理解、生成、分割、编辑的统一像素级视觉 LLM</title>
      <link>https://arxiv.org/abs/2412.19806</link>
      <description><![CDATA[arXiv:2412.19806v1 公告类型：新
摘要：视觉大型语言模型 (LLM) 的最新发展取得了显着进展，但在多模态通才方面仍然面临挑战，例如粗粒度的实例级理解、对图像和视频缺乏统一的支持以及对各种视觉任务的覆盖不足。在本文中，我们介绍了 VITRON，这是一种通用的像素级视觉 LLM，旨在全面理解、生成、分割和编辑静态图像和动态视频。VITRON 以 LLM 主干为基础，在其前端模块中整合了图像、视频和像素级区域视觉效果的编码器，同时采用最先进的视觉专家作为后端，通过它 VITRON 支持一系列视觉终端任务，涵盖从低级到高级的视觉理解到视觉生成。为了确保从 LLM 到后端模块传递消息的有效和精确性，我们提出了一种新颖的混合方法，同时集成离散文本指令和连续信号嵌入。此外，我们为 VITRON 设计了各种像素级时空视觉语言对齐学习，以达到最佳的细粒度视觉能力。最后，建议使用跨任务协同模块来学习最大化任务不变的细粒度视觉特征，增强不同视觉任务之间的协同作用。VITRON 演示了 12 多个视觉任务并在 22 个数据集上进行了评估，展示了其在四个主要视觉任务集群中的广泛功能。总体而言，这项工作阐明了开发更统一的多模态通才的巨大潜力。项目主页：https://vitron-llm.github.io/]]></description>
      <guid>https://arxiv.org/abs/2412.19806</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用功能性 MRI 数据检测重度抑郁症的多图谱集成图神经网络模型</title>
      <link>https://arxiv.org/abs/2412.19833</link>
      <description><![CDATA[arXiv:2412.19833v1 公告类型：新
摘要：重度抑郁症（MDD）是最常见的精神障碍之一，对许多日常活动和生活质量有重大影响。它是全球最常见的精神障碍之一，是导致残疾的第二大原因。目前对MDD的诊断方法主要依赖于临床观察和患者报告的症状，忽视了导致抑郁症的各种潜在原因和病理生理因素。因此，科学研究人员和临床医生必须更深入地了解MDD所涉及的病理生理机制。神经科学领域越来越多的证据表明抑郁症是一种大脑网络障碍，而磁共振成像（MRI）等神经成像的使用在识别和治疗MDD方面发挥着重要作用。静息状态功能磁共振成像（rs-fMRI）是用于研究MDD的最流行的神经成像技术之一。深度学习技术已广泛应用于神经成像数据，以帮助早期检测心理健康障碍。近年来，人们对图神经网络 (GNN) 的兴趣日益浓厚，这是一种专门设计用于处理 rs-fMRI 等图结构数据的深度神经架构。这项研究旨在开发一种基于集成的 GNN 模型，该模型能够从 rs-fMRI 图像中检测出判别性特征，以诊断 MDD。具体来说，我们通过结合来自多个大脑区域分割图谱的特征构建了一个集成模型，以捕捉大脑的复杂性并比基于单个图谱的模型更准确地检测出不同的特征。此外，通过评估模型在大型多站点 MDD 数据集上的性能，证明了我们的模型的有效性。所有模型中表现最佳的模型实现了 75.80% 的准确度、88.89% 的灵敏度、61.84% 的特异性、71.29% 的精确度和 79.12% 的 F1 分数。]]></description>
      <guid>https://arxiv.org/abs/2412.19833</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于交通需求预测的多视图融合神经网络</title>
      <link>https://arxiv.org/abs/2412.19839</link>
      <description><![CDATA[arXiv:2412.19839v1 公告类型：新 
摘要：时空特征的提取是交通研究中的一个重要研究课题，目前的研究通常采用统一的时间建模机制和固定的空间图来实现这一目的。然而，固定的空间图限制了相似但不直接相连的节点的空间特征的提取，而统一的时间建模机制忽略了不同节点时间变化的异质性。为了解决这些挑战，提出了一种多视图融合神经网络（MVFN）方法。在该方法中，通过使用图卷积网络（GCN）提取空间局部特征，并使用余弦重加权线性注意机制（CLA）提取空间全局特征。GCN和CLA结合起来创建一个图余弦模块（GCM）来提取整体空间特征。另外，多通道可分离时序卷积网络（MSTCN）在每一层都利用多通道时序卷积网络（MTCN）提取统一的时序特征，再利用可分离时序卷积网络（STCN）提取独立的时序特征，最后将时空特征数据输入预测层得到最终结果。该模型在两个交通需求数据集上进行了验证，取得了最佳的预测精度。]]></description>
      <guid>https://arxiv.org/abs/2412.19839</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ERPA：集成 OCR 和 LLM 的智能文档处理高效 RPA 模型</title>
      <link>https://arxiv.org/abs/2412.19840</link>
      <description><![CDATA[arXiv:2412.19840v1 公告类型：新
摘要：本文介绍了 ERPA，这是一种创新的机器人流程自动化 (RPA) 模型，旨在增强 ID 数据提取并优化移民工作流程中的光学字符识别 (OCR) 任务。传统的 RPA 解决方案在处理大量文档时通常会面临性能限制，从而导致效率低下。ERPA 通过结合大型语言模型 (LLM) 来提高提取文本的准确性和清晰度，从而有效处理模糊字符和复杂结构，从而解决这些挑战。与 UiPath 和 Automation Anywhere 等领先平台的基准比较表明，ERPA 显着缩短了高达 94% 的处理时间，仅需 9.94 秒即可完成 ID 数据提取。这些发现凸显了 ERPA 彻底改变文档自动化的潜力，为当前的 RPA 解决方案提供了更快、更可靠的替代方案。]]></description>
      <guid>https://arxiv.org/abs/2412.19840</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>FlameGS：通过高斯溅射重建火焰光场</title>
      <link>https://arxiv.org/abs/2412.19841</link>
      <description><![CDATA[arXiv:2412.19841v1 公告类型：new 
摘要：针对传统 ART 火焰燃烧诊断算法耗时、计算量大的问题，受火焰模拟技术的启发，提出了一种新的火焰表示方法。通过对火焰发光过程进行建模，并利用二维投影图像进行监督，实验验证表明，该模型在实际图像与预测的二维投影之间实现了平均结构相似度指数 0.96，峰值信噪比为 39.05。此外，与传统算法相比，它节省了约 34 倍的计算时间和约 10 倍的内存。]]></description>
      <guid>https://arxiv.org/abs/2412.19841</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于图稀疏注意机制和双向时间卷积网络的交通时空数据多模态联合预测</title>
      <link>https://arxiv.org/abs/2412.19842</link>
      <description><![CDATA[arXiv:2412.19842v1 公告类型：新 
摘要：交通流预测在城市交通系统的管理和运行中起着至关重要的作用。虽然对单个交通方式的预测已经进行了广泛的研究，但对不同交通方式的联合预测的研究相对有限。此外，现有的多模式交通联合建模方法往往缺乏时空特征提取的灵活性。为了解决这些问题，我们提出了一种称为图稀疏注意机制和双向时间卷积网络（GSABT）的多模式交通时空联合预测方法。首先，我们使用多模态图乘以自注意权重来捕获空间局部特征，然后采用Top-U稀疏注意机制来获得空间全局特征。其次，我们利用双向时间卷积网络增强输出和输入数据之间的时间特征相关性，并通过共享唯一模块提取模态间和模态内时间特征。最后，我们设计了一个可以灵活扩展到空间和时间维度的多模态联合预测框架。在三个真实数据集上进行的大量实验表明，所提出的模型始终能够达到最佳的预测性能。]]></description>
      <guid>https://arxiv.org/abs/2412.19842</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>神经影像学中潜在表征模型的回顾</title>
      <link>https://arxiv.org/abs/2412.19844</link>
      <description><![CDATA[arXiv:2412.19844v1 公告类型：新
摘要：神经影像数据，特别是来自 MRI 或 PET 等技术的神经影像数据，提供了有关大脑结构和活动的丰富但复杂的信息。为了管理这种复杂性，潜在表示模型（例如自动编码器、生成对抗网络 (GAN) 和潜在扩散模型 (LDM)）的应用越来越多。这些模型旨在将高维神经影像数据降低到低维潜在空间，在那里可以识别与大脑功能相关的关键模式和变化。通过对这些潜在空间进行建模，研究人员希望深入了解大脑的生物学和功能，包括其结构如何随着年龄或疾病而变化，或者它如何编码感官信息、预测和适应新输入。本综述讨论了这些模型如何用于临床应用，如疾病诊断和进展监测，以及如何探索基本大脑机制，如主动推理和预测编码。这些方法为理解和模拟大脑复杂的计算任务提供了强有力的工具，有可能增进我们对认知、感知和神经疾病的认识。]]></description>
      <guid>https://arxiv.org/abs/2412.19844</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>图像的符号解缠表征</title>
      <link>https://arxiv.org/abs/2412.19847</link>
      <description><![CDATA[arXiv:2412.19847v1 公告类型：新
摘要：解缠结表示的想法是将数据简化为产生数据的一组生成因子。通常，这种表示是潜在空间中的向量，其中每个坐标对应于生成因子之一。然后可以通过更改特定坐标的值来修改对象，但必须确定哪个坐标对应于所需的生成因子——如果向量表示具有高维度，则这是一项艰巨的任务。在本文中，我们提出了 ArSyD（符号解缠结架构），它将每个生成因子表示为与结果表示相同维度的向量。在 ArSyD 中，对象表示是作为生成因子向量表示的叠加而获得的。我们将这种表示称为 \textit{符号解缠结表示}。我们使用超维计算（也称为向量符号架构）的原理，其中符号表示为超向量，允许对其进行向量运算。解缠是通过构造实现的，训练期间不对底层分布做出任何额外假设，并且模型仅以弱监督的方式训练以重建图像。我们在 dSprites 和 CLEVR 数据集上研究 ArSyD，并对学习到的符号解缠表示进行全面分析。我们还提出了新的解缠指标，允许比较使用不同维度潜在表示的方法。ArSyD 允许以受控和可解释的方式编辑对象属性，并且对象属性表示的维数与对象表示本身的维数一致。]]></description>
      <guid>https://arxiv.org/abs/2412.19847</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>生成地标引导摘除眼镜 3D 人脸重建</title>
      <link>https://arxiv.org/abs/2412.19848</link>
      <description><![CDATA[arXiv:2412.19848v1 公告类型：新
摘要：单视图 3D 人脸重建是一个极其困难的基本计算机视觉问题。当前的系统通常假设输入是没有遮挡的人脸，这使得它们的方法不适合在野外条件下使用。我们提出了一种从单幅图像中去除眼镜的 3D 人脸重建方法。现有的人脸重建方法无法自动去除眼镜，无法在“野外”生成照片般逼真的 3D 人脸。我们方法的创新之处在于稳健地识别眼镜区域并智能地去除眼镜区域的过程。在这项工作中，我们估计了眼镜区域合理位置的 2D 人脸结构，用于构建 3D 纹理。一个优秀的抗眼镜人脸重建方法应该确保输出的真实性，包括眼睛、鼻子和嘴巴之间的拓扑结构。我们通过深度学习架构实现这一目标，该架构从单个 2D 图像直接回归 3DMM 表示的 3D 面部几何形状。我们还演示了如何将相关的面部解析任务纳入所提出的框架并帮助提高重建质量。我们对现有的 3D 面部重建任务进行了广泛的实验作为具体示例，以证明该方法比现有方法更出色的调节能力，而这些方法通常会失败。]]></description>
      <guid>https://arxiv.org/abs/2412.19848</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>遮挡场景下基于单色图像的带几何细节的 3D 人脸重建</title>
      <link>https://arxiv.org/abs/2412.19849</link>
      <description><![CDATA[arXiv:2412.19849v1 公告类型：新
摘要：3D人脸重建技术旨在自然逼真地生成人脸立体模型。以前的深度人脸重建方法通常旨在生成令人信服的纹理，不能很好地同时推广到多个遮挡场景。通过引入凹凸贴图，我们成功地将中级细节添加到粗糙的3D人脸中。更具创新性的是，我们的方法考虑了遮挡场景。因此，在常见的3D人脸重建方法的基础上，我们在本文中提出了一个统一的框架来同时处理多种类型的遮挡（例如，头发，手掌和眼镜等）。大量的实验和比较表明，我们的方法可以从遮挡场景下捕获的面部图像中生成具有几何细节的高质量重建结果。]]></description>
      <guid>https://arxiv.org/abs/2412.19849</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>条件平衡：改善图像生成中的多条件权衡</title>
      <link>https://arxiv.org/abs/2412.19853</link>
      <description><![CDATA[arXiv:2412.19853v1 公告类型：新
摘要：平衡内容保真度和艺术风格是图像生成的关键挑战。虽然传统的风格转换方法和现代的去噪扩散概率模型 (DDPM) 都努力实现这种平衡，但它们往往难以在不牺牲风格、内容或有时两者的情况下做到这一点。这项工作通过分析 DDPM 保持内容和风格平衡的能力来解决这一挑战。我们引入了一种新方法来识别 DDPM 注意层中的敏感度，识别与不同风格方面相对应的特定层。通过仅将条件输入定向到这些敏感层，我们的方法能够对风格和内容进行细粒度控制，从而显着减少因输入过度受限而引起的问题。我们的研究结果表明，这种方法通过更好地协调风格和内容来增强最近的风格化技术，最终提高生成的视觉内容的质量。]]></description>
      <guid>https://arxiv.org/abs/2412.19853</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>深度学习与 GIS 融合实现高级遥感图像分析</title>
      <link>https://arxiv.org/abs/2412.19856</link>
      <description><![CDATA[arXiv:2412.19856v1 公告类型：新
摘要：本文提出了一种创新的遥感图像分析框架，将深度学习技术（特别是卷积神经网络 (CNN) 和长短期记忆 (LSTM) 网络）与地理信息系统 (GIS) 融合在一起。主要目标是通过克服与高维、复杂模式和时间数据处理相关的挑战来提高空间数据分析的准确性和效率。我们实施了优化算法，即粒子群优化 (PSO) 和遗传算法 (GA)，以微调模型参数，从而提高性能指标。我们的研究结果表明，优化后分类准确率从 78% 显着提高到 92%，预测误差从 12% 降低到 6%。此外，模型的时间精度从 75% 提高到 88%，展示了框架有效监测动态变化的能力。GIS 的集成不仅丰富了空间分析，而且有助于更深入地了解地理特征之间的关系。这项研究表明，将先进的深度学习方法与 GIS 和优化策略相结合可以显著推动遥感应用的发展，为未来环境监测、城市规划和资源管理的发展铺平道路。]]></description>
      <guid>https://arxiv.org/abs/2412.19856</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>UniAvatar：通过全面的运动和照明控制实现逼真的音频驱动说话头部生成</title>
      <link>https://arxiv.org/abs/2412.19860</link>
      <description><![CDATA[arXiv:2412.19860v1 公告类型：新
摘要：最近，使用音频输入为肖像图像制作动画是一项流行的任务。制作栩栩如生的头部视频需要灵活自然的动作，包括面部和头部动态、相机运动、逼真的光影效果。现有的方法难以提供对这些方面的全面、多方面的控制。在这项工作中，我们介绍了 UniAvatar，这是一种设计方法，可对各种运动和照明条件进行广泛的控制。具体来说，我们使用 FLAME 模型将所有运动信息渲染到单个图像上，在实现细粒度像素级控制的同时保持 3D 运动细节的完整性。除了运动之外，这种方法还允许全面的全局照明控制。我们设计了独立的模块来管理 3D 运动和照明，允许单独和组合控制。大量实验表明，我们的方法在广泛运动控制和照明控制方面均优于其他方法。此外，为了增强当前数据集中运动和环境背景的多样性，我们收集并计划公开发布两个数据集，DH-FaceDrasMvVid-100 和 DH-FaceReliVid-200，它们捕捉讲话和各种光照场景中的显著头部运动。]]></description>
      <guid>https://arxiv.org/abs/2412.19860</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过可学习尺度实现无数据分组完全量化 Winograd 卷积</title>
      <link>https://arxiv.org/abs/2412.19867</link>
      <description><![CDATA[arXiv:2412.19867v1 公告类型：新 
摘要：尽管大规模文本到图像扩散模型在复杂视觉和下游任务方面取得了革命性的突破，但其极高的计算和存储成本限制了它们的可用性。最近的研究探索了扩散模型的量化，以降低计算成本和内存带宽使用率。为了进一步缩短推理时间，可以将 Winograd 等快速卷积算法用于卷积层，这在扩散模型中占了很大一部分计算量。然而，使用现有的粗粒度后训练量化方法完全量化的 Winograd 会造成显著的质量损失，再加上对如此大的模型的 Winograd 变换矩阵进行微调以恢复质量的复杂性和成本，使得它们不适合用于大规模基础模型。由于其中存在大量值，我们研究了细粒度分组量化在量化扩散模型中的影响。虽然分组量化可以在很大程度上处理完全量化的 Winograd 卷积，但它难以处理 Winograd 域计算中相当大一部分中的巨大分布不平衡。为了减少 Winograd 域中的范围差异，我们建议仅微调 Winograd 变换矩阵的比例参数，而不使用任何特定于域的训练数据。由于我们的方法不依赖于任何训练数据，因此可以安全地保证量化扩散模型的泛化性能。对于文本到图像生成任务，与全精度模型相比，带有 Winograd 的 8 位完全量化扩散模型提供了近乎无损的质量（FID 和 CLIP 分数）。对于图像分类，我们的方法在 ResNet18 和 ResNet-34 上的 top-1 ImageNet 准确率上分别比最先进的 Winograd PTQ 方法高出 1.62% 和 2.56%，Winograd F(6, 3)。]]></description>
      <guid>https://arxiv.org/abs/2412.19867</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>邻居确实很重要：用于医学半监督分割的密度感知对比学习</title>
      <link>https://arxiv.org/abs/2412.19871</link>
      <description><![CDATA[arXiv:2412.19871v1 公告类型：新
摘要：在医学图像分析中，多器官半监督分割面临着标签不足和软组织对比度低等挑战。为了解决这些问题，现有研究通常采用使用伪标记和一致性正则化的半监督分割技术。然而，这些方法主要依靠单个数据样本进行训练，忽略了特征空间中存在的丰富邻域信息。在这项工作中，我们认为监督信息可以直接从特征空间的几何形状中提取。受基于密度的聚类假设的启发，我们提出使用特征密度来定位特征簇内的稀疏区域。我们的目标是通过解决稀疏性问题来提高类内紧凑性。为了实现这一目标，我们提出了一种密度感知对比学习 (DACL) 策略，将稀疏区域中的锚定特征推向由高密度正样本近似的聚类中心，从而产生更紧凑的聚类。具体来说，我们的方法使用标记和未标记的数据样本构建密度感知邻域图，以估计特征密度并定位稀疏区域。我们还将标签引导的协同训练与密度引导的几何正则化相结合，以形成对未标记数据的互补监督。在多器官分割挑战数据集上的实验表明，我们提出的方法优于最先进的方法，凸显了其在医学图像分割任务中的有效性。]]></description>
      <guid>https://arxiv.org/abs/2412.19871</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>