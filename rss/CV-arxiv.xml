<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CV 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Tue, 03 Dec 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>利用深度学习绘制全球水道地图</title>
      <link>https://arxiv.org/abs/2412.00050</link>
      <description><![CDATA[arXiv:2412.00050v1 公告类型：新
摘要：水道塑造了地球系统过程和人类社会，更好地了解它们的分布有助于从地球系统建模到人类发展和灾害响应等一系列应用。迄今为止，大多数绘制世界水道的努力都需要大量的建模和背景专家的投入，而且重复的成本很高。仍然存在许多差距，特别是在经济发展较低的地区。在这里，我们提出了一个计算机视觉模型，该模型可以基于 10m Sentinel-2 卫星图像和 30m GLO-30 哥白尼数字高程模型绘制水道，该模型使用来自美国的高保真水道数据进行训练。我们将这个模型与矢量化过程结合起来，绘制了全球水道地图。对于广泛的公用事业和下游建模工作，我们在另一个数据集 TDX-Hydro 中现有的已绘制盆地和水道的主干上支撑这些新数据。总的来说，我们在 TDX-Hydro 数据集中现有的 5400 万公里水道基础上又添加了 1.24 亿公里的水道，是全球水道覆盖范围的三倍多。]]></description>
      <guid>https://arxiv.org/abs/2412.00050</guid>
      <pubDate>Tue, 03 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用人工智能构建巴基斯坦 IGP 地区砖窑数据集</title>
      <link>https://arxiv.org/abs/2412.00052</link>
      <description><![CDATA[arXiv:2412.00052v1 公告类型：新
摘要：砖窑是巴基斯坦空气污染的主要来源，许多砖窑在运营过程中没有受到监管。巴基斯坦和印度河-恒河平原面临的一个关键挑战是空气质量监测有限，缺乏透明的污染源数据。为了解决这个问题，我们提出了一种双重人工智能方法，结合低分辨率 Sentinel-2 和高分辨率图像来绘制砖窑位置。我们的流程从低分辨率分析开始，然后是后处理步骤，以减少误报，最大限度地减少对大量高分辨率图像的需求。这项分析最初确定了 20,000 个潜在的砖窑，高分辨率验证确认了大约 11,000 个砖窑。该数据集还区分了固定烟囱和之字形窑，从而可以更准确地估计每种类型的污染。我们的方法展示了如何将卫星图像与人工智能相结合来有效地检测特定的污染源。该数据集为监管者提供了有关砖窑污染的见解，支持对未注册砖窑的干预以及高污染事件期间的行动。]]></description>
      <guid>https://arxiv.org/abs/2412.00052</guid>
      <pubDate>Tue, 03 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用视觉语言模型改善医疗诊断：基于凸包的不确定性分析</title>
      <link>https://arxiv.org/abs/2412.00056</link>
      <description><![CDATA[arXiv:2412.00056v1 公告类型：新
摘要：近年来，视觉语言模型 (VLM) 已应用于医疗保健、教育、金融和制造业等各个领域，并取得了显著的成绩。然而，人们仍然担心 VLM 的一致性和不确定性，特别是在医疗保健等需要高度信任和可靠性的关键应用中。本文提出了一种新方法，使用凸包方法在医疗保健应用中评估 VLM 响应的不确定性，用于视觉问答 (VQA)。选择 LLM-CXR 模型作为医疗 VLM，用于在不同温度设置（即 0.001、0.25、0.50、0.75 和 1.00）下为给定提示生成响应。根据结果，LLM-CXR VLM 在较高温度设置下表现出很高的不确定性。实验结果强调了 VLM 响应不确定性的重要性，尤其是在医疗保健应用中。]]></description>
      <guid>https://arxiv.org/abs/2412.00056</guid>
      <pubDate>Tue, 03 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MOSABench：用于评估多模态大型语言模型对复杂图像理解的多对象情感分析基准</title>
      <link>https://arxiv.org/abs/2412.00060</link>
      <description><![CDATA[arXiv:2412.00060v1 公告类型：新
摘要：多模态大型语言模型 (MLLM) 在视觉问答、图像字幕和情感识别等高级语义任务中取得了显著进展。然而，尽管取得了进展，但仍然缺乏标准化的基准来评估 MLLM 在多对象情绪分析中的表现，这是语义理解的一项关键任务。为了解决这一差距，我们推出了 MOSABench，这是一个专为多对象情绪分析设计的新评估数据集。MOSABench 包括大约 1,000 张具有多个对象的图像，要求 MLLM 独立评估每个对象的情绪，从而反映现实世界的复杂性。MOSABench 的主要创新包括基于距离的目标注释、用于标准化输出的评估后处理以及改进的评分机制。我们的实验揭示了当前 MLLM 的显著局限性：虽然某些模型（如 mPLUG-owl 和 Qwen-VL2）表现出对情绪相关特征的有效关注，但其他模型表现出注意力分散且性能下降，尤其是当对象之间的空间距离增加时。这项研究强调了 MLLM 需要提高复杂、多对象情绪分析任务的准确性，并将 MOSABench 确立为提高 MLLM 情绪分析能力的基础工具。]]></description>
      <guid>https://arxiv.org/abs/2412.00060</guid>
      <pubDate>Tue, 03 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DiffGuard：基于文本的扩散模型安全检查器</title>
      <link>https://arxiv.org/abs/2412.00064</link>
      <description><![CDATA[arXiv:2412.00064v1 公告类型：新
摘要：扩散模型的最新进展使得从文本生成图像成为可能，其中强大的闭源模型（如 DALL-E 和 Midjourney）处于领先地位。然而，开源替代方案（如 StabilityAI 的 Stable Diffusion）也提供了类似的功能。这些托管在 Hugging Face 上的开源模型配备了道德过滤保护，旨在防止生成露骨图像。本文首先揭示了它们的局限性，然后提出了一种新颖的基于文本的安全过滤器，其性能优于现有解决方案。我们的研究是由解决人工智能生成内容滥用的迫切需求驱动的，特别是在信息战的背景下。DiffGuard 提高了过滤效率，其性能比现有最佳过滤器高出 14% 以上。]]></description>
      <guid>https://arxiv.org/abs/2412.00064</guid>
      <pubDate>Tue, 03 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>数据删除中的靶向治疗：基于场景图的对象学习</title>
      <link>https://arxiv.org/abs/2412.00067</link>
      <description><![CDATA[arXiv:2412.00067v1 公告类型：新
摘要：用户可能会无意中将个人身份信息 (PII) 上传到机器学习即服务 (MLaaS) 提供商。当用户不再希望他们的 PII 出现在这些服务上时，GDPR 和 COPPA 等法规要求这些用户享有遗忘权。因此，这些服务寻求有效的方法来消除特定数据点的影响。因此引入了机器反学习。传统上，反学习是通过删除整个数据样本（样本反学习）或整个数据集中的整个特征（特征反学习）来执行的。然而，这些方法无法处理更细致、更具挑战性的任务，即反学习样本中的特定对象。为了解决这一差距，我们提出了一个基于场景图的对象反学习框架。该框架利用语义表示丰富的场景图，将反学习请求透明地转换为可操作的步骤。结果是保留了生成图像的整体语义完整性，但保留了未学习的对象。此外，我们使用影响函数来近似反学习过程，从而管理高计算开销。为了进行验证，我们在图像重建和图像合成任务下评估反学习对象的输出保真度。我们提出的框架展示了改进的对象反学习结果，与样本和特征学习方法相比，保留了未请求的样本。这项工作通过忘记特定的对象级细节来增加有针对性的机器反学习的粒度，同时不牺牲整个数据样本或数据集特征的效用，从而解决了关键的隐私问题。]]></description>
      <guid>https://arxiv.org/abs/2412.00067</guid>
      <pubDate>Tue, 03 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用半监督伪标记和从不同的 PET/CT 数据集学习来增强肺癌生存预测</title>
      <link>https://arxiv.org/abs/2412.00068</link>
      <description><![CDATA[arXiv:2412.00068v1 公告类型：新
摘要：目的：本研究探索一种半监督学习 (SSL)，使用不同数据集的伪标记策略来增强肺癌 (LCa) 生存预测，使用混合机器学习系统 (HMLS) 分析 PET/CT 扫描中的手工制作和深度放射特征 (HRF/DRF)。方法：我们收集了 199 名 LCa 患者的 PET 和 CT 图像，这些图像来自癌症影像档案 (TCIA) 和我们的本地数据库，以及来自 TCIA 的 408 张头颈癌 (HNCa) PET/CT 图像。我们分别使用 PySERA 和 ViSERA 软件中的 3D-Autoencoder 从分割的原发性肿瘤中提取了 215 个 HRF 和 1024 个 DRF。监督策略 (SL) 采用 HMLSs：PCA 与 HRF 和 DRF 上的 4 个分类器相连。 SSL 策略使用相同的 HMLS 技术，将 408 个伪标记 HNCa 病例（由随机森林算法标记）添加到 199 个 LCa 病例中，从而扩展了数据集。此外，在生存风险比分析中使用了与 4 种生存预测算法相关的主成分分析 (PCA)。结果：SSL 策略优于 SL 方法（p 值 &lt;0.05），使用来自 PET 和 PCA+多层感知器 (MLP) 的 DRF 实现 0.85 的平均准确度，而使用来自 CT 和 PCA+K 最近邻 (KNN) 的 DRF 的 SL 策略为 0.65。此外，对从 CT 中提取的 HRF 和 DRF 进行与分量梯度提升生存分析相关的 PCA 的平均 c 指数为 0.80，对数秩 p 值 &lt;&lt;0.001，经外部测试证实。结论：从 HRF 和 SL 转向 DRF 和 SSL 策略，特别是在数据点有限的情况下，单独使用 CT 或 PET 就能显著实现高预测性能。]]></description>
      <guid>https://arxiv.org/abs/2412.00068</guid>
      <pubDate>Tue, 03 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>解决人工智能图像检测中的漏洞：挑战和建议的解决方案</title>
      <link>https://arxiv.org/abs/2412.00073</link>
      <description><![CDATA[arXiv:2412.00073v1 公告类型：新 
摘要：生成对抗网络 (GAN) 等先进 AI 模型和稳定扩散等扩散模型的兴起使得创建高度逼真的图像变得容易，但也带来了误用和操纵的风险。本研究评估了卷积神经网络 (CNN) 以及 DenseNet 架构在检测 AI 生成图像方面的有效性。使用 CIFAKE 数据集的变体（包括由不同版本的稳定扩散生成的图像）​​，我们分析了高斯模糊、提示文本更改和低秩自适应 (LoRA) 等更新和修改对检测准确性的影响。研究结果突出了当前检测方法中的漏洞，并提出了增强 AI 图像检测系统的稳健性和可靠性的策略。]]></description>
      <guid>https://arxiv.org/abs/2412.00073</guid>
      <pubDate>Tue, 03 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>计算机视觉最受欢迎的数据集 ImageNet 的缺陷</title>
      <link>https://arxiv.org/abs/2412.00076</link>
      <description><![CDATA[arXiv:2412.00076v1 公告类型：新
摘要：自发布以来，ImageNet-1k 数据集已成为评估模型性能的黄金标准。它已成为计算机视觉中许多其他数据集和训练任务的基础。随着模型准确性的提高，与标签正确性相关的问题变得越来越明显。在这篇博文中，我们分析了 ImageNet-1k 数据集中的问题，包括不正确的标签、重叠或模糊的类定义、训练-评估域转移和图像重复。一些问题的解决方案很简单。对于其他问题，我们希望就改进这个有影响力的数据集展开更广泛的讨论，以更好地服务于未来的研究。]]></description>
      <guid>https://arxiv.org/abs/2412.00076</guid>
      <pubDate>Tue, 03 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>自私进化：借助过度拟合动力学在极端标签噪声中进行发现</title>
      <link>https://arxiv.org/abs/2412.00077</link>
      <description><![CDATA[arXiv:2412.00077v1 公告类型：新
摘要：由于天体物理应用中适当标签的稀缺性，我们开发了一种称为自私进化的新技术，该技术允许以弱监督方式检测和纠正损坏的标签。与基于早期停止的方法不同，我们让模型在嘈杂的数据集上进行训练。只有这样我们才会进行干预并允许模型过度拟合单个样本。在此过程中，模型的“进化”揭示了具有足够信息的模式，包括标签的噪声以及其正确版本。我们在这些时空“进化立方体”上训练了一个二级网络，以纠正可能损坏的标签。我们以闭环方式整合该技术，允许自动收敛到几乎干净的数据集，而无需假设我们干预的网络的状态。我们对超新星狩猎数据集的主要任务进行评估，同时也展示了更标准的 MNIST 数据集上的效率。]]></description>
      <guid>https://arxiv.org/abs/2412.00077</guid>
      <pubDate>Tue, 03 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>残余注意单头视觉变换网络用于噪声环境下滚动轴承故障诊断</title>
      <link>https://arxiv.org/abs/2412.00085</link>
      <description><![CDATA[arXiv:2412.00085v1 公告类型：新 
摘要：滚动轴承在工业机械中起着至关重要的作用，直接影响设备的性能、耐用性和安全性。然而，高速度和高温等恶劣的操作条件经常导致轴承故障，从而造成停机、经济损失和安全隐患。本文提出了用于滚动轴承故障诊断的残差注意单头视觉变换器网络 (RA-SHViT-Net)。振动信号在通过 RA-SHViT-Net 处理之前，使用快速傅里叶变换 (FFT) 从时域转换为频域。该模型采用单头视觉变换器 (SHViT) 来捕获局部和全局特征，平衡计算效率和预测准确性。为了增强特征提取，自适应混合注意块 (AHAB) 集成了通道和空间注意机制。网络架构包括深度卷积、单头自注意力、残差前馈网络 (Res-FFN) 和 AHAB 模块，确保稳健的特征表示并缓解梯度消失问题。对凯斯西储大学和帕德博恩大学数据集的评估证明了 RA-SHViT-Net 在复杂、嘈杂环境中的卓越准确性和稳健性。消融研究进一步验证了各个组件的贡献，确立了 RA-SHViT-Net 作为早期故障检测和分类的有效工具，促进了工业环境中的有效维护策略。
关键词：滚动轴承、故障诊断、视觉变换器、注意力机制、嘈杂环境、快速傅里叶变换 (FFT)]]></description>
      <guid>https://arxiv.org/abs/2412.00085</guid>
      <pubDate>Tue, 03 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于可控 3D 场景生成的 Graph Canvas</title>
      <link>https://arxiv.org/abs/2412.00091</link>
      <description><![CDATA[arXiv:2412.00091v1 公告类型：新
摘要：空间智能是与物理世界交互的 AI 系统的基础，特别是在 3D 场景生成和空间理解方面。当前的 3D 场景生成方法通常严重依赖预定义的数据集，并且难以动态适应不断变化的空间关系。在本文中，我们介绍了 \textbf{GraphCanvas3D}，这是一个可编程、可扩展且适应性强的可控 3D 场景生成框架。利用上下文学习，GraphCanvas3D 无需重新训练即可实现动态适应性，支持灵活且可定制的场景创建。我们的框架采用分层的图形驱动场景描述，将空间元素表示为图形节点，并在 3D 环境中的对象之间建立连贯的关系。与传统方法不同，传统方法在适应性方面受到限制，通常需要预定义的输入掩码或重新训练以进行修改，而 GraphCanvas3D 允许无缝操作对象和动态调整场景。此外，GraphCanvas3D 支持 4D 场景生成，结合时间动态来模拟随时间的变化。实验结果和用户研究表明，GraphCanvas3D 增强了场景生成的可用性、灵活性和适应性。我们的代码和模型可在项目网站上找到：https://github.com/ILGLJ/Graph-Canvas。]]></description>
      <guid>https://arxiv.org/abs/2412.00091</guid>
      <pubDate>Tue, 03 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>OFCap：用于图像字幕的对象感知融合</title>
      <link>https://arxiv.org/abs/2412.00095</link>
      <description><![CDATA[arXiv:2412.00095v1 公告类型：新
摘要：图像字幕是一种将图像内容转换为自然语言描述的技术。许多应用场景，例如智能搜索引擎和视障人士的辅助工具，都涉及包含人物的图像。因此，数据集中通常有大量以人物为特色的图像。然而，这种数据不平衡可能导致过度拟合。该模型在为没有人的图像生成描述时可能表现不佳，甚至可能产生不相关的描述（幻觉）。为了解决这个问题，增加数据集的多样性可能是一个有效的解决方案。然而，获取高质量的图像-文本对的成本很高。在不改变数据集的情况下减少过度拟合可以显著节省资源。为了应对这一挑战，我们提出了一种目标感知提示策略。该方法使用对象检测器从图像中提取对象信息，并通过融合模块将这些信息集成到模型中。这有助于模型生成带有附加参考的描述（\textbf{OFCap}）。此外，该策略与模型无关。训练过程中可以使用预训练模型和固定参数，进一步降低计算成本。我们在 COCO 和 nocpas 数据集上进行了实验。结果表明，该策略有效缓解了过拟合，并显著提高了图像描述的质量。]]></description>
      <guid>https://arxiv.org/abs/2412.00095</guid>
      <pubDate>Tue, 03 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>控制矢量场中的整流流模型以生成受控图像</title>
      <link>https://arxiv.org/abs/2412.00100</link>
      <description><![CDATA[arXiv:2412.00100v1 公告类型：新
摘要：借助无分类器引导和图像反演技术，扩散模型 (DM) 在照片级真实感、图像编辑和解决逆问题方面表现出色。然而，整流流模型 (RFM) 在这些任务中仍未得到充分探索。现有的基于 DM 的方法通常需要额外的训练，缺乏对预训练潜在模型的泛化，表现不佳，并且由于通过 ODE 求解器和反演过程进行大量反向传播而需要大量计算资源。在这项工作中，我们首先从理论和经验上理解 RFM 的矢量场动力学，以有效地引导去噪轨迹。我们的研究结果表明，我们可以以确定性和无梯度的方式导航矢量场。利用这一特性，我们提出了 FlowChef，它利用矢量场来引导受控图像生成任务的去噪轨迹，并通过梯度跳跃来实现。 FlowChef 是一个统一的受控图像生成框架，它首次同时解决了分类器引导、线性逆问题和图像编辑问题，而无需额外的训练、逆向或密集的反向传播。最后，我们进行了广泛的评估，并表明 FlowChef 在性能、内存和时间要求方面明显优于基线，取得了新的最佳结果。项目页面：\url{https://flowchef.github.io}。]]></description>
      <guid>https://arxiv.org/abs/2412.00100</guid>
      <pubDate>Tue, 03 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ElectroVizQA：多模式 LLM 在电子视觉问答中的表现如何？</title>
      <link>https://arxiv.org/abs/2412.00102</link>
      <description><![CDATA[arXiv:2412.00102v1 公告类型：新
摘要：多模态大型语言模型 (MLLM) 因其处理多模态数据的能力而备受关注，可增强对复杂问题的上下文理解。MLLM 在视觉问答 (VQA) 等任务中表现出色；然而，它们经常在基本工程问题上挣扎，而且缺乏用于数字电子等主题训练的专门数据集。为了解决这一差距，我们提出了一个名为 ElectroVizQA 的基准数据集，专门用于评估 MLLM 在本科课程中常见的数字电子电路问题上的表现。该数据集是第一个为数字电子领域的 VQA 任务量身定制的数据集，包含大约 626 个视觉问题，全面概述了数字电子主题。本文严格评估了 MLLM 理解和解决数字电子电路问题的程度，深入了解了它们在这个专业领域的能力和局限性。通过引入这个基准数据集，我们旨在促进 MLLM 在工程教育中的应用的进一步研究和开发，最终缩小性能差距并提高这些模型在技术领域的有效性。]]></description>
      <guid>https://arxiv.org/abs/2412.00102</guid>
      <pubDate>Tue, 03 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>