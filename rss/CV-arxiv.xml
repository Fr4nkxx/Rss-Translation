<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CV 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Mon, 06 Jan 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>LS-GAN：使用潜在空间 GAN 进行人体运动合成</title>
      <link>https://arxiv.org/abs/2501.01449</link>
      <description><![CDATA[arXiv:2501.01449v1 公告类型：新
摘要：近年来，以文本输入为条件的人体运动合成因其在游戏、电影制作和虚拟现实等各个领域的潜在应用而备受关注。条件运动合成以文本为输入，输出与文本相对应的 3D 运动。虽然之前的研究已经探索了使用原始运动数据和潜在空间表示与扩散模型进行运动合成，但这些方法通常存在训练和推理时间较长的问题。在本文中，我们介绍了一种新颖的框架，该框架利用潜在空间中的生成对抗网络 (GAN) 来实现更快的训练和推理，同时实现与最先进的扩散方法相当的结果。我们在 HumanML3D、HumanAct12 基准上进行了实验，并证明与潜在扩散模型相比，潜在空间中非常简单的 GAN 实现了 0.482 的 FID，FLOP 减少了 91% 以上。我们的工作为使用潜在空间 GAN 实现高效、高质量的运动合成开辟了新的可能性。]]></description>
      <guid>https://arxiv.org/abs/2501.01449</guid>
      <pubDate>Mon, 06 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>更安全：通过锐度感知层选择性微调来增强视觉转换器的鲁棒性</title>
      <link>https://arxiv.org/abs/2501.01529</link>
      <description><![CDATA[arXiv:2501.01529v1 公告类型：新
摘要：视觉变换器 (ViT) 已成为高级计算机视觉应用和多模态基础模型中必不可少的支柱。尽管 ViT 具有优势，但它仍然容易受到对抗性干扰，其脆弱性堪比甚至超过卷积神经网络 (CNN)。此外，ViT 的大量参数数量和复杂架构使它们特别容易受到对抗性过度拟合的影响，通常会损害清洁和对抗准确性。
本文通过一种新颖的层选择性微调方法 SAFER 来缓解 ViT 中的对抗性过度拟合。我们不是优化整个模型，而是识别并选择性地微调最容易过度拟合的一小部分层，对这些层应用锐度感知最小化，同时冻结模型的其余部分。与基线方法相比，我们的方法始终如一地提高了清洁和对抗准确性。典型的改进幅度约为 5%，在某些情况下，在各种 ViT 架构和数据集中可实现高达 20% 的改进。]]></description>
      <guid>https://arxiv.org/abs/2501.01529</guid>
      <pubDate>Mon, 06 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>任务驱动注视网络：具有注视选择功能的高效架构</title>
      <link>https://arxiv.org/abs/2501.01548</link>
      <description><![CDATA[arXiv:2501.01548v1 公告类型：新
摘要：本文提出了一种具有自动注视点选择的新型神经网络架构，旨在以减少网络规模和计算开销的方式有效解决复杂任务。所提出的模型包括：从输入图像中捕获低分辨率全局特征的低分辨率通道；顺序提取局部高分辨率特征的高分辨率通道；以及集成两个通道特征的混合编码模块。混合编码模块的一个定义特征是包含一个注视点生成器，它可以动态生成注视点，使高分辨率通道能够聚焦于感兴趣的区域。注视点以任务驱动的方式生成，从而可以自动选择感兴趣的区域。这种方法避免了对整个图像进行详尽的高分辨率分析，从而保持了任务性能和计算效率。]]></description>
      <guid>https://arxiv.org/abs/2501.01548</guid>
      <pubDate>Mon, 06 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Click-Calib：一种用于环视系统的稳健外部校准方法</title>
      <link>https://arxiv.org/abs/2501.01557</link>
      <description><![CDATA[arXiv:2501.01557v1 公告类型：新
摘要：环视系统 (SVS) 是高级驾驶辅助系统 (ADAS) 的重要组成部分，需要精确校准。然而，传统的离线外部校准方法繁琐且耗时，因为它们严重依赖物理模式。此外，这些方法主要关注车辆周围的短距离区域，导致较远区域的校准质量较低。为了解决这些限制，我们提出了 Click-Calib，一种无模式的离线 SVS 外部校准方法。无需任何特殊设置，用户只需在自然场景中单击地面上的几个关键点即可。与其他离线校准方法不同，Click-Calib 通过最小化关键点的重新投影距离误差来优化大范围内的相机姿势，从而实现短距离和长距离的精确校准。此外，Click-Calib 支持单帧和多帧模式，后者提供更好的结果。对我们内部数据集和公共 WoodScape 数据集的评估表明，与基线方法相比，其准确性和稳健性更高。代码可在 https://github.com/lwangvaleo/click_calib 上获取。]]></description>
      <guid>https://arxiv.org/abs/2501.01557</guid>
      <pubDate>Mon, 06 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>D$^3$-Human：从单目视频中动态解开的数字人</title>
      <link>https://arxiv.org/abs/2501.01589</link>
      <description><![CDATA[arXiv:2501.01589v1 公告类型：新
摘要：我们介绍了一种从单目视频重建动态解缠数字人体几何的方法 D$^3$-Human。过去的单目视频人体重建主要侧重于重建未耦合的着衣人体或仅重建服装，因此很难直接应用于动画制作等应用。重建解耦的服装和身体的挑战在于服装在身体上造成的遮挡。为此，在重建过程中必须确保可见区域的细节和不可见区域的合理性。我们提出的方法结合显式和隐式表示来建模解耦的着衣人体，利用显式表示的鲁棒性和隐式表示的灵活性。具体而言，我们将可见区域重建为 SDF，并提出一种新颖的人体流形有符号距离场 (hmSDF) 来分割可见的服装和可见的身体，然后合并可见和不可见的身体。大量实验结果表明，与现有的重建方案相比，D$^3$-Human可以实现人体穿着不同服装的高质量解耦重建，并可直接应用于服装传输和动画。]]></description>
      <guid>https://arxiv.org/abs/2501.01589</guid>
      <pubDate>Mon, 06 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>自适应同质性聚类：一种用于高光谱图像的自适应滤波器结构同质性图学习</title>
      <link>https://arxiv.org/abs/2501.01595</link>
      <description><![CDATA[arXiv:2501.01595v1 公告类型：新
摘要：高光谱图像 (HSI) 聚类是一项基本但具有挑战性的任务，没有训练标签。目前，一些深度图聚类方法已经成功地应用于 HSI，因为它们在有效的空间结构信息编码方面表现出色。然而，结构信息利用不足、特征呈现能力差和图更新能力弱限制了它们的性能。因此，本文提出了一种用于 HSI 的自适应滤波器聚类方法 (AHSGC) 的同质结构图学习。具体而言，首先开发同质区域生成以进行 HSI 处理并构建原始图。然后，设计一个自适应滤波器图编码器来自适应地捕获图上的高频和低频特征以进行子序列处理。然后，使用 KL 散度开发一个图嵌入聚类自训练解码器，使用该解码器生成伪标签进行网络训练。同时，引入同质性增强结构学习，根据聚类任务更新图，其中采用方向相关性估计来估计节点连接，并设计图边稀疏化来动态调整图中的边。最后，引入联合网络优化来实现网络自训练和更新图。采用K均值来表达潜在特征。大量实验和反复的比较分析证明了我们的AHSGC具有较高的聚类精度、较低的计算复杂度和较强的鲁棒性。代码源将在https://github.com/DY-HYX上提供。]]></description>
      <guid>https://arxiv.org/abs/2501.01595</guid>
      <pubDate>Mon, 06 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过等方差实现小样本隐式函数生成</title>
      <link>https://arxiv.org/abs/2501.01601</link>
      <description><![CDATA[arXiv:2501.01601v1 公告类型：新
摘要：隐式神经表征 (INR) 已成为表示连续信号的强大框架。然而，由于训练数据有限，生成多样化的 INR 权重仍然具有挑战性。我们引入了少样本隐式函数生成，这是一种新的问题设置，旨在仅从几个示例中生成多样化但功能一致的 INR 权重。这很有挑战性，因为即使对于相同的信号，最佳 INR 也会根据其初始化而有很大差异。为了解决这个问题，我们提出了 EquiGen，这是一个可以从有限数据中生成新 INR 的框架。核心思想是功能相似的网络可以通过权重排列相互转换，形成等方差组。通过将这些权重投影到等变潜在空间中，即使只有很少的示例，我们也可以在这些组内实现多样化的生成。 EquiGen 通过对比学习和平滑增强训练的等变编码器、等变引导扩散过程和等变子空间中的受控扰动来实现这一点。在 2D 图像和 3D 形状 INR 数据集上进行的实验表明，我们的方法可以有效地生成不同的 INR 权重，同时在少量场景中保留其功能特性。]]></description>
      <guid>https://arxiv.org/abs/2501.01601</guid>
      <pubDate>Mon, 06 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>你所需要的就是 Google：用于轻量级多模态多任务分类模型的半监督迁移学习策略</title>
      <link>https://arxiv.org/abs/2501.01611</link>
      <description><![CDATA[arXiv:2501.01611v1 公告类型：新
摘要：随着数字图像数据量的增加，图像分类的有效性也随之增强。本研究引入了一种强大的多标签分类系统，旨在为单个图像分配多个标签，解决可能与多个类别（范围从 1 到 19，不包括 12）相关的图像的复杂性。我们提出了一种多模态分类器，将高级图像识别算法与自然语言处理 (NLP) 模型相结合，并结合融合模块来整合这些不同的模态。整合文本数据的目的是通过提供仅靠视觉分析无法完全捕捉的上下文理解来提高标签预测的准确性。我们提出的分类模型将用于图像处理的卷积神经网络 (CNN) 与用于分析文本描述（即标题）的 NLP 技术相结合。这种方法包括严格的训练和验证阶段，每个模型组件都通过消融实验进行验证和分析。初步结果证明了分类器的准确性和效率，凸显了其作为自动图像标记系统的潜力。]]></description>
      <guid>https://arxiv.org/abs/2501.01611</guid>
      <pubDate>Mon, 06 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>将上下文聚类与视觉状态空间模型相结合进行医学图像分割</title>
      <link>https://arxiv.org/abs/2501.01618</link>
      <description><![CDATA[arXiv:2501.01618v1 公告类型：新
摘要：医学图像分割需要聚合全局和局部特征表示，这对当前处理长距离和短距离特征交互的方法提出了挑战。最近，视觉曼巴 (ViM) 模型已成为解决模型复杂性的有希望的解决方案，它在线性复杂度的长距离特征迭代中表现出色。然而，现有的 ViM 方法忽视了通过直接展平空间标记来保留短距离局部依赖性的重要性，并且受到限制动态空间上下文信息捕获的固定扫描模式的限制。为了应对这些挑战，我们引入了一种简单而有效的方法，称为上下文聚类 ViM (CCViM)，它在现有的 ViM 模型中整合了一个上下文聚类模块，将图像标记分割成不同的窗口，以实现适应性局部聚类。我们的方法有效地结合了长距离和短距离特征交互，从而增强了医学图像分割任务的空间上下文表示。在各种公共数据集（例如 Kumar、CPM17、ISIC17、ISIC18 和 Synapse）上进行的大量实验评估表明，与当前最先进的方法相比，我们的方法具有更优越的性能。我们的代码可以在 https://github.com/zymissy/CCViM 找到。]]></description>
      <guid>https://arxiv.org/abs/2501.01618</guid>
      <pubDate>Mon, 06 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ACE：文本转图像模型中的反编辑概念擦除</title>
      <link>https://arxiv.org/abs/2501.01633</link>
      <description><![CDATA[arXiv:2501.01633v1 公告类型：新
摘要：文本到图像传播模型的最新进展极大地促进了高质量图像的生成，但也引发了对非法创建有害内容（例如受版权保护的图像）的担忧。现有的概念擦除方法在防止提示产生被擦除的概念方面取得了优异的效果，但在防止不必要的编辑方面通常表现不佳。为了解决这个问题，我们提出了一种反编辑概念擦除 (ACE) 方法，它不仅在生成过程中擦除目标概念，而且在编辑过程中将其过滤掉。具体而言，我们建议将擦除指导注入条件和无条件噪声预测中，使模型能够有效地防止在编辑和生成过程中产生擦除概念。此外，在训练过程中引入了随机校正指导来解决不相关概念的侵蚀问题。我们利用代表性编辑方法（例如 LEDITS++ 和 MasaCtrl）进行了擦除编辑实验，以擦除 IP 字符，结果表明我们的 ACE 能够有效过滤掉两种编辑类型的目标概念。擦除明确概念和艺术风格的额外实验进一步表明，我们的 ACE 的表现优于最先进的方法。我们的代码将在 https://github.com/120L020904/ACE 上公开提供。]]></description>
      <guid>https://arxiv.org/abs/2501.01633</guid>
      <pubDate>Mon, 06 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于不确定性和能量的损失引导半监督语义分割</title>
      <link>https://arxiv.org/abs/2501.01640</link>
      <description><![CDATA[arXiv:2501.01640v1 公告类型：新
摘要：半监督 (SS) 语义分割利用标记和未标记的图像来克服繁琐且昂贵的像素级注释问题。伪标签监督是使用伪标签和地面实况标签训练网络的核心方法之一。这项工作在交叉并集伪监督网络中使用随机或数据不确定性和基于能量的建模。随机不确定性正在使用两个预测分支对网络中数据的固有噪声变化进行建模。从网络获得的每像素方差参数给出了数据不确定性的定量概念。此外，基于能量的损失实现了下游 SS 分割任务上生成建模的潜力。随机和能量损失与相应网络分支上的伪交叉标签、伪并集标签和地面实况结合应用。与最先进方法的比较分析表明性能指标有所改善。]]></description>
      <guid>https://arxiv.org/abs/2501.01640</guid>
      <pubDate>Mon, 06 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>iCBIR-Sli：使用 2D 切片嵌入进行可解释的基于内容的图像检索</title>
      <link>https://arxiv.org/abs/2501.01642</link>
      <description><![CDATA[arXiv:2501.01642v1 公告类型：新
摘要：当前搜索脑部 MRI 图像的方法依赖于基于文本的方法，这凸显了对基于内容的图像检索 (CBIR) 系统的巨大需求。将 3D 脑部 MRI 图像直接应用于机器学习模型可以有效地学习大脑的结构；然而，构建通用模型需要大量的训练数据。虽然考虑深度方向并利用连续 2D 切片的模型已证明在涉及 3D 数据的分割和分类任务中取得了成功，但仍然存在问题。具体而言，使用一般的 2D 切片可能会导致忽视病理特征和深度方向信息的不连续性。此外，据作者所知，还没有尝试开发一种实用的 CBIR 系统来保存整个大脑的结构信息。在本研究中，我们提出了一种可解释的脑 MRI 图像 CBIR 方法，称为 iCBIR-Sli（具有 2D 切片嵌入的可解释 CBIR），这是全球首次使用一系列 2D 切片。iCBIR-Sli 通过有效地聚合切片信息解决了使用 2D 切片所带来的挑战，从而实现了具有高完整性、可用性、稳健性和互操作性的低维表示，这些是有效 CBIR 所必需的品质。在利用五个公开可用的脑 MR 数据集（ADNI2/3、OASIS3/4、AIBL）对阿尔茨海默病和认知正常进行检索评估实验中，iCBIR-Sli 表现出 top-1 检索性能（宏 F1 = 0.859），可与专门为分类而设计的现有深度学习模型相媲美，而无需外部分类器。此外，该方法通过清晰地识别指示所搜索疾病的大脑区域提供了很高的可解释性。]]></description>
      <guid>https://arxiv.org/abs/2501.01642</guid>
      <pubDate>Mon, 06 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>HLV-1K：用于特定时间长视频理解的大规模一小时视频基准</title>
      <link>https://arxiv.org/abs/2501.01645</link>
      <description><![CDATA[arXiv:2501.01645v1 公告类型：新
摘要：由于许多有前景的实际应用，多模态大型语言模型已成为深度视觉理解的热门话题。然而，由于 1）具有挑战性的长期视频分析、2）效率低下的大型模型方法和 3）缺乏大规模基准数据集，长达一小时的视频理解（持续时间超过一小时并包含数万个视觉帧）仍未得到充分探索。其中，在本文中，我们专注于构建一个大规模的长达一小时的长视频基准 HLV-1K，旨在评估长视频理解模型。HLV-1K 包含 1009 个长达一小时的视频，其中包含 14,847 个高质量问答 (QA) 和多项选择题 (MCQA) 对，具有时间感知查询和多样化注释，涵盖帧级、事件内级、跨事件级和长期推理任务。我们使用现有的最先进方法评估我们的基准，并证明其在不同级别和各种任务中测试深度长视频理解能力的价值。这包括在细粒度级别推动未来的长视频理解任务，例如对长直播视频、会议录音和电影的深入理解。]]></description>
      <guid>https://arxiv.org/abs/2501.01645</guid>
      <pubDate>Mon, 06 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有全局-局部感知的对偶互学习网络，用于 RGB-D 显著物体检测</title>
      <link>https://arxiv.org/abs/2501.01648</link>
      <description><![CDATA[arXiv:2501.01648v1 公告类型：新
摘要：RGB-D 显著性物体检测 (SOD) 旨在通过联合建模 RGB 和深度信息来突出显示给定场景的显著区域，是一项具有挑战性的像素级预测任务。最近，双注意机制因其能够加强检测过程而致力于这一领域。然而，大多数现有方法在手动强制融合范式下直接融合注意跨模态特征，而不考虑 RGB 和深度之间的固有差异，这可能会导致性能下降。此外，从全局和局部信息中得出的长距离依赖关系使得难以利用统一有效的融合策略。因此，在本文中，我们提出了 GL-DMNet，一种具有全局-局部意识的新型双相互学习网络。具体而言，我们提出了一个位置相互融合模块和一个通道相互融合模块，以利用空间和通道维度上不同模态之间的相互依赖性。此外，我们采用了基于级联变压器注入重建的高效解码器来联合集成多级融合特征。在六个基准数据集上进行的大量实验表明，我们提出的 GL-DMNet 比 24 种 RGB-D SOD 方法表现更好，与排名第二的模型 (S3Net) 相比，在四个评估指标上平均提高了约 3%。代码和结果可在 https://github.com/kingkung2016/GL-DMNet 上找到。]]></description>
      <guid>https://arxiv.org/abs/2501.01648</guid>
      <pubDate>Mon, 06 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>EAUWSeg：消除弱监督医学图像分割中的注释不确定性</title>
      <link>https://arxiv.org/abs/2501.01658</link>
      <description><![CDATA[arXiv:2501.01658v1 公告类型：新
摘要：弱监督医学图像分割越来越受到关注，因为它只需要粗略的注释而不是精确的像素到像素标签，从而减少了专家的工作量。尽管取得了一些进展，但标签高效方法和全监督方法之间仍然存在相当大的性能差距，这可以归因于这些弱标签的不确定性。为了解决这个问题，我们提出了一种新的弱注释方法，结合其学习框架 EAUWSeg 来消除注释的不确定性。具体来说，我们首先提出了有界多边形注释 (BPAnno)，只需为一个病变标记两个多边形。然后，提出了一种定制的学习机制，明确将有界多边形视为两个独立的注释，通过为模型训练提供对抗性监督信号来学习不变特征。随后，设计了一个置信度辅助一致性学习器与分类引导置信度生成器相结合，利用同一类别内像素之间的特征呈现一致性以及有界多边形注释中封装的类特定信息，为不确定区域中的像素提供可靠的监督信号。实验结果表明，EAUWSeg 优于现有的弱监督分割方法。此外，与全监督方法相比，所提出的方法不仅性能卓越，而且注释工作量也少得多。这凸显了我们方法的优越性和有效性。]]></description>
      <guid>https://arxiv.org/abs/2501.01658</guid>
      <pubDate>Mon, 06 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>