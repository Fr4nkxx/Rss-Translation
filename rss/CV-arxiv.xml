<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CV 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Tue, 12 Nov 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>SPACE：空间感知一致性正则化，用于工业应用中的异常检测</title>
      <link>https://arxiv.org/abs/2411.05822</link>
      <description><![CDATA[arXiv:2411.05822v1 公告类型：新
摘要：在本文中，我们提出了一种新颖的异常检测方法 SPACE，该方法将特征编码器 (FE) 集成到学生-教师方法的结构中。所提出的方法有两个关键要素：空间一致性正则化损失 (SCL) 和特征转换器模块 (FM)。SCL 通过避免过度模仿教师模型来防止学生模型中的过度拟合。同时，它通过避开通过数据增强生成的异常区域来促进正常数据特征的扩展。这种双重功能可确保正常数据和异常数据之间的稳健边界。FM 可防止从 FE 中学习模糊信息。这保护了学习到的特征并能够更有效地检测结构和逻辑异常。通过这些元素，SPACE 可用于在集成各种数据增强的同时最大限度地减少 FE 的影响。在本研究中，我们在 MVTec LOCO、MVTec AD 和 VisA 数据集上评估了所提出的方法。实验结果通过定性评估证明了与最先进的方法相比每个模块的检测和效率的优越性。]]></description>
      <guid>https://arxiv.org/abs/2411.05822</guid>
      <pubDate>Tue, 12 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>FlexCAD：具有精细调整的大型语言模型的统一、多功能可控 CAD 生成</title>
      <link>https://arxiv.org/abs/2411.05823</link>
      <description><![CDATA[arXiv:2411.05823v1 公告类型：新 
摘要：最近，人们对基于用户意图创建计算机辅助设计 (CAD) 模型的兴趣日益浓厚，这被称为可控 CAD 生成。现有工作提供的可控性有限，需要为不同类型的控制建立单独的模型，从而降低了效率和实用性。为了实现跨所有 CAD 构造层次结构的可控生成，例如草图挤压、挤压、草图、面、循环和曲线，我们提出了 FlexCAD，这是一个通过微调大型语言模型 (LLM) 而形成的统一模型。首先，为了增强 LLM 的理解力，我们将 CAD 模型表示为结构化文本，将每个层次结构抽象为一系列文本标记。其次，为了在统一模型中解决各种可控生成任务，我们引入了一种层次感知掩码策略。具体而言，在训练期间，我们使用掩码标记来掩码 CAD 文本中的层次感知字段。该字段由一系列标记组成，可以灵活设置以表示各种层次结构。随后，我们要求 LLM 预测这个掩码字段。在推理过程中，用户意图被转换为 CAD 文本，其中掩码标记替换用户想要修改的部分，然后将其输入到 FlexCAD 中以生成新的 CAD 模型。在公共数据集上进行的全面实验证明了 FlexCAD 在生成质量和可控性方面的有效性。代码将在 https://github.com/microsoft/CADGeneration/FlexCAD 上提供。]]></description>
      <guid>https://arxiv.org/abs/2411.05823</guid>
      <pubDate>Tue, 12 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从像素到散文：推进遥感多模态语言模型</title>
      <link>https://arxiv.org/abs/2411.05826</link>
      <description><![CDATA[arXiv:2411.05826v1 公告类型：新
摘要：遥感已从简单的图像采集发展为能够集成和处理视觉和文本数据的复杂系统。本综述研究了多模态语言模型 (MLLM) 在遥感领域的发展和应用，重点关注它们使用自然语言解释和描述卫星图像的能力。我们介绍了 MLLM 的技术基础，包括双编码器架构、Transformer 模型、自监督和对比学习以及跨模态集成。分析了遥感数据的独特挑战——不同的空间分辨率、光谱丰富度和时间变化——对 MLLM 性能的影响。讨论了场景描述、对象检测、变化检测、文本到图像检索、图像到文本生成和视觉问答等关键应用，以证明它们在环境监测、城市规划和灾害响应中的相关性。我们回顾了支持这些模型的训练和评估的重要数据集和资源。重点介绍了与计算需求、可扩展性、数据质量和领域适应性相关的挑战。最后，我们提出了未来的研究方向和技术进步，以进一步增强 MLLM 在遥感领域的实用性。]]></description>
      <guid>https://arxiv.org/abs/2411.05826</guid>
      <pubDate>Tue, 12 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>头骨雕刻的稳定性理论</title>
      <link>https://arxiv.org/abs/2411.05827</link>
      <description><![CDATA[arXiv:2411.05827v1 公告类型：新
摘要：面部运动的精确稳定对于 3D 游戏、虚拟现实、电影和训练数据收集的照片级虚拟形象构建应用至关重要。对于后者，稳定必须自动适用于具有不同形态的普通人群。区分刚性头骨运动和面部表情至关重要，因为头骨运动和面部表情之间的错位会导致动画模型难以控制并且无法适应自然运动。现有方法难以处理非常不同的稀疏表情集，例如当组合来自面部动作编码系统 (FACS) 的多个单元时。某些方法不够稳健，有些方法依赖运动数据来找到稳定点，而另一些方法则做出一刀切的无效生理假设。在本文中，我们利用神经有符号距离场和可微等值面网格的最新进展，直接在非结构化三角网格或点云上计算头骨稳定刚性变换，显着提高准确性和稳健性。我们引入了稳定外壳的概念，作为稳定扫描布尔交集的表面，类似于从轮廓中获取形状的视觉外壳和从空间雕刻中获取的照片外壳。该外壳类似于覆盖有最小软组织厚度的头骨，上牙自动包含在内。我们的头骨雕刻算法同时优化了稳定外壳形状和刚性变换，从而为大量不同的人群获得复杂表情的精确稳定，优于现有方法。]]></description>
      <guid>https://arxiv.org/abs/2411.05827</guid>
      <pubDate>Tue, 12 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多样化、情境化和适应性：神经图像编解码器的高效熵建模</title>
      <link>https://arxiv.org/abs/2411.05832</link>
      <description><![CDATA[arXiv:2411.05832v1 公告类型：新
摘要：设计一个快速有效的熵模型具有挑战性，但对于神经编解码器的实际应用至关重要。除了空间自回归熵模型之外，最近还开发了更高效的基于后向自适应的熵模型。它们不仅通过使用较少的建模步骤来减少解码时间，而且还通过利用更多样化的上下文进行后向自适应来保持甚至改善速率失真性能。尽管它们取得了重大进展，但我们认为它们的性能受到前向自适应设计惯例的简单采用的限制：仅使用单一类型的超潜在表示，这不能提供足够的上下文信息，尤其是在第一个建模步骤中。在本文中，我们提出了一个简单而有效的熵建模框架，该框架利用足够的上下文进行前向自适应而不会影响比特率。具体而言，我们引入了一种多样化超潜在表示以进行前向自适应的策略，即除了现有的单一类型的上下文外，还使用两种额外的上下文类型。此外，我们提出了一种有效利用不同上下文来对当前要编码/解码的元素进行上下文化的方法。通过解决以前方法的局限性，我们提出的框架可显著提高性能。在流行数据集上的实验结果表明，我们提出的框架可持续提高各种比特率区域的速率失真性能，例如，与柯达数据集上最先进的基线相比，BD 速率增益为 3.73%。]]></description>
      <guid>https://arxiv.org/abs/2411.05832</guid>
      <pubDate>Tue, 12 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Prion-ViT：受朊病毒启发的视觉转换器，利用散斑图进行温度预测</title>
      <link>https://arxiv.org/abs/2411.05836</link>
      <description><![CDATA[arXiv:2411.05836v1 公告类型：新
摘要：光纤散斑图传感器 (FSS) 因其对温度波动的高灵敏度而被广泛应用于环境监测，但散斑图数据的复杂非线性特性对传统预测模型提出了重大挑战。本研究引入了一种新型的 Prion-Vision Transformer (Prion-ViT) 模型，该模型受到生物朊病毒记忆机制的启发，旨在增强长期依赖性建模，以便使用 FSS 数据进行准确的温度预测。通过利用持久记忆状态，Prion-ViT 有效地保留和传播跨多个层的基本特征，从而提高预测准确性并将平均绝对误差 (MAE) 降低至“0.52 摄氏度”，优于 ResNet、Inception Net V2 和现有的基于变压器的架构等传统模型。这项研究解决了将视觉变换器 (ViT) 应用于 FSS 数据的特定挑战，并表明受朊病毒启发的记忆机制为捕捉散斑图中的复杂光学干涉图案提供了一种强大的解决方案。这些发现确立了 Prion-ViT 是实时工业温度监测应用的一项有希望的进步，并可能适用于其他光学传感领域。]]></description>
      <guid>https://arxiv.org/abs/2411.05836</guid>
      <pubDate>Tue, 12 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>高斯平滑显著图的稳定性与保真度之间的权衡</title>
      <link>https://arxiv.org/abs/2411.05837</link>
      <description><![CDATA[arXiv:2411.05837v1 公告类型：新
摘要：基于梯度的显著性图已广泛用于解释神经网络分类器的决策并从其学习函数中发现现象。经常观察到基于梯度的标准图对训练数据的随机性和训练过程中的随机性高度敏感。在这项工作中，我们研究了著名的 Smooth-Grad 算法中的随机平滑在基于梯度的图对训练样本随机性的稳定性中的作用。我们将算法稳定性框架扩展到基于梯度的显著性图，并证明了标准 Simple-Grad、Integrated-Gradients 和 Smooth-Grad 显著性图的稳定性误差的界限。我们的理论结果表明高斯平滑在提高基于梯度的图对训练设置随机性的稳定性方面发挥了作用。另一方面，我们分析了 Smooth-Grad 图与原始 Simple-Grad 图的忠实度，并表明在更强烈的高斯平滑下保真度较低。我们通过对标准图像数据集进行几次数值实验来支持我们的理论结果。我们的实证结果证实了我们关于高斯平滑应用于基于梯度的解释图时保真度-稳定性权衡的假设。]]></description>
      <guid>https://arxiv.org/abs/2411.05837</guid>
      <pubDate>Tue, 12 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>StegaVision：利用注意力机制增强隐写术</title>
      <link>https://arxiv.org/abs/2411.05838</link>
      <description><![CDATA[arXiv:2411.05838v1 公告类型：新
摘要：图像隐写术是一种在图像中嵌入秘密信息的技术。深度学习的发展推动了该领域的重大进步。然而，现有的方法往往难以平衡图像质量、嵌入容量和安全性。本文提出了一种新的图像隐写术方法，通过注意机制增强编码器-解码器架构，特别关注通道和空间注意模块。我们系统地研究了五种配置：（1）通道注意，（2）空间注意，（3）顺序通道后接空间注意，（4）空间注意后接通道注意和（5）并行通道和空间注意。我们的实验表明，添加注意机制可以提高嵌入隐藏信息的能力，同时保持图像的视觉质量。PSNR 和 SSIM 分数的增加表明，使用通道和空间注意的并行组合可以同时提高图像质量和隐藏容量。这与之前的研究形成了鲜明对比，之前的研究需要权衡它们之间的利弊。这项研究表明，图像隐写术中的注意力机制可以更好地隐藏秘密信息。我们的代码可在 https://github.com/vlgiitr/StegaVision 上找到。]]></description>
      <guid>https://arxiv.org/abs/2411.05838</guid>
      <pubDate>Tue, 12 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>神经网络的显著性辅助量化</title>
      <link>https://arxiv.org/abs/2411.05858</link>
      <description><![CDATA[arXiv:2411.05858v1 公告类型：新
摘要：深度学习方法在图像分类中占据了重要地位。虽然先前的研究侧重于提高最终结果，但这些模型中决策过程的不透明性仍然是专家们关注的问题。此外，在资源有限的环境中部署这些方法可能会有问题。本文通过在训练阶段提供实时解释来解决这些模型固有的黑盒性质，迫使模型专注于输入中最独特和最关键的方面。此外，我们采用成熟的量化技术来解决资源限制问题。为了评估我们方法的有效性，我们通过对标准和量化模型的显着性图进行比较分析，探索量化如何影响卷积神经网络的可解释性和准确性。量化是在训练阶段使用参数化剪辑激活方法实现的，重点是 MNIST 和 FashionMNIST 基准数据集。我们评估了三种位宽配置（2 位、4 位和混合 4/2 位），以探索效率和可解释性之间的权衡，每种配置都旨在突出对显着图清晰度和模型准确性的不同影响。结果表明，虽然量化对于在资源有限的设备上实现模型至关重要，但它需要在准确性和可解释性之间进行权衡。较低的位宽会导致这两个指标的下降更加明显，这凸显了在模型透明度至关重要的应用中，精心选择量化参数的必要性。这项研究强调了在部署神经网络时实现效率和可解释性之间的平衡的重要性。]]></description>
      <guid>https://arxiv.org/abs/2411.05858</guid>
      <pubDate>Tue, 12 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于纵向医学图像生成的条件扩散模型</title>
      <link>https://arxiv.org/abs/2411.05860</link>
      <description><![CDATA[arXiv:2411.05860v1 公告类型：新
摘要：阿尔茨海默病进展缓慢，涉及各种生物因素之间的复杂相互作用。纵向医学成像数据可以捕捉到这种随时间推移的进展。然而，纵向数据经常会遇到诸如由于患者退出、不规则的随访间隔和观察期长度不同而导致的数据缺失等问题。为了解决这些问题，我们设计了一个基于扩散的模型，用于使用单核磁共振成像 (MRI) 生成 3D 纵向医学成像。这涉及向模型注入调节 MRI 和时间访问编码，从而能够控制源图像和目标图像之间的变化。实验结果表明，与其他竞争方法相比，该方法可以生成更高质量的图像。]]></description>
      <guid>https://arxiv.org/abs/2411.05860</guid>
      <pubDate>Tue, 12 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>遥感分割中基于提示基础模型的联合优化无监督对抗域自适应</title>
      <link>https://arxiv.org/abs/2411.05878</link>
      <description><![CDATA[arXiv:2411.05878v1 公告类型：新
摘要：遥感语义分割的无监督域自适应 (UDA-RSSeg) 解决了将基于源域数据训练的模型调整到目标域样本的挑战，从而最大限度地减少了跨不同遥感场景对注释数据的需求。这项任务提出了两个主要挑战：(1) 不同遥感域之间的特征表示严重不一致，(2) 在将特征转换为预测逻辑时由于源域模式的表示偏差而出现的域差距。为了解决这些问题，我们提出了一个联合优化的对抗网络，结合了 UDA-RSSeg 的“分割任何模型 (SAM) (SAM-JOANet)”。我们的方法集成了 SAM 以利用其强大的广义表示能力，从而缓解特征不一致。我们引入了一个微调解码器，旨在将 SAM-Encoder 特征转换为预测逻辑。此外，还采用了基于特征级对抗的提示分割器来生成与类别无关的映射，以指导微调解码器的特征表示。该网络是端到端优化的，结合了提示分割器和微调解码器。对基准数据集（包括 ISPRS（波茨坦/Vaihingen）和 CITY-OSM（巴黎/芝加哥））的广泛评估证明了我们方法的有效性。结果由可视化和分析支持，证实了该方法的可解释性和稳健性。本文的代码可在 https://github.com/CV-ShuchangLyu/SAM-JOANet 上找到。]]></description>
      <guid>https://arxiv.org/abs/2411.05878</guid>
      <pubDate>Tue, 12 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>面带微笑，眼中却充满悲伤：基于面部表情和眼部行为的情绪识别</title>
      <link>https://arxiv.org/abs/2411.05879</link>
      <description><![CDATA[arXiv:2411.05879v1 公告类型：新
摘要：情绪识别（ER）是从给定数据中识别人类情绪的过程。目前，该领域严重依赖面部表情识别（FER），因为面部表情包含丰富的情绪线索。然而，需要注意的是，面部表情可能并不总是准确地反映真实的情绪，基于 FER 的结果可能会产生误导性的 ER。为了理解和弥合 FER 和 ER 之间的差距，我们引入眼部行为作为创建新的眼部行为辅助多模态情绪识别（EMER）数据集的重要情绪线索。与现有的多模态 ER 数据集不同，EMER 数据集采用刺激材料诱导的自发情绪生成方法，将非侵入性眼部行为数据（如眼球运动和眼球注视图）与面部视频相结合，旨在获得自然准确的人类情绪。值得注意的是，我们首次在 EMER 中为 ER 和 FER 提供了注释，从而可以进行全面分析以更好地说明这两项任务之间的差距。此外，我们专门设计了一种新的 EMERT 架构，通过有效识别和弥合两者之间的情感差距来同时提高 ER 和 FER 的性能。具体来说，我们的 EMERT 采用模态对抗特征解耦和多任务 Transformer 来增强眼部行为的建模，从而为面部表情提供有效的补充。在实验中，我们引入了七种多模态基准协议，对 EMER 数据集进行了各种综合评估。结果表明，EMERT 的表现远远优于其他最先进的多模态方法，揭示了建模眼部行为对于稳健 ER 的重要性。总之，我们全面分析了眼部行为在 ER 中的重要性，推动了解决 FER 和 ER 之间的差距以实现更稳健的 ER 性能的研究。]]></description>
      <guid>https://arxiv.org/abs/2411.05879</guid>
      <pubDate>Tue, 12 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>实现公平的自闭症诊断：使用行为和面部数据的机器和深度学习模型的比较研究</title>
      <link>https://arxiv.org/abs/2411.05880</link>
      <description><![CDATA[arXiv:2411.05880v1 公告类型：新
摘要：由于传统诊断方法忽视了性别特异性症状差异，自闭症谱系障碍 (ASD) 在女性中经常被漏诊。本研究评估了机器学习模型，特别是随机森林和卷积神经网络，以通过结构化数据和面部图像分析增强 ASD 诊断。随机森林在数据集中实现了 100% 的验证准确率，突显了其管理复杂关系和减少假阴性的能力，这对于早期干预和解决性别偏见至关重要。在基于图像的分析中，MobileNet 的表现优于基线 CNN，准确率达到 87%，但 30% 的验证损失表明可能存在过度拟合，需要进一步优化以在临床环境中保持稳健性。未来的工作将强调超参数调整、正则化和迁移学习。将行为数据与面部分析相结合可以改善对漏诊群体的诊断。这些发现表明，随机森林的高准确率和平衡的精确召回指标可以增强临床工作流程。 MobileNet 的轻量级结构也为资源有限的环境带来了希望，使 ASD 筛查变得更容易。解决模型可解释性和临床医生信任问题至关重要。]]></description>
      <guid>https://arxiv.org/abs/2411.05880</guid>
      <pubDate>Tue, 12 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用热成像进行状态监测的预测数字孪生</title>
      <link>https://arxiv.org/abs/2411.05887</link>
      <description><![CDATA[arXiv:2411.05887v1 公告类型：新
摘要：本文探讨了使用高级数学模型和热成像技术专门为状态监测而设计的预测数字孪生的开发和实际应用。我们的工作提出了一种综合方法，将本征正交分解 (POD)、稳健主成分分析 (RPCA) 和动态模式分解 (DMD) 结合起来，建立了一个稳健的预测数字孪生框架。我们在实时实验装置中采用这些方法，该装置涉及通过热成像监测的加热板。该系统有效地展示了数字孪生在实时预测、状态监测和异常检测方面的能力。此外，我们介绍了包括虚拟现实在内的人机界面的使用，增强了用户交互和系统理解。我们研究的主要贡献在于在有形设置中展示这些先进技术，展示了数字孪生通过实现更主动和战略性的资产管理来改变行业实践的潜力。]]></description>
      <guid>https://arxiv.org/abs/2411.05887</guid>
      <pubDate>Tue, 12 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>将物体检测模式集成到视觉语言模型中以增强自动驾驶代理</title>
      <link>https://arxiv.org/abs/2411.05898</link>
      <description><![CDATA[arXiv:2411.05898v1 公告类型：新
摘要：在本文中，我们提出了一种新颖的框架，通过将视觉语言模型 (VLM) 与专门用于物体检测的附加视觉感知模块相结合，增强自动驾驶系统的视觉理解能力。我们通过将基于 YOLOS 的检测网络与 CLIP 感知网络结合起来，扩展了 Llama-Adapter 架构，解决了物体检测和定位方面的局限性。我们的方法引入了摄像头 ID 分隔符来改进多视图处理，这对于全面的环境意识至关重要。在 DriveLM 视觉问答挑战赛上的实验表明，与基线模型相比，它有显着的改进，ChatGPT 分数、BLEU 分数和 CIDEr 指标的性能都有所提高，表明模型答案与地面实况的接近度。我们的方法代表着朝着更强大、更可解释的自动驾驶系统迈出了有希望的一步。我们还讨论了通过检测方式可能实现的安全性增强。]]></description>
      <guid>https://arxiv.org/abs/2411.05898</guid>
      <pubDate>Tue, 12 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>