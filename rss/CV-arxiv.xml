<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>CS.CV更新arxiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.cv更新arxiv.org e-print存档。</description>
    <lastBuildDate>Tue, 15 Apr 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>HAL-NERF：高精度定位利用神经辐射场</title>
      <link>https://arxiv.org/abs/2504.08901</link>
      <description><![CDATA[ARXIV：2504.08901V1公告类型：新 
摘要：精确的摄像头定位是XR应用程序和机器人技术中的关键任务。仅使用摄像头捕获作为系统的输入是一种廉价的选项，可以在大型室内和室外环境中进行定位，但在实现高准确性方面面临着挑战。具体而言，诸如绝对姿势回归（APR）之类的摄像机重新定位方法可以在室外场景中定位具有中位翻译错误的相机。本文介绍了HAL-NERF，这是一种高准确性的定位方法，将CNN姿势回归器与基于蒙特卡洛粒子滤波器的改进模块相结合。 Nerfacto模型是神经辐射场（NERFS）的实现，用于增强训练姿势回归器的数据并测量粒子滤光片细化模块中的光度损失。 HAL-NERF利用Nerfacto合成高质量的新型视图的能力，从而显着提高了定位管道的性能。 HAL-NERF取得了最先进的结果，这些结果通常以每个场景错误的中位数的平均值来衡量。翻译错误为$ 0.25万美元，旋转误差为0.59美元$度和0.4万度和0.58度，分别在7片镜数据集和剑桥地标数据集上，计算时间增加了。这项工作突出了将APR与基于NERF的改进技术相结合以提高单眼相机重新定位精度的潜力。]]></description>
      <guid>https://arxiv.org/abs/2504.08901</guid>
      <pubDate>Tue, 15 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Lookglass：通过拉普拉斯金字塔翘曲的生成变形</title>
      <link>https://arxiv.org/abs/2504.08902</link>
      <description><![CDATA[ARXIV：2504.08902V1公告类型：新 
摘要：变形是指有意扭曲的一类图像，直接观看时使它们无法识别。它们的真实形式只有从特定的角度看时才能揭示自己，这可以通过某些catadioptric设备（例如镜子或镜头）。尽管这些数学设备的构建最早可以追溯到17世纪，但只有从特定的有利位置观看并在正常视为时倾向于失去意义时，它们才能解释。在本文中，我们以产生的转折重新审视了这些著名的错觉。在潜在的整流流模型的帮助下，我们提出了一种创建变形图像的方法，该方法直接在直接查看时仍保留有效的解释。为此，我们引入了拉普拉斯金字塔翘曲，这是产生高质量视觉效果的频率感知图像翘曲技术的关键。我们的作品将视觉上的字眼（Arxiv：2311.17919）扩展到潜在的空间模型，并扩展到更广泛的空间变换，从而创造了新颖的生成感知幻象。]]></description>
      <guid>https://arxiv.org/abs/2504.08902</guid>
      <pubDate>Tue, 15 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>稳健的山姆：在视觉基础模型的对抗性鲁棒性上</title>
      <link>https://arxiv.org/abs/2504.08906</link>
      <description><![CDATA[ARXIV：2504.08906V1公告类型：新 
摘要：任何模型（SAM）的段是一个广泛使用的视觉基础模型，具有不同的应用，包括图像分割，检测和跟踪。鉴于Sam的广泛应用，了解其对对抗攻击的鲁棒性对于现实部署至关重要。但是，对山姆鲁棒性的研究仍处于早期阶段。现有的攻击通常忽略了提示在评估SAM鲁棒性中的作用，并且对防御方法的探索不足以平衡稳健性和准确性。为了解决这些差距，本文提出了一个旨在评估和增强SAM鲁棒性的对抗性鲁棒性框架。具体来说，我们引入了一种交叉攻击方法，以增强跨不同提示类型的攻击传递性。除了进攻外，我们提出了一些参数适应策略，以捍卫SAM免受各种对抗性攻击。为了平衡鲁棒性和准确性，我们使用单数值分解（SVD）来限制可训练参数的空间，而只有单数值是适应性的。实验表明，我们的交叉攻击方法在SAM和SAM 2上的攻击成功率方面优于先前的方法。通过仅适应512个参数，我们至少在平均交叉点上对联合（MIOU）的平均交叉点至少提高了15 \％，以针对各种对抗性攻击。与以前的防御方法相比，我们的方法增强了SAM的鲁棒性，同时最大程度地保持其原始性能。]]></description>
      <guid>https://arxiv.org/abs/2504.08906</guid>
      <pubDate>Tue, 15 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过冗余消除视觉基础模型的无参数微调</title>
      <link>https://arxiv.org/abs/2504.08915</link>
      <description><![CDATA[ARXIV：2504.08915V1公告类型：新 
摘要：视觉基础模型（VFM）是构成各种视觉任务的骨干的大型预训练模型。微调VFM可以进一步解锁其下游任务或场景的潜力。但是，VFM通常包含重要的功能冗余，这可能会限制其对新任务的适应性。在本文中，我们研究了该段中的任何模型（SAM）中的冗余，然后提出了一种无参数的微调方法来解决此问题。与调整参数的传统微调方法不同，我们的方法强调选择，重复使用和增强预训练的功能，从而提供有关模型微调的新观点。具体而言，我们根据模型的输出差引入通道选择算法，以识别冗余和有效的通道。通过选择性地用更有效的通道替换冗余通道，我们过滤掉较少有用的功能并重复使用与下游任务更相关的功能，从而增强了特定于任务的功能表示。对室外和内域数据集进行的实验证明了我们方法的效率和有效性。值得注意的是，我们的方法可以与现有的微调策略（例如Lora，适配器）无缝集成，从而进一步促进了已经微调模型的性能。此外，由于我们的通道选择仅涉及模型推断，因此我们的方法大大降低了计算和GPU内存开销。]]></description>
      <guid>https://arxiv.org/abs/2504.08915</guid>
      <pubDate>Tue, 15 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>运动抽奖者：与局部生成蒙版变压器一对多运动合成</title>
      <link>https://arxiv.org/abs/2504.08959</link>
      <description><![CDATA[ARXIV：2504.08959V1公告类型：新 
摘要：生成的蒙版变形金刚在各种内容生成任务中都表现出了很大的成功，这主要是由于它们有效地对大规模数据集分布进行高度一致性建模的能力。但是，在动画域中，大型数据集并不总是可用。应用生成胶面膜建模从单个MOCAP参考生成不同的实例可能会导致过度拟合，这一挑战尚未得到探索。在这项工作中，我们提出了MotionDreamer，这是一种局部掩盖的建模范式，旨在从具有任意拓扑和持续时间的给定运动中学习内部运动模式。通过将给定的运动嵌入使用新颖的分布正则化方法中的量化令牌中，MotionDreamer为局部运动模式构建了强大而有益的代码手册。此外，在我们的蒙版变压器中引入了滑动窗口的本地关注，从而使自然而多样的动画产生与参考运动模式非常相似。正如通过全面的实验所证明的那样，MotionDreamer的表现优于通常在忠诚和多样性中基于gan或扩散的最先进方法。由于基于量化的方法的一致性和鲁棒性，运动训练器还可以有效执行下游任务，例如时间运动编辑，\ textColor {update} {Crowd Animation} {Crowd Animation}，并使用单个参考运动。访问我们的项目页面：https：//motiondreamer.github.io/]]></description>
      <guid>https://arxiv.org/abs/2504.08959</guid>
      <pubDate>Tue, 15 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>协议：更快的视觉语言模型的基于修剪和基于聚类的令牌减少</title>
      <link>https://arxiv.org/abs/2504.08966</link>
      <description><![CDATA[ARXIV：2504.08966V1公告类型：新 
摘要：视觉语言模型需要大量的计算资源来进行推断，这是由于表示视觉信息所需的其他输入令牌。但是，这些视觉令牌通常包含冗余和不重要的信息，从而导致不必要的令牌数量。为了解决这个问题，我们介绍了PACT，该方法通过修剪无关的令牌并在语言模型的早期层中进行视觉冗余，从而减少推理时间和内存使用情况。我们的方法使用一种新颖的重要性指标来识别不重要的令牌而不依赖注意力评分，从而使其与闪光兼容兼容。我们还提出了一种新型的聚类算法，称为距离有界密度峰值聚类，该算法有效地将视觉令牌簇簇，同时通过预定义的阈值来约束群集中元素之间的距离。我们通过广泛的实验证明了契约的有效性。]]></description>
      <guid>https://arxiv.org/abs/2504.08966</guid>
      <pubDate>Tue, 15 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>视觉变压器的自适应加性参数更新，用于几次持续学习</title>
      <link>https://arxiv.org/abs/2504.08982</link>
      <description><![CDATA[ARXIV：2504.08982V1公告类型：新 
摘要：整合新的班级信息而不会丢失以前获得的知识，这仍然是人工智能的核心挑战，通常被称为灾难性遗忘。几乎没有射击类增量学习（FSCIL）通过首先训练基础类的强大数据集来解决此问题，然后在连续的会话中逐步调整它，仅使用每个小说类别的示例进行几个标记的示例。但是，这种方法很容易过度拟合有限的新数据，这可能会损害整体性能并加剧遗忘。在这项工作中，我们提出了一个简单而有效的新型FSCIL框架，该框架利用了冻结的视觉变压器（VIT）骨干，并增强了参数有效的添加剂更新。我们的方法将预先训练的VIT参数冻结，并通过加法更新机制有选择地将可训练的权重注入自我发项模块。该设计仅更新一小部分参数，即可容纳新课程，而无需牺牲基础会议期间所学的表示形式。通过微调有限数量的参数，我们的方法可以保留冻结的VIT中可推广的特征，同时降低了过度拟合的风险。此外，由于大多数参数保持固定，该模型避免了当引入小型新型数据批次时覆盖先前学习的知识。基准数据集的广泛实验表明，与基线FSCIL方法相比，我们的方法可以产生最先进的性能。]]></description>
      <guid>https://arxiv.org/abs/2504.08982</guid>
      <pubDate>Tue, 15 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用不确定标签的低分辨率图像上使用深卷积模型的胸部X射线分类</title>
      <link>https://arxiv.org/abs/2504.09033</link>
      <description><![CDATA[ARXIV：2504.09033V1公告类型：新 
摘要：深度卷积神经网络始终被证明可以在过去几年中大多数构成高质量数据的大多数成像任务上实现最新的成像结果。但是，重要的是要在低分辨率图像上工作，因为它可能是远程医疗保健访问的替代方案，而自动病理识别模型的主要需求。使用低分辨率图像的医学诊断很具有挑战性，因为关键细节可能无法轻易识别。在本文中，我们通过对胸部X射线的不同输入图像大小进行深入CNN模型来报告分类结果，并讨论各种图像大小上分类的可行性。我们还通过提出标签技术的随机翻转来利用数据集中的嘈杂标签。我们在额叶和横向研究上使用多标签分类模型的集合。我们的模型在公开可用的Chexpert数据集的14个胸部病理中进行了培训。我们结合了诸如增强，模型改进的正规化等技术，并使用类激活图来可视化神经网络的决策。已经提出了与原始Chexpert论文中报告的相应高分辨率图像获得的200名受试者的数据的分类结果的比较。对于心脏肿瘤，巩固和水肿的病理，我们的模型架构获得了3％的精度。]]></description>
      <guid>https://arxiv.org/abs/2504.09033</guid>
      <pubDate>Tue, 15 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>雕刻记忆：通过动态掩码和概念吸引的优化在扩散模型中遗忘多概念忘记</title>
      <link>https://arxiv.org/abs/2504.09039</link>
      <description><![CDATA[ARXIV：2504.09039V1公告类型：新 
摘要：文本对图像（T2I）扩散模型在从文本提示中生成高质量的图像方面取得了显着的成功。但是，它们存储大量知识的能力在必要遗忘的情况下引起了人们的关注，例如消除受版权保护的内容，减少偏见或消除有害的概念。尽管现有的未学习方法可以消除某些概念，但由于不稳定，剩余的知识持久性和发电质量退化而导致的多概念忘记遗忘。为了应对这些挑战，我们提出\ textbf {动态掩码，再加上概念感知损失}，这是一个新颖的学习框架，设计用于扩散模型中的多概念遗忘。我们的\ textbf {动态掩码}机制基于当前优化状态自适应地更新渐变掩模，从而可以选择性修改，以防止干扰无关的知识。此外，我们的\ textbf {概念感知损失}通过通过超类对齐来实现语义一致性来显式指导学习过程，而基于知识蒸馏的正则化损失确保了以前未经学习的概念在顺序未学习期间仍被遗忘。我们进行广泛的实验来评估我们的方法。结果表明，我们的方法在忘记有效性，输出保真度和语义连贯性方面优于现有的未学习技术，尤其是在多概念方案中。我们的工作为生成模型中的稳定且高保真的框架提供了一个有原则且灵活的框架。该代码将公开发布。]]></description>
      <guid>https://arxiv.org/abs/2504.09039</guid>
      <pubDate>Tue, 15 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Blockgaussian：有效的大型场景通过基于自适应块的高斯碎片构成小型景观综合</title>
      <link>https://arxiv.org/abs/2504.09048</link>
      <description><![CDATA[ARXIV：2504.09048V1公告类型：新 
摘要：在3D高斯脱落（3DG）中的最新进展在新型视图合成任务中表现出了巨大的潜力。分裂和诱饵范式已实现了大规模的现场重建，但是在场景分区，优化和合并过程中仍然存在重大挑战。本文介绍了Blockgoussian，这是一个新颖的框架，结合了内容感知的场景分区策略和可见性 - 吸引块优化，以实现高效且高质量的大规模场景重建。具体而言，我们的方法考虑了不同区域之间的内容复杂性变化，并在场景分配过程中平衡了计算负载，从而实现了有效的场景重建。为了解决独立块优化期间的监督不匹配问题，我们在单个块优化期间引入辅助点以使地面对齐的监督保持一致，从而提高了重建质量。此外，我们提出了一个伪视图的几何约束，可有效减轻块合并期间空域浮点数引起的降低降解。在大规模场景上进行了广泛的实验表明，我们的方法在重建效率和渲染质量方面都取得了最先进的性能，优化的速度为5倍，并且在多个基准测试方面的平均PSNR提高了1.21 dB。值得注意的是，Blockgouss显着降低了计算要求，从而在单个24GB VRAM设备上重建大规模的场景。该项目页面可从https://github.com/sunshinewyc/blockgaussian获得]]></description>
      <guid>https://arxiv.org/abs/2504.09048</guid>
      <pubDate>Tue, 15 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>您需要一个过渡飞机：桥接连续的全景3D重建，并透视高斯分裂</title>
      <link>https://arxiv.org/abs/2504.09062</link>
      <description><![CDATA[ARXIV：2504.09062V1公告类型：新 
摘要：最近，使用先进的3D高斯（3DGS）技术从单个全景图像重建场景引起了人们的兴趣。全景图像提供360美元$ \ times $ 180的视野（FOV），以单镜头捕获整个场景。然而，全景图像引入了严重的失真，这使得将3D高斯人直接变成2D扭曲的equirectandandabular空间具有挑战性。将等值的图像转换为CubeMap预测会部分减轻此问题，但引入了新的挑战，例如跨立方体面边界的投射失真和不连续性。为了解决这些局限性，我们提出了一个名为TPGS的新颖框架，以触发连续的全景3D场景重建，并透视高斯裂开。首先，我们在相邻的立方体面之间引入一个过渡平面，以使边界区域的脱落方向和减轻优化的歧义在边界区域中更平滑。此外，提出了一个对切入的面部优化策略，以增强本地细节并恢复各个立方面边界的视觉一致性。具体而言，我们优化了单个立方体面内的3D高斯人，然后在缝合的全景空间中微调它们。此外，我们引入了一种球形采样技术，以消除可见的缝线接缝。关于室内和室外，以自我为中心和漫游基准数据集的广泛实验表明，我们的方法表现优于现有的最新方法。代码和型号将在https://github.com/zhijieshen-bjtu/tpgs上找到。]]></description>
      <guid>https://arxiv.org/abs/2504.09062</guid>
      <pubDate>Tue, 15 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用双向街道视觉图像和预训练的视觉模型评估超本地灾难损害评估</title>
      <link>https://arxiv.org/abs/2504.09066</link>
      <description><![CDATA[ARXIV：2504.09066V1公告类型：新 
摘要：街道视图图像从视觉角度捕获影响并提供详细的现场见解时，为灾害损害估算提供了独特的优势。尽管有几项试图分析街道视图图像进行损害估算的调查，但它们主要集中于污点后图像。时间序列的街道视图图像的潜力仍未得到充实。预悬器图像为建筑和街道上的准确损害估算提供了宝贵的基准测试。这些图像可以帮助注释者客观地标记后策划后的影响，从而提高标记的数据集用于模型训练的可靠性，并有可能提高损害评估中的模型性能。这项研究的目的是使用双期街道视图图像和先进的预训练的视觉模型来估计超本地，现场灾难损害。 2024年米尔顿飓风之前和之后，在佛罗里达州马蹄海滩的米尔顿飓风之前和之后进行了实验。这些目标是：（1）评估将预施式街道视觉图像纳入无损害类别的绩效提高，包括Swin Transformer和Convnext，包括损害水平分类； （2）设计和评估一种双通道算法，该算法读取逐渐读取前和后式街道街道视图图像，以进行超本地损害评估。结果表明，结合预先展示的街景图像并采用双通道处理框架可以显着提高损害评估精度。使用双通道特征融合频道模型，SWIN Transferer基线的准确性从66.14％提高到77.11％。这项研究可以在超本地空间决议上进行快速，操作的损害评估，从而提供有价值的见解，以支持灾难管理和弹性计划中的有效决策。]]></description>
      <guid>https://arxiv.org/abs/2504.09066</guid>
      <pubDate>Tue, 15 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Uniflowrestore：通过流匹配和及时指导的一般视频修复框架</title>
      <link>https://arxiv.org/abs/2504.09069</link>
      <description><![CDATA[ARXIV：2504.09069V1公告类型：新 
摘要：视频成像通常会受到复杂降解的影响，例如模糊，噪声和压缩伪像。传统的恢复方法遵循“单任务单模”范式，导致概括和较高的计算成本，从而限制了它们在具有不同降解类型的现实情况下的适用性。我们提出了Uniflowrestore，这是一个通用的视频修复框架，在迅速和物理知识的矢量字段下，将恢复为及时的进化。物理感知的骨干物理学将降解先验编码为势能，而促使派生剂会产生与任务相关的提示作为动量。这些组件定义了一个哈密顿系统，其矢量场会集成惯性动力学，衰减的物理梯度和及时的基于指导。该系统通过固定步骤求解器进行了优化，以实现跨任务的有效统一修复。实验表明，Uniflowrestore以强大的概括和效率提供了现状的性能。定量结果表明，uniflowrestore在视频降解任务上达到了最高的PSNR（33.89 dB）和SSIM（0.97），同时在所有评估的任务中保持最高或第二高分。]]></description>
      <guid>https://arxiv.org/abs/2504.09069</guid>
      <pubDate>Tue, 15 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>探索协同合奏学习：团结CNN，MLP混合和视觉变压器以增强图像分类</title>
      <link>https://arxiv.org/abs/2504.09076</link>
      <description><![CDATA[ARXIV：2504.09076V1公告类型：新 
摘要：近年来，卷积神经网络（CNN），MLP混合物和视觉变压器已成为图像分类中领先的神经体系结构的突出。先前的研究强调了每种体系结构的独特优势，并且越来越多的证据表明，将来自不同体系结构的模块组合可以提高性能。在这项研究中，我们基于并改善了以前的工作，以探索不同建筑之间的互补性。我们保留每个体系结构的完整性，并使用集合技术合并它们，而不是通过反复试验从各种体系结构中启发模块进行启发。通过保持每个体系结构的独特性，我们旨在通过隐含的隔离来更深入地探索它们的固有互补性。这种方法对他们的个人优势提供了更系统的理解。
  除了发现对建筑互补性的见解外，我们还展示了甚至基本的集合方法的有效性，这些方法结合了不同建筑的模型。这些方法优于由相似架构组成的合奏。我们直接的整体框架是将互补体系结构融合的基础策略，为进一步研究不同体系结构之间的独特优势和协同作用提供了一个坚实的起点，并在图像分类中提供了共同点。这项工作的直接结果是创建了一个分类网络的集合，该网络超过了ImageNet上先前最新的单个分类网络的准确性，设定了新的基准，同时需要较小的整体延迟。]]></description>
      <guid>https://arxiv.org/abs/2504.09076</guid>
      <pubDate>Tue, 15 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>视觉自我注意到机制面部表达识别网络超越convnext</title>
      <link>https://arxiv.org/abs/2504.09077</link>
      <description><![CDATA[ARXIV：2504.09077V1公告类型：新 
摘要：面部表达识别是人工智能领域的重要研究方向。尽管近年来已经取得了新的突破，但数据集的分布不均匀，面部表情类别之间的相似性以及不同受试者之间同一类别之间的差异仍然是挑战。本文提出了基于截短的Convnext方法（Conver-Cut）的视觉面部表达信号特征处理网络，以提高在挑战性条件下FER的准确性。该网络使用截断的Convnext基键作为特征提取器，然后我们设计了一个详细提取块来提取详细的功能，并引入了一种自我发挥的机制，以使网络能够更有效地学习提取的功能。为了评估所提出的交流方法，我们对RAF-DB和FERPLUS数据集进行了实验，结果表明我们的模型已经达到了最先进的性能。我们的代码可以在GitHub访问。]]></description>
      <guid>https://arxiv.org/abs/2504.09077</guid>
      <pubDate>Tue, 15 Apr 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>