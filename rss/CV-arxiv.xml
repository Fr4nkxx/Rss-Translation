<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>CS.CV更新arxiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.cv更新arxiv.org e-print存档。</description>
    <lastBuildDate>Thu, 20 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>MotionMatcher：通过运动功能匹配的文本到视频扩散模型的运动自定义</title>
      <link>https://arxiv.org/abs/2502.13234</link>
      <description><![CDATA[Arxiv：2502.13234V1公告类型：新 
摘要：文本到视频（T2V）扩散模型在综合输入文本提示中综合现实视频方面表现出了有希望的功能。但是，仅输入文本说明就可以有限地控制精确的对象运动和相机框架。在这项工作中，我们解决了运动自定义问题，其中提供了作为运动指导的参考视频。尽管大多数现有方法选择微调预训练的扩散模型来重建参考视频的框架差异，但我们观察到，这种策略遭受参考视频中内容泄漏的影响，并且它们无法准确捕获复杂的运动。为了解决此问题，我们提出了MotionMatcher，这是一个运动自定义框架，该框架在功能级别上微调预训练的T2V扩散模型。 MotionMatcher不使用像素级目标，而是将高级时空运动特征与微调扩散模型进行比较，从而确保精确的运动学习。为了记忆效率和可访问性，我们使用了预先训练的T2V扩散模型，该模型包含有关视频运动的相当先验知识，以计算这些运动功能。在我们的实验中，我们演示了最新的运动自定义性能，从而验证了我们的框架设计。]]></description>
      <guid>https://arxiv.org/abs/2502.13234</guid>
      <pubDate>Thu, 20 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多览现场介绍的几何感知扩散模型</title>
      <link>https://arxiv.org/abs/2502.13335</link>
      <description><![CDATA[Arxiv：2502.13335V1公告类型：新 
摘要：在本文中，我们专注于3D场景介绍，其中从不同角度捕获的输入图像集的一部分被掩盖了。主要的挑战在于生成合理的图像完成，这些图像完成在各个视图上几乎是一致的。最新的工作通过将生成模型与3D辐射字段相结合以融合跨观点的信息来应对这一挑战。但是，这些方法的主要缺点是，由于不一致的跨视图图像融合，它们通常会产生模糊的图像。为了避免模糊的插图，我们避免完全使用显式或隐式辐射场，而是在学习空间中融合了跨视图的信息。特别是，我们引入了一个几何感知条件生成模型，该模型能够基于参考图像的几何和外观提示来介绍多视图一致的图像。我们方法比现有方法的关键优势是其独特的能力，可以用数量有限的视图（即少量视图介入）注入遮罩场景，而以前的方法需要相对较大的图像集来设置其3D模型拟合步骤。从经验上讲，我们在两个数据集上评估和比较了我们以场景为中心的镶嵌方法，即Spin-Nerf和Nerfiller，它们分别包含在狭窄和宽基线的图像，并在两者上实现最新的3D 3D介入性能。此外，我们证明了与先前方法相比，我们在几个视图设置中的方法的功效。]]></description>
      <guid>https://arxiv.org/abs/2502.13335</guid>
      <pubDate>Thu, 20 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>预验证的图像文本模型是秘密的视频标题</title>
      <link>https://arxiv.org/abs/2502.13363</link>
      <description><![CDATA[ARXIV：2502.13363V1公告类型：新 
摘要：开发视频字幕模型在计算上很昂贵。视频的动态性质也使可以有效地标题这些序列的多模型模型的设计变得复杂。但是，我们发现，通过使用最小的计算资源并且没有复杂的修改来解决视频动态，可以重新使用基于图像的模型以胜过几个专业的视频字幕系统。我们的改编模型在主要基准测试中表明了顶级性能，在MSRVTT和MSVD上排名第二，而Vatex上的第三级表现。我们通过训练典型的图像字幕模型Blip2，将其转换为竞争性的视频字幕，仅使用6,000个视频文本对，并且简单地将框架串联（比其他方法少得多），该帧使用2.5至1.44亿对。从资源优化的角度来看，此视频字幕研究的重点是三个基本因素：优化模型量表，最大化数据效率并纳入强化学习。这项广泛的研究表明，基于图像的适应性策略可以与最先进的视频字幕系统相匹配，为低资源场景提供实用的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2502.13363</guid>
      <pubDate>Thu, 20 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过事件摄像机和骨架数据融合，SNN驱动的多模式人类动作识别</title>
      <link>https://arxiv.org/abs/2502.13385</link>
      <description><![CDATA[ARXIV：2502.13385V1公告类型：新 
摘要：基于RGB和骨骼数据融合的多模式人类动作识别虽然有效，但受到重大局限性的限制，例如高计算复杂性，过度记忆力消耗和大量能量需求，尤其是在使用人工神经网络（ANN）实施时。这些限制限制了其在资源约束方案中的适用性。为了应对这些挑战，我们提出了一个新型的尖峰神经网络（SNN）驱动的框架，用于使用事件摄像机和骨架数据，用于多模式人类动作识别。我们的框架以两个关键创新为中心：（1）一种新型的多模式SNN体系结构，该体系结构对每种模式使用了不同的骨干网络 - 用于事件摄像机数据的基于AN SNN的MAMBA和尖峰图形卷积网络（SGN），用于与Skeleton数据合并的Skeletal网络一个尖刺的语义提取模块，以捕获深层的语义表示； （2）基于SNN的开创性离散信息瓶颈机制，用于模态融合，有效地平衡了特定于模态语义的保存和有效的信息压缩。为了验证我们的方法，我们提出了一种新的方法，用于构建一个集成事件摄像机和骨架数据的多模式数据集，从而实现全面的评估。广泛的实验表明，我们的方法在识别准确性和能源效率方面都能达到卓越的性能，从而为实用应用提供了有希望的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2502.13385</guid>
      <pubDate>Thu, 20 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>玉米 - 萨姆：零拍玉米耳朵表型</title>
      <link>https://arxiv.org/abs/2502.13399</link>
      <description><![CDATA[ARXIV：2502.13399V1公告类型：新 
摘要：量化玉米（Zea Mays L.）的产量成分特征的变化，共同确定了这种全球重要作物的总体生产力，在植物遗传学研究，植物育种以及改善农业实践的发展中起着至关重要的作用。每英亩的谷物产量是通过将每英亩植物的数量乘以每植物的耳朵，每耳朵的核数和平均核重量来计算。每耳朵的内核数取决于每耳的内核数乘以每行核的数量。测量这两个特征的传统手动方法是耗时的，限制了大规模数据收集。使用图像处理和深度学习的最新自动化工作遇到了诸如高注释成本和不确定的可推广性之类的挑战。
  我们通过探索用于零射，无注释玉米内核细分的大型视力模型来解决这些问题。通过使用开源大视觉模型，该段的任何模型（SAM），我们将单个内核分段玉米耳朵的RGB图像中的单个内核，并应用基于图的算法来计算每行核的数量。我们的方法成功地识别了各种玉米耳朵的每行核的数量，显示了与基础视觉模型结合图像处理技术相结合的零射击学习的潜力，以改善自动化并降低农艺数据收集中的主观性。我们所有的代码都是开源的，可以使这些人都可以使用这些负担得起的表型方法。]]></description>
      <guid>https://arxiv.org/abs/2502.13399</guid>
      <pubDate>Thu, 20 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>JL1-CD：一种用于遥感变更检测和强大的多教师知识蒸馏框架的新基准</title>
      <link>https://arxiv.org/abs/2502.13407</link>
      <description><![CDATA[Arxiv：2502.13407V1公告类型：新 
摘要：深度学习在遥感图像变化检测领域取得了重大成功（CD），但仍有两个主要挑战：子计的稀缺性，包含全包的开源CD数据集，以及难以实现一致和一致性和一致性和在变化区域不同的图像之间令人满意的检测结果。为了解决这些问题，我们介绍了JL1-CD数据集，该数据集包含5,000对512 x 512像素图像，分辨率为0.5至0.75米。此外，我们为CD提出了一个多教学知识蒸馏（MTKD）框架。 JL1-CD和SYSU-CD数据集的实验结果表明，MTKD框架可显着提高具有各种网络体系结构和参数大小的CD模型的性能，从而实现了新的最新结果。该代码可在https://github.com/circlelzy/mtkd-cd上找到。]]></description>
      <guid>https://arxiv.org/abs/2502.13407</guid>
      <pubDate>Thu, 20 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过跨模式学习中的知识注入来增强胸部X射线分类</title>
      <link>https://arxiv.org/abs/2502.13447</link>
      <description><![CDATA[ARXIV：2502.13447V1公告类型：新 
摘要：人工智能在医学成像中的整合表现出了巨大的潜力，但是在跨模式学习中，预训练的知识与表现之间的关系尚不清楚。这项研究调查了如何将医学知识注入学习过程中如何影响跨模式分类的性能，重点是胸部X射线（CXR）图像。我们介绍了一个基于理论的新型知识注入框架，该框架为CXR图像生成具有可控知识粒度的标题。使用此框架，我们对具有不同级别的医疗信息的标题进行微调剪辑模型。我们通过在CHEXPERT数据集上的零摄像分类来评估模型的性能，CHEXPERT数据集是CXR分类的基准。我们的结果表明，使用人类生成的标题时，注射细颗粒的医学知识显着提高了分类准确性，相比之下，达到72.5％\％。这突出了特定于域知识在医学跨模式学习中的关键作用。此外，我们探讨了知识密度的影响以及特定于领域的大语言模型（LLM）来产生字幕的影响，发现较密集的知识和专业的LLM有助于增强性能。这项研究通过证明知识注入对改善自动化CXR分类的有效性，为更准确和可靠的诊断工具铺平道路来推进医学图像分析。]]></description>
      <guid>https://arxiv.org/abs/2502.13447</guid>
      <pubDate>Thu, 20 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>2.5D U-NET具有3D冷冻对象识别的深度降低</title>
      <link>https://arxiv.org/abs/2502.13484</link>
      <description><![CDATA[ARXIV：2502.13484V1公告类型：新 
摘要：冷冻电子层析成像（冷冻）是揭示蛋白质复合物结构的关键技术。自动分析冷冻捕获的断层图是了解细胞结构的重要步骤。在本文中，我们介绍了CZII -Cryoet对象识别竞赛的第四名解决方案，该竞争是为了推动自动断层图分析技术的开发而组织的。我们的解决方案采用了基于热图的关键点检测方法，利用了两种不同类型的2.5D U-NET模型的集合，并降低了深度。尽管具有高度统一和简单的体系结构，但我们的方法还是获得了第四名，证明了其有效性。]]></description>
      <guid>https://arxiv.org/abs/2502.13484</guid>
      <pubDate>Thu, 20 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Mobilevim：3D医学图像分析的轻巧和尺寸独立的视觉mamba</title>
      <link>https://arxiv.org/abs/2502.13524</link>
      <description><![CDATA[ARXIV：2502.13524V1公告类型：新 
摘要：对三维（3D）医学图像的有效评估对于医疗保健中的诊断和治疗实践至关重要。近年来，应用深度学习和计算机愿景来分析和解释医学图像时有很大的吸收。传统方法，例如卷积神经网络（CNN）和视觉变压器（VIT），面临着重大的计算挑战，促使人们需要建筑进步。最近的努力导致引入了新颖的体系结构，例如``Mamba&#39;&#39;模型作为传统CNN或VIT的替代解决方案。 MAMBA模型在一维数据的线性处理方面表现出色。但是，曼巴（Mamba）进行3D医学图像分析的潜力仍然没有被忽略，并且随着尺寸的增加，可能面临重大的计算挑战。该手稿介绍了MobileVim，这是一种简化的体系结构，可有效分割3D医学图像。在MobileVim网络中，我们发明了一种独立于维度的机制和一种与基于视觉mamba的框架合并的双向遍历方法。 Mobilevim还采用了跨尺度桥接技术，以提高各种医学成像方式的效率和准确性。通过这些增强功能，MobileVim在单个图形处理单元（即NVIDIA RTX 4090）上实现了超过每秒90帧（FPS）的分割速度。该性能比使用相同的计算资源处理3D图像的最先进的深度学习模型快24 fps。此外，实验评估表明，MobileVim提供了卓越的性能，而PENGWIN，BRATS2024，ATLAS，ATLAS和Goothfairy2数据集的骰子相似性得分达到92.72％，86.69％，80.46％和77.43％，这显着占据了现有模型。]]></description>
      <guid>https://arxiv.org/abs/2502.13524</guid>
      <pubDate>Thu, 20 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CardiacMamba：一种具有远程生理测量状态空间模型的多模式RGB-RF融合框架</title>
      <link>https://arxiv.org/abs/2502.13624</link>
      <description><![CDATA[Arxiv：2502.13624V1公告类型：新 
摘要：通过远程光绘画学（RPPG）进行心率（HR）估计，提供了一种无创的解决方案用于健康监测。但是，由于照明变化，运动文物和肤色偏见，传统的单模式方法（RGB或射频（RF））在平衡鲁棒性和准确性方面面临挑战。在本文中，我们提出了CardiacMamba，这是一种多模式RGB-RF融合框架，利用这两种方式的互补优势。它引入了时间差异MAMBA模块（TDMM），以使用帧之间的时序差异捕获RF信号的动态变化，从而增强了本地和全局特征的提取。此外，CardiacMamba还采用双向SSM进行跨模式对齐和渠道快速傅立叶变换（CFFT），以有效捕获和完善RGB和RF信号的频域特征，最终提高心率估计的精度和周期性检测。在该数据集上进行的广泛实验表明了最先进的性能，从而取得了明显的准确性和鲁棒性的提高。 CardiacMamba大大减轻了肤色偏差，降低了人口统计组的性能差异，并在缺失模式的情况下保持了弹性。通过解决公平，适应性和精确性的关键挑战，该框架将RPPG技术朝着医疗保健中可靠的现实世界部署而发展。这些代码可在以下网址提供：https：//github.com/wuzheng42/cardiacmamba。]]></description>
      <guid>https://arxiv.org/abs/2502.13624</guid>
      <pubDate>Thu, 20 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>探索相互跨模式的关注，以了解上下文感知人类负担能力的产生</title>
      <link>https://arxiv.org/abs/2502.13637</link>
      <description><![CDATA[ARXIV：2502.13637V1公告类型：新 
摘要：人类负担能力学习研究了上下文相关的新型姿势预测，以便估计的姿势代表现场的有效人类行动。虽然该任务是机器感知和自动交互式导航代理的基础，但指数的可能的姿势和动作变化使问题具有挑战性和非平凡。但是，在文献中，2D场景中人类负担预测的现有数据集和方法受到了限制。在本文中，我们提出了一种新颖的跨注意机制，通过相互参与来自两种不同方式的空间特征图来编码现场上下文，以预测。所提出的方法在各个子任务之间分离，以有效地降低问题的复杂性。首先，我们使用在全局场景上下文编码的条件下，使用各种自动编码器（VAE）为场景中的一个人品尝了一个可能的位置。接下来，我们预测使用一组现有的人类姿势候选者的姿势模板使用分类器在围绕预测位置编码的本地上下文上进行。在随后的步骤中，我们使用两个VAE通过在本地上下文和模板类上进行调节来为预测的姿势模板采样规模和变形参数。我们的实验表明，与先前的人类负担能力注入基线的重大改善为复杂的2D场景。]]></description>
      <guid>https://arxiv.org/abs/2502.13637</guid>
      <pubDate>Thu, 20 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>kan集成变压器和扩张邻里注意力的医学图像分类</title>
      <link>https://arxiv.org/abs/2502.13693</link>
      <description><![CDATA[arxiv：2502.13693v1公告类型：新 
摘要：卷积网络，变形金刚，混合模型和基于MAMBA的体系结构在各种医学图像分类任务中都表现出强大的性能。但是，这些方法主要设计用于使用标记的数据对清洁图像进行分类。相比之下，现实世界中的临床数据通常涉及多中心研究独有的图像腐败，并且源于制造商的成像设备的变化。在本文中，我们将Medicil Vision Transformer（MEDVITV2）介绍了，这是一种新型的架构，将Kolmogorov-Arnold网络（KAN）层纳入变压器架构，旨在进行广义医学图像分类。我们已经开发了一个有效的KAN块，以减少计算负载，同时增强原始Medvit的准确性。此外，为了抵消在扩大规模时我们的Medvit的脆弱性，我们提出了增强的扩张邻里注意力（DINA），这是对能够捕获全球环境和扩大接受性领域的有效融合点 - 产物 - 产品注意内核的适应，以有效地扩展模型，并有效地扩展该模型。解决特征崩溃问题。此外，引入了层次混合策略，以有效的方式堆叠我们本地的特征感知和全球特征感知块，从而平衡本地和全球特征感知以提高性能。对17个医疗图像分类数据集和12个损坏的医疗图像数据集进行了广泛的实验，这表明MEDVITV2在29个实验中，在计算复杂性降低的29个实验中，获得了最新的实验。 Medvitv2比以前的版本高44 \％\％，并显着提高了准确性，在MedMnist上的提高了4.6 \％，在非MNIST上获得了5.8 \％的改善，而MedMnist-C-C-C基准的提高为13.4 \％。]]></description>
      <guid>https://arxiv.org/abs/2502.13693</guid>
      <pubDate>Thu, 20 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于事件的视频框架插值与跨模式的非对称双向运动场</title>
      <link>https://arxiv.org/abs/2502.13716</link>
      <description><![CDATA[ARXIV：2502.13716V1公告类型：新 
摘要：视频框架插值（VFI）旨在在连续输入帧之间生成中间视频帧。由于事件摄像机是由生物启发的传感器，仅通过微分离的时间分辨率编码亮度变化，因此有几项作品利用事件摄像头来增强VFI的性能。但是，现有方法估计只有事件或近似值的双向框架间运动场，在现实世界场景中无法考虑复杂的运动。在本文中，我们提出了一个基于事件的新型VFI框架，具有交叉模式的非对称双向运动场估计。详细说明，我们的EIF-BIOFNET利用事件和图像的每个有价值的特征，用于直接估算框架间运动场，而无需任何近似方法。此外，我们开发了一个基于交互式注意力的框架合成网络，以有效利用基于互补的基于扭曲和基于合成的特征。最后，我们构建了一个基于事件的大规模VFI数据集ERF-X170FPS，具有高帧速率，极端运动和动态纹理，以克服以前基于事件的VFI数据集的局限性。广泛的实验结果验证了我们的方法对各种数据集的最新VFI方法显示出显着的性能提高。我们的项目页面可在以下网址找到：https：//github.com/intelpro/cbmnet]]></description>
      <guid>https://arxiv.org/abs/2502.13716</guid>
      <pubDate>Thu, 20 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>护理：建筑物密度微调EO基础模型的置信度回归估计</title>
      <link>https://arxiv.org/abs/2502.13734</link>
      <description><![CDATA[Arxiv：2502.13734V1公告类型：新 
摘要：进行准确的置信度量化和评估对于深层神经网络预测其失败，提高性能并提高其在现实世界应用中的能力以及在现实生活中的实际部署至关重要。对于像素的回归任务，与语义分割等分类任务相反，文献中置信度量化和评估尚未得到很好的解决。 SoftMax输出层不用于解决像素回归问题的深层神经网络中。在本文中，为了解决这些问题，我们开发，训练和评估了所提出的模型置信度回归估计（CARE）。我们的模型护理计算并将置信度分配给回归输出结果。我们专注于将回归问题作为AI地球观察基础模型（EO）的下游任务。我们评估了提出的模型护理和实验结果，从哥白尼前哨卫星星座的数据中评估了估计建筑物密度的数据表明，该方法可以成功地应用于回归问题。我们还表明，我们的方法优于其他方法。]]></description>
      <guid>https://arxiv.org/abs/2502.13734</guid>
      <pubDate>Thu, 20 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于验证检测和分类的不同Yolo模型的基准测试</title>
      <link>https://arxiv.org/abs/2502.13740</link>
      <description><![CDATA[ARXIV：2502.13740V1公告类型：新 
摘要：本文使用从Web和DarkNet收集的数据集以及网页的合成数据进行了用于网页验证码检测的Yolov5，Yolov8和Yolov10模型的分析和比较。该研究检查了Yolo体系结构的Nano（N），小（S）和中（M）变体，并使用指标，例如精度，召回，F1分数，MAP@50和推理速度，以确定现实生活中的实用程序。此外，由于它是现实生活应用的关键部分，因此对经过训练的模型进行调查以检测新的验证码模式的可能性有效。提出了图像切片方法是改善超大输入图像检测指标的一种方式，这可能是网页分析中常见的情况。 Nano版本中的模型在速度方面取得了最佳结果，而更复杂的体系结构在其他指标方面得分更好。]]></description>
      <guid>https://arxiv.org/abs/2502.13740</guid>
      <pubDate>Thu, 20 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>