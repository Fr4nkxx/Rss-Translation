<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>CS.CV更新arxiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.cv更新arxiv.org e-print存档。</description>
    <lastBuildDate>Wed, 05 Mar 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>视觉语言模型</title>
      <link>https://arxiv.org/abs/2503.01863</link>
      <description><![CDATA[ARXIV：2503.01863V1公告类型：新 
摘要：随着视觉模型（VLM）的出现，医疗人工智能（AI）经历了重大的技术进步和范式转移。这项调查对医学视觉语言模型（MED-VLMS）的最新进步进行了广泛的综述，该研究将视觉和文本数据整合在一起以增强医疗保健结果。我们讨论了Med-vlms背后的基础技术，说明了如何适应复杂的医疗任务并检查其在医疗保健中的应用。 Med-vlms对临床实践，教育和患者护理的变革性影响，以及诸如数据稀缺，狭窄的任务概括，可解释性问题以及诸如公平，问责制和隐私等道德问题之类的挑战。这些局限性通过数据集分布，计算需求和监管障碍而加剧了这些限制。严格的评估方法和强大的监管框架对于安全整合到医疗保健工作流程至关重要。未来的方向包括利用大规模，不同的数据集，改善跨模式概括以及增强解释性。探索了诸如联邦学习，轻量级体系结构和电子健康记录（EHR）集成之类的创新，作为使访问和提高临床相关性民主化和提高临床相关性的途径。这篇综述旨在对Med-VLMS的优势和局限性提供全面的理解，从而促进其在医疗保健中的道德和平衡的采用。]]></description>
      <guid>https://arxiv.org/abs/2503.01863</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LIVS：包含公共空间的多元化对齐数据集</title>
      <link>https://arxiv.org/abs/2503.01894</link>
      <description><![CDATA[ARXIV：2503.01894V1公告类型：新 
摘要：我们介绍了本地交叉视觉空间（LIVS）数据集，这是包容性城市规划中文本对图像（T2I）模型多标准对齐的基准。 LIV通过与30个社区组织的两年参与过程开发，在634个初始概念中编码了各种空间偏好，并通过37,710个成对比较巩固了六个核心标准：可访问性，安全性，安全性，舒适性，邀请，包容性和多样性。使用直接偏好优化（DPO）来微调稳定的扩散XL，我们观察到可衡量的与社区偏好的比对增加，尽管中性等级的很大一部分突出了建模交叉点需求的复杂性。此外，随着注释量的增加，准确性进一步转移到了DPO调整的模型，这表明较大规模的偏好数据提高了微调效率。 LIV强调了将特定于上下文的，利益相关者驱动的标准集成到生成建模中的必要性，并为评估各种社会空间环境中的AI一致性方法提供了资源。]]></description>
      <guid>https://arxiv.org/abs/2503.01894</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>更快：长期3D对象检测的焦点令牌获取和缩放变压器</title>
      <link>https://arxiv.org/abs/2503.01899</link>
      <description><![CDATA[ARXIV：2503.01899V1公告类型：新 
摘要：基于激光雷达的最新表现最佳的时间3D检测器越来越多地采用了基于区域的范例。他们首先产生粗糙的建议，然后再进行编码和融合区域特征。但是，随着输入帧的数量的增长，不加区分的采样和融合通常忽略各个点的不同贡献，并导致指数增加的复杂性。此外，任意结果级串联限制了全局信息提取。在本文中，我们提出了一个焦点令牌acquring和缩放变压器（更快），该变压器（更快）动态选择焦点令牌并以适应性和轻量级的方式凝结令牌序列。强调单个代币的贡献，我们提出了一种简单但有效的自适应缩放机制，以捕获几何环境，同时筛选焦点。自适应地存储和处理仅在历史框架中的焦点大大降低了整体复杂性。此外，提出了一种新型的分组分层融合策略，逐步执行序列缩放和组内融合操作，以促进全球空间和时间信息的交换。 Waymo开放数据集的实验表明，我们更快的速度在性能和效率方面显着优于其他最先进的探测器，同时还表现出提高的灵活性和鲁棒性。该代码可在https://github.com/msundyy/faster.git上找到。]]></description>
      <guid>https://arxiv.org/abs/2503.01899</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>你在看什么？多模式医学深度学习方法的方式贡献</title>
      <link>https://arxiv.org/abs/2503.01904</link>
      <description><![CDATA[ARXIV：2503.01904V1公告类型：新 
摘要：目的是如今，可以通过巨大的深度神经网络对高维，多模式数据进行分析。已经开发了几种融合不同方式的融合方法。特别是，在医学领域及其存在高维多模式患者数据的多模型模型表征了下一步。但是，尚未得到充分展望的是这些模型如何详细处理源信息。解决这一目标的方法，我们实现了基于闭塞的模型和性能不可知的模式贡献方法，该方法可以定量测量数据集中每种模式的重要性，以使模型完成其任务。我们将方法应用于三个不同的多模式医学问题，以实验目的。结果在本文中，我们发现某些网络具有倾向于单峰倒塌的模式偏好，而某些数据集则从头开始不平衡。此外，我们可以确定我们的指标与单态训练网的性能之间的联系。结论信息通过我们的指标获得的信息具有巨大的潜力，可以改善多模型的开发和未来数据集的创建。通过我们的方法，我们为基于深度学习的多模式研究做出了至关重要的贡献，从而显着将多模式AI的整合性推向了临床实践。我们的代码可在https://github.com/christiangappgit/mc_mmd上公开获得。]]></description>
      <guid>https://arxiv.org/abs/2503.01904</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>REID-SAM的技术报告在SkitB视觉跟踪挑战2025</title>
      <link>https://arxiv.org/abs/2503.01907</link>
      <description><![CDATA[ARXIV：2503.01907V1公告类型：新 
摘要：本报告介绍了Reid-SAM，这是一种针对SkitB挑战开发的新型模型，该模型涉及跟踪滑雪者外观的复杂性。我们的方法将武士跟踪器与人重识别（RE-ID）模块和高级后处理技术集成在一起，以提高挑战滑雪场景的准确性。我们采用基于OSNET的重新ID模型来最大程度地减少身份开关，并使用Kalman过滤或基于Stark的对象检测来使用Yolov11进行精确设备跟踪。当在SKITB数据集上进行评估时，Reid-SAM的最先进的F1得分为0.870，超过了Alpine，Ski跳跃和自由泳滑雪学科的现有方法。这些结果表明，滑雪者跟踪准确性的显着进步，并为冬季运动中的计算机视觉应用提供了宝贵的见解。]]></description>
      <guid>https://arxiv.org/abs/2503.01907</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用4D mmwave雷达进行自动驾驶的道路边界检测</title>
      <link>https://arxiv.org/abs/2503.01930</link>
      <description><![CDATA[ARXIV：2503.01930V1公告类型：新 
摘要：检测道路边界，即可用驾驶区域的静态物理边缘，对于自动驾驶和高级驾驶员辅助系统（ADAS）的安全导航和有效的路径计划很重要。传统上，自动驾驶中的道路边界检测取决于相机和激光镜头。但是，它们容易受到较差的照明条件，例如夜间和阳光直射的眩光，或者对于低端车辆的昂贵。为此，本文介绍了4DADARDARRBD，这是基于4D MMWave Radar的第一种道路边界检测方法，在复杂的驾驶场景中具有成本效益且健壮。主要思想是道路边界（例如栅栏，灌木丛，障碍），反映毫米波，从而为雷达产生点云数据。为了克服4D MMWAVE雷达点云包含许多嘈杂点的挑战，我们最初通过道路边界的物理约束来减少嘈杂点，然后通过纳入基于距离的损失，从而将道路边界点从嘈杂点处分段，从而对远距离的损失进行了损害，该损失对远离实际道路边界的虚假探测点进行了损害。此外，我们通过利用从上一个帧获得的车辆运动补偿的道路边界检测结果以及点云的空间分布来捕获点云序列的时间动力学，以进行点云。我们通过实际驾驶测试评估了4DradarrBD，并达到了93 $ \％$的道路边界点分割精度，中位距离误差最高为0.023 m，与基线模型相比，误差降低了92.6 $ \％$。]]></description>
      <guid>https://arxiv.org/abs/2503.01930</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>可靠的多模式文档检索的重复增强视觉和语言变压器</title>
      <link>https://arxiv.org/abs/2503.01980</link>
      <description><![CDATA[ARXIV：2503.01980V1公告类型：新 
摘要：由于大规模的培训，新颖的建筑和学习设计及其在LLMS和多模式LLMS中的应用，跨模式检索正在增强研究社区的疗效和兴趣。在本文中，我们向前迈进了一步，并设计了一种允许由图像和文本组成的多模式查询的方法，并且可以在多模式文档的集合中搜索，其中图像和文本是交错的。我们的模型RET采用了从查询和文档侧的视觉和文本主干的不同层中提取的多层表示。为了允许多层次和跨模式的理解和特征提取，RET采用了一种新型的基于变压器的复发单元，该单元在不同层上同时集成了文本和视觉特征，并利用了受LSTMS经典设计启发的Sigmoidal Gates。对M2KR和M-Beir基准测试的广泛实验表明，RET在各种环境中实现了最先进的性能。我们的源代码和训练有素的模型可在https://github.com/aimagelab/ret上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2503.01980</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>morpheus：文本驱动的3D高斯舞会形状和颜色样式化</title>
      <link>https://arxiv.org/abs/2503.02009</link>
      <description><![CDATA[ARXIV：2503.02009V1公告类型：新 
摘要：使用Novel-View Consantes探索现实空间很有趣，并以不同的风格重新构想这些世界会增加另一层兴奋。风格化的世界也可以用于有限的培训数据并需要扩展模型的培训分配的下游任务。当前大多数新型视图合成风格化技术都无法令人信服地改变几何形状。这是因为任何几何变化都需要提高样式强度，这通常被限制在定型稳定性和一致性方面。在这项工作中，我们提出了一种新的自回归3D高斯拆卸样式方法。作为此方法的一部分，我们贡献了一种新的RGBD扩散模型，该模型允许对外观和形状风格的强度控制。为了确保在风格化框架之间的一致性，我们结合了新型深度引导的交叉注意，功能注入和经过复合框架条件的经纱控制网，以指导新框架的风格化。我们通过广泛的定性结果，定量实验和用户研究来验证我们的方法。代码将在线发布。]]></description>
      <guid>https://arxiv.org/abs/2503.02009</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ABN-Blip：异常与肺栓塞诊断和报告从CTPA产生报告的引导性语言图像预训练</title>
      <link>https://arxiv.org/abs/2503.02034</link>
      <description><![CDATA[ARXIV：2503.02034V1公告类型：新 
摘要：医学成像在现代医疗保健中起关键作用，计算机断层扫描肺血管造影（CTPA）是诊断肺栓塞和其他胸部状况的关键工具。但是，解释CTPA扫描和产生准确的放射学报告的复杂性仍然是一个重大挑战。本文介绍了ABN-Blip（与异常一致的自举语言图像​​预处理），这是一种高级诊断模型，旨在使异常发现与放射学报告的准确性和全面性相结合。通过利用可学习的查询和跨模式注意机制，我们的模型在检测异常，减少缺失的发现以及与现有方法相比生成结构化报告时表现出了卓越的性能。我们的实验表明，ABN-Blip在准确性和临床相关性上都优于最先进的医学视觉模型和3D报告生成方法。这些结果突出了整合多模式学习策略以改善放射学报告的潜力。源代码可在https://github.com/zzs95/abn-blip上找到。]]></description>
      <guid>https://arxiv.org/abs/2503.02034</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>v $^2 $拨号：通过多模式专家的视频和视觉对话统一</title>
      <link>https://arxiv.org/abs/2503.02063</link>
      <description><![CDATA[ARXIV：2503.02063V1公告类型：新 
摘要：我们提供V $^2 $ DIAL-一种基于专家的新型模型，专门用于同时处理图像和视频输入数据，以进行多模式对话任务。当前的多模型模型主要集中于更简单的任务（例如VQA，Videqa，Video-Text检索），并且经常忽略更具挑战性的对话对应物，例如视频和视觉/图像对话框。此外，尽管它们明显地相似，但它们彼此之间彼此之间的发展有限制了其适用性。为此，我们建议使用单个模型统一这两个任务，该模型首次通过专门的专家将图像和视频联合汇总图像和视频的空间和时间特征，并使用匹配和对比度学习技术对其进行对齐。此外，我们通过研究这些看似相关的任务是否可以从各自的培训数据中相互受益，从而系统地研究了这两个任务之间的域转移。对AVSD和Visdial广泛使用的视频和视觉对话框数据集进行了广泛的评估表明，我们的模型在零摄和微调设置中的四个基准测试中实现了新的最新结果。]]></description>
      <guid>https://arxiv.org/abs/2503.02063</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>低数据限制中NERFS的数据增强</title>
      <link>https://arxiv.org/abs/2503.02092</link>
      <description><![CDATA[ARXIV：2503.02092V1公告类型：新 
摘要：基于神经辐射场的当前方法在低数据限制中失败，尤其是在训练不完整的场景数据时。先前的工作仅在次要视图应用程序中增强培训数据，这会导致幻觉和模型崩溃的数据稀疏数据。相比之下，我们建议在训练期间通过从后部不确定性分布中进行排斥采样来添加一组视图，这是通过将体积不确定性估计器与空间覆盖范围相结合而产生的。我们在部分观察的场景上验证结果；平均而言，与最先进的基线相比，我们的方法的性能要好得多39.9％，而既定场景重建基准的变异性降低了87.5％。我们进一步证明，通过从任何分布中取样来增强训练会导致稀疏环境中更好，更一致的场景重建。这项工作是机器人任务的基础，在这些任务中，通过资源约束，先验未知的环境，增强数据集的数据集至关重要。视频和源代码可在https://murpheylab.github.io/low-data-nerf/上找到。]]></description>
      <guid>https://arxiv.org/abs/2503.02092</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>广义扩散检测器：从扩散模型中采矿的鲁棒特征，用于域将来检测</title>
      <link>https://arxiv.org/abs/2503.02101</link>
      <description><![CDATA[ARXIV：2503.02101V1公告类型：新 
摘要：用于对象检测的域概括（DG）旨在在看不见的情况下增强检测器的性能。由于现实世界应用中的复杂变化，此任务仍然具有挑战性。最近，扩散模型在不同的场景生成中表现出了非凡的功能，这激发了我们探索他们改善DG任务的潜力。我们的方法没有生成图像，而是在扩散过程中提取多步中间特征，以获取用于广义检测的域不变特征。此外，我们提出了一个有效的知识转移框架，该框架使检测器能够通过特征和对象级比对继承扩散模型的概括能力，而不会增加推理时间。我们对六个具有挑战性的DG基准进行了广泛的实验。结果表明，我们的方法可在不同领域和腐败类型的现有DG方法上实现14.0％的映射。值得注意的是，我们的方法甚至胜过大多数域适应方法，而无需访问任何目标域数据。此外，与基线相比，扩散引导的探测器平均显示出15.9％的地图的一致性提高。我们的工作旨在提出一种有效的域名检测方法，并在现实情况下为强大的视觉识别提供潜在的见解。该代码可在\ href {https://github.com/heboyong/generalized-diffusion-detector} {概括性扩散检测器}]]></description>
      <guid>https://arxiv.org/abs/2503.02101</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>掌握者：利用空间信息在单个阶段使用条件扩散模型呈现逼真的手</title>
      <link>https://arxiv.org/abs/2503.02127</link>
      <description><![CDATA[ARXIV：2503.02127V1公告类型：新 
摘要：尽管扩散方法在文本到图像生成中出色，但生成准确的手势仍然是一个重大挑战，导致严重的人工制品，例如手指数量不正确或不自然的手势。为了使扩散模型能够学习空间信息以提高生成的手的质量，我们提出了Handrawer，这是一个调节手工生成过程的模块。具体而言，我们应用图形卷积层来提取Mano手击网顶点中隐含的内源空间结构和物理约束。然后，我们通过交叉注意将这些空间特征与其他方式融合并融合。空间融合的特征用于指导单阶段扩散模型denoising过程，用于高质量的手部区域。为了提高空间特征融合的准确性，我们提出了一个保存位置的零填充（PPZP）融合策略，该策略可确保在扩散模型的相关层中将用档案提取的特征融合到感兴趣的区域中。掌握者了解了整个图像功能，同时要特别注意手动区域，这要归功于额外的手动重建损失与降解损失相结合。为了准确训练和评估我们的方法，我们对广泛使用的海格手势数据集进行了仔细的清洁和重新标记，并获得高质量的多模式数据。定量和定性分析证明了通过多个评估指标在海格数据集上我们方法的最新性能。源代码和我们的增强数据集将在接受论文的情况下公开发布。]]></description>
      <guid>https://arxiv.org/abs/2503.02127</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>太阳能光伏农场的空中红外健康监测</title>
      <link>https://arxiv.org/abs/2503.02128</link>
      <description><![CDATA[ARXIV：2503.02128V1公告类型：新 
摘要：太阳能光伏（PV）农场是全球可再生能源产生的主要来源，但其真正的运营效率通常在大规模上仍然未知。在本文中，我们提出了一个全面的，数据驱动的框架，用于对北美太阳能装置的大规模空降红外检查。利用高分辨率的热图像，我们构建和策划了一个包含数千个PV站点的地理上不同的数据集，从而使基于机器学习的检测和可见频谱中无法检测到的缺陷的定位。我们的管道集成了高级图像处理，地理发射和空气传播的热红外异常检测，以提供严格的性能损失估计。我们重点介绍了在广泛的环境和操作条件范围内的航空数据收集，注释方法和模型部署中的实际考虑。我们的工作为大型太阳能资产的可靠性提供了新的见解，并为可再生能源领域的绩效趋势，预测性维护和可扩展分析提供了持续研究的基础。]]></description>
      <guid>https://arxiv.org/abs/2503.02128</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>视频dprp：一种差异私人方法，用于视觉隐私视频人类活动识别</title>
      <link>https://arxiv.org/abs/2503.02132</link>
      <description><![CDATA[ARXIV：2503.02132V1公告类型：新 
摘要：保存隐私视频人的活动识别（HAR）已做出了巨大的努力。确保视频HAR中隐私保护的两种主要方法是差异隐私（DP）和视觉隐私。在培训期间执行DP的技术提供了强大的理论隐私保证，但为视觉隐私评估提供了有限的功能。相反，方法（例如低分辨率转换，数据混淆和对抗网络）强调视觉隐私，但缺乏明确的理论隐私保证。在这项工作中，我们重点介绍了两个主要目标：（1）利用DP属性在视频中开发一种无模型的视觉隐私方法，以及（2）使用差异隐私和视觉隐私评估对HAR任务进行评估我们所提出的技术。为了实现目标（1），我们介绍了视频-DPRP：视频样本差异化私人随机投影框架，用于保存HAR的隐私视频重建。通过使用随机投影，噪声矩阵和源自视频的单数值分解的正确奇异向量，视频dprp使用隐私参数（$ \ epsilon，\ delta $）重建了DP视频，同时启用了视觉隐私评估。对于目标（2），使用UCF101和HMDB51数据集，我们将视频DPRP与传统的DP方法以及最先进的ART（SOTA）视觉隐私技术进行比较。此外，我们使用PA-HMDB和VISPR数据集评估了其在保存与隐私相关的属性（例如面部特征，性别和肤色）方面的有效性。 Video-DPRP从DP和视觉隐私的角度结合了隐私保护，与SOTA方法不同，通常仅解决这些方面之一。]]></description>
      <guid>https://arxiv.org/abs/2503.02132</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>