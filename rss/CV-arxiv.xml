<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CV 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Fri, 31 Jan 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>VidSole：基于深度学习的关节动力学量化和疾病检测多模态数据集</title>
      <link>https://arxiv.org/abs/2501.17890</link>
      <description><![CDATA[arXiv:2501.17890v1 公告类型：新
摘要：了解内部关节负荷对于诊断膝关节骨关节炎等步态相关疾病至关重要；然而，目前测量关节风险因素的方法既耗时又昂贵，而且仅限于实验室环境。在本文中，我们通过三个关键贡献实现了大规模、经济高效的关节负荷生物力学分析：开发和部署新型仪器鞋垫、创建大型多模态生物力学数据集 (VidSole) 以及用于预测内部关节负荷因素的基线深度学习管道。我们新型的仪器鞋垫可测量足底五个高压点的三轴力和力矩。 VidSole 包含这些鞋垫测量的力和力矩，以及从两个视点拍摄的相应 RGB 视频、3D 身体运动捕捉和力板数据，这些数据来自 52 位不同参与者的 2,600 多次试验，这些参与者执行四项基本日常生活活动（从坐到站、从站到坐、步行和跑步）。我们将鞋垫数据和从视频中提取的运动参数（即姿势、膝盖角度）输入深度学习管道，该管道由集成门控循环单元 (GRU) 活动分类器和活动特定的长短期记忆 (LSTM) 回归网络组成，以估计膝关节内收力矩 (KAM)，这是膝关节骨关节炎的生物力学风险因素。成功对活动进行分类的准确率为 99.02%，KAM 估计的平均绝对误差 (MAE) 小于 0.5%*体重*身高，这是使用 KAM 准确检测膝关节骨关节炎的当前阈值，说明了我们的数据集对未来研究和临床环境的有用性。]]></description>
      <guid>https://arxiv.org/abs/2501.17890</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有目标补丁排名的无监督 Patch-GAN 用于医学成像中的细粒度新颖性检测</title>
      <link>https://arxiv.org/abs/2501.17906</link>
      <description><![CDATA[arXiv:2501.17906v1 公告类型：新
摘要：由于罕见异常的标记数据有限，检测医学成像中的新异常具有挑战性，而这些异常通常表现出高度的可变性和细微性。当小的异常区域嵌入较大的正常区域时，这一挑战会进一步加剧，因为整个图像预测经常会忽略这些细微的偏差。为了解决这些问题，我们提出了一个无监督的 Patch-GAN 框架，旨在通过捕获局部细节和全局结构来检测和定位异常。我们的框架首先重建蒙版图像以学习细粒度的、正常特定的特征，从而增强对偏离正常的微小偏差的灵敏度。通过将这些重建的图像分成块并评估每个块的真实性，我们的方法可以在更精细的级别识别异常，从而克服了整幅图像评估的局限性。此外，补丁排序机制优先考虑异常分数较高的区域，从而增强局部补丁差异与全局图像上下文之间的一致性。在 ISIC 2016 皮肤病变和 BraTS 2019 脑肿瘤数据集上的实验结果验证了我们框架的有效性，分别实现了 95.79% 和 96.05% 的 AUC，并且优于三个最先进的基线。]]></description>
      <guid>https://arxiv.org/abs/2501.17906</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>TransRAD：用于增强雷达物体检测的保留视觉变换器</title>
      <link>https://arxiv.org/abs/2501.17977</link>
      <description><![CDATA[arXiv:2501.17977v1 公告类型：新
摘要：尽管自动驾驶和智能机器人的环境感知能力取得了重大进步，但摄像头和激光雷达在低光照条件和恶劣天气下仍然非常不可靠，这限制了它们的有效性。雷达是一种可靠且低成本的传感器，可以有效地弥补这些局限性。然而，由于雷达数据固有的弱点，例如分辨率低、噪声高和缺乏视觉信息，基于雷达的物体检测尚未得到充分探索。在本文中，我们提出了 TransRAD，这是一种新颖的 3D 雷达物体检测模型，旨在通过利用保留视觉变换器 (RMT) 来更有效地从信息密集的雷达距离-方位角-多普勒 (RAD) 数据中学习特征来解决这些挑战。我们的方法利用 RMT 提供的保留曼哈顿自注意力 (MaSA) 机制来整合显式空间先验，从而能够更准确地与 RAD 数据中雷达目标的空间显着性特征对齐，并实现跨距离-方位角-多普勒维度的精确 3D 雷达检测。此外，我们提出了位置感知 NMS，以有效缓解深度雷达物体检测中常见的重复边界框问题。实验结果表明，TransRAD 在 2D 和 3D 雷达检测任务中均优于最先进的方法，实现了更高的精度、更快的推理速度和更低的计算复杂度。代码可在 https://github.com/radar-lab/TransRAD 获得]]></description>
      <guid>https://arxiv.org/abs/2501.17977</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>VoD-3DGS：依赖于视角不透明度的 3D 高斯溅射</title>
      <link>https://arxiv.org/abs/2501.17978</link>
      <description><![CDATA[arXiv:2501.17978v1 公告类型：新
摘要：从图像重建 3D 场景具有挑战性，因为光与表面的相互作用方式取决于观察者的位置和表面的材质。在经典计算机图形学中，材料可以分为漫反射或镜面反射，与光的相互作用不同。标准的 3D 高斯溅射模型难以表示与视图相关的内容，因为它无法区分场景中的物体与与其镜面相互作用的光，后者会产生高光或反射。在本文中，我们建议通过引入额外的对称矩阵来扩展 3D 高斯溅射模型，以增强每个 3D 高斯的不透明度表示。这种改进允许根据观察者的视角抑制某些高斯，从而更准确地表示与视图相关的反射和镜面高光，而不会损害场景的完整性。通过允许不透明度依赖于视图，我们的增强模型在 Mip-Nerf、Tanks\&amp;Temples、Deep Blending 和 Nerf-Synthetic 数据集上实现了最先进的性能，而不会显著损失渲染速度，实现 &gt;60FPS，并且仅导致内存使用量略有增加。]]></description>
      <guid>https://arxiv.org/abs/2501.17978</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>无人机目标检测的高效特征融合</title>
      <link>https://arxiv.org/abs/2501.17983</link>
      <description><![CDATA[arXiv:2501.17983v1 公告类型：新
摘要：由于图像质量不稳定、物体尺寸小、背景复杂以及环境遮挡，无人机 (UAV) 遥感图像中的物体检测面临重大挑战。特别是小物体在图像中占据的份额极小，因此准确检测非常困难。现有的多尺度特征融合方法通过聚合不同分辨率的特征在一定程度上解决了这些挑战。然而，这些方法往往无法有效地平衡小物体的分类和定位性能，主要是由于特征表示不足和网络信息流不平衡。在本文中，我们提出了一种专门为无人机物体检测任务设计的新型特征融合框架，以提高定位精度和分类性能。所提出的框架集成了混合上采样和下采样模块，使得来自不同网络深度的特征图可以灵活地调整到任意分辨率。这种设计有利于跨层连接和多尺度特征融合，确保改善小物体的表示。我们的方法利用混合下采样来增强细粒度特征表示，即使在复杂条件下也能改善小目标的空间定位。同时，上采样模块聚合全局上下文信息，优化跨尺度的特征一致性并增强杂乱场景中的分类鲁棒性。在两个公共无人机数据集上的实验结果证明了所提框架的有效性。集成到 YOLO-V10 模型中，我们的方法与基线 YOLO-V10 模型相比，平均精度 (AP) 提高了 2%，同时保持了相同数量的参数。这些结果凸显了我们的框架在准确、高效的无人机物体检测方面的潜力。]]></description>
      <guid>https://arxiv.org/abs/2501.17983</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 SIREN 进行压力场重建：复杂噪声环境下的无网格图像测速方法</title>
      <link>https://arxiv.org/abs/2501.17987</link>
      <description><![CDATA[arXiv:2501.17987v1 公告类型：新
摘要：本研究提出了一种使用 SIREN（正弦表示网络）从图像测速数据重建压力场的新方法，强调了其作为噪声环境中隐式神经表示的有效性及其无网格特性。虽然我们简要评估了最近提出的两种方法——一次性矩阵全向积分（OS-MODI）和格林函数积分（GFI），但主要关注的是 SIREN 方法的优势。OS-MODI 技术在无噪声条件和结构化网格中表现良好，但在应用于高纵横比的非结构化网格时会遇到困难。同样，GFI 方法由于牛顿核固有的奇异性而遇到困难。相比之下，所提出的 SIREN 方法是一种无网格方法，它直接重建压力场，无需固有的网格连接，因此避免了与病态单元和非结构化网格相关的挑战。这比传统的基于网格的方法具有明显的优势。此外，结果表明，SIREN 架构的变化可用于滤除测速数据中的固有噪声。这项工作将 SIREN 定位为一种强大而通用的压力重建解决方案，特别是在缺乏网格结构的嘈杂环境中，为该领域的创新应用开辟了新途径。]]></description>
      <guid>https://arxiv.org/abs/2501.17987</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>解剖学可能是您所需要的：预测手术期间要做什么</title>
      <link>https://arxiv.org/abs/2501.18011</link>
      <description><![CDATA[arXiv:2501.18011v1 公告类型：新
摘要：手术指导可以通过多种方式提供。在神经外科手术中，空间引导和定位主要通过参考术前 MRI 扫描的神经导航系统实现。最近，人们对通过分析内窥镜等工具的视频源提供实时指导的兴趣日益浓厚。现有的方法，包括解剖检测、方向反馈、相位识别和视觉问答，主要侧重于帮助外科医生评估当前的手术场景。这项工作旨在提供更精细的指导，旨在通过预测手术器械的轨迹来提供指导，从本质上解决下一步做什么的问题。为了完成这项任务，我们提出了一个模型，它不仅利用手术器械的历史位置，还整合了解剖特征。重要的是，我们的工作不依赖于器械轨迹的明确地面真实标签。相反，基本事实是由一个检测模型生成的，该模型经过训练，可以在包含垂体手术视频的综合数据集的手术视频中检测解剖结构和器械。通过分析这些视频中解剖结构和器械运动之间的相互作用并预测未来的器械运动，我们表明解剖特征是解决这一具有挑战性的任务的宝贵资产。据我们所知，这项工作是首次尝试解决手动手术的这一任务。]]></description>
      <guid>https://arxiv.org/abs/2501.18011</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>视觉生成人工智能：框架和应用的全面研究</title>
      <link>https://arxiv.org/abs/2501.18033</link>
      <description><![CDATA[arXiv:2501.18033v1 公告类型：新
摘要：生成式人工智能正在改变图像合成，使设计、媒体、医疗保健和自主系统等行业能够创建高质量、多样化和逼真的视觉效果。图像到图像转换、文本到图像生成、域传输和多模态对齐等技术的进步扩大了自动视觉内容创建的范围，支持广泛的应用。这些进步是由生成对抗网络 (GAN)、条件框架和基于扩散的方法（如稳定扩散）等模型推动的。这项工作根据输入的性质对图像生成技术进行了结构化分类，按输入模态（如噪声向量、潜在表示和条件输入）组织方法。我们探索这些模型背后的原理，重点介绍包括 DALL-E、ControlNet 和 DeepSeek Janus-Pro 在内的关键框架，并解决计算成本、数据偏差和输出与用户意图对齐等挑战。通过提供以输入为中心的视角，这项研究将技术深度与实践见解结合起来，为研究人员和从业者提供了全面的资源，以利用生成式人工智能来实现现实世界的应用。]]></description>
      <guid>https://arxiv.org/abs/2501.18033</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士无需任何培训就能看和听</title>
      <link>https://arxiv.org/abs/2501.18096</link>
      <description><![CDATA[arXiv:2501.18096v1 公告类型：新
摘要：我们提出了 MILS：多模态迭代 LLM 求解器，这是一种令人惊讶的简单、无需训练的方法，可将多模态功能注入您最喜欢的 LLM。利用其执行多步推理的先天能力，MILS 提示 LLM 生成候选输出，每个输出都经过评分并迭代反馈，最终生成任务的解决方案。这使得各种应用程序能够使用通常需要在特定于任务的数据上训练专门的模型。特别是，我们在新兴的零样本图像、视频和音频字幕方面建立了新的最先进技术。MILS 也无缝应用于媒体生成，发现提示重写以改进文本到图像的生成，甚至编辑提示以进行风格转换！最后，作为一种无梯度优化方法，MILS 可以将多模态嵌入反转为文本，从而实现跨模态算术等应用。]]></description>
      <guid>https://arxiv.org/abs/2501.18096</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过各向异性和局部性解开安全和不安全的损坏</title>
      <link>https://arxiv.org/abs/2501.18098</link>
      <description><![CDATA[arXiv:2501.18098v1 公告类型：新
摘要：最先进的机器学习系统容易受到输入的小扰动的影响，其中“小”是根据威胁模型定义的，该模型为每个扰动分配一个正威胁。大多数先前的工作定义了与任务无关的、各向同性的和全局的威胁，如$ \ ell_p $范数，其中扰动的大小完全决定了威胁的程度，而不是攻击的方向或其在空间物质中的位置。然而，这种威胁模型不能很好地捕捉到计算机视觉中常见的损坏，例如模糊、压缩或遮挡。本文提出了一种称为\ texttt {Projected Displacement}（PD）的新型威胁模型，以研究超越现有各向同性和全局威胁模型的鲁棒性。所提出的威胁模型通过扰动与 \textit{不安全方向} 的对齐来衡量扰动的威胁，\textit{不安全方向} 定义为输入空间中的方向，足够大的扰动会沿着该方向改变真实类别标签。根据观察到的训练数据，为每个输入在本地识别不安全方向。这样，PD 威胁模型表现出各向异性和局部性。在 Imagenet-1k 数据上进行的实验表明，对于任何输入，具有较小 PD 威胁的扰动集包括保留真实标签的大 $\ell_p$ 范数的 \textit{安全} 扰动，例如噪声、模糊和压缩，同时排除改变真实标签的 \textit{不安全} 扰动。与基于大视觉模型嵌入的感知威胁模型不同，PD 威胁模型可以轻松计算任意分类任务，而无需预训练或微调。其他附加任务注释（例如对图像区域或概念层次的敏感性）可以轻松集成到威胁评估中，因此 PD 威胁模型为从业者提供了灵活的、任务驱动的威胁规范。]]></description>
      <guid>https://arxiv.org/abs/2501.18098</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DeepFRC：用于功能注册和分类的端到端深度学习模型</title>
      <link>https://arxiv.org/abs/2501.18116</link>
      <description><![CDATA[arXiv:2501.18116v1 公告类型：新
摘要：功能数据分析 (FDA) 对于分析连续、高维数据至关重要，但现有方法通常会将功能配准和分类分离，从而限制其效率和性能。我们提出了 DeepFRC，这是一个端到端深度学习框架，可将这些任务统一到一个模型中。我们的方法结合了一个通过弹性函数配准学习时间扭曲函数的对齐模块和一个用于对对齐数据进行降维的可学习基础表示模块。这种集成提高了对齐精度和预测性能。理论分析表明 DeepFRC 实现了较低的错位和泛化误差，而模拟阐明了训练期间配准、重建和分类的进展。在真实数据集上的实验表明，DeepFRC 始终优于最先进的方法，特别是在解决复杂的配准挑战方面。代码可在以下位置获得：https://github.com/Drivergo-93589/DeepFRC。]]></description>
      <guid>https://arxiv.org/abs/2501.18116</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>远程：通过多模式视觉特征学习对各种内窥镜进行实时自我运动跟踪</title>
      <link>https://arxiv.org/abs/2501.18124</link>
      <description><![CDATA[arXiv:2501.18124v1 公告类型：新
摘要：内窥镜的实时自我运动跟踪是实现内窥镜高效导航和机器人自动化的重要任务。本文提出了一种用于内窥镜实时自我运动跟踪的新型框架。首先，提出一种多模态视觉特征学习网络进行相对姿态预测，其中提取光流中的运动特征、场景特征和两个相邻观测的联合特征进行预测。由于拼接图像的通道维度上存在更多相关信息，因此基于注意机制设计了一种新型特征提取器，以整合来自两个连续帧拼接的多维信息。为了从融合特征中提取更完整的特征表示，提出了一种新型姿态解码器，以在框架末尾从拼接特征图中预测姿态变换。最后，根据相对姿态计算内窥镜的绝对姿态。实验在三个不同内窥镜场景的数据集上进行，结果表明，所提出的方法优于最先进的方法。此外，所提出方法的推理速度超过每秒 30 帧，满足实时要求。项目页面在这里：\href{https://remote-bmxs.netlify.app}{remote-bmxs.netlify.app}]]></description>
      <guid>https://arxiv.org/abs/2501.18124</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>IROAM：通过从自动驾驶汽车数据域学习改进路边单目 3D 物体检测</title>
      <link>https://arxiv.org/abs/2501.18162</link>
      <description><![CDATA[arXiv:2501.18162v1 公告类型：新 
摘要：在自动驾驶中，路边传感器可以提高车辆的感知能力，从而提供对环境的整体视图。然而，现有的为车载摄像头设计的单目检测方法由于视点域差距而不适用于路边摄像头。为了弥合这一差距并改进路边单目 3D 物体检测，我们提出了 IROAM，这是一种语义几何解耦的对比学习框架，它同时将车侧和路侧数据作为输入。IROAM 有两个重要模块。域内查询交互模块利用转换器学习每个域的内容和深度信息并输出对象查询。跨域查询增强为了从两个域中学习更好的特征表示，跨域查询增强将查询解耦为语义和几何部分，并且仅使用前者进行对比学习。实验证明了 IROAM 在提高路边检测器性能方面的有效性。结果验证了IROAM具有学习跨域信息的能力。]]></description>
      <guid>https://arxiv.org/abs/2501.18162</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用脑电图数据检测抑郁症的机器学习公平性</title>
      <link>https://arxiv.org/abs/2501.18192</link>
      <description><![CDATA[arXiv:2501.18192v1 公告类型：新
摘要：本文首次尝试使用脑电图 (EEG) 数据评估机器学习在抑郁症检测中的公平性。我们使用不同的深度学习架构（例如卷积神经网络 (CNN)、长短期记忆 (LSTM) 网络和门控循环单元 (GRU) 网络）在三个 EEG 数据集（Mumtaz、MODMA 和 Rest）上进行实验。我们在预处理、中处理和后处理阶段采用五种不同的偏差缓解策略并评估其有效性。我们的实验结果表明，现有的抑郁症检测 EEG 数据集和算法存在偏差，不同的偏差缓解方法在不同公平性措施中解决不同程度的偏差。]]></description>
      <guid>https://arxiv.org/abs/2501.18192</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Free-T2M：具有一致性损失的频率增强文本到运动扩散模型</title>
      <link>https://arxiv.org/abs/2501.18232</link>
      <description><![CDATA[arXiv:2501.18232v1 公告类型：新
摘要：文本到运动生成的快速发展在很大程度上是由扩散模型推动的。然而，现有的方法只关注时间建模，从而忽略了频域分析。我们确定了运动去噪的两个关键阶段：**语义规划阶段**和**细粒度改进阶段**。为了有效地解决这些阶段，我们提出了**频率增强**t**ext-**to**m**运动扩散模型（**Free-T2M**），结合了阶段特定的一致性损失，增强了静态特征的鲁棒性并提高了细粒度准确性。大量实验证明了我们方法的有效性。具体来说，在 StableMoFusion 上，我们的方法将 FID 从 **0.189** 降低到 **0.051**，在扩散架构中建立了新的 SOTA 性能。这些发现强调了将频域见解纳入文本到运动生成以获得更精确和更稳健的结果的重要性。]]></description>
      <guid>https://arxiv.org/abs/2501.18232</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>