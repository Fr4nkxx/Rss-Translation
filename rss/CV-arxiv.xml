<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>CS.CV更新arxiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.cv更新arxiv.org e-print存档。</description>
    <lastBuildDate>Fri, 21 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>通过自同一数据增强多模式基础模型的认知和解释性</title>
      <link>https://arxiv.org/abs/2502.14044</link>
      <description><![CDATA[ARXIV：2502.14044V1公告类型：新 
摘要：大型多模型模型（LMM）在广泛的视觉任务中显示出令人印象深刻的功能。但是，他们经常在细粒度的视觉推理上挣扎，无法识别特定领域的目标，并为其预测提供了合理的解释。为了解决这个问题，我们提出了一个新颖的视觉拒绝采样框架，以使用自合成的数据提高LMM的认知和解释性。具体而言，视觉微调需要图像，查询和目标答案。我们的方法首先综合了包括可验证的视觉特征的可解释答案。这些功能基于专家定义的概念，根据它们与图像内容的对齐方式进行了精心选择。每一轮微调后，我们都会应用无奖励模型的过滤机制，为下一轮调整选择最高质量的可解释答案。这种数据合成和微调的迭代过程逐渐提高了模型产生准确和合理的解释的能力。实验结果证明了我们方法在提高专业视觉分类任务的准确性和解释性方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2502.14044</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>有效的6D：可扩展有效的6D对象姿势估计</title>
      <link>https://arxiv.org/abs/2502.14061</link>
      <description><![CDATA[ARXIV：2502.14061V1公告类型：新 
摘要：在需要实时反馈的工业应用中，例如质量控制和机器人操纵，对高速和准确的姿势估计的需求仍然至关重要。尽管提高了姿势估计的速度和准确性，但在计算效率和准确性之间找到平衡仍在动态环境中带来了重大挑战。当前大多数算法在估计时间中都缺乏可扩展性，尤其是对于不同的数据集，最新的（SOTA）方法通常太慢了。这项研究重点是基于GDRNPP开发一组快速，可扩展的姿势估计器，以满足或超过当前基准的准确性和鲁棒性，尤其是解决实时场景中必不可少的效率 - 准确性权衡问题。我们建议根据推理时间和准确性之间的特定应用权衡来量身定制使用模型。我们进一步显示了基于AMIS的模型选择在四个突出基准数据集（LM-O，YCB-V，T-less和ITODD）上的有效性。]]></description>
      <guid>https://arxiv.org/abs/2502.14061</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>PEDDET：用于多模式行人检测的自适应光谱优化</title>
      <link>https://arxiv.org/abs/2502.14063</link>
      <description><![CDATA[arxiv：2502.14063v1公告类型：新 
摘要：智能运输系统中的行人检测取得了重大进展，但面临两个关键挑战：（1）可见光和红外光谱之间的互补信息融合不足，尤其是在复杂的情况下，以及（2）对照明变化的敏感性，例如低 - 光线或过度曝光的条件，导致性能退化。为了解决这些问题，我们提出了PEDDET，这是一种自适应光谱优化互补性框架，专门增强和优化，可用于多光谱的行人检测。 PEDDET引入了多尺度光谱特征感知模块（MSFPM），以适应可见和红外功能，增强了功能提取方面的鲁棒性和灵活性。此外，通过解耦行人和背景特征，照明鲁棒性特征解耦模块（IRFDM）在不同的照明下提高了检测稳定性。我们进一步设计了对比度对齐，以增强联运特征歧视。 LLVIP和MSDS数据集的实验表明，PEDDET可以实现最先进的性能，即使在弱光条件下，也以卓越的检测精度提高了地图，这标志着道路安全的重要一步。代码将在https://github.com/aigeeksgroup/peddet上找到。]]></description>
      <guid>https://arxiv.org/abs/2502.14063</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>三合会：3D磁共振成像的视觉基础模型</title>
      <link>https://arxiv.org/abs/2502.14064</link>
      <description><![CDATA[ARXIV：2502.14064V1公告类型：新 
摘要：视觉基础模型（VFM）已在广泛的图像数据集上进行了预训练，以了解各种数据类型的一般表示形式。这些模型随后可以通过针对特定的下游任务进行微调，从而在广泛的应用程序中显着提高了性能。但是，声称适用于各种放射学任务的现有视觉基础模型主要是在3D计算机断层扫描（CT）上进行的，该模型受益于广泛的3D CT数据库的可用性。 CT和磁共振成像（MRI）在成像原理，信号特性和数据分布中之间的显着差异可能会阻碍其在MRI特异性应用中的实际性能和多功能性。在这里，我们提出了Triad，这是3D MRI的视觉基础模型。 Triad采用了广泛使用的自动编码器体系结构来从131,170 3D MRI量学习稳健表示，并使用无独立的成像描述来限制视觉模态的语义分布。上述培训数据集称为Triad-131K，目前是最大的3D MRI预训练数据集。我们使用25个下游数据集以两种数据方式（内域和域内）设置进行了两种数据模式（域内和室外）设置，评估了三个任务，即器官/肿瘤分割，器官/癌症分类和医疗图像注册。通过使用Triad的预训练的重量初始化模型，NNUNET-TRIAD将分割性能提高了6.88％，而NNUNET-SCRATTH则在17个数据集中提高了分段性能。 Swin-B-Triad在五个数据集中的分类任务中，Swin-B-Triad在分类任务中取得了3.97％的提高。在两个数据集中的注册任务中，与Swinunetr-Scratch相比，Swinunetr-Triad提高了4.00％。我们的研究表明，当上游和下游任务的数据方式和器官一致时，预训练可以最大程度地提高性能。]]></description>
      <guid>https://arxiv.org/abs/2502.14064</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>赛车数据集和基线模型，用于自动赛车中的轨道检测</title>
      <link>https://arxiv.org/abs/2502.14068</link>
      <description><![CDATA[Arxiv：2502.14068V1公告类型：新 
摘要：与赛车相关的研究中的一个重大挑战是缺乏包含针对下游任务的相应注释的原始图像的公开数据集。在本文中，我们介绍了Roratrack，Roratrack是一个新颖的数据集，其中包含来自赛车场景的带注释的多相机图像数据，以进行轨道检测。该数据是在印第安纳州的赛车巡回赛上与Indy Autonomous Challenge（IAC）合作收集的。 Roratrack解决了常见问题，例如由于高速，摄像机的颜色反转以及轨道上没有车道标记而导致的颜色。因此，我们建议Racegan，这是一种基于生成对抗网络（GAN）的基线模型，可有效解决这些挑战。所提出的模型与轨道检测中的当前最新机器学习模型相比表明了卓越的性能。该工作的数据集和代码可在github.com/racegan获得。]]></description>
      <guid>https://arxiv.org/abs/2502.14068</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DIFFEXP：在文本到图像扩散模型的奖励微调中有效探索</title>
      <link>https://arxiv.org/abs/2502.14070</link>
      <description><![CDATA[ARXIV：2502.14070V1公告类型：新 
摘要：最大化奖励的微调文本对图像扩散模型已被证明有效地增强了模型性能。但是，奖励微调方法通常由于在线样本的生成而经常遭受缓慢的收敛性。因此，获得具有强烈奖励信号的不同样品对于提高样本效率和整体性能至关重要。在这项工作中，我们介绍了DIFFEXP，这是一种简单而有效的探索策略，用于奖励文本对图像模型的微调。我们的方法采用了两种关键策略：（a）动态调整无分类器指导的规模以增强样本多样性，以及（b）文本提示的随机加权短语，以利用高质量的奖励信号。我们证明，这些策略可以显着增强在线样本生成期间的探索，从而提高了最近的奖励微调方法的样本效率，例如DDPO和AlignProp。]]></description>
      <guid>https://arxiv.org/abs/2502.14070</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>EO中的回归：VLMS是否应对挑战？</title>
      <link>https://arxiv.org/abs/2502.14088</link>
      <description><![CDATA[ARXIV：2502.14088V1公告类型：新 
摘要：地球观察（EO）数据涵盖了广泛的远程感知信息，具有多传感器和多阶段的信息，在理解我们的星球的动态方面发挥了必不可少的作用。最近，视觉语言模型（VLM）在感知和推理任务中取得了巨大的成功，为EO领域带来了新的见解和机会。但是，EO应用的潜力，尤其是对于科学回归相关的应用，在很大程度上尚未探索。本文通过系统地检查适应EO回归任务的VLM的挑战和机会来弥合差距。讨论首先将EO数据的独特属性与常规的计算机视觉数据集进行了对比，然后确定将VLMS应用于EO回归时的四个核心障碍：1）缺乏专用基准测试，2）离散的连续性表示不匹配，3）累积误差积累，以及4）数值任务中以文本为中心培训目标的次优质。接下来，探索了一系列方法论见解和潜在的微妙陷阱。最后，我们提供了一些有希望的未来方向，用于设计健壮的领域感知解决方案。我们的发现突出了VLM对EO科学回归的希望，为关键环境过程的更精确，更可解释的建模奠定了基础。]]></description>
      <guid>https://arxiv.org/abs/2502.14088</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用分辨率和质量条件的潜在概率估计器的点云几何形状可扩展编码</title>
      <link>https://arxiv.org/abs/2502.14099</link>
      <description><![CDATA[ARXIV：2502.14099V1公告类型：新 
摘要：在当前年龄，在网络，硬件和显示功能方面，用户在非常异构的情况下消耗多媒体内容。对此问题的幼稚解决方案是编码多个独立的流，每流涵盖客户的不同要求，对存储和计算要求都有明显的负面影响。可以通过使用启用可伸缩性的编解码器来避免这些缺点，即产生渐进性比特斯流的能力，其中包含基本层，然后是多个增强层，从而允许解码相同的bitstream服务多个重构和可视化规格。虽然可扩展的编码是常规图像和视频编解码器中的一项知名且涉及的功能，但本文侧重于一个新的且非常不同的问题，尤其是开发用于深度学习的点云（PC）编码的可扩展编码解决方案。该3D表示的特殊性使得难以实施不会损害编解码器其他功能的灵活解决方案。本文提出了一种联合质量和分辨率可伸缩性方案，称为可扩展分辨率和质量高位（SRQH），与以前的解决方案相反，可以模拟使用针对不同RD折衷方案和/或不同分辨率训练的模型获得的潜在关系的关系。通过在新兴JPEG PLENO学习基于PC编码标准中集成SRQH获得的实验结果表明，SRQH允许以不同的质量和分辨率用单个bitstream解码PC，同时仅在有限的RD惩罚和复杂性w.r.t.中出现。不可估计的JPEG PCC需要每个编码配置一个焦点。]]></description>
      <guid>https://arxiv.org/abs/2502.14099</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>以对比语言图像预处理中以对象为中心的绑定</title>
      <link>https://arxiv.org/abs/2502.14113</link>
      <description><![CDATA[ARXIV：2502.14113V1公告类型：新 
摘要：视觉语言模型（VLM）的最新进展是由诸如剪辑之类的对比模型驱动的，这些模型学会将视觉信息与相应的文本描述相关联。但是，这些模型在理解涉及多个对象及其空间关系的复杂组成场景方面有局限性。为了应对这些挑战，我们提出了一种新颖的方法，该方法与常用策略不同，该方法依赖于硬性增强的设计。取而代之的是，我们的工作着重于将归纳偏见整合到类似培训的夹子样模型中，以改善其组成理解，而无需使用任何其他硬性阴性。为此，我们引入了一个结合模块，该模块连接一个从文本描述中得出的场景图，并带有插槽结构的图像表示，从而促进了两种模式之间的结构化相似性评估。我们还利用关系作为文本条件的视觉约束，从而更有效地捕获对象之间的复杂相互作用。我们最终的模型不仅增强了基于夹的模型在多对象组成理解中的性能，而且还为复杂场景的更准确和样品效率的图像文本匹配铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2502.14113</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>模块化提示学习改善视觉语言模型</title>
      <link>https://arxiv.org/abs/2502.14125</link>
      <description><![CDATA[ARXIV：2502.14125V1公告类型：新 
摘要：预训练的视觉模型能够解释视觉概念和语言语义。及时学习，一种构造文本编码器或图像编码器提示的方法，引起了预训练的模型的潜力，并很容易地适应新方案。与微调相比，提示学习使模型能够使用更少的可训练参数实现可比较或更好的性能。此外，及时学习会冻结预训练的模型，并避免微调中的灾难性遗忘问题。连续提示插入每个变压器层的输入（即深提示）可以改善在下游任务上预训练模型的性能。对于第三变压器层，插入的提示替换了先前插入的提示，以$（i-1）$ -TH层。尽管自我发挥的机制在上一层的输出中插入了当前层和嵌入的新插入提示，但从上一层中删除了所有插入的提示，不可避免地会丢失连续提示中包含的信息。在这项工作中，我们提出了模块化提示学习（MPL），旨在促进插入的提示中包含的信息。我们评估了针对基本概括和跨数据集任务的建议方法。与最先进的方法相比，我们的方法平均有11个数据集，在基本到新的概括任务上获得了0.7％的性能增长。单个数据集的最大改进是10.7％（欧洲裔数据集）。]]></description>
      <guid>https://arxiv.org/abs/2502.14125</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Glossgau：具有各向异性球形高斯的光泽表面的有效逆呈现</title>
      <link>https://arxiv.org/abs/2502.14129</link>
      <description><![CDATA[ARXIV：2502.14129V1公告类型：新 
摘要：从校准照片中重建3D对象代表了计算机图形和视觉领域的基本而复杂的挑战。尽管基于神经辐射场（NERF）的神经重建方法表现出显着的功能，但它们的处理成本仍然很大。最近，3D高斯脱落（3D-GS）的出现在很大程度上提高了训练效率，并促进了实时产生逼真的渲染。但是，由于球形谐波（SH）代表高频信息的能力有限，因此3D-GS在重建光滑的物体方面缺乏。研究人员转向通过反向渲染来提高3D-GS的镜面表现力。然而，这些方法通常很难维持训练和提高效率，从而破坏了高斯脱衣技术的好处。在本文中，我们介绍了Glossgau，这是一个有效的反向渲染框架，它可以用光滑的表面重建场景，同时保持训练和渲染速度与Vanilla 3D-GS相当。具体而言，我们明确对表面正常，双向反射分布函数（BRDF）参数以及事件灯进行建模，并使用各向异性球形高斯（ASG）近似于微胶囊模型下的每高斯正态分布函数。我们利用2D高斯脱落（2D-GS）作为基础原始物质，并应用正则化以显着减轻相关工作中遇到的正常估计挑战。实验表明，Glossgau在具有光滑表面的数据集上实现了竞争性或优越的重建。与以前基于GS的工作相比，我们的优化时间要小得多。]]></description>
      <guid>https://arxiv.org/abs/2502.14129</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>modskill：身体角色技能模块化</title>
      <link>https://arxiv.org/abs/2502.14140</link>
      <description><![CDATA[Arxiv：2502.14140V1公告类型：新 
摘要：人类运动是高度多样和动态的，对模仿学习算法的挑战构成了旨在概括控制模拟字符的运动技能的挑战。以前的方法通常依靠通用全身控制器来跟踪参考运动（基于跟踪的模型）或统一的全身技能嵌入空间（技能嵌入）。但是，这些方法通常很难概括和扩展到更大的运动数据集。在这项工作中，我们介绍了一个新颖的技能学习框架Modskill，该框架将复杂的全身技能纳入了独立身体部位的组成，模块化技能。我们的框架具有一个技能模块化注意力层，该层将策略观察过程处理为模块化技能嵌入，可指导每个身体部位的低级控制器。我们还提出了一种具有生成自适应抽样的积极的技能学习方法，使用大型运动生成模型在挑战性跟踪方案中适应性地增强政策学习。我们的结果表明，通过生成抽样增强了这个模块化的技能学习框架，在精确的全身运动跟踪中优于现有方法，并启用可重复使用的技能嵌入，以实现各种目标驱动的任务。]]></description>
      <guid>https://arxiv.org/abs/2502.14140</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过侧图卷积适应的令牌适应，以在3D点云变压器的时间和空间有效微调上进行微调</title>
      <link>https://arxiv.org/abs/2502.14142</link>
      <description><![CDATA[ARXIV：2502.14142V1公告类型：新 
摘要：预先训练的3D点云变压器的参数有效微调（PEFT）已成为3D点云分析的有前途的技术。尽管现有的PEFT方法试图最大程度地减少可调参数的数量，但它们在微调过程中仍然遭受高时间和空间计算成本的困扰。本文提出了一种针对3D点云变压器的新型PEFT算法，称为邻域图（Stag）上的侧代币适应，以实现较高的时间和空间效率。 STAG采用图形卷积侧网络，该网络与冷冻的骨干变压器并行运行，以使令牌适应下游任务。 STAG的侧网络通过三个关键组件实现了高效率：与骨干的连接，该骨干可以减少梯度计算，参数共享框架和有效的图形卷积。此外，我们介绍点云分类13（PCC13），这是一种新的基准，包括多种公开可用的3D点云数据集，可以全面评估PEFT方法。使用多个预训练模型和PCC13进行的广泛实验证明了雄鹿的有效性。具体而言，Stag保持与现有方法相当的分类精度，同时将可调参数仅减少到0.43m，并在计算时间和记忆消耗中显着减少以进行微调。代码和基准将在以下网址提供：https：//github.com/takahikof/stag]]></description>
      <guid>https://arxiv.org/abs/2502.14142</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>PITVQA ++：垂体矩阵 - 低级适应性垂体手术中回答开放式视觉问题</title>
      <link>https://arxiv.org/abs/2502.14149</link>
      <description><![CDATA[ARXIV：2502.14149V1公告类型：新 
摘要：视觉问题回答（VQA）中的视觉模型（VLMS）为增强术中决策，促进直观的互动以及显着前进的手术教育提供了独特的机会。然而，由于数据集有限，并且在预审预周审经期间，VQA的VLM的开发因数据集有限以及过度拟合和灾难性遗忘的风险而具有挑战性。虽然参数有效的技术，例如低级适应（LORA）和等级适应的矩阵（MORA）地址适应挑战，但其统一参数分布忽略了深网中的特征层次结构，在深层网络中，较早的层次，这些层次，学习的综合特征，比更多的参数，比更多的参数后来的。这项工作引入了PITVQA ++，采用开放式PITVQA数据集和矢量矩阵 - 低级适应（Vector-Molora），这是一种创新的VLM微调方法，用于调整GPT-2对垂体手术。开放式的PITVQA包括25个程序视频中的约101,803帧，其中包括745,972个问题答案句子对，涵盖了关键手术元素，例如相位和步骤识别，上下文理解，工具检测，本地化和交互识别。 Vector-Molora结合了Lora和Mora的原理，以制定矩阵 - 低级适应策略，该策略采用矢量排名将更多参数分配给早期层，并逐渐减少后期的层。我们的方法在开放式PITVQA和EDEDOVIS18-VQA数据集上得到了验证，可以有效地减轻灾难性的遗忘，同时显着提高了最近基线的性能。此外，我们的风险覆盖分析强调了其在处理不确定预测时增强的可靠性和可信赖性。我们的源代码和数据集可在〜\ url {https://github.com/hrl-mike/pitvqa-plus}上获得。]]></description>
      <guid>https://arxiv.org/abs/2502.14149</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>混合信号：用于异质激光雷达V2X协作的多个点云数据集</title>
      <link>https://arxiv.org/abs/2502.14156</link>
      <description><![CDATA[ARXIV：2502.14156V1公告类型：新 
摘要：车辆到所有（V2X）协作感知已成为解决单车感知系统局限性的有前途解决方案。但是，现有的V2X数据集在范围，多样性和质量方面受到限制。为了解决这些差距，我们提出混合信号，一个全面的V2X数据集，其中包含45.1k点云和240.6k的边界框，这些框从三个连接的自动驾驶汽车（CAVS）收集，配备了两种不同类型的LiDAR传感器，以及一个带有双重痛的路边单元。我们的数据集提供了10个类的精确对齐点云和边界框注释，从而确保了可靠的知觉培训数据。我们提供了有关数据集质量的详细统计分析，并在其上进行了广泛的基准测试。混合信号V2X数据集是公开可用于V2X感知研究的最高质量大规模数据集之一。网站上的详细信息https://mixedsignalsdataset.cs.cornell.edu/。]]></description>
      <guid>https://arxiv.org/abs/2502.14156</guid>
      <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>