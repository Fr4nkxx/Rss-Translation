<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CV 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Fri, 24 Jan 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>MONA：从动态摄像机拍摄的视频中检测运动物体</title>
      <link>https://arxiv.org/abs/2501.13183</link>
      <description><![CDATA[arXiv:2501.13183v1 公告类型：新
摘要：动态城市环境的特点是移动的摄像机和物体，通过使摄像机引起的运动和物体运动之间的区别复杂化，对摄像机轨迹估计提出了重大挑战。我们介绍了 MONA，这是一种新颖的框架，旨在从动态摄像机拍摄的视频中进行稳健的移动物体检测和分割。MONA 包含两个关键模块：动态点提取，利用光流和跟踪任意点来识别动态点；移动物体分割，采用自适应边界框过滤，以及用于精确移动物体分割的 Segment Anything。我们通过与摄像机轨迹估计方法 LEAP-VO 集成来验证 MONA，与现有方法相比，它在 MPI Sintel 数据集上取得了最先进的结果。这些结果证明了 MONA 在移动物体检测方面的有效性及其在城市规划领域的许多其他应用中的潜力。]]></description>
      <guid>https://arxiv.org/abs/2501.13183</guid>
      <pubDate>Fri, 24 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MEDFORM：多癌症分析中 CT 成像和临床数值数据对比学习的基础模型</title>
      <link>https://arxiv.org/abs/2501.13277</link>
      <description><![CDATA[arXiv:2501.13277v1 公告类型：新
摘要：计算机断层扫描 (CT) 和临床数值数据是癌症评估的基本模式，但由于多层 CT 数据的结构复杂性和专家注释的高成本，构建用于开发医学基础模型的大规模多模态训练数据集仍然具有挑战性。在本研究中，我们提出了 MEDFORM，这是一种多模态预训练策略，它使用来自临床数据的互补信息指导 CT 图像表示学习，以开发医学基础模型。MEDFORM 通过多实例学习 (MIL) 高效处理 CT 切片并采用双重预训练策略：首先使用基于 SimCLR 的自监督学习对 CT 切片特征提取器进行预训练，然后通过跨模态对比学习将 CT 和临床模态对齐。我们的模型针对三种不同的癌症类型进行了预训练：肺癌（141,171 片）、乳腺癌（8,100 片）、结直肠癌（10,393 片）。实验结果表明，这种双重预训练策略可提高癌症分类性能，并在小样本学习场景中保持稳健的性能。代码可在 https://github.com/DigitalHealthcareLab/25MultiModalFoundationModel.git 上找到]]></description>
      <guid>https://arxiv.org/abs/2501.13277</guid>
      <pubDate>Fri, 24 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从跨模态到混合模态可见红外重新识别</title>
      <link>https://arxiv.org/abs/2501.13307</link>
      <description><![CDATA[arXiv:2501.13307v1 公告类型：新
摘要：可见红外行人重新识别 (VI-ReID) 旨在跨不同相机模式匹配个人，这是现代监控系统中的一项关键任务。虽然当前的 VI-ReID 方法专注于跨模态匹配，但实际应用通常涉及包含 V 和 I 图像的混合图库，其中最先进的方法由于域偏移大和混合模态之间的低区分度而显示出显着的性能限制。这是因为来自相同模态的图库图像可能具有较低的域间隙但对应于不同的身份。本文介绍了一种新颖的混合模态 ReID 设置，其中图库包含来自两种模态的数据。为了解决模态间域转移和模态内匹配中的低区分能力，我们提出了混合模态擦除和相关 (MixER) 方法。 MixER 学习方法通​​过正交分解、模态混淆和 ID 模态相关目标，解开特定模态和共享模态的身份信息。MixER 增强了跨模态的特征稳健性，提高了跨模态和混合模态设置的性能。我们在 SYSU-MM01、RegDB 和 LLMC 数据集上进行的大量实验表明，我们的方法可以使用单个主干提供最先进的结果，并展示了我们的方法在混合图库应用程序中的灵活性。]]></description>
      <guid>https://arxiv.org/abs/2501.13307</guid>
      <pubDate>Fri, 24 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Deblur-Avatar：来自运动模糊单目视频的可动画头像</title>
      <link>https://arxiv.org/abs/2501.13335</link>
      <description><![CDATA[arXiv:2501.13335v1 公告类型：新
摘要：我们介绍了 Deblur-Avatar，这是一种新颖的框架，用于从运动模糊的单目视频输入中建模高保真、可动画的 3D 人体头像。运动模糊在现实世界的动态视频捕捉中很普遍，尤其是由于 3D 人体头像建模中的人体运动。现有方法要么 (1) 假设图像输入清晰，无法解决运动模糊导致的细节损失，要么 (2) 主要考虑相机运动导致的模糊，而忽略了在可动画头像中更常见的人体运动模糊。我们提出的方法将基于人体运动的运动模糊模型集成到 3D 高斯溅射 (3DGS) 中。通过在曝光时间内明确建模人体运动轨迹，我们联合优化轨迹和 3D 高斯以重建清晰、高质量的人体头像。我们采用基于姿势的融合机制来区分运动身体区域，有效优化模糊和清晰区域。在合成和真实世界数据集上进行的大量实验表明，Deblur-Avatar 在渲染质量和定量指标方面明显优于现有方法，可生成清晰的头像重建，并在具有挑战性的运动模糊条件下实现实时渲染。]]></description>
      <guid>https://arxiv.org/abs/2501.13335</guid>
      <pubDate>Fri, 24 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用扩散模型进行无梯度对抗净化</title>
      <link>https://arxiv.org/abs/2501.13336</link>
      <description><![CDATA[arXiv:2501.13336v1 公告类型：新
摘要：对抗训练和对抗净化是两种有效且实用的防御方法，可以增强模型对对抗攻击的鲁棒性。然而，对抗训练需要额外的训练，而对抗净化的时间效率较低。更重要的是，当前的防御是在基于扰动的对抗威胁模型下设计的，这对最近提出的无限制对抗攻击无效。在本文中，我们提出了一种有效且高效的对抗防御方法，可以对抗基于扰动和无限制的对抗攻击。我们的防御受到以下观察的启发：对抗攻击通常位于决策边界附近并且对像素变化很敏感。为了解决这个问题，我们引入了对抗抗锯齿来减轻对抗修改。此外，我们提出了对抗性超分辨率，它利用干净数据集中的先验知识来良性地恢复图像。这些方法不需要额外的训练，并且无需计算梯度，计算效率高。针对基于扰动和无限制的对抗性攻击的大量实验表明，我们的防御方法优于最先进的对抗性净化方法。]]></description>
      <guid>https://arxiv.org/abs/2501.13336</guid>
      <pubDate>Fri, 24 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>检索可能会造成危害：检索增强扩散模型的对比后门攻击范式</title>
      <link>https://arxiv.org/abs/2501.13340</link>
      <description><![CDATA[arXiv:2501.13340v1 公告类型：新
摘要：扩散模型（DM）最近表现出了卓越的生成能力。然而，它们的训练通常需要大量的计算资源和大规模数据集。为了解决这些问题，最近的研究为 DM 提供了先进的检索增强生成（RAG）技术，并提出了检索增强扩散模型（RDM）。通过整合辅助数据库中的丰富知识，RAG 增强了扩散模型的生成和泛化能力，同时显著减少了模型参数。尽管取得了巨大的成功，但 RAG 可能会引入新的安全问题，值得进一步研究。在本文中，我们通过提出一种名为 BadRDM 的多模态对比攻击方法，揭示了 RDM 容易受到后门攻击。我们的框架充分考虑了 RAG 的特点，旨在操纵给定文本触发器的检索项目，从而进一步控制生成的内容。具体来说，我们首先将一小部分图像插入检索数据库作为目标毒性替代品。随后，采用对比学习的恶意变体将后门注入检索器，从而建立从触发器到毒性代理的快捷方式。此外，我们通过新颖的基于熵的选择和生成增强策略增强攻击，从而可以得到更好的毒性代理。在两个主流任务上进行的大量实验表明，提出的 BadRDM 在保留模型良性效用的同时实现了出色的攻击效果。]]></description>
      <guid>https://arxiv.org/abs/2501.13340</guid>
      <pubDate>Fri, 24 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用大型语言模型进行多方面知识提炼</title>
      <link>https://arxiv.org/abs/2501.13341</link>
      <description><![CDATA[arXiv:2501.13341v1 公告类型：新
摘要：深度学习的最新进展显著提高了计算机视觉任务的性能。以前的图像分类方法主要修改模型架构或添加特征，并使用类 logit 上的交叉熵损失来优化模型。由于它们专注于考虑类标签对图像进行分类，因此这些方法可能难以学习类的各种 \emph{方面}（例如，自然位置和形状变化）。从新颖的角度重新思考以前的方法，我们提出了一种使用多模态大型语言模型 (MLLM) 的多方面知识提炼方法。我们的方法包括：1) 使用与我们想要转移到模型的知识相关的多方面问题查询大型语言模型，2) 从 MLLM 中提取相应的 logit，以及 3) 扩展模型的输出维度以提炼这些多方面 logit。然后，我们将交叉熵损失应用于类 logit，将二元交叉熵损失应用于多方面 logit。通过我们的方法，模型不仅可以学习有关视觉方面的知识，还可以学习需要更深入理解的抽象和复杂方面的知识。我们主要将我们的方法应用于图像分类，为了探索扩展我们模型的潜力，我们将其扩展到其他任务，例如对象检测。在所有实验结果中，我们的方法都提高了基线的性能。此外，我们分析了多方面知识提炼的效果。这些结果表明，我们的方法可以将有关各个方面的知识转移到模型中，方面知识可以提高模型在计算机视觉任务中的性能。本文展示了多方面知识提炼的巨大潜力，我们相信它为计算机视觉及其他领域的未来研究提供了一个有希望的方向。]]></description>
      <guid>https://arxiv.org/abs/2501.13341</guid>
      <pubDate>Fri, 24 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>YOLOSCM：一种改进的 YOLO 算法，用于汽车检测</title>
      <link>https://arxiv.org/abs/2501.13343</link>
      <description><![CDATA[arXiv:2501.13343v1 公告类型：新
摘要：由于以下原因，在城市交通图像中检测物体存在相当大的困难：1）这些图像通常尺寸巨大，包含数百万甚至数亿像素，但计算资源受到限制。2）在某些情况下，车辆尺寸较小，导致信息不足以进行准确检测。3）车辆分布不均导致计算资源使用效率低下。为了解决这些问题，我们提出了一个高效且有效的框架 YOLOSCM（You Only Look Once with Segmentation Clustering Module）。为了应对大规模图像和车辆分布不均匀的挑战，我们提出了一个分割聚类模块（SCM）。该模块自适应地识别聚类区域，使模型能够专注于这些区域以进行更精确的检测。此外，我们提出了一种新的训练策略来优化复杂城市交通场景中小型车辆和密集目标的检测。我们在城市交通数据集上进行了大量的实验，以证明我们提出的方法的有效性和优越性。]]></description>
      <guid>https://arxiv.org/abs/2501.13343</guid>
      <pubDate>Fri, 24 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MSF：通过多尺度潜在因子分解实现的高效扩散模型</title>
      <link>https://arxiv.org/abs/2501.13349</link>
      <description><![CDATA[arXiv:2501.13349v1 公告类型：新
摘要：基于扩散的生成模型在视觉内容生成方面取得了显著进展。然而，传统的扩散模型直接从噪声输入中对整个图像进行去噪，而忽略了视觉信号中存在的层次结构。这种方法计算量大，尤其是对于高分辨率图像生成。信号处理通常利用分层分解；例如，傅里叶分析按频率分解信号，而小波分析捕获局部频率分量，同时反映空间和频率信息。受这些原理的启发，我们提出了一个多尺度扩散框架，该框架生成分层的视觉表示，随后将其集成以形成最终输出。扩散模型目标，无论是原始 RGB 像素还是来自变分自动编码器的潜在特征，都被分为多个组件，每个组件捕获不同的空间级别。低分辨率组件包含主要信息信号，而高分辨率组件添加高频细节，例如纹理。该方法将图像生成分为两个阶段：生成低分辨率基础信号，然后生成高分辨率残差信号。与全分辨率生成相比，这两个阶段都可以使用更简单、更轻量的 Transformer 架构进行有效建模。这种分解在概念上类似于小波分解，但提供了更简化和直观的设计。我们的方法称为 MSF（多尺度分解的缩写），在 ImageNet 256x256 基准上实现了 2.2 的 FID 和 255.4 的 IS，与基线方法相比，计算成本降低了 50%。]]></description>
      <guid>https://arxiv.org/abs/2501.13349</guid>
      <pubDate>Fri, 24 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>对比：用于低级视觉的 Transformer 与状态空间模型的混合架构</title>
      <link>https://arxiv.org/abs/2501.13353</link>
      <description><![CDATA[arXiv:2501.13353v1 公告类型：新
摘要：Transformers 因其强大的全局上下文建模能力而在图像超分辨率 (SR) 任务中越来越受欢迎。然而，它们的二次计算复杂度需要使用基于窗口的注意机制，这限制了接受域并限制了有效的上下文扩展。最近，Mamba 架构已成为一种有前途的替代方案，具有线性计算复杂度，使其能够避免窗口机制并保持较大的接受域。然而，当需要高像素级精度时，Mamba 在处理长上下文依赖性方面面临挑战，例如在 SR 任务中。这是由于它的隐藏状态机制，它可以压缩和存储大量上下文，但只能以近似的方式，导致不准确性，而 Transformers 不会受到影响。在本文中，我们提出了 \textbf{Contrast}，这是一种混合 SR 模型，结合了 \textbf{Con}卷积、\textbf{Tra}nsformer 和 \textbf{State}ate Space 组件，有效地融合了 transformers 和 Mamba 的优势，以解决它们各自的局限性。通过整合 transformer 和状态空间机制，\textbf{Contrast} 弥补了每种方法的缺点，增强了全局上下文建模和像素级准确性。我们证明，结合这两种架构可以减轻每种架构固有的问题，从而提高图像超分辨率任务的性能。]]></description>
      <guid>https://arxiv.org/abs/2501.13353</guid>
      <pubDate>Fri, 24 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>NUDT4MSTAR：用于野外 SAR 目标识别的新数据集和基准</title>
      <link>https://arxiv.org/abs/2501.13354</link>
      <description><![CDATA[arXiv:2501.13354v1 公告类型：新
摘要：合成孔径雷达 (SAR) 因其独特的全天候成像能力而成为地球观测不可或缺的传感器。然而，在数据驱动的时代，大规模数据集的稀缺对推进 SAR 自动目标识别 (ATR) 技术构成了重大瓶颈。本文介绍了 NUDT4MSTAR，这是一个用于野外车辆目标识别的大规模 SAR 数据集，包括 40 种目标类型和 5 种不同场景的多种成像条件。NUDT4MSTAR 代表了数据集规模的重大飞跃，包含超过 190,000 张图像，是其前身的十倍。为了增强该数据集的实用性，我们用详细的目标信息和成像条件对每张图像进行了细致的注释。我们还提供处理后的幅度图像和原始复杂格式的数据。然后，我们构建了一个全面的基准，该基准由 7 个实验和 15 种识别方法组成，重点关注稳定有效的 ATR 问题。此外，我们利用在 NUDT4MSTAR 上训练并应用于其他三个目标数据集的各种模型进行迁移学习实验，从而证明其对更广泛的地面物体 ATR 领域的巨大潜力。最后，我们讨论了该数据集的应用价值和 ATR 面临的重大挑战。据我们所知，这项工作标志着有史以来第一次尝试创建一个用于野外细粒度 SAR 识别的大规模数据集基准，其中包含大量经过详尽注释的车辆图像。我们期待 NUDT4MSTAR 的开源将促进 SAR ATR 的发展并吸引更广泛的研究人员群体。]]></description>
      <guid>https://arxiv.org/abs/2501.13354</guid>
      <pubDate>Fri, 24 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从 Sentinel-1 生成 NDWI 的轻量级模型</title>
      <link>https://arxiv.org/abs/2501.13357</link>
      <description><![CDATA[arXiv:2501.13357v1 公告类型：新
摘要：使用 Sentinel-2 图像计算归一化差异水指数 (NDWI) 有许多应用，包括水体面积检测。然而，云层覆盖在这方面带来了重大挑战，这阻碍了 Sentinel-2 图像在这种情况下的有效性。在本文中，我们提出了一个深度学习模型，可以根据 Sentinel-1 图像生成 NDWI，从而克服这一云障碍。我们展示了我们模型的有效性，它显示出 0.9134 的高准确度和 0.8656 的 AUC 来预测 NDWI。此外，我们观察到有希望的结果，R2 得分为 0.4984（用于回归 NDWI 值）和平均 IoU 为 0.4139（用于底层分割任务）。总之，我们的模型提供了第一个强大的解决方案，可以直接从 Sentinel-1 图像生成 NDWI 图像，随后即使在云层覆盖和夜间等具有挑战性的条件下也可用于各种应用。]]></description>
      <guid>https://arxiv.org/abs/2501.13357</guid>
      <pubDate>Fri, 24 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>增强的提取器选择器框架和对称加权二叉交叉熵用于边缘检测</title>
      <link>https://arxiv.org/abs/2501.13365</link>
      <description><![CDATA[arXiv:2501.13365v1 公告类型：新
摘要：最近的进展证明了提取器-选择器 (E-S) 框架在边缘检测 (ED) 任务中的有效性，该框架在定量指标和感知质量方面都达到了最先进的 (SOTA) 性能。然而，这种方法仍然未能充分利用特征提取器的潜力，因为选择器仅在高度压缩的特征图上运行，这些特征图缺乏多样性并且会遭受大量信息丢失。此外，虽然联合训练可以提高感知质量，但最高的评估分数通常是在没有联合训练的情况下获得的，从而在定量准确性和感知保真度之间产生了权衡。为了解决这些限制，我们提出了一种增强的 E-S 架构，它利用更丰富、损失更少的特征表示并在选择过程中结合辅助特征，从而提高特征选择机制的有效性。此外，我们引入了一种新颖的损失函数，即对称化权重二元交叉熵 (SWBCE)，它同时强调边缘像素的回忆和错误边缘预测的抑制，从而增强了预测的感知质量和预测准确性。大量实验证明了我们的方法相对于基线模型、标准 E-S 框架和标准权重二元交叉熵 (WBCE) 损失函数的有效性和优越性。例如，与基线模型相比，使用 SWBCE 损失函数训练的增强型 E-S 架构在 BIPED2 上测量的 ODS、OIS 和 AP 方面实现了 8.25$\%$、8.01$\%$ 和 33.25$\%$ 的平均改进，显着优于标准 E-S 方法。结果为 ED 任务设定了新的基准，并凸显了这些方法在未来的潜力。]]></description>
      <guid>https://arxiv.org/abs/2501.13365</guid>
      <pubDate>Fri, 24 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>元特征适配器：整合环境元数据以增强动物重新识别</title>
      <link>https://arxiv.org/abs/2501.13368</link>
      <description><![CDATA[arXiv:2501.13368v1 公告类型：新
摘要：在大型野生动物种群中识别单个动物对于有效的野生动物监测和保护工作至关重要。计算机视觉领域的最新进展表明，通过利用相机陷阱的数据，动物重新识别 (Animal ReID) 大有可为。然而，现有的方法完全依赖于视觉数据，而忽略了生态学家认为与动物行为和身份高度相关的环境元数据，例如温度和昼夜节律。为了弥补这一差距，我们提出了元特征适配器 (MFA)，这是一个轻量级模块，旨在将环境元数据集成到视觉语言基础模型（例如 CLIP）中，以增强动物 ReID 性能。我们的方法将环境元数据转换为自然语言描述，将它们编码为元数据感知的文本嵌入，并通过交叉注意机制将这些嵌入合并到图像特征中。此外，我们引入了一种门控交叉注意机制，可以动态调整元数据贡献的权重，从而进一步提高性能。为了验证我们的方法，我们构建了元数据增强动物重新识别 (MAAR) 数据集，该数据集涵盖了来自新西兰的六个物种，并具有配对的图像数据和环境元数据。大量实验表明，MFA 可在多个基线模型中持续提高动物重新识别的性能。]]></description>
      <guid>https://arxiv.org/abs/2501.13368</guid>
      <pubDate>Fri, 24 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从图像到点云：一种无需注释训练的跨媒体盲质量评估的有效解决方案</title>
      <link>https://arxiv.org/abs/2501.13387</link>
      <description><![CDATA[arXiv:2501.13387v1 公告类型：新
摘要：我们提出了一种新颖的质量评估方法，该方法可以利用图像中丰富的先验知识预测没有可用注释的新场景中点云的感知质量，称为分布加权图像传输点云质量评估 (DWIT-PCQA)。无论媒体类型如何，人类视觉系统 (HVS) 都是质量评估的决策者，我们可以通过神经网络模拟人类感知的评估标准，并利用图像中的先验知识进一步将质量预测能力从图像转移到点云。具体而言，可以利用域自适应 (DA) 通过在相同特征空间中对齐两种媒体的特征分布来桥接图像和点云。然而，图像和点云中失真的不同表现形式使特征对齐成为一项艰巨的任务。为了降低对齐难度并考虑对齐过程中不同的失真分布，我们推导出公式，将传统 DA 的优化目标分解为两个子优化函数，以失真为过渡。具体来说，通过网络实现，我们提出了失真引导的有偏特征对齐，将现有/估计的失真分布集成到对抗性 DA 框架中，强调特征对齐过程中的常见失真模式。此外，我们提出了质量感知特征解缠，以减轻在有偏失真的对齐过程中从特征到质量的映射的破坏。实验结果表明，与不需要点云注释的一般盲 PCQA 方法相比，我们提出的方法表现出可靠的性能。]]></description>
      <guid>https://arxiv.org/abs/2501.13387</guid>
      <pubDate>Fri, 24 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>