<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CV 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Wed, 08 Jan 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>使用深度学习进行植物叶片病害检测和分类：孟加拉国视角的回顾与系统建议</title>
      <link>https://arxiv.org/abs/2501.03305</link>
      <description><![CDATA[arXiv:2501.03305v1 公告类型：新
摘要：农业是孟加拉国人民就业、GDP贡献和主要生计的一个非常重要的部分。它在减少贫困和确保粮食安全方面发挥着至关重要的作用。植物疾病是孟加拉国农业生产的一个严重绊脚石。有时，人类无法用肉眼从受感染的叶子上检测出疾病。在植物中使用无机化学品或杀虫剂为时已晚，大多数时候都是徒劳的，使之前的所有劳动都付诸东流。基于叶子的图像分类的深度学习技术已经显示出令人印象深刻的结果，可以使识别和分类所有疾病的工作更加轻松和精确。在本文中，我们主要提出了一种更好的叶子疾病检测模型。我们提出的论文包括三种不同作物的数据收集：甜椒、西红柿和土豆。为了训练和测试所提出的 CNN 模型，我们使用了从 Kaggle 收集的植物叶片病害数据集，其中包含 17,430 张图像。这些图像被标记为 14 种不同的损伤类别。所开发的 CNN 模型性能高效，可以成功检测和分类所测试的疾病。所提出的 CNN 模型可能在农作物病害管理方面具有巨大潜力。]]></description>
      <guid>https://arxiv.org/abs/2501.03305</guid>
      <pubDate>Wed, 08 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CM3T：非均匀交互数据集的高效多模态学习框架</title>
      <link>https://arxiv.org/abs/2501.03332</link>
      <description><![CDATA[arXiv:2501.03332v1 公告类型：新
摘要：交叉学习面临的挑战包括训练数据量不均匀甚至不足，以及缺乏对大型预训练模型进行再训练的资源。受 NLP 中的迁移学习技术、适配器和前缀调整的启发，本文提出了一种用于交叉学习的新型模型无关插件架构 CM3T，该架构可将基于转换器的模型适应新信息或缺失信息。我们引入了两个适配器块：用于迁移学习的多头视觉适配器和用于多模态学习的交叉注意适配器。由于主干和其他插件不需要与这些附加功能一起进行微调，因此训练变得非常高效。对三个数据集 Epic-Kitchens-100、MPIIGroupInteraction 和 UDIVA v0.5 的比较和消融研究表明该框架在不同记录设置和任务上的有效性。与处理视频输入的主干相比，可训练参数仅为 12.8%，而对于另外两种模式，可训练参数仅为 22.3%，我们取得了与最先进技术相当甚至更好的结果。CM3T 对训练或预训练没有特定要求，是弥合通用模型与视频分类特定实际应用之间差距的一步。]]></description>
      <guid>https://arxiv.org/abs/2501.03332</guid>
      <pubDate>Wed, 08 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有融合定位和姿势估计的移动增强现实框架</title>
      <link>https://arxiv.org/abs/2501.03336</link>
      <description><![CDATA[arXiv:2501.03336v1 公告类型：新
摘要：作为一种新颖的信息呈现方式，增强现实（AR）使人们能够以直接直观的方式与物理世界进行交互。虽然有些移动 AR 产品以高昂的成本使用特定硬件实现，但在移动平台（如智能手机、平板电脑等）上实现 AR 的软件方法仍远未达到实际使用水平。基于 GPS 的移动 AR 系统通常由于室内环境中定位不准确而表现不佳。以前基于视觉的姿态估计方法需要在短距离内连续跟踪预定义的标记，这极大地降低了用户体验。本文首先对移动平台上最先进的 AR 和定位系统进行了全面研究。然后，我们提出了一种有效的室内移动 AR 框架。在该框架中，开发了一种融合定位方法和一种新的姿态估计实现，以提高整体匹配率，从而提高 AR 显示精度。实验表明，我们的框架比纯粹基于图像或 Wi-Fi 信号的方法具有更高的性能。当平均采样网格长度设置为0.5m时，我们实现了较低的平均误差距离（0.61-0.81m）和准确匹配率（77％-82％）。]]></description>
      <guid>https://arxiv.org/abs/2501.03336</guid>
      <pubDate>Wed, 08 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用扩散模型生成车牌图像</title>
      <link>https://arxiv.org/abs/2501.03374</link>
      <description><![CDATA[arXiv:2501.03374v1 公告类型：新
摘要：尽管车牌识别 (LPR) 具有明显的实际重要性，但由于《通用数据保护条例》(GDPR) 等隐私法规，相应的研究受到公开可用数据集数量的限制。为了应对这一挑战，合成数据生成已成为一种有前途的方法。在本文中，我们提出使用扩散模型合成逼真的车牌 (LP)，灵感来自图像和视频生成的最新进展。在我们的实验中，扩散模型在乌克兰 LP 数据集上成功训练，并生成了 1000 张合成图像进行详细分析。通过对生成的图像进行手动分类和注释，我们对模型输出进行了彻底的研究，例如成功率、字符分布和故障类型。我们的贡献包括对扩散模型用于 LP 合成的有效性的实验验证，以及对生成数据特征的见解。此外，我们还准备了一个由 10,000 张 LP 图像组成的合成数据集，可在 https://zenodo.org/doi/10.5281/zenodo.13342102 上公开获取。进行的实验从经验上证实了合成数据对 LPR 任务的实用性。尽管使用真实数据和合成数据训练的模型在初始性能上存在差距，但使用伪标记合成数据扩展训练数据集可使 LPR 准确率与基线相比提高 3%。]]></description>
      <guid>https://arxiv.org/abs/2501.03374</guid>
      <pubDate>Wed, 08 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DoubleDiffusion：将热扩散与去噪扩散相结合，用于 3D 网格的生成学习</title>
      <link>https://arxiv.org/abs/2501.03397</link>
      <description><![CDATA[arXiv:2501.03397v1 公告类型：新
摘要：本文提出了 DoubleDiffusion，这是一种结合散热扩散和去噪扩散的新型框架，用于在 3D 网格表面上进行直接生成学习。我们的方法解决了在曲线流形表面上生成连续信号分布的挑战。与以前依赖于将 3D 网格展开为 2D 或采用场表示的方法不同，DoubleDiffusion 利用拉普拉斯-贝尔特拉米算子来处理尊重网格结构的特征。这种组合可以在底层几何体上实现有效的几何感知信号扩散。如图 ~\ref{fig:teaser} 所示，我们证明了 DoubleDiffusion 能够在复杂的 3D 网格表面上生成 RGB 信号分布，并实现跨不同形状几何体的每个类别形状条件纹理生成。我们的工作为基于扩散的 3D 表面生成建模开辟了新方向，并可能应用于 3D 资产生成领域。]]></description>
      <guid>https://arxiv.org/abs/2501.03397</guid>
      <pubDate>Wed, 08 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用优化特征平面和标准视频编解码器进行 3D 高斯溅射压缩</title>
      <link>https://arxiv.org/abs/2501.03399</link>
      <description><![CDATA[arXiv:2501.03399v1 公告类型：新
摘要：3D Gaussian Splatting 是一种公认​​的 3D 场景表示方法，以其高渲染质量和速度而闻名。然而，它对数据的大量要求给实际应用带来了挑战。在本文中，我们介绍了一种有效的压缩技术，该技术通过使用紧凑表示显着降低了存储开销。我们提出了一种统一的架构，通过渐进式三平面结构将点云数据和特征平面结合起来。我们的方法利用 2D 特征平面，实现连续的空间表示。为了进一步优化这些表示，我们在频域中加入了熵建模，专门为标准视频编解码器设计。我们还提出了按通道分配比特的方法，以在比特率消耗和特征平面表示之间实现更好的权衡。因此，我们的模型有效地利用了特征平面内的空间相关性，以使用标准的、不可微分的视频编解码器来增强速率失真性能。实验结果表明，我们的方法在数据紧凑性方面优于现有方法，同时保持了高渲染质量。我们的项目页面为 https://fraunhoferhhi.github.io/CodecGS]]></description>
      <guid>https://arxiv.org/abs/2501.03399</guid>
      <pubDate>Wed, 08 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ScaleMAI：加速可信数据集和 AI 模型的开发</title>
      <link>https://arxiv.org/abs/2501.03410</link>
      <description><![CDATA[arXiv:2501.03410v1 公告类型：新
摘要：构建可信数据集对于透明和负责任的医学人工智能 (MAI) 研究至关重要，但即使是创建小型、高质量的数据集也需要多学科团队多年的努力。这个过程通常会延迟人工智能的收益，因为以人为中心的数据创建和以人工智能为中心的模型开发被视为单独的、连续的步骤。为了克服这个问题，我们提出了 ScaleMAI，一种人工智能集成数据管理和注释的代理，允许数据质量和人工智能性能在自我强化的循环中提高，并将开发时间从数年缩短到数月。我们以胰腺肿瘤检测为例。首先，ScaleMAI 逐步创建一个包含 25,362 个 CT 扫描的数据集，包括良性/恶性肿瘤和 24 个解剖结构的逐体素注释。其次，通过渐进式人机交互迭代，ScaleMAI 提供了旗舰 AI 模型，该模型在检测胰腺肿瘤方面可以达到专家注释者（30 年经验）的熟练程度。旗舰模型的表现明显优于从较小、固定质量数据集开发的模型，在三个著名基准上，肿瘤检测（+14%）、分割（+5%）和分类（72%）均有显著提高。总之，ScaleMAI 改变了医疗数据集创建的速度、规模和可靠性，为各种有影响力的数据驱动应用铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2501.03410</guid>
      <pubDate>Wed, 08 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于自监督图像表征学习的信息最大化软变量离散化</title>
      <link>https://arxiv.org/abs/2501.03469</link>
      <description><![CDATA[arXiv:2501.03469v1 公告类型：新
摘要：自监督学习 (SSL) 已成为图像处理、编码和理解中的一项关键技术，尤其是用于开发当今的视觉基础模型，这些模型利用没有注释的大规模数据集来增强各种下游任务。本研究介绍了一种用于图像表示学习的新型 SSL 方法，即信息最大化软变量离散化 (IMSVD)。具体而言，IMSVD 对潜在空间中的每个变量进行软离散化，从而能够估计它们在训练批次中的概率分布，并允许信息度量直接指导学习过程。受多视图假设的启发，我们提出了一个信息论目标函数来学习变换不变、非工作和冗余最小化的表示特征。然后，我们推导出一个用于自监督图像表示学习的联合交叉熵损失函数，理论上它在减少特征冗余方面优于现有方法。值得注意的是，我们的非对比 IMSVD 方法在统计上执行对比学习。大量实验结果表明，IMSVD 在各种下游任务上都具有准确性和效率方面的有效性。得益于我们的变量离散化，IMSVD 优化的嵌入特征在变量级别提供了独特的可解释性。IMSVD 有可能适应其他学习范式。我们的代码可在 https://github.com/niuchuangnn/IMSVD 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2501.03469</guid>
      <pubDate>Wed, 08 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>VOILA：通过与语言交互的体素对 CT 图像进行复杂性感知的通用分割</title>
      <link>https://arxiv.org/abs/2501.03482</link>
      <description><![CDATA[arXiv:2501.03482v1 公告类型：新
摘要：最近，CT 图像的通用分割取得了令人满意的进展。随着视觉语言方法的成功，利用文本提示和对比学习来开发通用分割模型的趋势日益增长。然而，3D 图像和文本提示之间的信息密度存在显著不平衡。此外，标准的全连接层分割方法在处理多个类别时面临重大挑战，并且表现出较差的通用性。为了应对这些挑战，我们提出了用于通用 CT 图像分割的 VOxel 与语言交互方法 (VOILA)。首先，我们将体素和语言对齐到共享表示空间中，并根据余弦相似性对体素进行分类。随后，我们开发了体素-语言交互框架，以减轻由前景-背景差异和目标体积变化引起的类别不平衡的影响。此外，我们还提出了一种复杂度感知采样方法来关注难以分割的区域，该方法通过从可训练的高斯混合分布生成伪热图来实现。我们的结果表明，所提出的 VOILA 能够在训练期间通过减少参数和计算成本来实现更高的性能。此外，它还展示了跨不同数据集的显著通用性，而无需额外的微调。]]></description>
      <guid>https://arxiv.org/abs/2501.03482</guid>
      <pubDate>Wed, 08 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SceneBooth：基于扩散的保留主题的文本到图像生成框架</title>
      <link>https://arxiv.org/abs/2501.03490</link>
      <description><![CDATA[arXiv:2501.03490v1 公告类型：新
摘要：由于对个性化图像生成的需求，主题驱动的文本到图像生成方法（基于文本提示创建输入主题的新颖再现）引起了越来越多的研究兴趣。现有方法通常学习主题表示并将其合并到提示嵌入中以指导图像生成，但它们在保持主题保真度方面存在困难。为了解决这个问题，本文提出了一种名为 SceneBooth 的新颖框架，用于保留主题的文本到图像生成，该框架使用主题图像、对象短语和文本提示的输入。我们的 SceneBooth 不是学习主题表示和生成主题，而是修复给定的主题图像并在文本提示的指导下生成其背景图像。为此，我们的 SceneBooth 引入了两个关键组件，即多模态布局生成模块和背景绘制模块。前者通过生成与文本标题、对象短语和主体视觉信息相一致的适当场景布局来确定主体的位置和比例。后者将两个适配器（ControlNet 和 Gated Self-Attention）集成到潜在扩散模型中，以生成由场景布局和文本描述引导的与主体协调的背景。通过这种方式，我们的 SceneBooth 确保在输出中准确保留主体的外观。定量和定性实验结果表明，SceneBooth 在主体保留、图像协调和整体质量方面明显优于基线方法。]]></description>
      <guid>https://arxiv.org/abs/2501.03490</guid>
      <pubDate>Wed, 08 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过扩散桥将图像编辑的视觉提示文本化</title>
      <link>https://arxiv.org/abs/2501.03495</link>
      <description><![CDATA[arXiv:2501.03495v1 公告类型：新
摘要：视觉提示是一对编辑前后的图像，可以传达难以形容的图像转换，并在图像编辑中大放异彩。然而，目前的视觉提示方法依赖于预先训练的文本引导的图像到图像生成模型，该模型需要一组文本、之前和之后的图像来对文本到图像模型进行再训练。这种制作三元组和再训练过程限制了编辑的可扩展性和泛化。在本文中，我们提出了一个基于任何单一文本到图像模型的框架，而不依赖于显式的图像到图像模型，从而增强了泛化性和可扩展性。具体而言，通过利用概率流常方程，我们构建了一个扩散桥，在文本引导下转移前后图像之间的分布。通过桥接优化文本，该框架自适应地将视觉提示传达的编辑转换文本化为文本嵌入，而无需其他模型。同时，我们在文本优化过程中引入了差异化注意力控制，将文本嵌入与前后图像的不变性分离开来，使其仅捕捉细微的变换并推广到编辑各种图像。在真实图像上进行的实验验证了在泛化、上下文连贯性和精细编辑的高保真度方面具有竞争力的结果，仅使用一个图像对作为视觉提示即可实现。]]></description>
      <guid>https://arxiv.org/abs/2501.03495</guid>
      <pubDate>Wed, 08 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>深度学习能否根据移动设备捕获的图像触发警报？</title>
      <link>https://arxiv.org/abs/2501.03499</link>
      <description><![CDATA[arXiv:2501.03499v1 公告类型：新
摘要：我们的研究提出了一种利用移动摄像机图像数据进行实时空气质量评估和推荐的综合方法。我们开发了一个基于回归的卷积神经网络模型，并通过利用输出参数之间的固有关系明确地将其定制为空气质量预测。结果，分别针对 2 种和 5 种污染物获得的 0.0077 和 0.0112 的均方误差优于现有模型。此外，我们旨在验证增强原始数据集的常见做法，以期在训练阶段引入更多变化。我们的最重要贡献之一是，我们的实验结果表明原始数据集和增强数据集之间的准确度差异最小。最后，实现了一个实时、用户友好的仪表板，可动态显示从捕获的移动摄像机图像中得出的空气质量指数和污染物值。根据当前空气质量指标，考虑用户的健康状况以推荐某个位置是否合适。总体而言，这项研究有助于验证数据增强技术、基于 CNN 的空气质量预测回归模型以及通过移动技术进行以用户为中心的空气质量监测。所提出的系统为个人做出明智的环境健康和福祉决策提供了实用的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2501.03499</guid>
      <pubDate>Wed, 08 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>自监督学习中准确率-鲁棒性权衡与训练效率的实证研究</title>
      <link>https://arxiv.org/abs/2501.03507</link>
      <description><![CDATA[arXiv:2501.03507v1 公告类型：新
摘要：自监督学习 (SSL) 显著提高了图像表示学习，但效率挑战仍然存在，尤其是在对抗性训练中。许多 SSL 方法需要大量的时间才能实现收敛，在对抗性环境中，这一需求进一步放大。为了解决这种低效率问题，我们重新审视了稳健的 EMP-SSL 框架，强调增加每幅图像的裁剪数量以加速学习的重要性。与传统的对比学习不同，稳健的 EMP-SSL 利用多裁剪采样，集成了不变性项和正则化，并减少了训练时间，提高了时间效率。通过标准线性分类器和多补丁嵌入聚合进行评估，稳健的 EMP-SSL 为 SSL 评估策略提供了新的见解。
我们的结果表明，基于裁剪的稳健 EMP-SSL 不仅加速了收敛，而且在干净准确度和对抗鲁棒性之间实现了出色的平衡，优于多裁剪嵌入聚合。此外，我们通过多裁剪 SSL 中的免费对抗训练扩展了这种方法，引入了免费对抗多裁剪自监督学习 (CF-AMC-SSL) 方法。CF-AMC-SSL 证明了免费对抗训练在减少训练时间方面的有效性，同时提高了干净准确度和对抗鲁棒性。这些发现强调了 CF-AMC-SSL 在实际 SSL 应用中的潜力。我们的代码可在 https://github.com/softsys4ai/CF-AMC-SSL 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2501.03507</guid>
      <pubDate>Wed, 08 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>TexHOI：在单目手物交互场景中重建 3D 未知物体的纹理</title>
      <link>https://arxiv.org/abs/2501.03525</link>
      <description><![CDATA[arXiv:2501.03525v1 公告类型：新 
摘要：近年来，从单目帧序列重建具有高保真纹理的动态真实世界物体的 3D 模型一直是一个具有挑战性的问题。这种困难源于阴影、间接照明以及由于遮挡手与物体的相互作用而导致的不准确的物体姿势估计等因素。为了应对这些挑战，我们提出了一种新方法，可以预测手对环境可见性的影响以及间接照明对物体表面反照率的影响。我们的方法首先通过辐射场的复合渲染来学习物体、手和背景的几何形状和低保真纹理。同时，我们优化手和物体的姿势以实现准确的物体姿势估计。然后，我们改进基于物理的渲染参数 - 包括粗糙度、镜面反射、反照率、手部可见性、肤色反射和环境照明 - 以产生精确的反照率以及准确的手部照明和阴影区域。我们的方法超越了纹理重建领域最先进的方法，并且据我们所知，它是第一个在物体纹理重建中考虑手与物体相互作用的方法。]]></description>
      <guid>https://arxiv.org/abs/2501.03525</guid>
      <pubDate>Wed, 08 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>异常三重网络：使用深度度量学习考虑遮挡的手动装配工作进度识别模型</title>
      <link>https://arxiv.org/abs/2501.03533</link>
      <description><![CDATA[arXiv:2501.03533v1 Announce Type: new 
摘要：本文提出了一种使用深度度量学习考虑遮挡的进度识别方法，以可视化工厂中的产品装配过程。首先，使用基于深度学习的物体检测方法从安装在工厂中的定点相机获取的图像中检测目标装配产品。接下来，从图像中裁剪检测区域。最后，通过对裁剪后的图像使用基于深度度量学习的分类方法，将产品装配工作的进度估计为粗略的进度步骤。
作为具体的进度估计模型，我们提出了一种异常三重网络，将异常样本添加到三重损失中以进行考虑遮挡的进度估计。
在实验中，使用异常三重网络的进度估计方法的成功率为 82.9%。
我们还试验了检测、裁剪和进度估计顺序的实用性，并确认了整体系统的有效性。]]></description>
      <guid>https://arxiv.org/abs/2501.03533</guid>
      <pubDate>Wed, 08 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>