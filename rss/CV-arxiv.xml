<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CV 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Fri, 27 Sep 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>以艺术为中心的视角看待基于人工智能的裸体内容审核</title>
      <link>https://arxiv.org/abs/2409.17156</link>
      <description><![CDATA[arXiv:2409.17156v1 公告类型：新
摘要：在生成人工智能对视觉艺术的影响成为备受争议的话题之际，我们将注意力转向一个更微妙的现象：在线艺术裸体的算法审查。我们分析了三个“不适合工作”图像分类器在艺术裸体方面的表现，并通过经验揭示了性别和风格偏见的存在，以及明显的技术限制，尤其是在仅考虑视觉信息时。因此，我们提出了一种多模态零样本分类方法，以改进艺术裸体分类。从我们的研究中，我们得出了一些启示，希望这些启示能够为未来关于这个主题的研究提供参考。]]></description>
      <guid>https://arxiv.org/abs/2409.17156</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>自动驾驶车道检测的跨数据集分析和网络架构修复</title>
      <link>https://arxiv.org/abs/2409.17158</link>
      <description><![CDATA[arXiv:2409.17158v1 公告类型：新
摘要：迁移学习已成为解决问题的标准方法之一，通过利用为一项任务获得的知识来解决另一项相关任务，以克服孤立学习范式。然而，在将迁移学习引入应用程序进行进一步验证和解释之前，需要进行研究以确定初始步骤。在这项研究中，我们对自动驾驶汽车中的车道检测应用进行了跨数据集分析和网络架构修复。车道检测是自动驾驶汽车辅助系统的一个重要方面。在大多数情况下，基于深度学习的现代车道识别系统是成功的，但它们在处理具有复杂拓扑的车道时会遇到困难。所提出的架构 ERFCondLaneNet 是对用于车道识别框架的 CondlaneNet 的增强，以解决检测具有复杂拓扑（如密集、弯曲和分叉线）的车道线的困难。新提出的技术分别在两个常见的车道检测基准 CULane 和 CurveLanes 以及两个不同的主干 ResNet 和 ERFNet 上进行了测试。采用 ERFCondLaneNet 研究的技术与 ResnetCondLaneNet 相比表现出相似的性能，但使用的特征减少了 33%，从而使模型尺寸减少了 46%。]]></description>
      <guid>https://arxiv.org/abs/2409.17158</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AACLiteNet：用于检测细粒度腹主动脉钙化的轻量级模型</title>
      <link>https://arxiv.org/abs/2409.17203</link>
      <description><![CDATA[arXiv:2409.17203v1 公告类型：新
摘要：心血管疾病 (CVD) 是全球死亡的主要原因，每年夺走 1790 万人的生命。腹主动脉钙化 (AAC) 是 CVD 的既定标志，可在侧视椎体骨折评估 (VFA) 扫描中观察到，通常用于检测椎体骨折。早期发现 AAC 可能有助于通过鼓励预防措施来降低患临床 CVD 的风险。手动分析 VFA 扫描以测量 AAC 非常耗时，并且需要经过培训的人工评估员。最近，人们一直在努力实现该过程的自动化，但是，所提出的模型要么准确度低，要么缺乏粒度级分数预测，要么在推理时间和内存占用方面太重。考虑到现有算法的所有这些缺点，我们提出了“AACLiteNet”，这是一种轻量级深度学习模型，可以高精度地预测累积和粒度级别的 AAC 分数，并且内存占用和计算成本（浮点运算 (FLOP)）较低。与之前的最佳 81.98% 相比，AACLiteNet 实现了 85.94% 的显著提高的一对多平均准确率，计算成本降低了 19.88 倍，内存占用降低了 2.26 倍，使其可以在便携式计算设备上实现。]]></description>
      <guid>https://arxiv.org/abs/2409.17203</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>2024 BRAVO 挑战赛第 1 场第一名报告：评估语义分割视觉基础模型的稳健性</title>
      <link>https://arxiv.org/abs/2409.17208</link>
      <description><![CDATA[arXiv:2409.17208v1 公告类型：新
摘要：在本报告中，我们介绍了 2024 年 BRAVO 挑战赛第 1 赛道的解决方案，其中在 Cityscapes 上训练模型，并在多个分布外数据集上评估其稳健性。我们的解决方案利用视觉基础模型学习到的强大表示，将一个简单的分割解码器附加到 DINOv2 并微调整个模型。这种方法优于更复杂的现有方法，并在挑战赛中取得第一名。我们的代码可在 https://github.com/tue-mps/benchmark-vfm-ss 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2409.17208</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>神经网络架构搜索支持广度深度学习 (NAS-WD)，用于感知空间异质属性的鸡胸肉分类和硬度回归</title>
      <link>https://arxiv.org/abs/2409.17210</link>
      <description><![CDATA[arXiv:2409.17210v1 公告类型：新
摘要：近年来，由于对快速生长率和高肉鸡产量的密集遗传选择，全球家禽业面临着木质胸脯 (WB) 状况的挑战性问题。这种情况每年造成的重大经济损失高达 2 亿美元，而 WB 的根本原因尚未确定。人类触诊是区分 WB 与其他 WB 的最常用方法。然而，这种方法既费时又主观。高光谱成像 (HSI) 结合机器学习算法可以以非侵入性、客观和高通量的方式评估鱼片的 WB 状况。在本研究中，采集了 250 个生鸡胸肉鱼片样本（正常、轻度、重度），在设计 HSI 处理模型时首先考虑了空间不均匀的硬度分布。该研究不仅从 HSI 中对 WB 水平进行了分类，还建立了一个回归模型来将光谱信息与样品硬度数据相关联。为了得到满意的分类回归模型，利用神经网络架构搜索（NAS）实现了宽深神经网络模型NAS-WD。在NAS-WD中，NAS首次用于自动优化网络架构和超参数。分类结果表明，NAS-WD对三个WB等级的分类总体准确率达到95%，优于传统的机器学习模型，光谱数据与硬度之间的回归相关性为0.75，明显优于传统的回归模型。]]></description>
      <guid>https://arxiv.org/abs/2409.17210</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Walker：通过时间外观图行走进行自监督多目标跟踪</title>
      <link>https://arxiv.org/abs/2409.17221</link>
      <description><![CDATA[arXiv:2409.17221v1 公告类型：新
摘要：对最先进的多对象跟踪 (MOT) 方法的监督需要大量的注释工作来为所有视频的所有帧提供边界框，并提供实例 ID 以将它们与时间关联起来。为此，我们引入了 Walker，这是第一个从具有稀疏边界框注释且没有跟踪标签的视频中学习的自监督跟踪器。首先，我们设计了一个准密集的时间对象外观图，并提出了一种新颖的多正对比目标来优化图上的随机游走并学习实例相似性。然后，我们引入了一种算法来在图中的各个实例之间强制执行互斥的连接属性，从而优化 MOT 的学习拓扑。在推理时，我们建议根据运动约束双向游走下的最大似然过渡状态将检测到的实例与轨迹相关联。 Walker 是第一个在 MOT17、DanceTrack 和 BDD100K 上取得竞争性表现的自监督跟踪器。值得注意的是，即使将注释要求大幅降低高达 400 倍，我们的提案仍优于之前的自监督跟踪器。]]></description>
      <guid>https://arxiv.org/abs/2409.17221</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Disco4D：从单个图像中解开 4D 人体生成和动画</title>
      <link>https://arxiv.org/abs/2409.17280</link>
      <description><![CDATA[arXiv:2409.17280v1 公告类型：新
摘要：我们提出了 \textbf{Disco4D}，这是一种新颖的高斯 Splatting 框架，用于从单个图像生成 4D 人体和动画。与现有方法不同，Disco4D 独特地将服装（使用高斯模型）与人体（使用 SMPL-X 模型）分开，大大增强了生成细节和灵活性。它具有以下技术创新。 \textbf{1)} Disco4D 学习有效地在 SMPL-X 高斯上拟合服装高斯。 \textbf{2)} 它采用扩散模型来增强 3D 生成过程，\textit{例如}，对输入图像中不可见的遮挡部分进行建模。 \textbf{3)} 它学习每个服装高斯的身份编码，以促进服装资产的分离和提取。此外，Disco4D 自然支持具有生动动态的 4D 人体动画。大量实验证明了 Disco4D 在 4D 人体生成和动画任务上的优势。我们的可视化效果可以在 \url{https://disco-4d.github.io/} 中找到。]]></description>
      <guid>https://arxiv.org/abs/2409.17280</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>探索细微差别：视觉语言导航的细粒度评估</title>
      <link>https://arxiv.org/abs/2409.17313</link>
      <description><![CDATA[arXiv:2409.17313v1 公告类型：新
摘要：本研究提出了一种用于视觉语言导航 (VLN) 任务的新型评估框架。它旨在以更细粒度的级别诊断各种指令类别的当前模型。该框架围绕任务的上下文无关语法 (CFG) 构建。CFG 是问题分解的基础和指令类别设计的核心前提。我们提出了一种借助大型语言模型 (LLM) 构建 CFG 的半自动方法。然后，我们引入并生成涵盖五个主要指令类别（即方向变化、地标识别、区域识别、垂直移动和数字理解）的数据。我们对不同模型的分析揭示了显著的性能差异和反复出现的问题。数字理解的停滞、对方向概念的严重选择性偏见以及其他有趣的发现有助于未来语言引导导航系统的发展。]]></description>
      <guid>https://arxiv.org/abs/2409.17313</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Bi-TTA：用于远程生理测量的双向测试时间适配器</title>
      <link>https://arxiv.org/abs/2409.17316</link>
      <description><![CDATA[arXiv:2409.17316v1 公告类型：新
摘要：远程光电容积描记法 (rPPG) 因其仅使用摄像头监测生理信号的非侵入式方法而备受关注。尽管前景光明，但由于生理信号的环境敏感性，rPPG 模型对新的、看不见的领域的适应性受到阻碍。为了解决这个问题，我们在 rPPG 中率先采用了测试时间自适应 (TTA)，使预训练模型能够在推理过程中适应目标域，从而避免了出于隐私考虑而对注释或源数据的需求。特别是，仅利用用户的面部视频流作为可访问的目标域数据，rPPG 模型通过调整它遇到的每个单个实例来调整。然而，1) TTA 算法主要用于分类任务，由于监督不足，不适合 rPPG 等回归任务。 2) 以单实例方式调整预训练模型会引入可变性和不稳定性，对有效过滤领域相关特征和领域无关特征同时保留学习到的信息提出了挑战。为了克服这些挑战，我们提出了 Bi-TTA，一种基于专家知识的新型双向测试时间适配器框架。具体来说，我们的 Bi-TTA 利用两个专家知识先验提供自我监督，主要包括两个模块：一个前瞻性适应 (PA) 模块，使用锐度感知最小化来消除领域无关噪声，增强适应过程中的稳定性和有效性；一个回顾性稳定 (RS) 模块，用于动态强化关键的学习模型参数，避免过度拟合或灾难性遗忘导致的性能下降。为此，我们在 TTA 协议下为 rPPG 任务建立了一个大规模基准。实验结果表明，我们的方法明显优于最先进的方法。]]></description>
      <guid>https://arxiv.org/abs/2409.17316</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>VL4AD：视觉语言模型改进像素级异常检测</title>
      <link>https://arxiv.org/abs/2409.17330</link>
      <description><![CDATA[arXiv:2409.17330v1 公告类型：新
摘要：在独立且相同分布的数据假设下，语义分割网络取得了重大成功。然而，由于这些网络通常训练的视觉概念集有限，因此它们通常难以检测来自未知语义类别的异常。为了解决这个问题，异常分割通常涉及对异常样本进行微调，需要额外努力进行数据收集、标记和模型再训练。为了避免这种繁琐的工作，我们采取了不同的方法，并建议将视觉语言 (VL) 编码器合并到现有的异常检测器中，以利用语义广泛的 VL 预训练来提高异常值意识。此外，我们提出了一种新的评分函数，可通过文本提示实现无数据和无训练的异常值监督。由此产生的 VL4AD 模型（包括最大逻辑提示集成和类合并策略）在广泛使用的基准数据集上实现了具有竞争力的性能，从而展示了视觉语言模型在逐像素异常检测方面的潜力。]]></description>
      <guid>https://arxiv.org/abs/2409.17330</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ChatCam：通过对话式人工智能实现摄像头控制</title>
      <link>https://arxiv.org/abs/2409.17331</link>
      <description><![CDATA[arXiv:2409.17331v1 公告类型：新
摘要：电影摄影师巧妙地捕捉世界的本质，通过复杂的摄像机运动制作引人入胜的视觉叙事。见证大型语言模型在感知和与 3D 世界交互方面取得的进步，本研究探索了它们在人类语言指导下控制摄像机的能力。我们推出了 ChatCam，这是一个通过与用户的对话来导航摄像机运动的系统，模仿专业电影摄影师的工作流程。为了实现这一点，我们提出了 CineGPT，这是一个基于 GPT 的自回归模型，用于文本条件摄像机轨迹生成。我们还开发了一个锚点确定器来确保精确的摄像机轨迹放置。ChatCam 理解用户请求并使用我们提出的工具来生成轨迹，这些轨迹可用于在辐射场表示上渲染高质量的视频片段。我们的实验，包括与最先进的方法和用户研究的比较，证明了我们的方法能够解释和执行复杂的相机操作指令，并在现实世界的生产环境中展示出有前景的应用。]]></description>
      <guid>https://arxiv.org/abs/2409.17331</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>块扩展 DINORET：调整自然领域基础模型，实现视网膜成像，避免灾难性遗忘</title>
      <link>https://arxiv.org/abs/2409.17332</link>
      <description><![CDATA[arXiv:2409.17332v1 公告类型：新
摘要：将深度学习整合到医学成像中有望极大地推进诊断方法，但它面临着普遍性的挑战。基于自监督学习的基础模型解决了这些问题并提高了数据效率。自然领域基础模型在医学成像方面前景广阔，但评估领域适应性的系统研究，尤其是使用自监督学习和参数高效微调的研究仍未得到充分探索。此外，很少有研究解决基础模型微调过程中灾难性遗忘的问题。我们使用自监督学习调整了 DINOv2 视觉变换器以用于视网膜成像分类任务，并生成了两个新的基础模型，称为 DINORET 和 BE DINORET。公开的彩色眼底照片被用于模型开发和随后的微调，以进行糖尿病视网膜病变分期和青光眼检测。我们引入了块扩展作为一种新颖的领域适应策略，并评估了灾难性遗忘模型。模型以 RETFound（眼科领域最先进的基础模型）为基准。DINORET 和 BE DINORET 在视网膜成像任务上表现出色，其中块扩展模型在大多数数据集上取得了最高分。块扩展成功缓解了灾难性遗忘。我们的小样本学习研究表明，DINORET 和 BE DINORET 在数据效率方面优于 RETFound。这项研究强调了使用自监督学习和块扩展将自然领域视觉模型应用于视网膜成像的潜力。BE DINORET 提供了强大的性能，而不会牺牲先前获得的功能。我们的研究结果表明，这些方法可以使医疗机构为其患者群体开发量身定制的视觉模型，从而增强全球医疗保健的包容性。]]></description>
      <guid>https://arxiv.org/abs/2409.17332</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过可重构 CMOS 图像传感器实现具有智能跳过功能的节能实时计算机视觉</title>
      <link>https://arxiv.org/abs/2409.17341</link>
      <description><![CDATA[arXiv:2409.17341v1 公告类型：新
摘要：当前基于视频的计算机视觉 (CV) 应用通常会因读取和处理帧中的所有像素（无论其重要性如何）而遭受高能耗。虽然以前的研究试图通过跳过输入补丁或像素并使用来自最终任务的反馈来指导跳过算法来降低这种能量，但跳过不是在传感器读取阶段执行的。因此，这些方法无法优化前端传感器能量。此外，由于部署在后端的现代 CV 网络的长延迟，它们可能不适合实时应用。为了应对这一挑战，本文提出了一种定制设计的可重构 CMOS 图像传感器 (CIS) 系统，该系统通过在传感器的读出阶段和随后的模数转换 (ADC) 阶段选择性地跳过帧内平淡无奇的区域或行来提高能源效率。一种新颖的掩蔽算法可以实时智能地指导跳过过程，从而优化前端传感器和后端神经网络，以用于自动驾驶和增强/虚拟现实 (AR/VR) 等应用。根据应用需求，我们的系统还可以在不跳过的情况下以标准模式运行。我们评估了基于 BDD100K 和 ImageNetVID 的物体检测硬件算法协同设计框架以及基于 OpenEDS 的凝视估计，在保持最先进 (SOTA) 精度的同时，前端传感器能耗降低了 53%。]]></description>
      <guid>https://arxiv.org/abs/2409.17341</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SeaSplat：使用 3D 高斯溅射和基于物理的图像形成模型来表示水下场景</title>
      <link>https://arxiv.org/abs/2409.17345</link>
      <description><![CDATA[arXiv:2409.17345v1 公告类型：新
摘要：我们介绍了 SeaSplat，这是一种利用 3D 辐射场的最新进展实现水下场景实时渲染的方法。水下场景是具有挑战性的视觉环境，因为通过水等介质进行渲染会对图像捕获产生范围和颜色相关的影响。我们限制了 3D 高斯溅射 (3DGS)，这是辐射场的最新进展，它使用物理接地的水下图像形成模型，可以快速训练和实时渲染完整的 3D 场景。将 SeaSplat 应用于 SeaThru-NeRF 数据集中的真实场景、美属维尔京群岛水下航行器收集的场景以及模拟降级的真实场景，我们不仅看到了在存在介质的情况下从场景中渲染新视点的定量性能提高，而且还能够恢复场景的底层真实颜色并恢复渲染，使其不存在中间介质。我们表明，水下图像形成有助于学习场景结构，具有更好的深度图，同时也表明我们的改进保持了利用 3D 高斯表示所带来的显著的计算改进。]]></description>
      <guid>https://arxiv.org/abs/2409.17345</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于视觉的工业装配线人类行为理解框架</title>
      <link>https://arxiv.org/abs/2409.17356</link>
      <description><![CDATA[arXiv:2409.17356v1 公告类型：新
摘要：本文介绍了一种基于视觉的框架，用于捕捉和理解工业装配线上的人类行为，重点关注车门制造。该框架利用先进的计算机视觉技术来估计工人的位置和 3D 姿势，并分析工作姿势、动作和任务进度。一个关键的贡献是引入了 CarDA 数据集，该数据集包含在现实环境中捕获的领域相关装配动作，以支持对人体姿势和动作分析框架的分析。该数据集包括时间同步的多摄像机 RGB-D 视频、在真实汽车制造环境中记录的运动捕捉数据以及基于 EAWS 的人体工程学风险评分和装配活动的注释。实验结果证明了所提出的方法在对工人姿势进行分类方面的有效性以及在监控装配任务进度方面的稳健性能。]]></description>
      <guid>https://arxiv.org/abs/2409.17356</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>