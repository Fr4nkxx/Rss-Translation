<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CV 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Fri, 16 Aug 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>外科 SAM 2：通过高效的帧修剪实时分割手术视频中的任何内容</title>
      <link>https://arxiv.org/abs/2408.07931</link>
      <description><![CDATA[arXiv:2408.07931v1 公告类型：新
摘要：手术视频分割是计算机辅助手术中的一项关键任务，对于提高手术质量和患者治疗效果至关重要。最近，Segment Anything Model 2 (SAM2) 框架在图像和视频分割方面取得了卓越的进步。然而，由于处理高分辨率图像和手术视频中复杂且长距离的时间动态对计算的要求很高，SAM2 在效率方面遇到了困难。为了应对这些挑战，我们引入了 Surgical SAM 2 (SurgSAM-2)，这是一种利用 SAM2 和高效帧修剪 (EFP) 机制的先进模型，以促进实时手术视频分割。EFP 机制通过有选择地仅保留最具信息量的帧来动态管理存储库，从而减少内存使用量和计算成本，同时保持较高的分割精度。我们的大量实验表明，与 vanilla SAM2 相比，SurgSAM-2 显著提高了效率和分割精度。值得注意的是，与 SAM2 相比，SurgSAM-2 实现了 3$\times$ FPS，同时在使用低分辨率数据进行微调后也提供了最先进的性能。这些进步使 SurgSAM-2 成为领先的手术视频分析模型，使资源受限环境中的实时手术视频分割成为可行的现实。]]></description>
      <guid>https://arxiv.org/abs/2408.07931</guid>
      <pubDate>Fri, 16 Aug 2024 06:17:25 GMT</pubDate>
    </item>
    <item>
      <title>训练空间频率视觉提示和概率聚类以实现准确的黑盒迁移学习</title>
      <link>https://arxiv.org/abs/2408.07944</link>
      <description><![CDATA[arXiv:2408.07944v1 公告类型：新
摘要：尽管黑盒预训练模型（PTM）（例如预测 API 服务）越来越流行，但由于数据分布差距，将通用模型直接应用于现实场景仍然存在重大挑战。考虑到数据不足和计算资源受限的情况，本文提出了一种用于黑盒设置中的视觉识别模型的新型参数高效迁移学习框架。我们的框架结合了两种新颖的训练技术。首先，我们通过生成空间和频域的视觉提示将 PTM 的输入空间（即图像）与目标数据分布对齐。除了新颖的空间频率混合视觉提示器之外，我们还设计了一种基于概率聚类的新型训练技术，它可以增强输出空间中的类分离（即预测概率）。在实验中，我们的模型在广泛的视觉识别数据集的少量迁移学习设置中表现出色，超越了最先进的基线。此外，我们表明，所提出的方法有效地降低了训练和推理阶段的计算成本。]]></description>
      <guid>https://arxiv.org/abs/2408.07944</guid>
      <pubDate>Fri, 16 Aug 2024 06:17:25 GMT</pubDate>
    </item>
    <item>
      <title>FlashGS：用于大规模高分辨率渲染的高效 3D 高斯分布</title>
      <link>https://arxiv.org/abs/2408.07967</link>
      <description><![CDATA[arXiv:2408.07967v1 公告类型：新
摘要：这项工作介绍了 FlashGS，一个开源 CUDA Python 库，旨在通过算法和内核级优化促进 3D Gaussian Splatting 的高效可微光栅化。FlashGS 是基于对渲染过程的全面分析的观察而开发的，旨在提高计算效率并使该技术得到广泛采用。本文包括一套优化策略，包括冗余消除、高效流水线、精细的控制和调度机制以及内存访问优化，所有这些都经过精心整合，以增强光栅化过程的性能。对 FlashGS 性能的广泛评估已在各种合成和现实世界的大规模场景中进行，涵盖了各种图像分辨率。实证结果表明，FlashGS 始终比移动消费者 GPU 实现平均 4 倍的加速，同时降低了内存消耗。这些结果强调了 FlashGS 的卓越性能和资源优化能力，使其成为 3D 渲染领域的强大工具。]]></description>
      <guid>https://arxiv.org/abs/2408.07967</guid>
      <pubDate>Fri, 16 Aug 2024 06:17:25 GMT</pubDate>
    </item>
    <item>
      <title>3D 医学图像的持久图像：超像素和优化高斯系数</title>
      <link>https://arxiv.org/abs/2408.07905</link>
      <description><![CDATA[arXiv:2408.07905v1 公告类型：新
摘要：拓扑数据分析 (TDA) 揭示了医学成像中物体的关键特性。基于持久同源性的方法已证明其在捕捉传统深度学习方法无法在放射学和病理学中检测到的拓扑特征方面具有优势。然而，以前的研究主要集中在 2D 图像分析上，忽略了全面的 3D 背景。在本文中，我们提出了一种创新的 3D TDA 方法，该方法结合超像素的概念将 3D 医学图像特征转换为点云数据。通过利用优化的高斯系数，所提出的 3D TDA 方法首次有效地为 3D 体积数据生成整体持久图像。与其他传统方法相比，我们的 3D TDA 方法在 MedMNist3D 数据集上表现出优异的性能，展示了其在分类任务中对基于 3D 持久同源性的拓扑分析建模的潜在有效性。源代码可在https://github.com/hrlblab/TopologicalDataAnalysis3D上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2408.07905</guid>
      <pubDate>Fri, 16 Aug 2024 06:17:24 GMT</pubDate>
    </item>
    <item>
      <title>一种基于深度特征的方法，使用改进的 ResNet50 和梯度提升进行视觉情感分类</title>
      <link>https://arxiv.org/abs/2408.07922</link>
      <description><![CDATA[arXiv:2408.07922v1 公告类型：新
摘要：视觉情绪分析 (VSA) 的多功能性是其日益受到关注的原因之一。由于之前的研究集中在文本等单一模态的情绪分​​析 (SA) 上，因此很难有效地管理包含视觉信息的社交媒体数据。此外，大多数视觉情绪研究需要充分分类情绪，因为它们主要关注简单地合并模态属性而不研究它们复杂的关系。这促使人们提出开发深度学习和机器学习算法的融合。在本研究中，使用基于深度特征的多类分类方法从修改后的 ResNet50 中提取深度特征。此外，梯度提升算法已用于对包含情感内容的照片进行分类。该方法在两个基准数据集 CrowdFlower 和 GAPED 上进行了彻底评估。最后，使用尖端的深度学习和机器学习模型来比较所提出的策略。与最先进的方法相比，所提出的方法在所呈现的数据集上表现出色。]]></description>
      <guid>https://arxiv.org/abs/2408.07922</guid>
      <pubDate>Fri, 16 Aug 2024 06:17:24 GMT</pubDate>
    </item>
    <item>
      <title>MambaVT：用于稳健的 RGB-T 跟踪的时空上下文建模</title>
      <link>https://arxiv.org/abs/2408.07889</link>
      <description><![CDATA[arXiv:2408.07889v1 公告类型：新 
摘要：现有的 RGB-T 跟踪算法通过利用 Transformer 架构的全局交互能力和大量预训练模型取得了显着进展。然而，这些方法主要采用图像对外观匹配，并且面临注意机制固有的高二次复杂度的挑战，导致时间信息的利用受到限制。受最近出现的状态空间模型 Mamba 的启发，以其令人印象深刻的长序列建模能力和线性计算复杂度而闻名，这项工作创新地提出了一个纯基于 Mamba 的框架 (MambaVT)，以充分利用时空上下文建模进行鲁棒的可见热跟踪。具体而言，我们设计了远程跨帧集成组件以全局适应目标外观变化，并引入短期历史轨迹提示以根据局部时间位置线索预测后续目标状态。大量实验表明，Mamba Vision 在 RGB-T 跟踪方面具有巨大潜力，其中 MambaVT 在四个主流基准上实现了最佳性能，同时所需的计算成本较低。我们的目标是将这项工作作为简单而强大的基线，以促进该领域的未来研究。代码和预训练模型将公开。]]></description>
      <guid>https://arxiv.org/abs/2408.07889</guid>
      <pubDate>Fri, 16 Aug 2024 06:17:23 GMT</pubDate>
    </item>
    <item>
      <title>用于文本情感分析的量子启发式可解释深度学习架构</title>
      <link>https://arxiv.org/abs/2408.07891</link>
      <description><![CDATA[arXiv:2408.07891v1 公告类型：新
摘要：文本已成为社交媒体上的主要交流形式，包含丰富的情感细微差别。因此，从文本中提取情感信息至关重要。尽管先前的研究取得了一些进展，但现有的文本情感分析模型在整合各种语义信息方面仍然面临挑战，并且缺乏可解释性。为了解决这些问题，我们提出了一种量子启发的深度学习架构，将量子力学的基本原理 (QM 原理) 与用于文本情感分析的深度学习模型相结合。具体而言，我们分析文本表示和 QM 原理之间的共性，以设计一种量子启发的文本表示方法，并进一步开发量子启发的文本嵌入层。此外，我们设计了一个基于长短期记忆 (LSTM) 网络和自注意机制 (SAM) 的特征提取层。最后，我们使用量子复数原理计算文本密度矩阵，并应用 2D 卷积神经网络 (CNN) 进行特征浓缩和降维。通过一系列可视化、比较和消融实验，我们证明我们的模型不仅在准确性和效率方面比以前的相关模型具有显著优势，而且通过整合 QM 原理实现了一定的可解释性。我们的代码可在 QISA 获得。]]></description>
      <guid>https://arxiv.org/abs/2408.07891</guid>
      <pubDate>Fri, 16 Aug 2024 06:17:23 GMT</pubDate>
    </item>
    <item>
      <title>持续感知基准</title>
      <link>https://arxiv.org/abs/2408.07867</link>
      <description><![CDATA[arXiv:2408.07867v1 公告类型：新
摘要：人类不断感知和处理视觉信号。然而，当前的视频模型通常要么稀疏地采样关键帧，要么将视频分成块并在每个块内进行密集采样。这种方法源于这样一个事实：大多数现有的视频基准可以通过分析关键帧或从单独的块中聚合信息来解决。我们预计下一代视觉模型将通过连续和整体地处理视觉输入来模拟人类感知。为了促进此类模型的开发，我们提出了连续感知基准，这是一项视频问答任务，无法通过仅关注几个帧或为小块添加字幕然后使用语言模型进行总结来解决。大量实验表明，现有的模型（无论是商业模型还是开源模型）都难以完成这些任务，这表明需要在这个方向上取得新的技术进步。]]></description>
      <guid>https://arxiv.org/abs/2408.07867</guid>
      <pubDate>Fri, 16 Aug 2024 06:17:22 GMT</pubDate>
    </item>
    <item>
      <title>是否归纳：多生物特征融合的建议</title>
      <link>https://arxiv.org/abs/2408.07883</link>
      <description><![CDATA[arXiv:2408.07883v1 公告类型：新
摘要：通过融合将来自不同生物特征系统的匹配分数结合起来是一种提高识别准确率的行之有效的方法。然而，缺失的分数会降低性能，并限制可能应用的融合技术。在多生物特征系统中，插补是一种很有前途的技术，用于替换缺失的数据。在本文中，我们在三个多模态生物特征分数数据集（即 NIST BSSR1、BIOCOP2008 和 MIT LL Trimodal）上评估了各种分数插补方法，并研究了可能影响插补有效性的因素。我们的研究揭示了三个关键的观察结果：（1）即使融合规则不需要完整的分数数据，插补也比不插补缺失分数更可取。（2）平衡训练数据中的类别对于减轻插补技术对代表性不足的类别的负面偏差至关重要，即使这涉及删除大量分数向量。 （3）当模态之间的得分相关时，多元归因方法似乎有益，而单变量方法似乎有益于模态之间的得分相关性较低的情况。]]></description>
      <guid>https://arxiv.org/abs/2408.07883</guid>
      <pubDate>Fri, 16 Aug 2024 06:17:22 GMT</pubDate>
    </item>
    <item>
      <title>深度学习模型可靠性差的空间尺度探索：以屋顶光伏系统遥感为例</title>
      <link>https://arxiv.org/abs/2408.07828</link>
      <description><![CDATA[arXiv:2408.07828v1 公告类型：新
摘要：光伏 (PV) 能源增长迅速，对于电力系统的脱碳至关重要。然而，记录屋顶光伏系统技术特征的集中式注册中心往往缺失，因此很难准确监测这种增长。缺乏监测可能会威胁光伏能源与电网的整合。为了避免这种情况，使用深度学习对屋顶光伏系统进行遥感是一种有前途的解决方案。然而，现有技术不够可靠，无法被公共当局或输电系统运营商 (TSO) 用来构建屋顶光伏车队的最新统计数据。可靠性的缺乏源于深度学习模型对分布变化很敏感。这项工作提出了对分布变化对经过训练以检测高架图像上的屋顶光伏板的深度学习模型的分类准确性的影响的全面评估。我们构建了一个基准来隔离分布变化的来源，并引入了一种新方法，该方法利用可解释的人工智能 (XAI) 和输入图像和模型决策的尺度分解来了解分布变化如何影响深度学习模型。最后，基于我们的分析，我们引入了一种数据增强技术，旨在提高深度学习分类器对不同采集条件的鲁棒性。我们表明我们提出的方法优于竞争方法。我们讨论了一些使用俯视图像和深度学习模型绘制光伏系统地图的实用建议。]]></description>
      <guid>https://arxiv.org/abs/2408.07828</guid>
      <pubDate>Fri, 16 Aug 2024 06:17:21 GMT</pubDate>
    </item>
    <item>
      <title>学习沉浸式显示的单通道多任务感知图形</title>
      <link>https://arxiv.org/abs/2408.07836</link>
      <description><![CDATA[arXiv:2408.07836v1 公告类型：新
摘要：沉浸式显示器通过利用新兴的感知图形方法（如注视点渲染）在提供感知逼真的图像方面取得了迅速发展。实际上，需要按顺序执行多种此类方法以增强感知质量。然而，驱动沉浸式显示器的设备功率和计算资源有限，因此很难同时部署多个感知模型。
我们通过提出一种计算轻量级、文本引导、学习型多任务感知图形模型来解决这一挑战。给定 RGB 输入图像，我们的模型通过执行提供的文本提示描述的一个或多个感知任务来输出感知增强的图像。我们的模型通过多任务学习支持各种感知任务，包括注视点渲染、动态范围增强、图像去噪和彩色立体视觉。独特的是，我们模型的单个推理步骤支持以不同的提示速率（即轻度、轻微）对这些感知任务进行不同的排列，从而无需菊花链连接多个模型即可获得所需的感知效果。我们在新的源和感知增强图像数据集及其相应的文本提示上训练我们的模型。我们评估了我们模型在嵌入式平台上的性能，并通过用户研究验证了我们模型的感知质量。我们的方法使用单个推理步骤实现了与最先进的任务特定方法相当的质量，同时提供了更快的推理速度和灵活性，可以混合不同强度的效果。]]></description>
      <guid>https://arxiv.org/abs/2408.07836</guid>
      <pubDate>Fri, 16 Aug 2024 06:17:21 GMT</pubDate>
    </item>
    <item>
      <title>卷积神经网络中更快预测的代数表示</title>
      <link>https://arxiv.org/abs/2408.07815</link>
      <description><![CDATA[arXiv:2408.07815v1 公告类型：新
摘要：卷积神经网络 (CNN) 是计算机视觉任务的流行模型选择。当 CNN 由多层组成，从而形成深度神经网络时，可以添加跳跃连接以创建更容易的梯度优化问题，同时保留模型表现力。在本文中，我们表明，具有跳跃连接的任意复杂、经过训练的线性 CNN 可以简化为单层模型，从而大大减少预测时间内的计算要求。我们还提出了一种训练非线性模型的方法，跳跃连接在整个训练过程中逐渐被移除，从而在预测时间内无需计算开销即可获得跳跃连接的好处。这些结果通过残差网络 (ResNet) 架构上的实际示例进行了演示。]]></description>
      <guid>https://arxiv.org/abs/2408.07815</guid>
      <pubDate>Fri, 16 Aug 2024 06:17:20 GMT</pubDate>
    </item>
    <item>
      <title>SSRFlow：用于现实世界场景流的语义感知融合与时空重新嵌入</title>
      <link>https://arxiv.org/abs/2408.07825</link>
      <description><![CDATA[arXiv:2408.07825v1 公告类型：新
摘要：场景流从两个连续点云提供第一帧的 3D 运动场，对于动态场景感知至关重要。然而，当代场景流方法面临三大挑战。首先，它们缺乏全局流嵌入或在嵌入之前仅考虑单个点云的上下文，导致嵌入点难以感知另一帧的一致语义关系。为了解决这个问题，我们提出了一种称为双交叉注意 (DCA) 的新方法，用于基于语义上下文的两帧之间的潜在融合和对齐。然后将其集成到全局融合流嵌入 (GF) 中，以基于上下文和欧几里得空间中的全局相关性初始化流嵌入。其次，在扭曲层之后，非刚性物体中存在变形，这会扭曲连续帧之间的时空关系。为了更精确地估计下一级别的残差流，我们设计了时空重嵌入 (STR) 模块来更新当前级别的点序列特征。最后，由于合成数据集和 LiDAR 扫描数据集之间存在显著的域差距，因此通常会观察到较差的泛化能力。我们利用新颖的域自适应损失来有效地弥合从合成到现实世界的运动推理差距。实验表明，我们的方法在各种数据集上都实现了最先进的 (SOTA) 性能，在现实世界的 LiDAR 扫描情况下尤其表现出色。我们的代码将在发布后发布。]]></description>
      <guid>https://arxiv.org/abs/2408.07825</guid>
      <pubDate>Fri, 16 Aug 2024 06:17:20 GMT</pubDate>
    </item>
    <item>
      <title>NeuroPapyri：用于手写纸莎草纸检索的深度注意力嵌入网络</title>
      <link>https://arxiv.org/abs/2408.07785</link>
      <description><![CDATA[arXiv:2408.07785v1 公告类型：新
摘要：计算机视觉和机器学习的交叉已经成为推进历史研究的一条有希望的途径，有助于更深入地探索我们的过去。然而，机器学习方法在历史古文字学中的应用常常受到批评，因为它们被认为是“黑匣子”性质。为了应对这一挑战，我们推出了 NeuroPapyri，这是一种创新的基于深度学习的模型，专门用于分析包含古希腊纸莎草纸的图像。为了解决与透明度和可解释性相关的问题，该模型采用了一种注意力机制。这种注意力机制不仅增强了模型的性能，而且还提供了对决策过程有重大贡献的图像区域的视觉表示。该模型专门针对处理带有手写文本行的纸莎草纸文件图像进行了校准，利用单独的注意力图来告知输入图像中特定字符的存在与否。本文介绍了 NeuroPapyri 模型，包括其架构和训练方法。评估结果证明了 NeuroPapyri 在文档检索方面的功效，展现了其推动历史手稿分析的潜力。]]></description>
      <guid>https://arxiv.org/abs/2408.07785</guid>
      <pubDate>Fri, 16 Aug 2024 06:17:19 GMT</pubDate>
    </item>
    <item>
      <title>Cropper：通过上下文学习进行图像裁剪的视觉语言模型</title>
      <link>https://arxiv.org/abs/2408.07790</link>
      <description><![CDATA[arXiv:2408.07790v1 公告类型：新
摘要：图像裁剪的目标是识别图像中具有视觉吸引力的裁剪。传统方法依赖于在特定数据集上训练的专门架构，这些架构很难适应新的要求。大型视觉语言模型 (VLM) 的最新突破使得无需明确训练即可进行视觉上下文学习。然而，使用 VLM 进行视觉下游任务的有效策略仍然很大程度上不清楚且尚未得到充分探索。在本文中，我们提出了一种利用 VLM 进行更好图像裁剪的有效方法。首先，我们提出了一种有效的图像裁剪快速检索机制，以自动选择上下文示例。其次，我们引入了一种迭代细化策略来迭代增强预测的裁剪。提出的框架名为 Cropper，适用于广泛的裁剪任务，包括自由形式裁剪、主题感知裁剪和纵横比感知裁剪。大量实验和用户研究表明，Cropper 在多个基准测试中的表现明显优于最先进的方法。]]></description>
      <guid>https://arxiv.org/abs/2408.07790</guid>
      <pubDate>Fri, 16 Aug 2024 06:17:19 GMT</pubDate>
    </item>
    </channel>
</rss>