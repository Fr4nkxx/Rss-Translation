<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>CS.CV更新arxiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.cv更新arxiv.org e-print存档。</description>
    <lastBuildDate>Tue, 11 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>Vistaflow：通过Q学习的动态分辨率管理的影片量重建</title>
      <link>https://arxiv.org/abs/2502.05222</link>
      <description><![CDATA[ARXIV：2502.05222V1公告类型：新 
摘要：我们介绍了Vistaflow，这是一种可扩展的三维成像技术，能够从一组2D照片中重建完全交互的3D体积图像。我们的模型通过能够在感性3D场景上的动态分辨率管理的可区分渲染系统综合了新的观点。我们通过引入Quiq，这是一种通过Q学习训练的新型中间视频控制器，通过以毫秒的精度调整渲染分辨率，以保持始终如一的帧速率。值得注意的是，Vistaflow在集成的CPU图形上本地运行，使其可行，可在移动和入门级设备上可行，同时仍提供高性能渲染。 Vistaflow绕过神经辐射场（NERFS），使用PLENOCTREE数据结构来呈现复杂的光相互作用，例如反射和地下散射，并具有最小的硬件要求。我们的模型能够以1080p的分辨率在消费者硬件上以1080p的分辨率以1080p的分辨率优于最先进的方法。通过为每种设备的功能定制渲染质量，Vistaflow具有提高光真逼真的3D场景的效率和可访问性的潜力，从高端工作站到廉价的微控制器。]]></description>
      <guid>https://arxiv.org/abs/2502.05222</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>L2GNET：用于通用医学图像分割的解剖结构的最佳局部到全球表示</title>
      <link>https://arxiv.org/abs/2502.05229</link>
      <description><![CDATA[ARXIV：2502.05229V1公告类型：新 
摘要：连续的潜在空间（CLS）和离散的潜在空间（DLS）模型，例如Attnunet和Vqunet，在医学图像细分方面都表现出色。相比之下，协同连续和离散的潜在空间（CDLS）模型在处理细粒和粗粒信息方面显示出希望。但是，他们在建模远程依赖性方面很难。基于CLS或CDLS的模型（例如Transunet或Synergynet）擅长捕获长期依赖性。由于它们在很大程度上依赖于使用自我注意力的特征池或聚集，因此他们可能会捕获冗余区域之间的依赖性。这阻碍了对解剖结构含量的理解，在建模阶层和阶层间依赖性，增加错误的负面因素并损害概括方面提出了挑战。在解决这些问题时，我们提出了L2GNET，该L2GNET通过使用最佳传输和可训练的参考来对齐代码获得从DLS获得的离散代码来学习全球依赖性。 L2GNET可以在自我注意力模型中没有额外的权重矩阵实现歧视性代表性学习，从而在医疗应用中有效地计算有效。关于多器官分割和心脏数据集的广泛实验表明，L2GNET优于最先进的方法，包括CDLS方法Synergynet，提供了一种新颖的方法来增强深度学习模型在医学图像分析中的性能。]]></description>
      <guid>https://arxiv.org/abs/2502.05229</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>对AI生成的媒体检测的调查：从非MLLM到MLLM</title>
      <link>https://arxiv.org/abs/2502.05240</link>
      <description><![CDATA[ARXIV：2502.05240V1公告类型：新 
摘要：AI生成的媒体的扩散对信息真实性和社会信任提出了重大挑战，使可靠的检测方法高度要求。检测AI生成的培养基的方法已迅速发展，与多模式大型语言模型（MLLM）的进步相似。当前的检测方法可以分为两个主要组：基于非MLLM和基于MLLM的方法。前者采用了由深度学习技术提供动力的高精度，特定于领域的探测器，而后者则利用基于MLLM的通用检测器，这些探测器基于整合真实性验证，解释性和本地化功能的MLLM。尽管在该领域取得了重大进展，但文献中仍然存在有关一项综合调查的差距，该调查研究了从域特异性到通用检测方法的过渡。本文通过对两种方法进行系统的综述，从单模式和多模式的角度分析它们来解决这一差距。我们对这些类别进行了详细的比较分析，研究了它们的方法论上的相似性和差异。通过此分析，我们探讨了潜在的混合方法，并确定了伪造检测中的关键挑战，为将来的研究提供了方向。此外，随着MLLM在检测任务中越来越普遍，道德和安全考虑因素已成为关键的全球关注点。我们研究了各个司法管辖区围绕生成AI（Genai）的监管景观，为该领域的研究人员和从业人员提供了宝贵的见解。]]></description>
      <guid>https://arxiv.org/abs/2502.05240</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用人级概念来解释的失败检测</title>
      <link>https://arxiv.org/abs/2502.05275</link>
      <description><![CDATA[ARXIV：2502.05275V1公告类型：新 
摘要：可靠的故障检测在安全至关重要的应用中至关重要。然而，已知神经网络会对错误分类的样本产生过度自信的预测。结果，由于现有的置信得分功能依赖于类别级信号，logits来检测故障，因此它仍然是有问题的问题。这项研究介绍了一种创新的策略，利用人类水平的概念出于双重目的：可靠地检测模型何时失败并透明地解释原因。通过整合每个类别的细微信号，我们的方法可以对模型的置信度进行详细的评估。我们基于对输入图像的概念激活的序数排名提出了一种简单而高效的方法。没有铃铛和哨子，我们的方法会大大降低各种现实世界图像分类基准的假正率，特别是Imagenet的3.7％，而欧洲裔则为9％。]]></description>
      <guid>https://arxiv.org/abs/2502.05275</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Invizo：阿拉伯语手写文档光学识别解决方案</title>
      <link>https://arxiv.org/abs/2502.05277</link>
      <description><![CDATA[ARXIV：2502.05277V1公告类型：新 
摘要：将阿拉伯文本的图像转换为纯文本是学术界和行业中广泛研究的主题。但是，由于阿拉伯文字的变化的复杂性质，对阿拉伯语手写和印刷文本的认识提出了困难的挑战。这项工作提出了一种端到端解决方案，用于识别阿拉伯语手写，印刷和阿拉伯语数字，并以结构化的方式介绍数据。我们达到了81.66％的精度，78.82％的召回率和79.07％的F量，以供应拟议解决方案的文本检测任务。提出的识别模型结合了基于CNN的最先进的特征提取，以及基于变压器的序列建模，以适应手写样式，中风厚度，比对和噪声条件的变化。该模型的评估表明，其在印刷文本和手写文本上都表现出色，在印刷文本上产生0.59％的CER和1.72％的速度，而手写文本则为7.91％的CER和31.41％的WER。事实证明，总体建议的解决方案是在现实生活中的OCR任务中依赖的。配备了检测和识别模型，以及其他功能提取和匹配帮助算法。通过通用实施，使解决方案对任何给定的文档或收据有效。因此，它在任何给定的情况下都是实用且有用的。]]></description>
      <guid>https://arxiv.org/abs/2502.05277</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>同构的同态性呈误报和负面问题，在医学图像密集的对比表示学习中</title>
      <link>https://arxiv.org/abs/2502.05282</link>
      <description><![CDATA[ARXIV：2502.05282V1公告类型：新 
摘要：密集的对比度表示学习（DCRL）极大地提高了图像密集的预测任务的学习效率，显示出其降低医学图像收集和密集注释的巨大成本的巨大潜力。但是，医学图像的特性使对应关系发现不可靠，从而在DCRL中带来了一个大规模假阳性和负（FP＆amp; n）的开放问题。在本文中，我们提出了几何视觉密度相似性（Gemini）学习，该学习嵌入了DCRL之前的同构，并启用了可靠的对应性发现，以实现有效的密集对比度。我们提出了一个可变形的同构学习（DHL），该学习对医学图像的同态同态进行了建模，并学会了估算可变形的映射，以预测拓扑保存下像素的对应关系。它有效地减少了配对的搜索空间，并通过梯度驱动了负面对的隐式和软学习。我们还提出了一个几何语义相似性（GSS），该语义相似性（GSS）在特征中提取语义信息，以测量对应学习的比对度。它将促进变形的学习效率和性能，从而可靠地构建正对。在实验中，我们对两个典型表示学习任务实施了两个实用变体。我们在七个数据集上的有希望的结果胜过现有方法表明我们的优势。我们将在同伴链接上发布代码：https：//github.com/yutinghe-list/gemini。]]></description>
      <guid>https://arxiv.org/abs/2502.05282</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用Yolo和基于规则的方法进行无人机检测和跟踪</title>
      <link>https://arxiv.org/abs/2502.05292</link>
      <description><![CDATA[ARXIV：2502.05292V1公告类型：新 
摘要：传统上，无人机或无人机用于军事任务，战争和间谍活动。但是，由于涉及安全和检查，运输，研究目的和娱乐无人机飞行的多个工业应用，无人机的使用情况大大增加。这样的增加在公共场所中的无人机活动数量增加，就需要为隐私保护和安全而进行监管行动。因此，对非法无人机活动（例如边界侵占）的检测成为必要。这种检测任务通常是由在注释图像数据集上训练的深度学习模型自动化和执行的。本文以先前的工作为基础，并扩展了已经发布的开源数据集。提供了整个数据集的描述和分析。该数据集用于训练Yolov7深学习模型及其一些次要变体，并提供了结果。由于检测模型基于单个图像输入，因此使用简单的基于互相关的跟踪器来减少检测下降并改善视频中的跟踪性能。最后，总结了整个无人机检测系统。]]></description>
      <guid>https://arxiv.org/abs/2502.05292</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>迈向细粒度的肾脏脉管系统分割：FH-SEG的全尺度分层学习</title>
      <link>https://arxiv.org/abs/2502.05320</link>
      <description><![CDATA[ARXIV：2502.05320V1公告类型：新 
摘要：肾脏脉管系统的准确细粒细分对于肾脏分析至关重要，但是由于多样化和不足的注释图像，它面临挑战。现有方法难以准确细分肾脏脉管系统的复杂区域，例如内壁和外壁，动脉和病变。在本文中，我们介绍了FH-SEG，这是一个全面的分层学习框架，旨在全面分割肾脏脉管系统。具体而言，FH-SEG采用了完整的跳过连接，将详细的解剖信息与跨尺度的上下文语义合并，有效地弥合了结构和病理环境之间的差距。此外，我们实施了可学习的层次软关注门，以适应地减少非核心信息的干扰，从而增强对关键血管特征的关注。为了推进对肾脏病理学细分的研究，我们还开发了一个大型肾脏脉管系统（LRV）数据集，该数据集包含16,212个5,600个肾动脉的细粒注释图像。在LRV数据集上进行的广泛实验表明，FH-SEG的出色精度（71.23％骰子，73.06％F1），分别优于2.67和2.13个百分点。代码可在以下网址提供：https：//github.com/hrlblab/fh-seg。]]></description>
      <guid>https://arxiv.org/abs/2502.05320</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>NextBestPath：有效的3D图映射</title>
      <link>https://arxiv.org/abs/2502.05378</link>
      <description><![CDATA[ARXIV：2502.05378V1公告类型：新 
摘要：这项工作解决了主动3D映射的问题，在该问题中，代理必须找到有效的轨迹以详尽地重建新场景。先前的方法主要预测代理商位置附近的下一个最佳视图，这很容易陷入当地。此外，由于几何复杂性和不准确的地面真相网格，现有的室内数据集不足。为了克服这些局限性，我们介绍了一个新颖的数据集Aimdoom，其中包含用于厄运视频游戏的地图生成器，从而可以在不同的室内环境中更好地基准主动3D映射。此外，我们提出了一种我们称为次要路径（NBP）的新方法，该方法预测了长期目标，而不是仅专注于短视观点。该模型共同预测了长期目标和障碍图的累积表面覆盖率增长，从而可以通过统一模型有效地规划最佳路径。通过利用在线数据收集，数据增强和课程学习，NBP在现有的MP3D数据集和我们的AIMDOOM数据集上都显着优于最先进的方法，从而在各种复杂性的室内环境中实现了更有效的映射。]]></description>
      <guid>https://arxiv.org/abs/2502.05378</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>粗到最新的结构感知艺术风格转移</title>
      <link>https://arxiv.org/abs/2502.05387</link>
      <description><![CDATA[ARXIV：2502.05387V1公告类型：新 
摘要：艺术风格的转移旨在使用样式图像和内容图像来合成目标图像，该目标图像保留了与样式图像相同的艺术表达式，同时保留内容图像的基本内容。许多最近提出的样式转移方法有一个常见的问题。也就是说，他们只是将样式图像的纹理和颜色传递到内容图像的全局结构。结果，内容图像具有与样式图像的本地结构不同的本地结构。在本文中，我们提出了一种有效的方法，该方法可用于传输样式模式，同时将本地样式结构融合到本地内容结构中。在我们的方法中，首先使用粗网络以低分辨率重建粗糙的风格化功能，其中样式的色彩分布大致传递，内容结构与样式结构结合在一起。然后，采用了重建的功能和内容功能，以使用具有三个结构性选择性融合（SSF）模块的优质网络合成具有高分辨率的高质量结构感知的风格化图像。通过产生具有吸引力的高质量风格化结果以及与某些最先进的风格转移方法的共同参与，我们方法的有效性得到了证明。]]></description>
      <guid>https://arxiv.org/abs/2502.05387</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>超越和没有扩散：可逆的指导一致性训练</title>
      <link>https://arxiv.org/abs/2502.05391</link>
      <description><![CDATA[ARXIV：2502.05391V1公告类型：新 
摘要：图像生成中的指导导向模型迈向更高质量或更靶向的输出，通常在扩散模型（DMS）中通过无分类器指导（CFG）实现。但是，最近提供较少功能评估的最新一致性模型（CMS）依赖于从验证的DMS中提取CFG知识来实现​​指导，从而使其成本高昂且僵化。在这项工作中，我们提出了可逆的指导一致性培训（IGCT），这是一个完全由数据驱动的引导CMS的新型培训框架。作为一项开创性的工作，IGCT有助于快速和有指导的图像生成和编辑，而无需培训和蒸馏DM，从而大大降低了整体计算要求。 IGCT解决了在高引导量表下CFG中看到的饱和伪像。我们在CIFAR-10和Imagenet64上进行的广泛实验表明，与CFG相比，IGCT显着提高了FID和精度。在13的指导下，IGCT将精度提高到0.8，而DM的精度下降到0.47。我们的工作朝着在不依赖DMS的情况下为CM的指导和反转迈出了第一步。]]></description>
      <guid>https://arxiv.org/abs/2502.05391</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>图像压缩的卷积深色：一种基于色网的方法</title>
      <link>https://arxiv.org/abs/2502.05402</link>
      <description><![CDATA[ARXIV：2502.05402V1公告类型：新 
摘要：搜索图像压缩优化技术是在学术界内外都引起人们一直感兴趣的话题。一种显示该领域未来改进有望的方法是图像着色，因为图像着色算法可以减少需要存储用于图像的颜色数据的量。我们的工作着重于优化一种基于色网格的方法，以实现图像压缩的目的，就卷积着色网络体系结构进行了全自动图像色彩信息保留。更一般而言，使用卷积神经网络进行图像重新化，我们希望最大程度地减少存储的颜色信息的数量，同时仍然能够忠实地重新彩色图像。我们的结果产生了有希望的图像压缩率，同时仍允许成功的图像重塑达到高CSIM值。]]></description>
      <guid>https://arxiv.org/abs/2502.05402</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在海洋环境中无人机的深度单眼姿势估计的环境模拟中的视觉模拟</title>
      <link>https://arxiv.org/abs/2502.05409</link>
      <description><![CDATA[ARXIV：2502.05409V1公告类型：新 
摘要：本文提出了一个在环境中的视觉模拟环境，以对在海洋环境中运行的无人机进行深度单眼姿势估计。最近，一个具有变压器体系结构的深神经网络已成功训练，以估算无人机相对于研究船的飞行甲板的姿势，从而克服了基于GPS的方法的几个限制。但是，由于研究船的可用性有限和相关的运营成本，验证实际海洋环境中的深层姿势估计方案构成了重大挑战。为了解决这些问题，我们提出了一个逼真的3D虚拟环境，利用高斯碎片的最新进步，这是一种新颖的技术，该技术通过将图像像素像素作为3D空间中的高斯分布来代表3D场景，从而创建了一个轻质和高质量的视觉模型观点。这种方法可以创建一个虚拟环境，整合了原位收集的多个现实世界图像。由此产生的仿真可以对飞行操作进行室内测试，同时验证飞行软件，硬件和深层单眼姿势估计方案的各个方面。这种方法为测试和验证船上无人机的自动飞行提供了一种具有成本效益的解决方案，特别是专门针对基于视觉的控制和估计算法。]]></description>
      <guid>https://arxiv.org/abs/2502.05409</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Show-o Turbo：迈向加速统一的多模式理解和产生</title>
      <link>https://arxiv.org/abs/2502.05415</link>
      <description><![CDATA[ARXIV：2502.05415V1公告类型：新 
摘要：对建立统一的多模式理解和生成模型的研究兴趣越来越大，其中Show-O是一个著名的代表，这对文本到图像和图像到文本的生成都展现了巨大的希望。 Show-O的推论涉及逐步确定图像令牌和自动汇总解码文本令牌，因此不幸的是，双方都遭受了效率低下的问题。本文介绍了Show-o Turbo来弥合差距。我们首先根据文本令牌的平行解码来确定统一的denoising观点，用于在show-o中生成图像和文本。然后，我们建议将一致性蒸馏（CD）扩展，这是一种缩短扩散模型的去核过程的合格方法，到show-o的多模式denoising轨迹。我们引入了轨迹分割策略和课程学习程序，以改善培训融合。从经验上讲，在文本到图像生成中，show-o涡轮在不使用无分类器指导（CFG）的情况下以4个采样步骤显示了遗传得分为0.625，以优于原始Show-O的8个步骤和CFG的表现；在图像到文本生成中，Show-o Turbo表现出1.5倍的速度，而不会显着牺牲性能。该代码可从https://github.com/zhijie-group/show-o-turbo获得。]]></description>
      <guid>https://arxiv.org/abs/2502.05415</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LRA-GNN：具有初始和动态残差的潜在关系感知图形神经网络，用于面部年龄估计</title>
      <link>https://arxiv.org/abs/2502.05423</link>
      <description><![CDATA[ARXIV：2502.05423V1公告类型：新 
摘要：面部信息主要集中在面部要点之间，Frontier Research已开始使用图形神经网络将面孔分为斑块作为节点，以模拟复杂的面部表征。但是，这些方法基于相似性阈值构建节点与节点关系，因此存在一个潜在关系的问题。这些潜在关系对于面部衰老的深层语义表示至关重要。在这部小说中，我们提出了一个具有初始和动态残留（LRA-GNN）的新的潜在关系感知的图形神经网络，以实现强大而全面的面部表现。具体而言，我们首先构建了一个初始图，利用面部钥匙点作为先验知识，然后将随机的步行策略用于初始图，以获取全局结构，两者一起指导随后的有效探索和全面表示。然后，LRA-GNN利用多意见机制来捕获潜在关系，并基于上述指导生成一组完全连接的图表，这些图包含丰富的面部信息和完整的结构。为了避免在完全连接的图上进行深度特征提取的过度光滑问题，仔细设计了深度剩余图形卷积网络，融合了自适应的初始残留物和动态发育残差，以确保信息的一致性和多样性。最后，为了提高估计准确性和概括能力，提出了渐进式增强学习以优化集成分类回归器。我们提出的框架超过了几个年龄估计基准的最新基线，表明其强度和有效性。]]></description>
      <guid>https://arxiv.org/abs/2502.05423</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>