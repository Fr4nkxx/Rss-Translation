<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CV 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Fri, 15 Nov 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>通过偏好优化对齐视觉对比学习模型</title>
      <link>https://arxiv.org/abs/2411.08923</link>
      <description><![CDATA[arXiv:2411.08923v1 公告类型：新
摘要：对比学习模型已经展示了通过在嵌入空间中对齐表示来捕获语义相似性的令人印象深刻的能力。然而，它们的性能可能会受到训练数据的质量及其固有偏差的限制。虽然强化学习从人类反馈 (RLHF) 和直​​接偏好优化 (DPO) 已应用于生成模型以使其与人类偏好保持一致，但它们在对比学习中的应用尚未被探索。本文介绍了一种使用偏好优化 (PO) 来分解复杂概念的对比学习模型训练新方法。我们的方法系统地将模型行为与期望的偏好对齐，从而提高目标任务的性能。特别是，我们专注于增强模型对印刷攻击的鲁棒性，这种攻击在 CLIP 等对比模型中很常见。我们进一步应用我们的方法来解开性别理解并减轻性别偏见，从而对这些敏感属性提供更细致的控制。我们的实验表明，使用 PO 训练的模型优于标准对比学习技术，同时保留了处理对抗性挑战和保持其他下游任务准确性的能力。这使得我们的方法非常适合需要公平性、稳健性和与特定偏好一致的任务。我们在几个视觉语言任务上评估了我们的方法，解决了诸如排版攻击等挑战。此外，我们还探索了该模型解开性别概念和减轻性别偏见的能力，展示了我们方法的多功能性。]]></description>
      <guid>https://arxiv.org/abs/2411.08923</guid>
      <pubDate>Fri, 15 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从 DESIS 图像中检索 O$_2$-A 吸收带中太阳诱导的植物荧光</title>
      <link>https://arxiv.org/abs/2411.08925</link>
      <description><![CDATA[arXiv:2411.08925v1 公告类型：新
摘要：我们提供了第一种允许检索 30 米地面分辨率的星载 SIF 地图的方法，该地图与高质量的机载太阳诱导荧光 (SIF) 估计值具有很强的相关性（r^2=0.6）。SIF 估计可以为许多与农业管理和生理研究相关的任务提供解释信息。虽然机载平台的 SIF 产品准确且空间分辨率高，但此类产品的数据采集仍然以科学为导向，并且仅限于时间受限的活动。另一方面，星载 SIF 产品在全球范围内可用，并且通常有足够的重访时间。然而，星载 SIF 产品的空间分辨率对于农业应用来说太小了。鉴于 ESA 即将进行的 FLEX 任务，我们开发了一种在高光谱 DESIS 图像的 O$_2$-A 波段中检索 SIF 的方法，为高空间分辨率的星载 SIF 检索提供初步见解。为此，我们训练了一个基于模拟的自监督网络，该网络使用一种新颖的基于扰动的正则化器，并在额外的监督正则化大气变量预测下测试性能改进。在对相应的 HyPlant 得出的 740 nm SIF 估计值的验证研究中，我们发现我们的模型达到了 0.78 mW / nm / sr / m$^2$ 的平均绝对差异。]]></description>
      <guid>https://arxiv.org/abs/2411.08925</guid>
      <pubDate>Fri, 15 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用扩散模型进行结构化模式扩展</title>
      <link>https://arxiv.org/abs/2411.08930</link>
      <description><![CDATA[arXiv:2411.08930v1 公告类型：新
摘要：扩散模型的最新进展显著改善了材料、纹理和 3D 形状的合成。通过文本或图像调节这些模型，用户可以指导生成，从而减少创建数字资产所需的时间。在本文中，我们讨论了结构化、静止模式的合成，其中扩散模型通常不太可靠，更重要的是，不太可控。
我们的方法利用了专门针对模式域调整的扩散模型的生成能力。它使用户能够通过将部分手绘模式扩展为更大的设计，同时保留输入的结构和细节，直接控制合成。为了提高图案质量，我们使用低秩自适应 (LoRA) 对结构化模式上的图像预训练扩散模型进行微调，应用噪声滚动技术以确保可平铺性，并利用基于补丁的方法来促进大规模资产的生成。
我们通过一系列全面的实验证明了我们方法的有效性，表明它在生成直接响应用户输入的多样化、一致的模式方面优于现有模型。]]></description>
      <guid>https://arxiv.org/abs/2411.08930</guid>
      <pubDate>Fri, 15 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>对现成模型进行置信度感知去噪微调，以实现经过认证的稳健性</title>
      <link>https://arxiv.org/abs/2411.08933</link>
      <description><![CDATA[arXiv:2411.08933v1 公告类型：新
摘要：深度学习的显著进步导致了许多现成的分类器的出现，例如大型预训练模型。然而，由于它们通常是在干净的数据上训练的，因此它们仍然容易受到对抗性攻击。尽管存在这种脆弱性，但它们的卓越性能和可转移性使现成的分类器在实践中仍然很有价值，需要进一步努力以事后方式为它们提供对抗性鲁棒性。最近提出的一种方法，去噪平滑，利用分类器前面的去噪器模型来获得可证明的鲁棒性，而无需额外的训练。然而，去噪器经常会产生幻觉，即图像失去了最初分配的类别的语义，从而导致鲁棒性下降。此外，其噪声和去噪程序引入了与原始分布的显着分布偏移，导致去噪平滑框架实现次优鲁棒性。在本文中，我们介绍了一种基于置信度感知的去噪图像选择微调 (FT-CADIS)，这是一种新颖的微调方案，可增强现成分类器的认证稳健性。FT-CADIS 的灵感来自于这样的观察：现成分类器的置信度可以在去噪平滑过程中有效识别幻觉图像。基于此，我们开发了一个基于置信度感知的训练目标来处理此类幻觉图像并提高去噪图像微调的稳定性。通过这种方式，可以仅使用有利于对抗鲁棒性的图像来对分类器进行微调。我们还发现，这种微调可以通过更新分类器的一小部分参数来完成。大量实验表明，FT-CADIS 在各种基准测试中在所有 $\ell_2$ 对手半径范围内建立了去噪平滑方法中最先进的认证稳健性。]]></description>
      <guid>https://arxiv.org/abs/2411.08933</guid>
      <pubDate>Fri, 15 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用卫星和家庭图像预测莫桑比克家庭的社会经济地位</title>
      <link>https://arxiv.org/abs/2411.08934</link>
      <description><![CDATA[arXiv:2411.08934v1 公告类型：新
摘要：许多研究已经使用卫星数据预测了村庄等聚合空间单元的社会经济地位 (SEP)，但尚未探索家庭层面和其他图像来源的 SEP 预测。我们收集了莫桑比克南部半农村地区 975 个家庭的数据集，包括自我报告的资产、支出和收入 SEP 数据，以及包括卫星图像和 11 个家庭元素的地面照片调查在内的多模态图像。我们对卷积神经网络进行了微调，以从图像中提取特征向量，然后在回归分析中使用这些特征向量，使用不同类型的图像对家庭 SEP 进行建模。当使用所有图像类型的随机森林模型对基于资产的 SEP 进行建模时，发现预测性能最佳，而基于支出和收入的 SEP 的性能较低。使用 SHAP，我们观察到了具有最大正负影响的图像之间的明显差异，并确定了预测中最相关的家庭元素。最后，我们仅使用已确定的相关家庭元素拟合了一个额外的简化模型，与使用所有图像的模型相比，该模型的性能仅略低。我们的结果显示了地面家庭照片如何允许从区域级别放大到单个家庭预测，同时通过使用可解释的机器学习最大限度地减少数据收集工作量。开发的工作流程可以潜在地集成到常规家庭调查中，其中收集到的家庭图像可用于其他目的，例如精细资产表征和环境暴露评估。]]></description>
      <guid>https://arxiv.org/abs/2411.08934</guid>
      <pubDate>Fri, 15 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用深度学习根据眼角膜照片对角膜炎进行分类</title>
      <link>https://arxiv.org/abs/2411.08935</link>
      <description><![CDATA[arXiv:2411.08935v1 公告类型：新
摘要：角膜炎是一种炎症性角膜疾病，占中低收入国家 (LMIC) 视力障碍的 10%，细菌、真菌或变形虫是最常见的感染病因。虽然准确及时的诊断对于所选治疗和患者的视力结果至关重要，但由于 LMIC 实验室诊断成本高且可用性有限，诊断通常仅通过临床观察进行，尽管其准确性较低。在本研究中，我们研究并比较了不同的深度学习方法来诊断感染源：1) 三个用于感染类型预测的独立二元模型；2) 具有共享主干和三个并行分类层的多任务模型 (Multitask V1)；3) 具有共享主干和多头分类层的多任务模型 (Multitask V2)。我们使用私人巴西角膜数据集进行实证评估。我们利用 Multitask V2 取得了最佳结果，受试者工作特征曲线下面积 (AUROC) 置信区间为 0.7413-0.7740（细菌）、0.8395-0.8725（真菌）和 0.9448-0.9616（变形虫）。对患者特征对模型性能影响的统计分析表明，性别显著影响变形虫感染预测，年龄似乎影响真菌和细菌预测。]]></description>
      <guid>https://arxiv.org/abs/2411.08935</guid>
      <pubDate>Fri, 15 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>双头知识提炼：通过辅助头提高 Logits 利用率</title>
      <link>https://arxiv.org/abs/2411.08937</link>
      <description><![CDATA[arXiv:2411.08937v1 公告类型：新
摘要：传统知识蒸馏侧重于将学生的预测概率与真实标签和老师的预测概率对齐。然而，从 logit 到预测概率的过渡会掩盖某些不可或缺的信息。为了解决这个问题，直观的做法是额外引入一个 logit 级损失函数作为广泛使用的概率级损失函数的补充，以利用 logit 的潜在信息。不幸的是，我们通过经验发现，新引入的 logit 级损失与之前的概率级损失的融合会导致性能下降，甚至落后于单独使用任一损失的性能。我们将这种现象归因于分类头的崩溃，这通过我们基于神经崩溃理论的理论分析得到了验证。具体而言，两个损失函数的梯度在线性分类器中表现出矛盾，但在主干中没有表现出这种冲突。基于理论分析，我们提出了一种名为双头知识蒸馏的新方法，该方法将线性分类器划分为两个负责不同损失的分类头，从而保留两种损失对主干的有益影响，同时消除对分类头的不利影响。大量实验证明，我们的方法可以有效利用 logits 中的信息，并取得优于最先进方法的性能。]]></description>
      <guid>https://arxiv.org/abs/2411.08937</guid>
      <pubDate>Fri, 15 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用元光学进行计算机断层扫描</title>
      <link>https://arxiv.org/abs/2411.08995</link>
      <description><![CDATA[arXiv:2411.08995v1 公告类型：新
摘要：计算机视觉任务需要处理大量数据来执行图像分类、分割和特征提取。光学预处理器可以潜在地减少计算机视觉任务所需的浮点运算数量，从而实现低功耗和低延迟操作。然而，现有的光学预处理器大多是学习的，因此严重依赖于训练数据，因此缺乏普遍适用性。在本文中，我们提出了一种元光学成像仪，它实现了 Radon 变换，无需训练光学器件。通过使用同步代数重建技术，可以实现高质量图像重建，压缩率为 0.6%。通过对数字变换图像进行训练的神经网络，在实验测量的 Radon 数据集上实现了 90% 准确率的图像分类。]]></description>
      <guid>https://arxiv.org/abs/2411.08995</guid>
      <pubDate>Fri, 15 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有选择性注意的尺度对比学习用于盲图像质量评估</title>
      <link>https://arxiv.org/abs/2411.09007</link>
      <description><![CDATA[arXiv:2411.09007v1 公告类型：新
摘要：盲图像质量评估 (BIQA) 是计算机视觉中的一项基本任务，但它往往无法与人类的主观感知保持一致。最近的进展表明，多尺度评估策略很有前景，因为它们能够复制人类视觉的层次结构。然而，由于缺乏对不同图像尺度如何影响感知质量的理解，这些策略的有效性受到限制。本文解决了两个主要挑战：不同尺度上的信息存在大量冗余，以及组合这些尺度上可能质量差异很大的特征所造成的混乱。为此，提出了一种新的多尺度 BIQA 框架，即对比度约束尺度聚焦 IQA 框架 (CSFIQA)。CSFIQA 具有选择性聚焦注意机制，可最大限度地减少信息冗余并突出显示关键的质量相关信息。此外，CSFIQA 还包含一个尺度级对比学习模块，该模块配备了噪声样本匹配机制，用于识别同一图像内容在不同尺度下的质量差异。通过探索图像尺度与感知质量之间的内在关系，提出的 CSFIQA 在八个基准数据集上取得了领先的性能，例如，SRCC 值达到 0.967（CSIQ 为 0.947）和 0.905（LIVEC 为 0.876）。]]></description>
      <guid>https://arxiv.org/abs/2411.09007</guid>
      <pubDate>Fri, 15 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>弥合视觉鸿沟：利用知识适配字幕微调多模态模型</title>
      <link>https://arxiv.org/abs/2411.09018</link>
      <description><![CDATA[arXiv:2411.09018v1 公告类型：新
摘要：最近的研究越来越多地关注使用长而详细的图像字幕训练视觉语言模型 (VLM)。然而，小规模的 VLM 通常难以平衡这些字幕的丰富性与微调过程中产生幻觉内容的风险。在本文中，我们探讨了 VLM 如何适应此类字幕。为了量化字幕质量，我们提出了分解 NLI (DNLI)，这是一个评估框架，它将生成的字幕分解为单独的命题，并单独评估每个命题。这种细粒度的分析揭示了捕捉描述性细节和防止幻觉之间的关键平衡。我们的研究结果表明，仅仅降低字幕复杂性或采用标准数据管理技术并不能有效解决这个问题。为了应对这一挑战，我们引入了知识适应 (KnowAda) 微调，这是一种以数据为中心的方法，可以根据模型现有的知识和视觉理解自动调整训练数据。 KnowAda 可最大程度减少幻觉，同时保持较高的描述性。我们在多个小规模 VLM（最多 7B 个参数）和密集字幕数据集中验证了这种方法，表明 KnowAda 可有效平衡幻觉减少和描述性。我们的结果表明，KnowAda 在自动指标和人工评估方面均优于各种基准。我们将发布我们的代码和模型。]]></description>
      <guid>https://arxiv.org/abs/2411.09018</guid>
      <pubDate>Fri, 15 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CoMiX：用于 HSI-X 语义分割的可变形卷积跨模态融合</title>
      <link>https://arxiv.org/abs/2411.09023</link>
      <description><![CDATA[arXiv:2411.09023v1 公告类型：新
摘要：通过利用补充数据类型（称为 X 模态）的互补信息来改进高光谱图像 (HSI) 语义分割是有希望的，但由于成像传感器、图像内容和分辨率的差异，这一方法也具有挑战性。当前的技术难以增强特定模态和共享模态的信息，以及捕捉不同模态之间的动态交互和融合。为此，本研究提出了 CoMiX，这是一种用于 HSI-X 语义分割的具有可变形卷积 (DCN) 的非对称编码器-解码器架构。CoMiX 旨在从 HSI 和 X 数据中提取、校准和融合信息。其管道包括一个具有两个并行且相互作用的主干的编码器和一个轻量级全多层感知器 (ALL-MLP) 解码器。编码器由四个阶段组成，每个阶段都包含用于 X 模型的 2D DCN 块以适应几何变化，以及用于 HSI 的 3D DCN 块以自适应地聚合空间光谱特征。此外，每个阶段都包括一个跨模态特征增强和交换 (CMFeX) 模块和一个特征融合模块 (FFM)。CMFeX 旨在利用不同模态的空间光谱相关性来重新校准和增强模态特定和模态共享特征，同时自适应地在它们之间交换互补信息。CMFeX 的输出被输入到 FFM 中进行融合，并传递到下一阶段进行进一步的信息学习。最后，ALL-MLP 解码器集成每个 FFM 的输出以进行最终预测。大量实验表明，我们的 CoMiX 实现了卓越的性能，并且可以很好地推广到各种多模态识别任务。CoMiX 代码即将发布。]]></description>
      <guid>https://arxiv.org/abs/2411.09023</guid>
      <pubDate>Fri, 15 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于 Transformer 的 Visual Piano 转录算法</title>
      <link>https://arxiv.org/abs/2411.09037</link>
      <description><![CDATA[arXiv:2411.09037v1 公告类型：新
摘要：音乐表演的自动音乐转录 (AMT) 是音乐信息检索 (MIR) 领域的一个长期存在的问题。视觉钢琴转录 (VPT) 是 AMT 的一个多模态子问题，其重点是仅从视觉信息中提取钢琴演奏的符号表示（例如，从钢琴键盘的自上而下的视频中）。受到 Transformers 在基于音频的 AMT 方面的成功以及它们在其他计算机视觉任务中取得的最新成功的启发，在本文中，我们提出了一种基于 Transformer 的 VPT 架构。所提出的 VPT 系统将钢琴边界框检测模型与起始和音高检测模型相结合，使我们的系统在更自然的条件下表现良好，例如钢琴周围不完美的图像裁剪和略微倾斜的图像。]]></description>
      <guid>https://arxiv.org/abs/2411.09037</guid>
      <pubDate>Fri, 15 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用深度和图像数据对制造零件进行多模态物体检测</title>
      <link>https://arxiv.org/abs/2411.09062</link>
      <description><![CDATA[arXiv:2411.09062v1 公告类型：新 
摘要：制造业需要可靠的物体检测方法来精确拾取和处理各种类型的制造零件和部件。传统的物体检测方法要么仅利用来自摄像机的 2D 图像，要么利用来自激光雷达或类似 3D 传感器的 3D 数据。然而，这些传感器都有弱点和局限性。相机没有深度感知，3D 传感器通常不携带颜色信息。这些弱点会破坏工业制造系统的可靠性和稳健性。为了应对这些挑战，这项工作提出了一种结合红绿蓝 (RGB) 相机和 3D 点云传感器的多传感器系统。这两个传感器经过校准，以精确对准从两个硬件设备捕获的多模态数据。开发了一种新颖的多模态物体检测方法来处理 RGB 和深度数据。该物体检测器基于 Faster R-CNN 基线，该基线最初设计用于仅处理相机图像。结果表明，在已建立的对象检测指标上，多模态模型明显优于仅深度和仅 RGB 基线。更具体地说，与仅 RGB 基线相比，多模态模型将 mAP 提高了 13%，平均精度提高了 11.8%。与仅深度基线相比，它将 mAP 提高了 78%，平均精度提高了 57%。因此，该方法有助于为智能制造应用提供更可靠、更强大的对象检测。]]></description>
      <guid>https://arxiv.org/abs/2411.09062</guid>
      <pubDate>Fri, 15 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用纯合成数据训练的深度神经网络进行无人机检测</title>
      <link>https://arxiv.org/abs/2411.09077</link>
      <description><![CDATA[arXiv:2411.09077v1 公告类型：新
摘要：无人机检测受益于深度神经网络的改进，但与许多其他应用一样，它也受到准确训练数据可用性的困扰。合成数据提供了低成本数据生成的潜力，并且已被证明可以提高数据可用性和质量。然而，在合成数据集上训练的模型需要证明它们在现实世界数据上执行的能力，这被称为模拟到现实的可转移性问题。在这里，我们提出了一个无人机检测 Faster-RCNN 模型，该模型在纯合成数据集上训练，并转移到现实世界数据。我们发现，在 MAV-Vid（一个真实的飞行无人机数据集）上进行评估时，它的 AP_50 达到 97.0%，而使用现实世界数据训练的等效模型的 AP_50 为 97.8%。我们的结果表明，使用合成数据进行无人机检测有可能降低数据收集成本并提高标签质量。这些发现可以作为更复杂的合成无人机数据集的起点。例如，对特定场景进行逼真的再现可以降低安全关键应用（如机场无人机检测）数据集生成的风险。此外，合成数据可以实现可靠的无人机检测系统，这可能使其他领域受益，例如无人交通管理系统。代码可在 https://github.com/mazqtpopx/cranfield-synthetic-drone-detection 上找到，数据集可在 https://huggingface.co/datasets/mazqtpopx/cranfield-synthetic-drone-detection 上找到。]]></description>
      <guid>https://arxiv.org/abs/2411.09077</guid>
      <pubDate>Fri, 15 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>视觉变换器与卷积神经网络在遥感图像语义分割中的启发式比较</title>
      <link>https://arxiv.org/abs/2411.09101</link>
      <description><![CDATA[arXiv:2411.09101v1 公告类型：新
摘要：Vision Transformers (ViT) 最近在计算机视觉领域掀起了一波新研究浪潮。这些模型在图像分类和分割领域表现尤为出色。随着新架构的出现，语义和实例分割的研究也开始加速，iSAID 数据集前 20 个基准测试中有超过 80% 是基于 ViT 架构或其成功背后的注意机制。本文重点介绍了在 iSAID 上使用（或不使用）ViT 对遥感航拍图像进行语义分割的三个关键因素的启发式比较。在研究过程中观察到的实验结果受到以下目标的审查：1. 使用加权融合损失函数实现最大平均交并比 (mIoU) 分数、Dice 分数，并最小化或保持熵或类表示；2. 比较 Meta 的 MaskFormer（基于 ViT 的语义分割模型）上的迁移学习与通用 UNet 卷积神经网络 (CNN) 上的迁移学习，以 mIoU、Dice 分数、训练效率和推理时间进行判断；3. 我们得到什么，又失去什么？即，将这两个模型与当前最先进的分割模型进行比较。我们表明，与迁移学习 ViT 相比，使用新颖的组合加权损失函数可显著提高 CNN 模型的性能。此实现的代码可在 \url{https://github.com/ashimdahal/ViT-vs-CNN-ImageSegmentation} 上找到。]]></description>
      <guid>https://arxiv.org/abs/2411.09101</guid>
      <pubDate>Fri, 15 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>