<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CV 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Fri, 20 Sep 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>ScaleFlow++：从视频中稳健而准确地估计 3D 运动</title>
      <link>https://arxiv.org/abs/2409.12202</link>
      <description><![CDATA[arXiv:2409.12202v1 公告类型：新
摘要：感知和理解3D运动是自动驾驶、机器人和运动预测等领域的核心技术。本文提出了一种易于推广的3D运动感知方法ScaleFlow++。仅使用一对RGB图像，ScaleFlow++就可以稳健地估计光流和深度运动（MID）。大多数现有方法直接从两个RGB帧或光流中回归MID，导致结果不准确且不稳定。我们的关键见解是跨尺度匹配，它通过在不同尺度的图像对中匹配对象来提取深度运动线索。与以前的方法不同，ScaleFlow++将光流和MID估计集成到统一的架构中，基于特征匹配端到端估计光流和MID。此外，我们还提出了全局初始化网络、全局迭代优化器和混合训练管道等模块，以整合全局运动信息，减少迭代次数，并防止训练期间过度拟合。在 KITTI 上，ScaleFlow++ 实现了最佳的单目场景流估计性能，将 SF-all 从 6.21 降低到 5.79。MID 的评估甚至超越了基于 RGBD 的方法。此外，ScaleFlow++ 在刚性和非刚性场景中都实现了令人惊叹的零样本泛化性能。代码可在 \url{https://github.com/HanLingsgjk/CSCV} 获得。]]></description>
      <guid>https://arxiv.org/abs/2409.12202</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>半导体材料科学中的通用人工智能 (AGI) 火花：生成式人工智能辅助电子显微图分析的下一个前沿的早期探索</title>
      <link>https://arxiv.org/abs/2409.12244</link>
      <description><![CDATA[arXiv:2409.12244v1 公告类型：新
摘要：由于纳米材料结构的复杂性，使用电子显微照片表征材料对自动标记提出了重大挑战。为了解决这个问题，我们引入了一种全自动端到端流程，利用生成式人工智能的最新进展。它旨在分析​​和理解半导体材料的微观结构，其有效性可与人类专家相媲美，有助于实现纳米材料识别中的通用人工智能 (AGI)。我们的方法利用大型多模态模型 (LMM)，例如 GPT-4V，以及文本到图像模型，例如 DALLE-3。我们集成了 GPT-4 引导的视觉问答 (VQA) 方法来分析纳米材料图像，通过 DALLE-3 生成合成纳米材料图像，并在 GPT-4V 中采用上下文学习和少量提示来准确识别纳米材料。我们的方法通过提高纳米材料识别的精度和优化高通量筛选流程超越了传统技术。]]></description>
      <guid>https://arxiv.org/abs/2409.12244</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>GCA-SUN：用于无样本计数的门控上下文感知 Swin-UNet</title>
      <link>https://arxiv.org/abs/2409.12249</link>
      <description><![CDATA[arXiv:2409.12249v1 公告类型：新
摘要：无样本计数旨在对感兴趣的对象进行计数，而无需对对象或样本进行密集注释。为了实现这一目标，我们提出了门控上下文感知 Swin-UNet (GCA-SUN)，将输入图像直接映射到可数对象的密度图。具体而言，在编码器中设计了一个门控上下文感知调制模块，通过门控机制抑制不相关的对象或背景，并通过自相似矩阵利用感兴趣对象的注意支持。门控策略也被纳入瓶颈网络和解码器，以突出显示与感兴趣对象最相关的特征。通过明确利用可数对象之间的注意支持并通过门控机制消除不相关的特征，提出的 GCA-SUN 无需依赖预定义的类别或样本即可关注和计数感兴趣的对象。 FSC-147 和 CARPK 数据集上的实验结果表明 GCA-SUN 优于最先进的方法。]]></description>
      <guid>https://arxiv.org/abs/2409.12249</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>WiLoR：端到端 3D 野外手部定位与重建</title>
      <link>https://arxiv.org/abs/2409.12259</link>
      <description><![CDATA[arXiv:2409.12259v1 公告类型：新
摘要：近年来，3D 手势估计方法因其在人机交互、虚拟现实和机器人技术中的广泛应用而备受关注。相比之下，手部检测流程存在明显差距，对构建有效的现实世界多手重建系统提出了重大挑战。在这项工作中，我们提出了一种数据驱动的流程，用于在野外进行高效的多手重建。所提出的流程由两个部分组成：实时全卷积手部定位和基于高保真变压器的 3D 手部重建模型。为了解决以前方法的局限性并构建一个强大而稳定的检测网络，我们引入了一个大规模数据集，其中包含超过 200 万张具有各种光照、照明和遮挡条件的野外手部图像。我们的方法在流行的 2D 和 3D 基准测试中的效率和准确性都优于以前的方法。最后，我们展示了我们的流程的有效性，无需使用任何时间分量即可从单目视频中实现流畅的 3D 手部跟踪。代码、模型和数据集可在 https://rolpotamias.github.io/WiLoR 上找到。]]></description>
      <guid>https://arxiv.org/abs/2409.12259</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>自闭症检测中 fMRI 时间序列转换器的自监督预训练任务</title>
      <link>https://arxiv.org/abs/2409.12304</link>
      <description><![CDATA[arXiv:2409.12304v1 公告类型：新
摘要：自闭症谱系障碍 (ASD) 是一种神经发育疾病，包含多种症状和损伤程度，这使得诊断和治疗具有挑战性。功能性磁共振成像 (fMRI) 已广泛用于研究 ASD 中的大脑活动，并且机器学习方法已应用于分析静息状态 fMRI (rs-fMRI) 数据。然而，很少有研究探索最近基于 rs-fMRI 数据的 Transformer 模型。鉴于 Transformer 模型在捕获序列数据中的长距离依赖关系方面的优势，我们开发了一个基于 Transformer 的自监督框架，可直接分析时间序列 fMRI 数据而无需计算功能连接。为了解决小数据集中的过度拟合问题并提高模型性能，我们提出了自监督的预训练任务来重建随机掩蔽的 fMRI 时间序列数据，研究各种掩蔽策略的影响。然后，我们针对 ASD 分类任务对模型进行微调，并使用两个公共数据集和具有不同数量训练数据的五重交叉验证对其进行评估。实验表明，随机屏蔽整个 ROI 比在预训练步骤中随机屏蔽时间点的模型性能更好，与在不同级别的训练数据可用性上从头开始训练的 Transformer 模型相比，AUC 平均提高了 10.8%，受试者准确率平均提高了 9.3%。我们的代码可在 GitHub 上找到。]]></description>
      <guid>https://arxiv.org/abs/2409.12304</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>一项关于不同人群中商业远程身份验证技术的性能和公平性的大规模研究</title>
      <link>https://arxiv.org/abs/2409.12318</link>
      <description><![CDATA[arXiv:2409.12318v1 公告类型：新
摘要：随着越来越多的交易类型转移到线上，远程验证某人身份的需求也日益增加。远程身份验证 (RIdV) 技术应运而生，以满足这一需求。RIdV 解决方案通常使用智能设备通过将面部自拍与证件上的面部照片进行比较来验证身份证件（如驾照）。最近的研究重点是确保生物识别系统在各个人口群体中公平运作。本研究评估了五种商业 RIdV 解决方案在 3,991 名测试对象中在年龄、性别、种族/民族和肤色方面的公平性。本文采用统计方法来辨别不同人口群体的 RIdV 结果是否具有统计上的可区分性。其中两种 RIdV 解决方案在所有人口统计数据中都是公平的，而两种 RIdV 解决方案至少有一个人口统计数据不公平。例如，一项技术的结果的假阴性率为 10.5% +/- 4.5%，其对每个人口统计类别的表现都在误差范围内，因此是公平的。其他技术要么整体表现不佳，要么表现不公平。对于其中一项技术，黑人/非裔美国人 (B/AA) 种族以及肤色较深的参与者 (Monk 量表 7/8/9/10) 经历了更高的错误拒绝。最后，一项技术对亚裔美国人和太平洋岛民 (AAPI) 人口表现出更有利但不公平的表现。这项研究证实，有必要对跨人口统计群体的产品进行评估，以充分了解远程身份验证技术的性能。]]></description>
      <guid>https://arxiv.org/abs/2409.12318</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型是强大的视听语音识别学习者</title>
      <link>https://arxiv.org/abs/2409.12319</link>
      <description><![CDATA[arXiv:2409.12319v1 公告类型：新
摘要：多模态大型语言模型 (MLLM) 因其强大的多模态理解能力而成为研究的焦点。例如，在音频和语音领域，只需将音频标记（用音频编码器计算）和文本标记连接起来，LLM 即可配备（自动）语音识别 (ASR) 功能，以实现最先进的结果。相反，像视觉和视听语音识别 (VSR/AVSR) 这样的任务也利用了噪声不变的唇部运动信息，却很少或根本没有受到关注。为了弥补这一差距，我们提出了 Llama-AVSR，这是一种具有强大视听语音识别能力的新型 MLLM。它利用预先训练的音频和视频编码器来生成特定于模态的标记，这些标记与文本标记一起由预先训练的 LLM（例如 Llama3.1-8B）处理，以自回归方式产生结果响应。Llama-AVSR 需要少量可训练参数，因为只有特定于模态的投影仪和 LoRA 模块经过训练，而多模态编码器和 LLM 保持冻结。我们在最大的公共 AVSR 基准 LRS3 上评估了我们提出的方法，并在 ASR 和 AVSR 任务中取得了新的最先进结果，WER 分别为 0.81% 和 0.77%。为了支持我们的结果，我们研究了支撑 Llama-AVSR 有效性的关键因素：预训练编码器和 LLM 的选择、LoRA 模块的有效集成以及通过模态感知压缩率获得的最佳性能效率权衡。]]></description>
      <guid>https://arxiv.org/abs/2409.12319</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于 3D 高斯溅射连体散焦的深度估计</title>
      <link>https://arxiv.org/abs/2409.12323</link>
      <description><![CDATA[arXiv:2409.12323v1 公告类型：新
摘要：深度估计是 3D 几何中的一项基本任务。虽然立体深度估计可以通过三角测量方法实现，但对于需要整合全局和局部信息的单目方法来说，这并不那么简单。离焦深度 (DFD) 方法利用相机镜头模型和参数从模糊图像中恢复深度信息，并且已被证明效果良好。然而，这些方法依赖于全焦 (AIF) 图像进行深度估计，这在实际应用中几乎是不可能获得的。为了解决这个问题，我们提出了一个基于 3D 高斯分布和孪生网络的自监督框架。通过学习焦点堆栈中同一场景在不同焦距下的模糊程度，该框架从单个离焦图像预测离焦图和弥散圆 (CoC)，并使用离焦图作为 DepthNet 的输入进行单目深度估计。 3D 高斯 splatting 模型使用预测的 CoC 渲染散焦图像，这些图像与真实散焦图像之间的差异为 Siamese Defocus 自监督网络提供了额外的监督信号。该框架已在人工合成和真实模糊数据集上得到验证。后续的定量和可视化实验表明，我们提出的框架作为 DFD 方法非常有效。]]></description>
      <guid>https://arxiv.org/abs/2409.12323</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ReFu：无样本 3D 类增量学习的递归融合</title>
      <link>https://arxiv.org/abs/2409.12326</link>
      <description><![CDATA[arXiv:2409.12326v1 公告类型：新
摘要：我们引入了一种新颖的递归融合模型，称为 ReFu，旨在整合点云和网格，实现无样本 3D 类增量学习，其中模型学习新的 3D 类，同时保留以前学习过的知识。与现有的要么依赖存储历史数据来减轻遗忘，要么专注于单一数据模态的方法不同，ReFu 消除了对样本存储的需求，同时利用了点云和网格的互补优势。为了实现这一点，我们引入了一种递归方法，通过更新正则化的自相关矩阵来不断积累知识。此外，我们提出了一个融合模块，该模块具有一个点云引导的网格注意层，可以学习两种模态之间的相关性。该机制有效地整合了点云和网格特征，从而实现了更稳健、更稳定的持续学习。在各种数据集上的实验表明，我们提出的框架在 3D 类增量学习中的表现优于现有方法。项目页面：https://arlo397.github.io/ReFu/]]></description>
      <guid>https://arxiv.org/abs/2409.12326</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过机器视觉和无人机技术推进农业黄瓜病害检测</title>
      <link>https://arxiv.org/abs/2409.12350</link>
      <description><![CDATA[arXiv:2409.12350v1 公告类型：新
摘要：本研究利用机器视觉和无人机技术提出了一种诊断农业黄瓜病害的独特方法。这项研究的基础是精心策划的真实田间条件下获取的高光谱照片数据集。与早期的数据集不同，这项研究涵盖了多种疾病类型，可以进行精确的早期检测。经过大量数据增强后，该模型在区分八种独特的黄瓜病害方面实现了 87.5% 的出色准确率。无人机技术与高分辨率图像的结合改善了疾病评估。这一发展对改善作物管理、降低劳动力成本和提高农业生产力具有巨大的潜力。这项研究实现了疾病检测的自动化，代表着朝着更高效和可持续的农业未来迈出了重要一步。]]></description>
      <guid>https://arxiv.org/abs/2409.12350</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过课程训练方法最小化对抗性互信息来增强 3D 机器人视觉鲁棒性</title>
      <link>https://arxiv.org/abs/2409.12379</link>
      <description><![CDATA[arXiv:2409.12379v1 公告类型：新
摘要：对抗性攻击通过精心设计的小扰动来利用模型决策边界中的漏洞，从而导致严重的错误预测。在 3D 视觉中，数据的高维性和稀疏性极大地扩展了攻击面，使得 3D 视觉对于安全关键型机器人来说特别容易受到攻击。为了增强 3D 视觉的对抗性鲁棒性，我们提出了一个训练目标，该目标同时最小化对抗性扰动下的预测损失和互信息 (MI)，以控制错误预测误差的上限。与需要对对抗性样本进行明确搜索和训练的传统方法相比，这种方法简化了对抗性示例的处理。然而，最小化预测损失与最小化 MI 相冲突，导致鲁棒性降低和灾难性遗忘。为了解决这个问题，我们在训练设置中整合了课程顾问，逐步引入对抗性目标来平衡训练并防止模型在流程早期被困难的案例压垮。顾问还通过熵正则化器鼓励对不同的 MI 示例进行训练来增强鲁棒性。我们使用 PointNet、DGCNN、SECOND 和 PointTransformers 在 ModelNet40 和 KITTI 上评估了我们的方法，在 ModelNet40 上实现了 2-5% 的准确率提升，在对象检测中实现了 5-10% 的 mAP 改进。我们的代码可在 https://github.com/nstrndrbi/Mine-N-Learn 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2409.12379</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>透过面具看：通过去遮挡蒸馏实现蒙面人脸识别</title>
      <link>https://arxiv.org/abs/2409.12385</link>
      <description><![CDATA[arXiv:2409.12385v1 公告类型：新
摘要：当今许多现实世界的应用，如视频监控和城市治理，都需要解决蒙面人脸识别问题，其中用不同的蒙面人脸替换内容往往会导致外观不完整和表示模糊，从而导致准确率急剧下降。受最近非模态感知进展的启发，我们提出使用端到端去遮挡蒸馏框架将非模态补全机制迁移到蒙面人脸识别任务中，该框架由两个模块组成。\textit{去遮挡}模块应用生成对抗网络执行人脸补全，恢复蒙面人脸下的内容并消除外观模糊性。\textit{蒸馏}模块以预先训练的通用人脸识别模型作为老师，并将其知识转移到使用大量在线合成人脸对训练学生完成人脸识别。特别是，老师知识以多个顺序的实例之间的结构关系表示，这作为后验正则化来实现自适应。通过这种方式，知识可以被充分提炼和迁移以识别蒙面人脸。在合成和真实数据集上的实验证明了该方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2409.12385</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多模态多标签皮肤病变分类的新视角</title>
      <link>https://arxiv.org/abs/2409.12390</link>
      <description><![CDATA[arXiv:2409.12390v1 公告类型：新
摘要：基于深度学习的皮肤病计算机辅助诊断 (CAD) 方法的有效性依赖于分析多种数据模式（即临床+皮肤镜图像和患者元数据）并解决多标签分类的挑战。当前的方法倾向于依赖有限的多模态技术，并将多标签问题视为多个多类问题，忽略了与不平衡学习和多标签相关性相关的问题。本文介绍了创新的皮肤病变分类器，利用基于多模态多标签 TransFormer 的模型 (SkinM2Former)。对于多模态分析，我们引入了三模态交叉注意变换器 (TMCT)，它将三种图像和元数据模态融合在变换器编码器的各个特征级别。对于多标签分类，我们引入了多头注意力 (MHA) 模块来学习多标签相关性，并辅以处理多标签和不平衡学习问题的优化。SkinM2Former 在公共 Derm7pt 数据集上实现了 77.27% 的平均准确率和 77.85% 的平均诊断准确率，优于最先进的 (SOTA) 方法。]]></description>
      <guid>https://arxiv.org/abs/2409.12390</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ITPatch：一种针对交通标志识别的隐形触发式物理对抗补丁</title>
      <link>https://arxiv.org/abs/2409.12394</link>
      <description><![CDATA[arXiv:2409.12394v1 公告类型：新
摘要：物理对抗补丁已成为现实世界中导致交通标志识别 (TSR) 系统分类错误的主要对抗攻击。然而，现有的对抗补丁隐蔽性较差，一旦部署就会​​不加区分地攻击所有车辆。在本文中，我们引入了一种隐形触发物理对抗补丁 (ITPatch)，它采用了一种新颖的攻击媒介，即荧光墨水，以推进最先进的技术。它将精心设计的荧光扰动应用于目标标志，攻击者随后可以使用不可见的紫外线触发荧光效果，导致 TSR 系统对标志进行错误分类并可能导致交通事故。我们进行了全面的评估以调查 ITPatch 的有效性，结果显示其在低光照条件下的成功率为 98.31%。此外，我们的攻击成功绕过了五种流行的防御措施，成功率达到 96.72%。]]></description>
      <guid>https://arxiv.org/abs/2409.12394</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LMT-Net：车道模型变换网络，用于根据稀疏车辆观测数据进行自动高清测绘</title>
      <link>https://arxiv.org/abs/2409.12409</link>
      <description><![CDATA[arXiv:2409.12409v1 公告类型：新
摘要：在自动驾驶中，高清 (HD) 地图提供了完整的车道模型，不受传感器范围和遮挡的限制。然而，高清地图的生成和维护涉及定期数据收集和人工注释，限制了可扩展性。为了解决这个问题，我们研究了车道模型生成的自动化以及使用稀疏车辆观测而不是密集传感器测量。对于我们的方法，预处理步骤通过对齐和聚合观察到的车道边界来生成折线。对齐的驱动轨迹用作预测由左边界点和右边界点定义的车道对的起点。我们提出了车道模型变换器网络 (LMT-Net)，这是一种编码器-解码器神经网络架构，可执行折线编码并预测车道对及其连通性。车道图是通过使用预测的车道对作为节点和预测的车道连通性作为边来形成的。我们在内部数据集上评估了 LMT-Net 的性能，该数据集由多个车辆观测值以及作为地面实况 (GT) 的人工注释组成。评估结果令人鼓舞，并且与高速公路和非高速公路运营设计域 (ODD) 上实施的基线相比表现出卓越的性能。]]></description>
      <guid>https://arxiv.org/abs/2409.12409</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>