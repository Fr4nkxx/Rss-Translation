<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CV 在 arXiv.org 上的更新</title>
    <link>http://rss.arxiv.org/rss/cs.CV</link>
    <description>cs.CV 在 arXiv.org 电子印刷档案上更新。</description>
    <lastBuildDate>Mon, 27 Jan 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>DEFEND：用于预防烟草成瘾的大规模 1M 数据集和基础模型</title>
      <link>https://arxiv.org/abs/2501.13950</link>
      <description><![CDATA[arXiv:2501.13950v1 公告类型：新
摘要：虽然烟草广告以前所未有的速度创新，但传统的监控方法仍然停滞不前，尤其是在社交媒体背景下。缺乏大规模、全面的数据集和复杂的监测系统，导致行业进步与公共卫生监督之间的差距越来越大。本文通过介绍 Tobacco-1M（一个包含 100 万张烟草产品图像的综合数据集，具有涵盖 75 个产品类别的分层标签）和 DEFEND（一种用于理解烟草产品的新基础模型）来解决这一关键挑战。我们的方法集成了用于丰富多模态表示学习的特征增强模块、用于详细特征区分的局部-全局视觉一致性机制和用于精确产品表征的增强图像-文本对齐策略。实验结果证明了 DEFEND 的卓越性能，在产品分类中实现了 83.1% 的准确率，在视觉问答任务中实现了 73.8% 的准确率，远远优于现有方法。此外，该模型表现出强大的零样本学习能力，对新产品类别的准确率达到 45.6%。这项工作为监管机构和公共卫生研究人员提供了强大的工具来监测新兴烟草产品和营销策略，有可能彻底改变烟草控制和公共卫生监测的方法。]]></description>
      <guid>https://arxiv.org/abs/2501.13950</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于加速工业锥形束 X 射线计算机断层扫描的快速、可扩展且稳健的基于深度学习的迭代重建框架</title>
      <link>https://arxiv.org/abs/2501.13961</link>
      <description><![CDATA[arXiv:2501.13961v1 公告类型：新
摘要：具有大型探测器的锥形束 X 射线计算机断层扫描 (XCT) 和相应的大规模 3D 重建在各个行业的材料和零件的微米级表征中起着关键作用。在这项工作中，我们提出了一种基于深度神经网络的新型迭代算法，该算法将伪影减少训练的 CNN 作为先验模型与自动正则化参数选择相结合，专门针对大规模工业锥形束 XCT 数据进行定制。我们的方法只需几次迭代即可实现高质量的 3D 重建，即使对于非常密集的厚金属部件也是如此 - 这传统上对工业 CT 图像构成挑战。此外，我们展示了我们的方法对在不同扫描条件下获得的分布外扫描的通用性。我们的方法有效地处理了显着的噪声和条纹伪影，超越了在相同数据上训练的最先进的监督学习方法。]]></description>
      <guid>https://arxiv.org/abs/2501.13961</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用激光雷达数据程序生成 3D 玉米植株结构</title>
      <link>https://arxiv.org/abs/2501.13963</link>
      <description><![CDATA[arXiv:2501.13963v1 公告类型：新
摘要：本研究引入了一个强大的框架，用于从 LiDAR 点云数据生成玉米 (Zea mays) 植物的程序化 3D 模型，为传统的基于田间的表型分析提供了一种可扩展的替代方案。我们的框架利用非均匀有理 B 样条 (NURBS) 曲面来模拟玉米植株的叶子，结合粒子群优化 (PSO) 对曲面进行初始近似，并结合可微分编程框架对曲面进行精确细化以拟合点云数据。在第一个优化阶段，PSO 通过优化其控制点、将曲面与 LiDAR 数据对齐并提供可靠的细化起点来生成近似 NURBS 曲面。第二阶段使用可微分编程框架 NURBS-Diff，通过细化曲面几何形状和捕捉复杂的叶片细节来提高初始拟合的准确性。我们的结果表明，虽然 PSO 建立了稳健的初始拟合，但可微分 NURBS 的集成显著提高了重建表面的整体质量和保真度。这种分层优化策略能够对不同基因型的玉米叶片进行精确的 3D 重建，从而有助于随后提取叶序等复杂性状。我们在田间种植的玉米植株的不同基因型上展示了我们的方法。我们所有的代码都是开源的，以使这些表型分析方法更加大众化。]]></description>
      <guid>https://arxiv.org/abs/2501.13963</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>推进对 AR 生成场景的理解和评估：当视觉语言模型大放异彩时</title>
      <link>https://arxiv.org/abs/2501.13964</link>
      <description><![CDATA[arXiv:2501.13964v1 公告类型：新 
摘要：增强现实 (AR) 通过集成虚拟内容增强了现实世界，但确保 AR 体验的质量、可用性和安全性面临着重大挑战。视觉语言模型 (VLM) 能否为 AR 生成场景的自动评估提供解决方案？视觉语言模型 (VLM) 能否为 AR 生成场景的自动评估提供解决方案？在本研究中，我们评估了三种最先进的商业 VLM——GPT、Gemini 和 Claude——在识别和描述 AR 场景方面的能力。为此，我们使用 DiverseAR，这是第一个专门设计用于评估 VLM 在各种 AR 场景复杂性中分析虚拟内容的能力的 AR 数据集。我们的研究结果表明，VLM 通常能够感知和描述 AR 场景，在感知方面实现高达 93% 的真实阳性率 (TPR)，在描述方面实现高达 71% 的真实阳性率 (TPR)。虽然它们擅长识别明显的虚拟物体，例如发光的苹果，但在面对无缝集成的内容（例如具有逼真阴影的虚拟锅）时却举步维艰。我们的结果突出了 VLM 在理解 AR 场景方面的优势和局限性。我们确定了影响 VLM 性能的关键因素，包括虚拟内容放置、渲染质量和物理合理性。这项研究强调了 VLM 作为评估 AR 体验质量工具的潜力。]]></description>
      <guid>https://arxiv.org/abs/2501.13964</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>FedDAG：面向通用医学图像分析的联合域对抗生成</title>
      <link>https://arxiv.org/abs/2501.13967</link>
      <description><![CDATA[arXiv:2501.13967v1 公告类型：新
摘要：联合域泛化旨在从多个源域训练全局模型并确保其对未见过的目标域的泛化能力。{由于目标域具有未知的域偏移，尝试通过源域来近似这些差距可能是提高模型泛化能力的关键。}现有的工作主要侧重于共享和重组局部域特定属性，以增加数据多样性并模拟潜在的域偏移。{然而，这些方法可能不够充分，因为只有局部属性重组很难触及全局数据的分布不均。}在本文中，我们提出了一个简单而有效的框架，称为联合域对抗生成（FedDAG）。 {它旨在通过对抗性地生成不同于本地和全局源域的新域来模拟域转移并提高模型泛化能力。} 具体而言，它通过最大化原始图像和生成图像之间的实例级特征差异来生成新颖风格的图像，并通过最小化它们的特征差异来训练可泛化的任务模型。{此外，我们观察到 FedDAG 可能会对本地模型带来不同的性能改进。这可能是由于客户端之间固有的数据隔离和异构性，加剧了它们对全局模型的泛化贡献的不平衡。} {忽略这种不平衡会导致全局模型的泛化能力不理想，从而进一步限制新域生成过程。} 因此，为了缓解这种不平衡，FedDAG 使用锐度概念来评估客户端模型泛化贡献，在客户端内和跨客户端级别分层聚合本地模型。{在四个医学基准上进行的大量实验证明了 FedDAG 能够增强联邦医疗场景中的泛化能力。}]]></description>
      <guid>https://arxiv.org/abs/2501.13967</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过反事实图像生成增强合成图像检索的三重态合成</title>
      <link>https://arxiv.org/abs/2501.13968</link>
      <description><![CDATA[arXiv:2501.13968v1 公告类型：新
摘要：组合图像检索 (CIR) 提供了一种管理和访问大规模视觉数据的有效方法。CIR 模型的构建利用由参考图像、描述所需更改的修改文本和反映这些更改的目标图像组成的三元组。为了有效地训练 CIR 模型，需要大量手动注释来构建高质量的训练数据集，这可能既耗时又费力。为了解决这个问题，本文提出了一种利用反事实图像生成的新型三元组合成方法。通过反事实图像生成控制视觉特征修改，我们的方法可以自动生成不同的训练三元组，而无需任何人工干预。这种方法有助于创建更大、更具表现力的数据集，从而提高 CIR 模型的性能。]]></description>
      <guid>https://arxiv.org/abs/2501.13968</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>InsTex：室内场景风格化纹理合成</title>
      <link>https://arxiv.org/abs/2501.13969</link>
      <description><![CDATA[arXiv:2501.13969v1 公告类型：新
摘要：为 3D 场景生成高质量纹理对于室内设计、游戏和增强/虚拟现实 (AR/VR) 中的应用至关重要。尽管 3D 生成模型的最新进展增强了内容创作，但在实现广泛泛化和保持跨多个视点的风格一致性方面仍然存在重大挑战。当前的方法，例如适用于 3D 纹理的 2D 扩散模型，存在处理时间长和视觉伪影的问题，而由 3D 数据驱动的方法通常无法有效概括。为了克服这些挑战，我们引入了 InsTex，这是一种两阶段架构，旨在为 3D 室内场景生成高质量、风格一致的纹理。InsTex 在粗到细的管道中使用深度到图像扩散先验，首先使用预先训练的 2D 扩散模型生成多视图图像，然后细化纹理以保持一致性。我们的方法支持文本和视觉提示，在视觉质量和定量指标方面取得了最先进的结果，并证明了其在各种 3D 纹理应用中的有效性。]]></description>
      <guid>https://arxiv.org/abs/2501.13969</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>GS-LiDAR：利用全景高斯溅射生成逼真的 LiDAR 点云</title>
      <link>https://arxiv.org/abs/2501.13971</link>
      <description><![CDATA[arXiv:2501.13971v1 公告类型：新 
摘要：LiDAR 新视图合成 (NVS) 已成为 LiDAR 模拟中的一项新任务，它从新视角提供有价值的模拟点云数据，以辅助自动驾驶系统。然而，现有的 LiDAR NVS 方法通常依赖神经辐射场 (NeRF) 作为其 3D 表示，这在训练和渲染中都会产生大量的计算成本。此外，NeRF 及其变体是为对称场景设计的，使其不适合驾驶场景。为了应对这些挑战，我们提出了 GS-LiDAR，这是一种使用全景高斯溅射生成逼真的 LiDAR 点云的新型框架。我们的方法采用具有周期性振动特性的 2D 高斯基元，允许在驾驶场景中精确地几何重建静态和动态元素。我们进一步介绍了一种由全景 LiDAR 监督指导的具有显式射线溅射相交的新型全景渲染技术。通过将强度和光线下降球谐函数 (SH) 系数合并到高斯基元中，我们增强了渲染点云的真实感。在 KITTI-360 和 nuScenes 上进行的大量实验证明了我们的方法在定量指标、视觉质量以及训练和渲染效率方面的优势。]]></description>
      <guid>https://arxiv.org/abs/2501.13971</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>允许不完整轨迹输入的时空图网络用于行人轨迹预测</title>
      <link>https://arxiv.org/abs/2501.13973</link>
      <description><![CDATA[arXiv:2501.13973v1 公告类型：新
摘要：行人轨迹预测是行人环境下移动机器人导航研究中的重要课题。大多数行人轨迹预测算法都要求输入的历史轨迹完整。如果行人在过去的任何一帧中都无法观察到，那么它的历史轨迹就不完整，算法将无法预测其未来轨迹。为了解决这一限制，我们提出了STGN-IT，这是一个允许不完整轨迹输入的时空图网络，它可以预测具有不完整历史轨迹的行人的未来轨迹。STGN-IT使用时空图和附加编码方法来表示行人的历史轨迹和观察状态。此外，STGN-IT引入了环境中可能影响未来轨迹的静态障碍物作为节点，以进一步提高预测精度。在时空图的构建中还应用了聚类算法。在公共数据集上的实验表明，STGN-IT 在这些指标上的表现优于最先进的算法。]]></description>
      <guid>https://arxiv.org/abs/2501.13973</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>3DGS$^2$：近二阶收敛 3D 高斯溅射</title>
      <link>https://arxiv.org/abs/2501.13975</link>
      <description><![CDATA[arXiv:2501.13975v1 公告类型：新
摘要：3D 高斯分层 (3DGS) 已成为新型视图合成和 3D 重建的主流解决方案。通过使用一组高斯核明确编码 3D 场景，3DGS 以卓越的效率实现了高质量的渲染。作为一种基于学习的方法，3DGS 训练已采用标准随机梯度下降 (SGD) 方法处理，该方法最多提供线性收敛。因此，即使使用 GPU 加速，训练也通常需要数十分钟。本文介绍了一种 (近) 二阶收敛的 3DGS 训练算法，利用其独特的特性。我们的方法受到两个关键观察的启发。首先，高斯核的属性对图像空间损失有独立的贡献，这支持孤立和局部优化算法。我们利用这一点，在各个内核属性级别上拆分优化，为每个参数组分析构建小型牛顿系统，并在 GPU 线程上高效地解决这些系统。这样可以在不依赖全局 Hessian 的情况下实现每个训练图像的牛顿式收敛。其次，内核在输入图像之间表现出稀疏和结构化的耦合。此属性使我们能够有效利用空间信息来减轻随​​机训练期间的超调。我们的方法比基于 GPU 的标准 3DGS 训练收敛速度快一个数量级，所需的迭代次数减少了 $10\times$ 以上，同时保持或超越了基于 SGD 的 3DGS 重建的质量。]]></description>
      <guid>https://arxiv.org/abs/2501.13975</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>增强型 PEC-YOLO 用于检测电力线工人是否佩戴不当安全装备</title>
      <link>https://arxiv.org/abs/2501.13981</link>
      <description><![CDATA[arXiv:2501.13981v1 公告类型：新
摘要：针对复杂电力线环境下安全装备使用不当导致目标遮挡、方差大等问题，本文提出了一种增强型PEC-YOLO目标检测算法。该方法将深度感知与多尺度特征融合相结合，利用PConv和EMA注意机制提高特征提取效率，降低模型复杂度。将CPCA注意机制融入SPPF模块，提高模型聚焦关键信息的能力，提高检测精度，尤其是在具有挑战性的条件下。此外，BiFPN颈部结构的引入优化了低级和高级特征的利用率，通过自适应融合和上下文感知机制增强了特征表示。实验结果表明，与YOLOv8s相比，提出的PEC-YOLO在检测精度上提高了2.7%，同时模型参数减少了42.58%。在相同条件下，PEC-YOLO 的检测速度优于其他模型，满足了建筑工地安全装置检测的严格精度要求。本研究有助于开发高效、准确的智能监测系统，确保危险环境中的工人安全。]]></description>
      <guid>https://arxiv.org/abs/2501.13981</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 CLIP 进行基于属性的图像分类视觉重编程</title>
      <link>https://arxiv.org/abs/2501.13982</link>
      <description><![CDATA[arXiv:2501.13982v1 公告类型：新
摘要：视觉重编程 (VR) 通过在输入中添加可训练的噪声模式，将预训练的视觉模型重新用于下游图像分类任务。当应用于视觉语言模型（例如 CLIP）时，现有的 VR 方法遵循视觉模型（例如 ResNet、ViT）中使用的相同流程，其中将真实类别标签插入固定文本模板以指导 VR 模式的优化。然而，这种基于标签的方法忽略了 CLIP 可以利用的丰富信息和多样化的属性引导文本表示，这可能导致样本分类错误。在本文中，我们为 CLIP 提出了基于属性的视觉重编程 (AttrVR)，利用描述性属性 (DesAttrs) 和独特属性 (DistAttrs)，分别表示不同类别的共同和独特特征描述。此外，由于同一类图像在 VR 之后可能会反映不同的属性，AttrVR 使用每个图像样本的 $k$ 近邻 DesAttrs 和 DistAttrs 迭代细化模式，从而实现更动态和针对样本的优化。从理论上讲，AttrVR 可以减少类内方差并增加类间分离。从经验上讲，它在基于 ViT 和基于 ResNet 的 CLIP 的 12 个下游任务中都取得了优异的表现。AttrVR 的成功促进了 VR 从单峰视觉模型更有效地集成到视觉语言模型中。我们的代码可在 https://github.com/tmlr-group/AttrVR 获得。]]></description>
      <guid>https://arxiv.org/abs/2501.13982</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CGI：使用示例图像识别条件生成模型</title>
      <link>https://arxiv.org/abs/2501.13991</link>
      <description><![CDATA[arXiv:2501.13991v1 公告类型：新
摘要：生成模型最近取得了令人瞩目的表现，因此模型中心应运而生。现有的模型中心通常假设基本的文本匹配足以搜索模型。然而，实际上，由于抽象不同且模型中心中的模型数量众多，用户不容易查看模型描述和示例图像，选择最符合其需求的模型。因此，有必要明智地描述模型功能，以便未来的用户可以有效地搜索最适合其需求的模型。解决这个问题的努力仍然有限。在本文中，我们提出了条件生成模型识别（CGI），旨在提供一种有效的方法来使用用户提供的示例图像来识别最合适的模型，而不是要求用户手动查看带有示例图像的大量模型。为了解决这个问题，我们提出了基于提示的模型识别（PMI），它可以充分描述模型功能并精确地匹配需求和规范。为了评估 PMI 方法并促进相关研究，我们提供了一个包含 65 个模型和 9100 个识别任务的基准。大量实验和人工评估结果表明 PMI 是有效的。例如，当提供四张示例图像时，92% 的模型被正确识别，并且 FID 得分明显更高。]]></description>
      <guid>https://arxiv.org/abs/2501.13991</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CSAOT：用于主动对象跟踪的协作多智能体系统</title>
      <link>https://arxiv.org/abs/2501.13994</link>
      <description><![CDATA[arXiv:2501.13994v1 公告类型：新
摘要：对象跟踪对于许多计算机视觉应用至关重要，例如自动导航、监视和机器人技术。与依靠静态摄像机视点在连续帧中检测和跟踪对象的被动对象跟踪 (POT) 不同，主动对象跟踪 (AOT) 需要控制器代理主动调整其视点以在复杂环境中与移动目标保持视觉接触。现有的 AOT 解决方案主要是基于单代理的，由于信息收集和处理能力有限，它们在动态和复杂场景中表现不佳，通常导致决策不理想。缓解这些限制需要开发一个多代理系统，其中不同的代理扮演不同的角色并协作以增强动态和复杂环境中的学习和稳健性。虽然 AOT 存在一些多代理方法，但它们通常依赖于外部辅助代理，这需要额外的设备，因此成本高昂。相比之下，我们引入了主动对象跟踪协作系统 (CSAOT)，这种方法利用多智能体深度强化学习 (MADRL) 和混合专家 (MoE) 框架，使多个智能体能够在单个设备上运行，从而提高跟踪性能并降低成本。我们的方法增强了对遮挡和快速运动的鲁棒性，同时优化了摄像机运动以延长跟踪时间。我们在具有动态和静止障碍物的各种交互式地图上验证了 CSAOT 的有效性。]]></description>
      <guid>https://arxiv.org/abs/2501.13994</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>将波斯唇读技术融入 Surena-V 人形机器人，实现人机交互</title>
      <link>https://arxiv.org/abs/2501.13996</link>
      <description><![CDATA[arXiv:2501.13996v1 公告类型：新
摘要：唇读对于社交环境中的机器人至关重要，可以提高它们理解人类交流的能力。这项技能使它们能够在拥挤的环境中更轻松地交流，尤其是在护理和客户服务角色中。本研究生成了波斯唇读数据集，将波斯唇读技术集成到 Surena-V 人形机器人中，以提高其语音识别能力。探索了两种互补的方法，一种是使用面部标志跟踪的间接方法，另一种是利用卷积神经网络 (CNN) 和长短期记忆 (LSTM) 网络的直接方法。间接方法侧重于跟踪关键面部标志，尤其是嘴唇周围，以推断动作，而直接方法处理原始视频数据以进行动作和语音识别。性能最佳的模型 LSTM 实现了 89% 的准确率，并已成功应用于 Surena-V 机器人以实现实时人机交互。该研究强调了这些方法的有效性，特别是在口头交流有限的环境中。]]></description>
      <guid>https://arxiv.org/abs/2501.13996</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>